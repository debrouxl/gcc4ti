diff -Naur gcc-4.1-20051216.orig/config.guess gcc-4.1-20051216-src/config.guess
--- gcc-4.1-20051216.orig/config.guess	2005-11-24 13:49:42.000000000 +0100
+++ gcc-4.1-20051216-src/config.guess	2005-12-18 22:33:47.000000000 +0100
@@ -770,11 +770,11 @@
 	echo ${UNAME_MACHINE}-pc-cygwin
 	exit ;;
     i*:MINGW*:*)
-	echo ${UNAME_MACHINE}-pc-mingw32
+	echo i386-pc-mingw32
 	exit ;;
     i*:windows32*:*)
     	# uname -m includes "-pc" on this system.
-    	echo ${UNAME_MACHINE}-mingw32
+    	echo i386-pc-mingw32
 	exit ;;
     i*:PW*:*)
 	echo ${UNAME_MACHINE}-pc-pw32
diff -Naur gcc-4.1-20051216.orig/gcc/attribs.c gcc-4.1-20051216-src/gcc/attribs.c
--- gcc-4.1-20051216.orig/gcc/attribs.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/attribs.c	2005-12-18 22:24:27.000000000 +0100
@@ -131,7 +131,11 @@
    information, in the form of a bitwise OR of flags in enum attribute_flags
    from tree.h.  Depending on these flags, some attributes may be
    returned to be applied at a later stage (for example, to apply
-   a decl attribute to the declaration rather than to its type).  */
+   a decl attribute to the declaration rather than to its type).  If
+   ATTR_FLAG_BUILT_IN is not set and *NODE is a DECL, then also consider
+   whether there might be some default attributes to apply to this DECL;
+   if so, decl_attributes will be called recursively with those attributes
+   and ATTR_FLAG_BUILT_IN set.  */
 
 tree
 decl_attributes (tree *node, tree attributes, int flags)
@@ -144,6 +148,10 @@
 
   targetm.insert_attributes (*node, &attributes);
 
+  if (DECL_P (*node) && TREE_CODE (*node) == FUNCTION_DECL
+      && !(flags & (int) ATTR_FLAG_BUILT_IN))
+    (*lang_hooks.insert_default_attributes) (*node);
+
   for (a = attributes; a; a = TREE_CHAIN (a))
     {
       tree name = TREE_PURPOSE (a);
diff -Naur gcc-4.1-20051216.orig/gcc/builtin-attrs.def gcc-4.1-20051216-src/gcc/builtin-attrs.def
--- gcc-4.1-20051216.orig/gcc/builtin-attrs.def	2005-06-27 14:17:39.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/builtin-attrs.def	2005-12-18 22:24:27.000000000 +0100
@@ -169,6 +169,10 @@
 DEF_FORMAT_ATTRIBUTE(SCANF,1,1_2)
 DEF_FORMAT_ATTRIBUTE(SCANF,2,2_0)
 DEF_FORMAT_ATTRIBUTE(SCANF,2,2_3)
+DEF_FORMAT_ATTRIBUTE(SCANF,3,3_0)
+DEF_FORMAT_ATTRIBUTE(SCANF,3,3_4)
+DEF_FORMAT_ATTRIBUTE(SCANF,4,4_0)
+DEF_FORMAT_ATTRIBUTE(SCANF,4,4_5)
 DEF_FORMAT_ATTRIBUTE(STRFTIME,3,3_0)
 DEF_FORMAT_ATTRIBUTE(STRFMON,3,3_4)
 #undef DEF_FORMAT_ATTRIBUTE
@@ -181,3 +185,25 @@
 DEF_FORMAT_ARG_ATTRIBUTE(2)
 #undef DEF_FORMAT_ARG_ATTRIBUTE
 
+/* (TIGCC 20040219, 20050205) Default attributes. */
+#define DEF_FN_ATTR_IDENT(NAME, ATTRS, PREDICATE)	\
+  DEF_ATTR_IDENT (ATTR_ ## NAME, #NAME)	\
+  DEF_FN_ATTR (ATTR_ ## NAME, ATTRS, PREDICATE)
+#define DEF_C89_ATTR(NAME, ATTRS) DEF_FN_ATTR_IDENT (NAME, ATTRS, flag_hosted)
+DEF_C89_ATTR (printf, ATTR_FORMAT_PRINTF_1_2)
+DEF_C89_ATTR (fprintf, ATTR_FORMAT_PRINTF_2_3)
+DEF_C89_ATTR (sprintf, ATTR_FORMAT_PRINTF_2_3)
+DEF_C89_ATTR (scanf, ATTR_FORMAT_SCANF_1_2)
+DEF_C89_ATTR (fscanf, ATTR_FORMAT_SCANF_2_3)
+DEF_C89_ATTR (sscanf, ATTR_FORMAT_SCANF_2_3)
+DEF_C89_ATTR (vprintf, ATTR_FORMAT_PRINTF_1_0)
+DEF_C89_ATTR (vfprintf, ATTR_FORMAT_PRINTF_2_0)
+DEF_C89_ATTR (vsprintf, ATTR_FORMAT_PRINTF_2_0)
+DEF_C89_ATTR (vcbprintf, ATTR_FORMAT_PRINTF_3_0)
+DEF_C89_ATTR (cbprintf, ATTR_FORMAT_PRINTF_3_4)
+DEF_C89_ATTR (vcbscanf, ATTR_FORMAT_SCANF_4_0)
+DEF_C89_ATTR (cbscanf, ATTR_FORMAT_SCANF_4_5)
+DEF_C89_ATTR (vscanf, ATTR_FORMAT_SCANF_1_0)
+DEF_C89_ATTR (vfscanf, ATTR_FORMAT_SCANF_2_0)
+DEF_C89_ATTR (vsscanf, ATTR_FORMAT_SCANF_2_0)
+
diff -Naur gcc-4.1-20051216.orig/gcc/builtins.c gcc-4.1-20051216-src/gcc/builtins.c
--- gcc-4.1-20051216.orig/gcc/builtins.c	2005-12-01 03:32:58.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/builtins.c	2005-12-18 22:24:28.000000000 +0100
@@ -47,6 +47,7 @@
 #include "langhooks.h"
 #include "basic-block.h"
 #include "tree-mudflap.h"
+#include "ggc.h"
 
 #ifndef PAD_VARARGS_DOWN
 #define PAD_VARARGS_DOWN BYTES_BIG_ENDIAN
@@ -76,7 +77,9 @@
 static rtx c_readstr (const char *, enum machine_mode);
 static int target_char_cast (tree, char *);
 static rtx get_memory_rtx (tree, tree);
+#if 0
 static tree build_string_literal (int, const char *);
+#endif /* 0 */
 static int apply_args_size (void);
 static int apply_result_size (void);
 #if defined (HAVE_untyped_call) || defined (HAVE_untyped_return)
@@ -1177,7 +1180,13 @@
 	size += GET_MODE_SIZE (Pmode);
 
       for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
-	if (FUNCTION_ARG_REGNO_P (regno))
+	if (0 /*FUNCTION_ARG_REGNO_P (regno)*/)
+	/* (TIGCC) Do NOT use register passing for __builtin_apply since:
+	           1. It doesn't work: ALL registers are POSSIBLE registers for
+	                               function parameters, so this code uses up all
+	                               registers.
+	           2. It significantly increases code size.
+	           3. The default calling convention is stkparm anyway. */
 	  {
 	    mode = reg_raw_mode[regno];
 
@@ -1630,6 +1639,7 @@
 tree
 mathfn_built_in (tree type, enum built_in_function fn)
 {
+#if 0
   enum built_in_function fcode, fcodef, fcodel;
 
   switch (fn)
@@ -1724,9 +1734,11 @@
   else if (TYPE_MAIN_VARIANT (type) == long_double_type_node)
     return implicit_built_in_decls[fcodel];
   else
+#endif /* 0 */
     return 0;
 }
 
+#if 0
 /* If errno must be maintained, expand the RTL to check if the result,
    TARGET, of a built-in function call, EXP, is NaN, and if so set
    errno to EDOM.  */
@@ -2837,6 +2849,7 @@
     }
   return 0;
 }
+#endif /* 0 */
 
 /* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
    bytes from constant string DATA + OFFSET and return it as target
@@ -2930,6 +2943,7 @@
     }
 }
 
+#if 0
 /* Expand a call to the mempcpy builtin, with arguments in ARGLIST.
    Return 0 if we failed; the caller should emit a normal call,
    otherwise try to get the result in TARGET, if convenient (and in
@@ -3353,6 +3367,7 @@
     }
   return 0;
 }
+#endif /* 0 */
 
 /* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
    bytes from constant string DATA + OFFSET and return it as target
@@ -3500,6 +3515,7 @@
     }
 }
 
+#if 0
 /* Expand expression EXP, which is a call to the bzero builtin.  Return 0
    if we failed the caller should emit a normal call.  */
 
@@ -4031,6 +4047,7 @@
     }
   return 0;
 }
+#endif /* 0 */
 
 /* Expand a call to __builtin_saveregs, generating the result in TARGET,
    if that's convenient.  */
@@ -4584,6 +4601,7 @@
   return convert_to_mode (target_mode, target, 0);
 }
 
+#if 0
 /* If the string passed to fputs is a constant and is one character
    long, we attempt to transform this call into __builtin_fputc().  */
 
@@ -4600,6 +4618,7 @@
     }
   return 0;
 }
+#endif /* 0 */
 
 /* Expand a call to __builtin_expect.  We return our argument and emit a
    NOTE_INSN_EXPECTED_VALUE note.  This is the expansion of __builtin_expect in
@@ -4772,6 +4791,35 @@
   emit_barrier ();
 }
 
+/* (TIGCC 20050206) Implement ER_throw. */
+static void
+expand_builtin_ER_throw (tree arglist)
+{
+  tree arg;
+  char buffer[40];
+
+  if (!validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    {
+      error ("invalid argument list for ER_throw");
+      return;
+    }
+
+  arg = TREE_VALUE (arglist);
+
+  if (TREE_CODE (arg) != INTEGER_CST)
+    {
+      error ("argument to ER_throw must be a constant");
+      return;
+    }
+
+  sprintf (buffer, ".word _A_LINE+%d", (int) TREE_INT_CST_LOW (arg));
+
+  emit_insn (gen_rtx_ASM_INPUT (VOIDmode, ggc_strdup (buffer)));
+
+  emit_barrier ();
+}
+
+#if 0
 /* Expand a call to fabs, fabsf or fabsl with arguments ARGLIST.
    Return 0 if a normal call should be emitted rather than expanding
    the function inline.  If convenient, the result should be placed
@@ -5140,6 +5188,7 @@
 
   return 0;
 }
+#endif /* 0 */
 
 /* Expand a call to either the entry or exit function profiler.  */
 
@@ -5244,6 +5293,7 @@
   return tramp;
 }
 
+#if 0
 /* Expand a call to the built-in signbit, signbitf or signbitl function.
    Return NULL_RTX if a normal call should be emitted rather than expanding
    the function in-line.  EXP is the expression that is a call to the builtin
@@ -5579,6 +5629,7 @@
   expand_builtin_synchronize ();
   emit_move_insn (mem, val);
 }
+#endif /* 0 */
 
 /* Expand an expression EXP that calls a built-in function,
    with result going to TARGET if that's convenient
@@ -5638,6 +5689,7 @@
 
   switch (fcode)
     {
+#if 0
     case BUILT_IN_FABS:
     case BUILT_IN_FABSF:
     case BUILT_IN_FABSL:
@@ -5806,6 +5858,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
     case BUILT_IN_APPLY_ARGS:
       return expand_builtin_apply_args ();
@@ -5942,6 +5995,7 @@
 	return target;
       break;
 
+#if 0
     case BUILT_IN_STRLEN:
       target = expand_builtin_strlen (arglist, target, target_mode);
       if (target)
@@ -6015,6 +6069,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
     case BUILT_IN_MEMCPY:
       target = expand_builtin_memcpy (exp, target, mode);
@@ -6022,6 +6077,7 @@
 	return target;
       break;
 
+#if 0
     case BUILT_IN_MEMPCPY:
       target = expand_builtin_mempcpy (arglist, TREE_TYPE (exp), target, mode, /*endp=*/ 1);
       if (target)
@@ -6040,6 +6096,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
     case BUILT_IN_MEMSET:
       target = expand_builtin_memset (arglist, target, mode, exp);
@@ -6047,6 +6104,7 @@
 	return target;
       break;
 
+#if 0
     case BUILT_IN_BZERO:
       target = expand_builtin_bzero (exp);
       if (target)
@@ -6071,6 +6129,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
     case BUILT_IN_SETJMP:
       target = expand_builtin_setjmp (arglist, target);
@@ -6124,6 +6183,7 @@
       expand_builtin_trap ();
       return const0_rtx;
 
+#if 0
     case BUILT_IN_PRINTF:
       target = expand_builtin_printf (exp, target, mode, false);
       if (target)
@@ -6172,6 +6232,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
       /* Various hooks for the DWARF 2 __throw routine.  */
     case BUILT_IN_UNWIND_INIT:
@@ -6224,6 +6285,7 @@
     case BUILT_IN_ADJUST_TRAMPOLINE:
       return expand_builtin_adjust_trampoline (arglist);
 
+#if 0
     case BUILT_IN_FORK:
     case BUILT_IN_EXECL:
     case BUILT_IN_EXECV:
@@ -6459,6 +6521,7 @@
 enum built_in_function
 builtin_mathfn_code (tree t)
 {
+#if 0
   tree fndecl, arglist, parmlist;
   tree argtype, parmtype;
 
@@ -6513,13 +6576,16 @@
 	    return END_BUILTINS;
 	}
       else
+#endif /* 0 */
 	return END_BUILTINS;
+#if 0
 
       arglist = TREE_CHAIN (arglist);
     }
 
   /* Variable-length argument list.  */
   return DECL_FUNCTION_CODE (fndecl);
+#endif /* 0 */
 }
 
 /* Fold a call to __builtin_constant_p, if we know it will evaluate to a
@@ -6619,6 +6685,7 @@
 			type_to_class (TREE_TYPE (TREE_VALUE (arglist))));
 }
 
+#if 0
 /* Fold a call to __builtin_strlen.  */
 
 static tree
@@ -7320,6 +7387,7 @@
 
   return fold_trunc_transparent_mathfn (fndecl, arglist);
 }
+#endif /* 0 */
 
 /* Fold function call to builtin lround, lroundf or lroundl (or the
    corresponding long long versions) and other rounding functions.
@@ -7493,6 +7561,7 @@
   return NULL_TREE;
 }
 
+#if 0
 /* Return true if EXPR is the real constant contained in VALUE.  */
 
 static bool
@@ -7883,6 +7952,7 @@
 
   return 0;
 }
+#endif /* 0 */
 
 /* Fold function call to builtin memcpy.  Return
    NULL_TREE if no simplification can be made.  */
@@ -7911,6 +7981,7 @@
   return 0;
 }
 
+#if 0
 /* Fold function call to builtin mempcpy.  Return
    NULL_TREE if no simplification can be made.  */
 
@@ -8644,6 +8715,7 @@
   return fold_build1 (TRUTH_NOT_EXPR, type,
 		      fold_build2 (code, type, arg0, arg1));
 }
+#endif /* 0 */
 
 /* Used by constant folding to simplify calls to builtin functions.  EXP is
    the CALL_EXPR of a call to a builtin function.  IGNORE is true if the
@@ -8662,6 +8734,7 @@
   fcode = DECL_FUNCTION_CODE (fndecl);
   switch (fcode)
     {
+#if 0
     case BUILT_IN_FPUTS:
       return fold_builtin_fputs (arglist, ignore, false, NULL_TREE);
 
@@ -8712,6 +8785,7 @@
 
     case BUILT_IN_SPRINTF:
       return fold_builtin_sprintf (arglist, ignore);
+#endif /* 0 */
 
     case BUILT_IN_CONSTANT_P:
       {
@@ -8733,6 +8807,7 @@
     case BUILT_IN_CLASSIFY_TYPE:
       return fold_builtin_classify_type (arglist);
 
+#if 0
     case BUILT_IN_STRLEN:
       return fold_builtin_strlen (arglist);
 
@@ -8944,6 +9019,7 @@
     case BUILT_IN_MEMCPY:
       return fold_builtin_memcpy (fndecl, arglist);
 
+#if 0
     case BUILT_IN_MEMPCPY:
       return fold_builtin_mempcpy (arglist, type, /*endp=*/1);
 
@@ -9173,6 +9249,7 @@
     return false;
 }
 
+#if 0
 /* Simplify a call to the strstr builtin.
 
    Return 0 if no simplification was possible, otherwise return the
@@ -9711,6 +9788,7 @@
      hence there's no need to cast the result to integer_type_node.  */
   return build_function_call_expr (fn, arglist);
 }
+#endif /* 0 */
 
 /* Fold the new_arg's arguments (ARGLIST). Returns true if there was an error
    produced.  False otherwise.  This is done so that we don't output the error
@@ -9780,6 +9858,7 @@
 }
 
 
+#if 0
 /* Simplify a call to the sprintf builtin.
 
    Return 0 if no simplification was possible, otherwise return the
@@ -11062,3 +11141,5 @@
     }
   return true;
 }
+#endif /* 0 */
+
diff -Naur gcc-4.1-20051216.orig/gcc/builtins.c.orig gcc-4.1-20051216-src/gcc/builtins.c.orig
--- gcc-4.1-20051216.orig/gcc/builtins.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/builtins.c.orig	2005-12-01 03:32:58.000000000 +0100
@@ -0,0 +1,11064 @@
+/* Expand builtin functions.
+   Copyright (C) 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
+   2000, 2001, 2002, 2003, 2004, 2005 Free Software Foundation, Inc.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 2, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING.  If not, write to the Free
+Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA
+02110-1301, USA.  */
+
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "tm.h"
+#include "machmode.h"
+#include "real.h"
+#include "rtl.h"
+#include "tree.h"
+#include "tree-gimple.h"
+#include "flags.h"
+#include "regs.h"
+#include "hard-reg-set.h"
+#include "except.h"
+#include "function.h"
+#include "insn-config.h"
+#include "expr.h"
+#include "optabs.h"
+#include "libfuncs.h"
+#include "recog.h"
+#include "output.h"
+#include "typeclass.h"
+#include "toplev.h"
+#include "predict.h"
+#include "tm_p.h"
+#include "target.h"
+#include "langhooks.h"
+#include "basic-block.h"
+#include "tree-mudflap.h"
+
+#ifndef PAD_VARARGS_DOWN
+#define PAD_VARARGS_DOWN BYTES_BIG_ENDIAN
+#endif
+
+/* Define the names of the builtin function types and codes.  */
+const char *const built_in_class_names[4]
+  = {"NOT_BUILT_IN", "BUILT_IN_FRONTEND", "BUILT_IN_MD", "BUILT_IN_NORMAL"};
+
+#define DEF_BUILTIN(X, N, C, T, LT, B, F, NA, AT, IM, COND) #X,
+const char * built_in_names[(int) END_BUILTINS] =
+{
+#include "builtins.def"
+};
+#undef DEF_BUILTIN
+
+/* Setup an array of _DECL trees, make sure each element is
+   initialized to NULL_TREE.  */
+tree built_in_decls[(int) END_BUILTINS];
+/* Declarations used when constructing the builtin implicitly in the compiler.
+   It may be NULL_TREE when this is invalid (for instance runtime is not
+   required to implement the function call in all cases).  */
+tree implicit_built_in_decls[(int) END_BUILTINS];
+
+static int get_pointer_alignment (tree, unsigned int);
+static const char *c_getstr (tree);
+static rtx c_readstr (const char *, enum machine_mode);
+static int target_char_cast (tree, char *);
+static rtx get_memory_rtx (tree, tree);
+static tree build_string_literal (int, const char *);
+static int apply_args_size (void);
+static int apply_result_size (void);
+#if defined (HAVE_untyped_call) || defined (HAVE_untyped_return)
+static rtx result_vector (int, rtx);
+#endif
+static rtx expand_builtin_setjmp (tree, rtx);
+static void expand_builtin_update_setjmp_buf (rtx);
+static void expand_builtin_prefetch (tree);
+static rtx expand_builtin_apply_args (void);
+static rtx expand_builtin_apply_args_1 (void);
+static rtx expand_builtin_apply (rtx, rtx, rtx);
+static void expand_builtin_return (rtx);
+static enum type_class type_to_class (tree);
+static rtx expand_builtin_classify_type (tree);
+static void expand_errno_check (tree, rtx);
+static rtx expand_builtin_mathfn (tree, rtx, rtx);
+static rtx expand_builtin_mathfn_2 (tree, rtx, rtx);
+static rtx expand_builtin_mathfn_3 (tree, rtx, rtx);
+static rtx expand_builtin_int_roundingfn (tree, rtx, rtx);
+static rtx expand_builtin_args_info (tree);
+static rtx expand_builtin_next_arg (void);
+static rtx expand_builtin_va_start (tree);
+static rtx expand_builtin_va_end (tree);
+static rtx expand_builtin_va_copy (tree);
+static rtx expand_builtin_memcmp (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strcmp (tree, rtx, enum machine_mode);
+static rtx expand_builtin_strncmp (tree, rtx, enum machine_mode);
+static rtx builtin_memcpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+static rtx expand_builtin_strcat (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strncat (tree, rtx, enum machine_mode);
+static rtx expand_builtin_strspn (tree, rtx, enum machine_mode);
+static rtx expand_builtin_strcspn (tree, rtx, enum machine_mode);
+static rtx expand_builtin_memcpy (tree, rtx, enum machine_mode);
+static rtx expand_builtin_mempcpy (tree, tree, rtx, enum machine_mode, int);
+static rtx expand_builtin_memmove (tree, tree, rtx, enum machine_mode, tree);
+static rtx expand_builtin_bcopy (tree);
+static rtx expand_builtin_strcpy (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_stpcpy (tree, rtx, enum machine_mode);
+static rtx builtin_strncpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+static rtx expand_builtin_strncpy (tree, rtx, enum machine_mode);
+static rtx builtin_memset_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+static rtx builtin_memset_gen_str (void *, HOST_WIDE_INT, enum machine_mode);
+static rtx expand_builtin_memset (tree, rtx, enum machine_mode, tree);
+static rtx expand_builtin_bzero (tree);
+static rtx expand_builtin_strlen (tree, rtx, enum machine_mode);
+static rtx expand_builtin_strstr (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strpbrk (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strchr (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strrchr (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_alloca (tree, rtx);
+static rtx expand_builtin_unop (enum machine_mode, tree, rtx, rtx, optab);
+static rtx expand_builtin_frame_address (tree, tree);
+static rtx expand_builtin_fputs (tree, rtx, bool);
+static rtx expand_builtin_printf (tree, rtx, enum machine_mode, bool);
+static rtx expand_builtin_fprintf (tree, rtx, enum machine_mode, bool);
+static rtx expand_builtin_sprintf (tree, rtx, enum machine_mode);
+static tree stabilize_va_list (tree, int);
+static rtx expand_builtin_expect (tree, rtx);
+static tree fold_builtin_constant_p (tree);
+static tree fold_builtin_classify_type (tree);
+static tree fold_builtin_strlen (tree);
+static tree fold_builtin_inf (tree, int);
+static tree fold_builtin_nan (tree, tree, int);
+static int validate_arglist (tree, ...);
+static bool integer_valued_real_p (tree);
+static tree fold_trunc_transparent_mathfn (tree, tree);
+static bool readonly_data_expr (tree);
+static rtx expand_builtin_fabs (tree, rtx, rtx);
+static rtx expand_builtin_signbit (tree, rtx);
+static tree fold_builtin_cabs (tree, tree);
+static tree fold_builtin_sqrt (tree, tree);
+static tree fold_builtin_cbrt (tree, tree);
+static tree fold_builtin_pow (tree, tree, tree);
+static tree fold_builtin_powi (tree, tree, tree);
+static tree fold_builtin_sin (tree);
+static tree fold_builtin_cos (tree, tree, tree);
+static tree fold_builtin_tan (tree);
+static tree fold_builtin_atan (tree, tree);
+static tree fold_builtin_trunc (tree, tree);
+static tree fold_builtin_floor (tree, tree);
+static tree fold_builtin_ceil (tree, tree);
+static tree fold_builtin_round (tree, tree);
+static tree fold_builtin_int_roundingfn (tree, tree);
+static tree fold_builtin_bitop (tree, tree);
+static tree fold_builtin_memcpy (tree, tree);
+static tree fold_builtin_mempcpy (tree, tree, int);
+static tree fold_builtin_memmove (tree, tree);
+static tree fold_builtin_strchr (tree, tree);
+static tree fold_builtin_memcmp (tree);
+static tree fold_builtin_strcmp (tree);
+static tree fold_builtin_strncmp (tree);
+static tree fold_builtin_signbit (tree, tree);
+static tree fold_builtin_copysign (tree, tree, tree);
+static tree fold_builtin_isascii (tree);
+static tree fold_builtin_toascii (tree);
+static tree fold_builtin_isdigit (tree);
+static tree fold_builtin_fabs (tree, tree);
+static tree fold_builtin_abs (tree, tree);
+static tree fold_builtin_unordered_cmp (tree, tree, enum tree_code,
+					enum tree_code);
+static tree fold_builtin_1 (tree, tree, bool);
+
+static tree fold_builtin_strpbrk (tree, tree);
+static tree fold_builtin_strstr (tree, tree);
+static tree fold_builtin_strrchr (tree, tree);
+static tree fold_builtin_strcat (tree);
+static tree fold_builtin_strncat (tree);
+static tree fold_builtin_strspn (tree);
+static tree fold_builtin_strcspn (tree);
+static tree fold_builtin_sprintf (tree, int);
+
+static rtx expand_builtin_object_size (tree);
+static rtx expand_builtin_memory_chk (tree, rtx, enum machine_mode,
+				      enum built_in_function);
+static void maybe_emit_chk_warning (tree, enum built_in_function);
+static void maybe_emit_sprintf_chk_warning (tree, enum built_in_function);
+static tree fold_builtin_object_size (tree);
+static tree fold_builtin_strcat_chk (tree, tree);
+static tree fold_builtin_strncat_chk (tree, tree);
+static tree fold_builtin_sprintf_chk (tree, enum built_in_function);
+static tree fold_builtin_printf (tree, tree, bool, enum built_in_function);
+static tree fold_builtin_fprintf (tree, tree, bool, enum built_in_function);
+static bool init_target_chars (void);
+
+static unsigned HOST_WIDE_INT target_newline;
+static unsigned HOST_WIDE_INT target_percent;
+static unsigned HOST_WIDE_INT target_c;
+static unsigned HOST_WIDE_INT target_s;
+static char target_percent_c[3];
+static char target_percent_s[3];
+static char target_percent_s_newline[4];
+
+/* Return true if NODE should be considered for inline expansion regardless
+   of the optimization level.  This means whenever a function is invoked with
+   its "internal" name, which normally contains the prefix "__builtin".  */
+
+static bool called_as_built_in (tree node)
+{
+  const char *name = IDENTIFIER_POINTER (DECL_NAME (node));
+  if (strncmp (name, "__builtin_", 10) == 0)
+    return true;
+  if (strncmp (name, "__sync_", 7) == 0)
+    return true;
+  return false;
+}
+
+/* Return the alignment in bits of EXP, a pointer valued expression.
+   But don't return more than MAX_ALIGN no matter what.
+   The alignment returned is, by default, the alignment of the thing that
+   EXP points to.  If it is not a POINTER_TYPE, 0 is returned.
+
+   Otherwise, look at the expression to see if we can do better, i.e., if the
+   expression is actually pointing at an object whose alignment is tighter.  */
+
+static int
+get_pointer_alignment (tree exp, unsigned int max_align)
+{
+  unsigned int align, inner;
+
+  if (! POINTER_TYPE_P (TREE_TYPE (exp)))
+    return 0;
+
+  align = TYPE_ALIGN (TREE_TYPE (TREE_TYPE (exp)));
+  align = MIN (align, max_align);
+
+  while (1)
+    {
+      switch (TREE_CODE (exp))
+	{
+	case NOP_EXPR:
+	case CONVERT_EXPR:
+	case NON_LVALUE_EXPR:
+	  exp = TREE_OPERAND (exp, 0);
+	  if (! POINTER_TYPE_P (TREE_TYPE (exp)))
+	    return align;
+
+	  inner = TYPE_ALIGN (TREE_TYPE (TREE_TYPE (exp)));
+	  align = MIN (inner, max_align);
+	  break;
+
+	case PLUS_EXPR:
+	  /* If sum of pointer + int, restrict our maximum alignment to that
+	     imposed by the integer.  If not, we can't do any better than
+	     ALIGN.  */
+	  if (! host_integerp (TREE_OPERAND (exp, 1), 1))
+	    return align;
+
+	  while (((tree_low_cst (TREE_OPERAND (exp, 1), 1))
+		  & (max_align / BITS_PER_UNIT - 1))
+		 != 0)
+	    max_align >>= 1;
+
+	  exp = TREE_OPERAND (exp, 0);
+	  break;
+
+	case ADDR_EXPR:
+	  /* See what we are pointing at and look at its alignment.  */
+	  exp = TREE_OPERAND (exp, 0);
+	  if (TREE_CODE (exp) == FUNCTION_DECL)
+	    align = FUNCTION_BOUNDARY;
+	  else if (DECL_P (exp))
+	    align = DECL_ALIGN (exp);
+#ifdef CONSTANT_ALIGNMENT
+	  else if (CONSTANT_CLASS_P (exp))
+	    align = CONSTANT_ALIGNMENT (exp, align);
+#endif
+	  return MIN (align, max_align);
+
+	default:
+	  return align;
+	}
+    }
+}
+
+/* Compute the length of a C string.  TREE_STRING_LENGTH is not the right
+   way, because it could contain a zero byte in the middle.
+   TREE_STRING_LENGTH is the size of the character array, not the string.
+
+   ONLY_VALUE should be nonzero if the result is not going to be emitted
+   into the instruction stream and zero if it is going to be expanded.
+   E.g. with i++ ? "foo" : "bar", if ONLY_VALUE is nonzero, constant 3
+   is returned, otherwise NULL, since
+   len = c_strlen (src, 1); if (len) expand_expr (len, ...); would not
+   evaluate the side-effects.
+
+   The value returned is of type `ssizetype'.
+
+   Unfortunately, string_constant can't access the values of const char
+   arrays with initializers, so neither can we do so here.  */
+
+tree
+c_strlen (tree src, int only_value)
+{
+  tree offset_node;
+  HOST_WIDE_INT offset;
+  int max;
+  const char *ptr;
+
+  STRIP_NOPS (src);
+  if (TREE_CODE (src) == COND_EXPR
+      && (only_value || !TREE_SIDE_EFFECTS (TREE_OPERAND (src, 0))))
+    {
+      tree len1, len2;
+
+      len1 = c_strlen (TREE_OPERAND (src, 1), only_value);
+      len2 = c_strlen (TREE_OPERAND (src, 2), only_value);
+      if (tree_int_cst_equal (len1, len2))
+	return len1;
+    }
+
+  if (TREE_CODE (src) == COMPOUND_EXPR
+      && (only_value || !TREE_SIDE_EFFECTS (TREE_OPERAND (src, 0))))
+    return c_strlen (TREE_OPERAND (src, 1), only_value);
+
+  src = string_constant (src, &offset_node);
+  if (src == 0)
+    return 0;
+
+  max = TREE_STRING_LENGTH (src) - 1;
+  ptr = TREE_STRING_POINTER (src);
+
+  if (offset_node && TREE_CODE (offset_node) != INTEGER_CST)
+    {
+      /* If the string has an internal zero byte (e.g., "foo\0bar"), we can't
+	 compute the offset to the following null if we don't know where to
+	 start searching for it.  */
+      int i;
+
+      for (i = 0; i < max; i++)
+	if (ptr[i] == 0)
+	  return 0;
+
+      /* We don't know the starting offset, but we do know that the string
+	 has no internal zero bytes.  We can assume that the offset falls
+	 within the bounds of the string; otherwise, the programmer deserves
+	 what he gets.  Subtract the offset from the length of the string,
+	 and return that.  This would perhaps not be valid if we were dealing
+	 with named arrays in addition to literal string constants.  */
+
+      return size_diffop (size_int (max), offset_node);
+    }
+
+  /* We have a known offset into the string.  Start searching there for
+     a null character if we can represent it as a single HOST_WIDE_INT.  */
+  if (offset_node == 0)
+    offset = 0;
+  else if (! host_integerp (offset_node, 0))
+    offset = -1;
+  else
+    offset = tree_low_cst (offset_node, 0);
+
+  /* If the offset is known to be out of bounds, warn, and call strlen at
+     runtime.  */
+  if (offset < 0 || offset > max)
+    {
+      warning (0, "offset outside bounds of constant string");
+      return 0;
+    }
+
+  /* Use strlen to search for the first zero byte.  Since any strings
+     constructed with build_string will have nulls appended, we win even
+     if we get handed something like (char[4])"abcd".
+
+     Since OFFSET is our starting index into the string, no further
+     calculation is needed.  */
+  return ssize_int (strlen (ptr + offset));
+}
+
+/* Return a char pointer for a C string if it is a string constant
+   or sum of string constant and integer constant.  */
+
+static const char *
+c_getstr (tree src)
+{
+  tree offset_node;
+
+  src = string_constant (src, &offset_node);
+  if (src == 0)
+    return 0;
+
+  if (offset_node == 0)
+    return TREE_STRING_POINTER (src);
+  else if (!host_integerp (offset_node, 1)
+	   || compare_tree_int (offset_node, TREE_STRING_LENGTH (src) - 1) > 0)
+    return 0;
+
+  return TREE_STRING_POINTER (src) + tree_low_cst (offset_node, 1);
+}
+
+/* Return a CONST_INT or CONST_DOUBLE corresponding to target reading
+   GET_MODE_BITSIZE (MODE) bits from string constant STR.  */
+
+static rtx
+c_readstr (const char *str, enum machine_mode mode)
+{
+  HOST_WIDE_INT c[2];
+  HOST_WIDE_INT ch;
+  unsigned int i, j;
+
+  gcc_assert (GET_MODE_CLASS (mode) == MODE_INT);
+
+  c[0] = 0;
+  c[1] = 0;
+  ch = 1;
+  for (i = 0; i < GET_MODE_SIZE (mode); i++)
+    {
+      j = i;
+      if (WORDS_BIG_ENDIAN)
+	j = GET_MODE_SIZE (mode) - i - 1;
+      if (BYTES_BIG_ENDIAN != WORDS_BIG_ENDIAN
+	  && GET_MODE_SIZE (mode) > UNITS_PER_WORD)
+	j = j + UNITS_PER_WORD - 2 * (j % UNITS_PER_WORD) - 1;
+      j *= BITS_PER_UNIT;
+      gcc_assert (j <= 2 * HOST_BITS_PER_WIDE_INT);
+
+      if (ch)
+	ch = (unsigned char) str[i];
+      c[j / HOST_BITS_PER_WIDE_INT] |= ch << (j % HOST_BITS_PER_WIDE_INT);
+    }
+  return immed_double_const (c[0], c[1], mode);
+}
+
+/* Cast a target constant CST to target CHAR and if that value fits into
+   host char type, return zero and put that value into variable pointed to by
+   P.  */
+
+static int
+target_char_cast (tree cst, char *p)
+{
+  unsigned HOST_WIDE_INT val, hostval;
+
+  if (!host_integerp (cst, 1)
+      || CHAR_TYPE_SIZE > HOST_BITS_PER_WIDE_INT)
+    return 1;
+
+  val = tree_low_cst (cst, 1);
+  if (CHAR_TYPE_SIZE < HOST_BITS_PER_WIDE_INT)
+    val &= (((unsigned HOST_WIDE_INT) 1) << CHAR_TYPE_SIZE) - 1;
+
+  hostval = val;
+  if (HOST_BITS_PER_CHAR < HOST_BITS_PER_WIDE_INT)
+    hostval &= (((unsigned HOST_WIDE_INT) 1) << HOST_BITS_PER_CHAR) - 1;
+
+  if (val != hostval)
+    return 1;
+
+  *p = hostval;
+  return 0;
+}
+
+/* Similar to save_expr, but assumes that arbitrary code is not executed
+   in between the multiple evaluations.  In particular, we assume that a
+   non-addressable local variable will not be modified.  */
+
+static tree
+builtin_save_expr (tree exp)
+{
+  if (TREE_ADDRESSABLE (exp) == 0
+      && (TREE_CODE (exp) == PARM_DECL
+	  || (TREE_CODE (exp) == VAR_DECL && !TREE_STATIC (exp))))
+    return exp;
+
+  return save_expr (exp);
+}
+
+/* Given TEM, a pointer to a stack frame, follow the dynamic chain COUNT
+   times to get the address of either a higher stack frame, or a return
+   address located within it (depending on FNDECL_CODE).  */
+
+static rtx
+expand_builtin_return_addr (enum built_in_function fndecl_code, int count)
+{
+  int i;
+
+#ifdef INITIAL_FRAME_ADDRESS_RTX
+  rtx tem = INITIAL_FRAME_ADDRESS_RTX;
+#else
+  rtx tem;
+
+  /* For a zero count, we don't care what frame address we return, so frame
+     pointer elimination is OK, and using the soft frame pointer is OK.
+     For a non-zero count, we require a stable offset from the current frame
+     pointer to the previous one, so we must use the hard frame pointer, and
+     we must disable frame pointer elimination.  */
+  if (count == 0)
+    tem = frame_pointer_rtx;
+  else 
+    {
+      tem = hard_frame_pointer_rtx;
+
+      /* Tell reload not to eliminate the frame pointer.  */
+      current_function_accesses_prior_frames = 1;
+    }
+#endif
+
+  /* Some machines need special handling before we can access
+     arbitrary frames.  For example, on the sparc, we must first flush
+     all register windows to the stack.  */
+#ifdef SETUP_FRAME_ADDRESSES
+  if (count > 0)
+    SETUP_FRAME_ADDRESSES ();
+#endif
+
+  /* On the sparc, the return address is not in the frame, it is in a
+     register.  There is no way to access it off of the current frame
+     pointer, but it can be accessed off the previous frame pointer by
+     reading the value from the register window save area.  */
+#ifdef RETURN_ADDR_IN_PREVIOUS_FRAME
+  if (fndecl_code == BUILT_IN_RETURN_ADDRESS)
+    count--;
+#endif
+
+  /* Scan back COUNT frames to the specified frame.  */
+  for (i = 0; i < count; i++)
+    {
+      /* Assume the dynamic chain pointer is in the word that the
+	 frame address points to, unless otherwise specified.  */
+#ifdef DYNAMIC_CHAIN_ADDRESS
+      tem = DYNAMIC_CHAIN_ADDRESS (tem);
+#endif
+      tem = memory_address (Pmode, tem);
+      tem = gen_frame_mem (Pmode, tem);
+      tem = copy_to_reg (tem);
+    }
+
+  /* For __builtin_frame_address, return what we've got.  */
+  if (fndecl_code == BUILT_IN_FRAME_ADDRESS)
+    return tem;
+
+  /* For __builtin_return_address, Get the return address from that
+     frame.  */
+#ifdef RETURN_ADDR_RTX
+  tem = RETURN_ADDR_RTX (count, tem);
+#else
+  tem = memory_address (Pmode,
+			plus_constant (tem, GET_MODE_SIZE (Pmode)));
+  tem = gen_frame_mem (Pmode, tem);
+#endif
+  return tem;
+}
+
+/* Alias set used for setjmp buffer.  */
+static HOST_WIDE_INT setjmp_alias_set = -1;
+
+/* Construct the leading half of a __builtin_setjmp call.  Control will
+   return to RECEIVER_LABEL.  This is used directly by sjlj exception
+   handling code.  */
+
+void
+expand_builtin_setjmp_setup (rtx buf_addr, rtx receiver_label)
+{
+  enum machine_mode sa_mode = STACK_SAVEAREA_MODE (SAVE_NONLOCAL);
+  rtx stack_save;
+  rtx mem;
+
+  if (setjmp_alias_set == -1)
+    setjmp_alias_set = new_alias_set ();
+
+  buf_addr = convert_memory_address (Pmode, buf_addr);
+
+  buf_addr = force_reg (Pmode, force_operand (buf_addr, NULL_RTX));
+
+  /* We store the frame pointer and the address of receiver_label in
+     the buffer and use the rest of it for the stack save area, which
+     is machine-dependent.  */
+
+  mem = gen_rtx_MEM (Pmode, buf_addr);
+  set_mem_alias_set (mem, setjmp_alias_set);
+  emit_move_insn (mem, targetm.builtin_setjmp_frame_value ());
+
+  mem = gen_rtx_MEM (Pmode, plus_constant (buf_addr, GET_MODE_SIZE (Pmode))),
+  set_mem_alias_set (mem, setjmp_alias_set);
+
+  emit_move_insn (validize_mem (mem),
+		  force_reg (Pmode, gen_rtx_LABEL_REF (Pmode, receiver_label)));
+
+  stack_save = gen_rtx_MEM (sa_mode,
+			    plus_constant (buf_addr,
+					   2 * GET_MODE_SIZE (Pmode)));
+  set_mem_alias_set (stack_save, setjmp_alias_set);
+  emit_stack_save (SAVE_NONLOCAL, &stack_save, NULL_RTX);
+
+  /* If there is further processing to do, do it.  */
+#ifdef HAVE_builtin_setjmp_setup
+  if (HAVE_builtin_setjmp_setup)
+    emit_insn (gen_builtin_setjmp_setup (buf_addr));
+#endif
+
+  /* Tell optimize_save_area_alloca that extra work is going to
+     need to go on during alloca.  */
+  current_function_calls_setjmp = 1;
+
+  /* Set this so all the registers get saved in our frame; we need to be
+     able to copy the saved values for any registers from frames we unwind.  */
+  current_function_has_nonlocal_label = 1;
+}
+
+/* Construct the trailing part of a __builtin_setjmp call.
+   This is used directly by sjlj exception handling code.  */
+
+void
+expand_builtin_setjmp_receiver (rtx receiver_label ATTRIBUTE_UNUSED)
+{
+  /* Clobber the FP when we get here, so we have to make sure it's
+     marked as used by this function.  */
+  emit_insn (gen_rtx_USE (VOIDmode, hard_frame_pointer_rtx));
+
+  /* Mark the static chain as clobbered here so life information
+     doesn't get messed up for it.  */
+  emit_insn (gen_rtx_CLOBBER (VOIDmode, static_chain_rtx));
+
+  /* Now put in the code to restore the frame pointer, and argument
+     pointer, if needed.  */
+#ifdef HAVE_nonlocal_goto
+  if (! HAVE_nonlocal_goto)
+#endif
+    emit_move_insn (virtual_stack_vars_rtx, hard_frame_pointer_rtx);
+
+#if ARG_POINTER_REGNUM != HARD_FRAME_POINTER_REGNUM
+  if (fixed_regs[ARG_POINTER_REGNUM])
+    {
+#ifdef ELIMINABLE_REGS
+      size_t i;
+      static const struct elims {const int from, to;} elim_regs[] = ELIMINABLE_REGS;
+
+      for (i = 0; i < ARRAY_SIZE (elim_regs); i++)
+	if (elim_regs[i].from == ARG_POINTER_REGNUM
+	    && elim_regs[i].to == HARD_FRAME_POINTER_REGNUM)
+	  break;
+
+      if (i == ARRAY_SIZE (elim_regs))
+#endif
+	{
+	  /* Now restore our arg pointer from the address at which it
+	     was saved in our stack frame.  */
+	  emit_move_insn (virtual_incoming_args_rtx,
+			  copy_to_reg (get_arg_pointer_save_area (cfun)));
+	}
+    }
+#endif
+
+#ifdef HAVE_builtin_setjmp_receiver
+  if (HAVE_builtin_setjmp_receiver)
+    emit_insn (gen_builtin_setjmp_receiver (receiver_label));
+  else
+#endif
+#ifdef HAVE_nonlocal_goto_receiver
+    if (HAVE_nonlocal_goto_receiver)
+      emit_insn (gen_nonlocal_goto_receiver ());
+    else
+#endif
+      { /* Nothing */ }
+
+  /* @@@ This is a kludge.  Not all machine descriptions define a blockage
+     insn, but we must not allow the code we just generated to be reordered
+     by scheduling.  Specifically, the update of the frame pointer must
+     happen immediately, not later.  So emit an ASM_INPUT to act as blockage
+     insn.  */
+  emit_insn (gen_rtx_ASM_INPUT (VOIDmode, ""));
+}
+
+/* __builtin_setjmp is passed a pointer to an array of five words (not
+   all will be used on all machines).  It operates similarly to the C
+   library function of the same name, but is more efficient.  Much of
+   the code below (and for longjmp) is copied from the handling of
+   non-local gotos.
+
+   NOTE: This is intended for use by GNAT and the exception handling
+   scheme in the compiler and will only work in the method used by
+   them.  */
+
+static rtx
+expand_builtin_setjmp (tree arglist, rtx target)
+{
+  rtx buf_addr, next_lab, cont_lab;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  if (target == 0 || !REG_P (target)
+      || REGNO (target) < FIRST_PSEUDO_REGISTER)
+    target = gen_reg_rtx (TYPE_MODE (integer_type_node));
+
+  buf_addr = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);
+
+  next_lab = gen_label_rtx ();
+  cont_lab = gen_label_rtx ();
+
+  expand_builtin_setjmp_setup (buf_addr, next_lab);
+
+  /* Set TARGET to zero and branch to the continue label.  Use emit_jump to
+     ensure that pending stack adjustments are flushed.  */
+  emit_move_insn (target, const0_rtx);
+  emit_jump (cont_lab);
+
+  emit_label (next_lab);
+
+  expand_builtin_setjmp_receiver (next_lab);
+
+  /* Set TARGET to one.  */
+  emit_move_insn (target, const1_rtx);
+  emit_label (cont_lab);
+
+  /* Tell flow about the strange goings on.  Putting `next_lab' on
+     `nonlocal_goto_handler_labels' to indicates that function
+     calls may traverse the arc back to this label.  */
+
+  current_function_has_nonlocal_label = 1;
+  nonlocal_goto_handler_labels
+    = gen_rtx_EXPR_LIST (VOIDmode, next_lab, nonlocal_goto_handler_labels);
+
+  return target;
+}
+
+/* __builtin_longjmp is passed a pointer to an array of five words (not
+   all will be used on all machines).  It operates similarly to the C
+   library function of the same name, but is more efficient.  Much of
+   the code below is copied from the handling of non-local gotos.
+
+   NOTE: This is intended for use by GNAT and the exception handling
+   scheme in the compiler and will only work in the method used by
+   them.  */
+
+static void
+expand_builtin_longjmp (rtx buf_addr, rtx value)
+{
+  rtx fp, lab, stack, insn, last;
+  enum machine_mode sa_mode = STACK_SAVEAREA_MODE (SAVE_NONLOCAL);
+
+  if (setjmp_alias_set == -1)
+    setjmp_alias_set = new_alias_set ();
+
+  buf_addr = convert_memory_address (Pmode, buf_addr);
+
+  buf_addr = force_reg (Pmode, buf_addr);
+
+  /* We used to store value in static_chain_rtx, but that fails if pointers
+     are smaller than integers.  We instead require that the user must pass
+     a second argument of 1, because that is what builtin_setjmp will
+     return.  This also makes EH slightly more efficient, since we are no
+     longer copying around a value that we don't care about.  */
+  gcc_assert (value == const1_rtx);
+
+  last = get_last_insn ();
+#ifdef HAVE_builtin_longjmp
+  if (HAVE_builtin_longjmp)
+    emit_insn (gen_builtin_longjmp (buf_addr));
+  else
+#endif
+    {
+      fp = gen_rtx_MEM (Pmode, buf_addr);
+      lab = gen_rtx_MEM (Pmode, plus_constant (buf_addr,
+					       GET_MODE_SIZE (Pmode)));
+
+      stack = gen_rtx_MEM (sa_mode, plus_constant (buf_addr,
+						   2 * GET_MODE_SIZE (Pmode)));
+      set_mem_alias_set (fp, setjmp_alias_set);
+      set_mem_alias_set (lab, setjmp_alias_set);
+      set_mem_alias_set (stack, setjmp_alias_set);
+
+      /* Pick up FP, label, and SP from the block and jump.  This code is
+	 from expand_goto in stmt.c; see there for detailed comments.  */
+#if HAVE_nonlocal_goto
+      if (HAVE_nonlocal_goto)
+	/* We have to pass a value to the nonlocal_goto pattern that will
+	   get copied into the static_chain pointer, but it does not matter
+	   what that value is, because builtin_setjmp does not use it.  */
+	emit_insn (gen_nonlocal_goto (value, lab, stack, fp));
+      else
+#endif
+	{
+	  lab = copy_to_reg (lab);
+
+	  emit_insn (gen_rtx_CLOBBER (VOIDmode,
+				      gen_rtx_MEM (BLKmode,
+						   gen_rtx_SCRATCH (VOIDmode))));
+	  emit_insn (gen_rtx_CLOBBER (VOIDmode,
+				      gen_rtx_MEM (BLKmode,
+						   hard_frame_pointer_rtx)));
+
+	  emit_move_insn (hard_frame_pointer_rtx, fp);
+	  emit_stack_restore (SAVE_NONLOCAL, stack, NULL_RTX);
+
+	  emit_insn (gen_rtx_USE (VOIDmode, hard_frame_pointer_rtx));
+	  emit_insn (gen_rtx_USE (VOIDmode, stack_pointer_rtx));
+	  emit_indirect_jump (lab);
+	}
+    }
+
+  /* Search backwards and mark the jump insn as a non-local goto.
+     Note that this precludes the use of __builtin_longjmp to a
+     __builtin_setjmp target in the same function.  However, we've
+     already cautioned the user that these functions are for
+     internal exception handling use only.  */
+  for (insn = get_last_insn (); insn; insn = PREV_INSN (insn))
+    {
+      gcc_assert (insn != last);
+
+      if (JUMP_P (insn))
+	{
+	  REG_NOTES (insn) = alloc_EXPR_LIST (REG_NON_LOCAL_GOTO, const0_rtx,
+					      REG_NOTES (insn));
+	  break;
+	}
+      else if (CALL_P (insn))
+	break;
+    }
+}
+
+/* Expand a call to __builtin_nonlocal_goto.  We're passed the target label
+   and the address of the save area.  */
+
+static rtx
+expand_builtin_nonlocal_goto (tree arglist)
+{
+  tree t_label, t_save_area;
+  rtx r_label, r_save_area, r_fp, r_sp, insn;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  t_label = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  t_save_area = TREE_VALUE (arglist);
+
+  r_label = expand_expr (t_label, NULL_RTX, VOIDmode, 0);
+  r_label = convert_memory_address (Pmode, r_label);
+  r_save_area = expand_expr (t_save_area, NULL_RTX, VOIDmode, 0);
+  r_save_area = convert_memory_address (Pmode, r_save_area);
+  r_fp = gen_rtx_MEM (Pmode, r_save_area);
+  r_sp = gen_rtx_MEM (STACK_SAVEAREA_MODE (SAVE_NONLOCAL),
+		      plus_constant (r_save_area, GET_MODE_SIZE (Pmode)));
+
+  current_function_has_nonlocal_goto = 1;
+
+#if HAVE_nonlocal_goto
+  /* ??? We no longer need to pass the static chain value, afaik.  */
+  if (HAVE_nonlocal_goto)
+    emit_insn (gen_nonlocal_goto (const0_rtx, r_label, r_sp, r_fp));
+  else
+#endif
+    {
+      r_label = copy_to_reg (r_label);
+
+      emit_insn (gen_rtx_CLOBBER (VOIDmode,
+				  gen_rtx_MEM (BLKmode,
+					       gen_rtx_SCRATCH (VOIDmode))));
+
+      emit_insn (gen_rtx_CLOBBER (VOIDmode,
+				  gen_rtx_MEM (BLKmode,
+					       hard_frame_pointer_rtx)));
+
+      /* Restore frame pointer for containing function.
+	 This sets the actual hard register used for the frame pointer
+	 to the location of the function's incoming static chain info.
+	 The non-local goto handler will then adjust it to contain the
+	 proper value and reload the argument pointer, if needed.  */
+      emit_move_insn (hard_frame_pointer_rtx, r_fp);
+      emit_stack_restore (SAVE_NONLOCAL, r_sp, NULL_RTX);
+
+      /* USE of hard_frame_pointer_rtx added for consistency;
+	 not clear if really needed.  */
+      emit_insn (gen_rtx_USE (VOIDmode, hard_frame_pointer_rtx));
+      emit_insn (gen_rtx_USE (VOIDmode, stack_pointer_rtx));
+      emit_indirect_jump (r_label);
+    }
+
+  /* Search backwards to the jump insn and mark it as a
+     non-local goto.  */
+  for (insn = get_last_insn (); insn; insn = PREV_INSN (insn))
+    {
+      if (JUMP_P (insn))
+	{
+	  REG_NOTES (insn) = alloc_EXPR_LIST (REG_NON_LOCAL_GOTO,
+					      const0_rtx, REG_NOTES (insn));
+	  break;
+	}
+      else if (CALL_P (insn))
+	break;
+    }
+
+  return const0_rtx;
+}
+
+/* __builtin_update_setjmp_buf is passed a pointer to an array of five words
+   (not all will be used on all machines) that was passed to __builtin_setjmp.
+   It updates the stack pointer in that block to correspond to the current
+   stack pointer.  */
+
+static void
+expand_builtin_update_setjmp_buf (rtx buf_addr)
+{
+  enum machine_mode sa_mode = Pmode;
+  rtx stack_save;
+
+
+#ifdef HAVE_save_stack_nonlocal
+  if (HAVE_save_stack_nonlocal)
+    sa_mode = insn_data[(int) CODE_FOR_save_stack_nonlocal].operand[0].mode;
+#endif
+#ifdef STACK_SAVEAREA_MODE
+  sa_mode = STACK_SAVEAREA_MODE (SAVE_NONLOCAL);
+#endif
+
+  stack_save
+    = gen_rtx_MEM (sa_mode,
+		   memory_address
+		   (sa_mode,
+		    plus_constant (buf_addr, 2 * GET_MODE_SIZE (Pmode))));
+
+#ifdef HAVE_setjmp
+  if (HAVE_setjmp)
+    emit_insn (gen_setjmp ());
+#endif
+
+  emit_stack_save (SAVE_NONLOCAL, &stack_save, NULL_RTX);
+}
+
+/* Expand a call to __builtin_prefetch.  For a target that does not support
+   data prefetch, evaluate the memory address argument in case it has side
+   effects.  */
+
+static void
+expand_builtin_prefetch (tree arglist)
+{
+  tree arg0, arg1, arg2;
+  rtx op0, op1, op2;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, 0))
+    return;
+
+  arg0 = TREE_VALUE (arglist);
+  /* Arguments 1 and 2 are optional; argument 1 (read/write) defaults to
+     zero (read) and argument 2 (locality) defaults to 3 (high degree of
+     locality).  */
+  if (TREE_CHAIN (arglist))
+    {
+      arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+      if (TREE_CHAIN (TREE_CHAIN (arglist)))
+	arg2 = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      else
+	arg2 = build_int_cst (NULL_TREE, 3);
+    }
+  else
+    {
+      arg1 = integer_zero_node;
+      arg2 = build_int_cst (NULL_TREE, 3);
+    }
+
+  /* Argument 0 is an address.  */
+  op0 = expand_expr (arg0, NULL_RTX, Pmode, EXPAND_NORMAL);
+
+  /* Argument 1 (read/write flag) must be a compile-time constant int.  */
+  if (TREE_CODE (arg1) != INTEGER_CST)
+    {
+      error ("second argument to %<__builtin_prefetch%> must be a constant");
+      arg1 = integer_zero_node;
+    }
+  op1 = expand_expr (arg1, NULL_RTX, VOIDmode, 0);
+  /* Argument 1 must be either zero or one.  */
+  if (INTVAL (op1) != 0 && INTVAL (op1) != 1)
+    {
+      warning (0, "invalid second argument to %<__builtin_prefetch%>;"
+	       " using zero");
+      op1 = const0_rtx;
+    }
+
+  /* Argument 2 (locality) must be a compile-time constant int.  */
+  if (TREE_CODE (arg2) != INTEGER_CST)
+    {
+      error ("third argument to %<__builtin_prefetch%> must be a constant");
+      arg2 = integer_zero_node;
+    }
+  op2 = expand_expr (arg2, NULL_RTX, VOIDmode, 0);
+  /* Argument 2 must be 0, 1, 2, or 3.  */
+  if (INTVAL (op2) < 0 || INTVAL (op2) > 3)
+    {
+      warning (0, "invalid third argument to %<__builtin_prefetch%>; using zero");
+      op2 = const0_rtx;
+    }
+
+#ifdef HAVE_prefetch
+  if (HAVE_prefetch)
+    {
+      if ((! (*insn_data[(int) CODE_FOR_prefetch].operand[0].predicate)
+	     (op0,
+	      insn_data[(int) CODE_FOR_prefetch].operand[0].mode))
+	  || (GET_MODE (op0) != Pmode))
+	{
+	  op0 = convert_memory_address (Pmode, op0);
+	  op0 = force_reg (Pmode, op0);
+	}
+      emit_insn (gen_prefetch (op0, op1, op2));
+    }
+#endif
+
+  /* Don't do anything with direct references to volatile memory, but
+     generate code to handle other side effects.  */
+  if (!MEM_P (op0) && side_effects_p (op0))
+    emit_insn (op0);
+}
+
+/* Get a MEM rtx for expression EXP which is the address of an operand
+   to be used in a string instruction (cmpstrsi, movmemsi, ..).  LEN is
+   the maximum length of the block of memory that might be accessed or
+   NULL if unknown.  */
+
+static rtx
+get_memory_rtx (tree exp, tree len)
+{
+  rtx addr = expand_expr (exp, NULL_RTX, ptr_mode, EXPAND_NORMAL);
+  rtx mem = gen_rtx_MEM (BLKmode, memory_address (BLKmode, addr));
+
+  /* Get an expression we can use to find the attributes to assign to MEM.
+     If it is an ADDR_EXPR, use the operand.  Otherwise, dereference it if
+     we can.  First remove any nops.  */
+  while ((TREE_CODE (exp) == NOP_EXPR || TREE_CODE (exp) == CONVERT_EXPR
+	  || TREE_CODE (exp) == NON_LVALUE_EXPR)
+	 && POINTER_TYPE_P (TREE_TYPE (TREE_OPERAND (exp, 0))))
+    exp = TREE_OPERAND (exp, 0);
+
+  if (TREE_CODE (exp) == ADDR_EXPR)
+    exp = TREE_OPERAND (exp, 0);
+  else if (POINTER_TYPE_P (TREE_TYPE (exp)))
+    exp = build1 (INDIRECT_REF, TREE_TYPE (TREE_TYPE (exp)), exp);
+  else
+    exp = NULL;
+
+  /* Honor attributes derived from exp, except for the alias set
+     (as builtin stringops may alias with anything) and the size
+     (as stringops may access multiple array elements).  */
+  if (exp)
+    {
+      set_mem_attributes (mem, exp, 0);
+
+      /* Allow the string and memory builtins to overflow from one
+	 field into another, see http://gcc.gnu.org/PR23561.
+	 Thus avoid COMPONENT_REFs in MEM_EXPR unless we know the whole
+	 memory accessed by the string or memory builtin will fit
+	 within the field.  */
+      if (MEM_EXPR (mem) && TREE_CODE (MEM_EXPR (mem)) == COMPONENT_REF)
+	{
+	  tree mem_expr = MEM_EXPR (mem);
+	  HOST_WIDE_INT offset = -1, length = -1;
+	  tree inner = exp;
+
+	  while (TREE_CODE (inner) == ARRAY_REF
+		 || TREE_CODE (inner) == NOP_EXPR
+		 || TREE_CODE (inner) == CONVERT_EXPR
+		 || TREE_CODE (inner) == NON_LVALUE_EXPR
+		 || TREE_CODE (inner) == VIEW_CONVERT_EXPR
+		 || TREE_CODE (inner) == SAVE_EXPR)
+	    inner = TREE_OPERAND (inner, 0);
+
+	  gcc_assert (TREE_CODE (inner) == COMPONENT_REF);
+
+	  if (MEM_OFFSET (mem)
+	      && GET_CODE (MEM_OFFSET (mem)) == CONST_INT)
+	    offset = INTVAL (MEM_OFFSET (mem));
+
+	  if (offset >= 0 && len && host_integerp (len, 0))
+	    length = tree_low_cst (len, 0);
+
+	  while (TREE_CODE (inner) == COMPONENT_REF)
+	    {
+	      tree field = TREE_OPERAND (inner, 1);
+	      gcc_assert (! DECL_BIT_FIELD (field));
+	      gcc_assert (TREE_CODE (mem_expr) == COMPONENT_REF);
+	      gcc_assert (field == TREE_OPERAND (mem_expr, 1));
+
+	      if (length >= 0
+		  && TYPE_SIZE_UNIT (TREE_TYPE (inner))
+		  && host_integerp (TYPE_SIZE_UNIT (TREE_TYPE (inner)), 0))
+		{
+		  HOST_WIDE_INT size
+		    = tree_low_cst (TYPE_SIZE_UNIT (TREE_TYPE (inner)), 0);
+		  /* If we can prove the memory starting at XEXP (mem, 0)
+		     and ending at XEXP (mem, 0) + LENGTH will fit into
+		     this field, we can keep that COMPONENT_REF in MEM_EXPR.  */
+		  if (offset <= size
+		      && length <= size
+		      && offset + length <= size)
+		    break;
+		}
+
+	      if (offset >= 0
+		  && host_integerp (DECL_FIELD_OFFSET (field), 0))
+		offset += tree_low_cst (DECL_FIELD_OFFSET (field), 0)
+			  + tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 1)
+			    / BITS_PER_UNIT;
+	      else
+		{
+		  offset = -1;
+		  length = -1;
+		}
+
+	      mem_expr = TREE_OPERAND (mem_expr, 0);
+	      inner = TREE_OPERAND (inner, 0);
+	    }
+
+	  if (mem_expr == NULL)
+	    offset = -1;
+	  if (mem_expr != MEM_EXPR (mem))
+	    {
+	      set_mem_expr (mem, mem_expr);
+	      set_mem_offset (mem, offset >= 0 ? GEN_INT (offset) : NULL_RTX);
+	    }
+	}
+      set_mem_alias_set (mem, 0);
+      set_mem_size (mem, NULL_RTX);
+    }
+
+  return mem;
+}
+
+/* Built-in functions to perform an untyped call and return.  */
+
+/* For each register that may be used for calling a function, this
+   gives a mode used to copy the register's value.  VOIDmode indicates
+   the register is not used for calling a function.  If the machine
+   has register windows, this gives only the outbound registers.
+   INCOMING_REGNO gives the corresponding inbound register.  */
+static enum machine_mode apply_args_mode[FIRST_PSEUDO_REGISTER];
+
+/* For each register that may be used for returning values, this gives
+   a mode used to copy the register's value.  VOIDmode indicates the
+   register is not used for returning values.  If the machine has
+   register windows, this gives only the outbound registers.
+   INCOMING_REGNO gives the corresponding inbound register.  */
+static enum machine_mode apply_result_mode[FIRST_PSEUDO_REGISTER];
+
+/* For each register that may be used for calling a function, this
+   gives the offset of that register into the block returned by
+   __builtin_apply_args.  0 indicates that the register is not
+   used for calling a function.  */
+static int apply_args_reg_offset[FIRST_PSEUDO_REGISTER];
+
+/* Return the size required for the block returned by __builtin_apply_args,
+   and initialize apply_args_mode.  */
+
+static int
+apply_args_size (void)
+{
+  static int size = -1;
+  int align;
+  unsigned int regno;
+  enum machine_mode mode;
+
+  /* The values computed by this function never change.  */
+  if (size < 0)
+    {
+      /* The first value is the incoming arg-pointer.  */
+      size = GET_MODE_SIZE (Pmode);
+
+      /* The second value is the structure value address unless this is
+	 passed as an "invisible" first argument.  */
+      if (targetm.calls.struct_value_rtx (cfun ? TREE_TYPE (cfun->decl) : 0, 0))
+	size += GET_MODE_SIZE (Pmode);
+
+      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+	if (FUNCTION_ARG_REGNO_P (regno))
+	  {
+	    mode = reg_raw_mode[regno];
+
+	    gcc_assert (mode != VOIDmode);
+
+	    align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	    if (size % align != 0)
+	      size = CEIL (size, align) * align;
+	    apply_args_reg_offset[regno] = size;
+	    size += GET_MODE_SIZE (mode);
+	    apply_args_mode[regno] = mode;
+	  }
+	else
+	  {
+	    apply_args_mode[regno] = VOIDmode;
+	    apply_args_reg_offset[regno] = 0;
+	  }
+    }
+  return size;
+}
+
+/* Return the size required for the block returned by __builtin_apply,
+   and initialize apply_result_mode.  */
+
+static int
+apply_result_size (void)
+{
+  static int size = -1;
+  int align, regno;
+  enum machine_mode mode;
+
+  /* The values computed by this function never change.  */
+  if (size < 0)
+    {
+      size = 0;
+
+      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+	if (FUNCTION_VALUE_REGNO_P (regno))
+	  {
+	    mode = reg_raw_mode[regno];
+
+	    gcc_assert (mode != VOIDmode);
+
+	    align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	    if (size % align != 0)
+	      size = CEIL (size, align) * align;
+	    size += GET_MODE_SIZE (mode);
+	    apply_result_mode[regno] = mode;
+	  }
+	else
+	  apply_result_mode[regno] = VOIDmode;
+
+      /* Allow targets that use untyped_call and untyped_return to override
+	 the size so that machine-specific information can be stored here.  */
+#ifdef APPLY_RESULT_SIZE
+      size = APPLY_RESULT_SIZE;
+#endif
+    }
+  return size;
+}
+
+#if defined (HAVE_untyped_call) || defined (HAVE_untyped_return)
+/* Create a vector describing the result block RESULT.  If SAVEP is true,
+   the result block is used to save the values; otherwise it is used to
+   restore the values.  */
+
+static rtx
+result_vector (int savep, rtx result)
+{
+  int regno, size, align, nelts;
+  enum machine_mode mode;
+  rtx reg, mem;
+  rtx *savevec = alloca (FIRST_PSEUDO_REGISTER * sizeof (rtx));
+
+  size = nelts = 0;
+  for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+    if ((mode = apply_result_mode[regno]) != VOIDmode)
+      {
+	align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	if (size % align != 0)
+	  size = CEIL (size, align) * align;
+	reg = gen_rtx_REG (mode, savep ? regno : INCOMING_REGNO (regno));
+	mem = adjust_address (result, mode, size);
+	savevec[nelts++] = (savep
+			    ? gen_rtx_SET (VOIDmode, mem, reg)
+			    : gen_rtx_SET (VOIDmode, reg, mem));
+	size += GET_MODE_SIZE (mode);
+      }
+  return gen_rtx_PARALLEL (VOIDmode, gen_rtvec_v (nelts, savevec));
+}
+#endif /* HAVE_untyped_call or HAVE_untyped_return */
+
+/* Save the state required to perform an untyped call with the same
+   arguments as were passed to the current function.  */
+
+static rtx
+expand_builtin_apply_args_1 (void)
+{
+  rtx registers, tem;
+  int size, align, regno;
+  enum machine_mode mode;
+  rtx struct_incoming_value = targetm.calls.struct_value_rtx (cfun ? TREE_TYPE (cfun->decl) : 0, 1);
+
+  /* Create a block where the arg-pointer, structure value address,
+     and argument registers can be saved.  */
+  registers = assign_stack_local (BLKmode, apply_args_size (), -1);
+
+  /* Walk past the arg-pointer and structure value address.  */
+  size = GET_MODE_SIZE (Pmode);
+  if (targetm.calls.struct_value_rtx (cfun ? TREE_TYPE (cfun->decl) : 0, 0))
+    size += GET_MODE_SIZE (Pmode);
+
+  /* Save each register used in calling a function to the block.  */
+  for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+    if ((mode = apply_args_mode[regno]) != VOIDmode)
+      {
+	align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	if (size % align != 0)
+	  size = CEIL (size, align) * align;
+
+	tem = gen_rtx_REG (mode, INCOMING_REGNO (regno));
+
+	emit_move_insn (adjust_address (registers, mode, size), tem);
+	size += GET_MODE_SIZE (mode);
+      }
+
+  /* Save the arg pointer to the block.  */
+  tem = copy_to_reg (virtual_incoming_args_rtx);
+#ifdef STACK_GROWS_DOWNWARD
+  /* We need the pointer as the caller actually passed them to us, not
+     as we might have pretended they were passed.  Make sure it's a valid
+     operand, as emit_move_insn isn't expected to handle a PLUS.  */
+  tem
+    = force_operand (plus_constant (tem, current_function_pretend_args_size),
+		     NULL_RTX);
+#endif
+  emit_move_insn (adjust_address (registers, Pmode, 0), tem);
+
+  size = GET_MODE_SIZE (Pmode);
+
+  /* Save the structure value address unless this is passed as an
+     "invisible" first argument.  */
+  if (struct_incoming_value)
+    {
+      emit_move_insn (adjust_address (registers, Pmode, size),
+		      copy_to_reg (struct_incoming_value));
+      size += GET_MODE_SIZE (Pmode);
+    }
+
+  /* Return the address of the block.  */
+  return copy_addr_to_reg (XEXP (registers, 0));
+}
+
+/* __builtin_apply_args returns block of memory allocated on
+   the stack into which is stored the arg pointer, structure
+   value address, static chain, and all the registers that might
+   possibly be used in performing a function call.  The code is
+   moved to the start of the function so the incoming values are
+   saved.  */
+
+static rtx
+expand_builtin_apply_args (void)
+{
+  /* Don't do __builtin_apply_args more than once in a function.
+     Save the result of the first call and reuse it.  */
+  if (apply_args_value != 0)
+    return apply_args_value;
+  {
+    /* When this function is called, it means that registers must be
+       saved on entry to this function.  So we migrate the
+       call to the first insn of this function.  */
+    rtx temp;
+    rtx seq;
+
+    start_sequence ();
+    temp = expand_builtin_apply_args_1 ();
+    seq = get_insns ();
+    end_sequence ();
+
+    apply_args_value = temp;
+
+    /* Put the insns after the NOTE that starts the function.
+       If this is inside a start_sequence, make the outer-level insn
+       chain current, so the code is placed at the start of the
+       function.  */
+    push_topmost_sequence ();
+    emit_insn_before (seq, NEXT_INSN (entry_of_function ()));
+    pop_topmost_sequence ();
+    return temp;
+  }
+}
+
+/* Perform an untyped call and save the state required to perform an
+   untyped return of whatever value was returned by the given function.  */
+
+static rtx
+expand_builtin_apply (rtx function, rtx arguments, rtx argsize)
+{
+  int size, align, regno;
+  enum machine_mode mode;
+  rtx incoming_args, result, reg, dest, src, call_insn;
+  rtx old_stack_level = 0;
+  rtx call_fusage = 0;
+  rtx struct_value = targetm.calls.struct_value_rtx (cfun ? TREE_TYPE (cfun->decl) : 0, 0);
+
+  arguments = convert_memory_address (Pmode, arguments);
+
+  /* Create a block where the return registers can be saved.  */
+  result = assign_stack_local (BLKmode, apply_result_size (), -1);
+
+  /* Fetch the arg pointer from the ARGUMENTS block.  */
+  incoming_args = gen_reg_rtx (Pmode);
+  emit_move_insn (incoming_args, gen_rtx_MEM (Pmode, arguments));
+#ifndef STACK_GROWS_DOWNWARD
+  incoming_args = expand_simple_binop (Pmode, MINUS, incoming_args, argsize,
+				       incoming_args, 0, OPTAB_LIB_WIDEN);
+#endif
+
+  /* Push a new argument block and copy the arguments.  Do not allow
+     the (potential) memcpy call below to interfere with our stack
+     manipulations.  */
+  do_pending_stack_adjust ();
+  NO_DEFER_POP;
+
+  /* Save the stack with nonlocal if available.  */
+#ifdef HAVE_save_stack_nonlocal
+  if (HAVE_save_stack_nonlocal)
+    emit_stack_save (SAVE_NONLOCAL, &old_stack_level, NULL_RTX);
+  else
+#endif
+    emit_stack_save (SAVE_BLOCK, &old_stack_level, NULL_RTX);
+
+  /* Allocate a block of memory onto the stack and copy the memory
+     arguments to the outgoing arguments address.  */
+  allocate_dynamic_stack_space (argsize, 0, BITS_PER_UNIT);
+  dest = virtual_outgoing_args_rtx;
+#ifndef STACK_GROWS_DOWNWARD
+  if (GET_CODE (argsize) == CONST_INT)
+    dest = plus_constant (dest, -INTVAL (argsize));
+  else
+    dest = gen_rtx_PLUS (Pmode, dest, negate_rtx (Pmode, argsize));
+#endif
+  dest = gen_rtx_MEM (BLKmode, dest);
+  set_mem_align (dest, PARM_BOUNDARY);
+  src = gen_rtx_MEM (BLKmode, incoming_args);
+  set_mem_align (src, PARM_BOUNDARY);
+  emit_block_move (dest, src, argsize, BLOCK_OP_NORMAL);
+
+  /* Refer to the argument block.  */
+  apply_args_size ();
+  arguments = gen_rtx_MEM (BLKmode, arguments);
+  set_mem_align (arguments, PARM_BOUNDARY);
+
+  /* Walk past the arg-pointer and structure value address.  */
+  size = GET_MODE_SIZE (Pmode);
+  if (struct_value)
+    size += GET_MODE_SIZE (Pmode);
+
+  /* Restore each of the registers previously saved.  Make USE insns
+     for each of these registers for use in making the call.  */
+  for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+    if ((mode = apply_args_mode[regno]) != VOIDmode)
+      {
+	align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	if (size % align != 0)
+	  size = CEIL (size, align) * align;
+	reg = gen_rtx_REG (mode, regno);
+	emit_move_insn (reg, adjust_address (arguments, mode, size));
+	use_reg (&call_fusage, reg);
+	size += GET_MODE_SIZE (mode);
+      }
+
+  /* Restore the structure value address unless this is passed as an
+     "invisible" first argument.  */
+  size = GET_MODE_SIZE (Pmode);
+  if (struct_value)
+    {
+      rtx value = gen_reg_rtx (Pmode);
+      emit_move_insn (value, adjust_address (arguments, Pmode, size));
+      emit_move_insn (struct_value, value);
+      if (REG_P (struct_value))
+	use_reg (&call_fusage, struct_value);
+      size += GET_MODE_SIZE (Pmode);
+    }
+
+  /* All arguments and registers used for the call are set up by now!  */
+  function = prepare_call_address (function, NULL, &call_fusage, 0, 0);
+
+  /* Ensure address is valid.  SYMBOL_REF is already valid, so no need,
+     and we don't want to load it into a register as an optimization,
+     because prepare_call_address already did it if it should be done.  */
+  if (GET_CODE (function) != SYMBOL_REF)
+    function = memory_address (FUNCTION_MODE, function);
+
+  /* Generate the actual call instruction and save the return value.  */
+#ifdef HAVE_untyped_call
+  if (HAVE_untyped_call)
+    emit_call_insn (gen_untyped_call (gen_rtx_MEM (FUNCTION_MODE, function),
+				      result, result_vector (1, result)));
+  else
+#endif
+#ifdef HAVE_call_value
+  if (HAVE_call_value)
+    {
+      rtx valreg = 0;
+
+      /* Locate the unique return register.  It is not possible to
+	 express a call that sets more than one return register using
+	 call_value; use untyped_call for that.  In fact, untyped_call
+	 only needs to save the return registers in the given block.  */
+      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+	if ((mode = apply_result_mode[regno]) != VOIDmode)
+	  {
+	    gcc_assert (!valreg); /* HAVE_untyped_call required.  */
+
+	    valreg = gen_rtx_REG (mode, regno);
+	  }
+
+      emit_call_insn (GEN_CALL_VALUE (valreg,
+				      gen_rtx_MEM (FUNCTION_MODE, function),
+				      const0_rtx, NULL_RTX, const0_rtx));
+
+      emit_move_insn (adjust_address (result, GET_MODE (valreg), 0), valreg);
+    }
+  else
+#endif
+    gcc_unreachable ();
+
+  /* Find the CALL insn we just emitted, and attach the register usage
+     information.  */
+  call_insn = last_call_insn ();
+  add_function_usage_to (call_insn, call_fusage);
+
+  /* Restore the stack.  */
+#ifdef HAVE_save_stack_nonlocal
+  if (HAVE_save_stack_nonlocal)
+    emit_stack_restore (SAVE_NONLOCAL, old_stack_level, NULL_RTX);
+  else
+#endif
+    emit_stack_restore (SAVE_BLOCK, old_stack_level, NULL_RTX);
+
+  OK_DEFER_POP;
+
+  /* Return the address of the result block.  */
+  result = copy_addr_to_reg (XEXP (result, 0));
+  return convert_memory_address (ptr_mode, result);
+}
+
+/* Perform an untyped return.  */
+
+static void
+expand_builtin_return (rtx result)
+{
+  int size, align, regno;
+  enum machine_mode mode;
+  rtx reg;
+  rtx call_fusage = 0;
+
+  result = convert_memory_address (Pmode, result);
+
+  apply_result_size ();
+  result = gen_rtx_MEM (BLKmode, result);
+
+#ifdef HAVE_untyped_return
+  if (HAVE_untyped_return)
+    {
+      emit_jump_insn (gen_untyped_return (result, result_vector (0, result)));
+      emit_barrier ();
+      return;
+    }
+#endif
+
+  /* Restore the return value and note that each value is used.  */
+  size = 0;
+  for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+    if ((mode = apply_result_mode[regno]) != VOIDmode)
+      {
+	align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	if (size % align != 0)
+	  size = CEIL (size, align) * align;
+	reg = gen_rtx_REG (mode, INCOMING_REGNO (regno));
+	emit_move_insn (reg, adjust_address (result, mode, size));
+
+	push_to_sequence (call_fusage);
+	emit_insn (gen_rtx_USE (VOIDmode, reg));
+	call_fusage = get_insns ();
+	end_sequence ();
+	size += GET_MODE_SIZE (mode);
+      }
+
+  /* Put the USE insns before the return.  */
+  emit_insn (call_fusage);
+
+  /* Return whatever values was restored by jumping directly to the end
+     of the function.  */
+  expand_naked_return ();
+}
+
+/* Used by expand_builtin_classify_type and fold_builtin_classify_type.  */
+
+static enum type_class
+type_to_class (tree type)
+{
+  switch (TREE_CODE (type))
+    {
+    case VOID_TYPE:	   return void_type_class;
+    case INTEGER_TYPE:	   return integer_type_class;
+    case CHAR_TYPE:	   return char_type_class;
+    case ENUMERAL_TYPE:	   return enumeral_type_class;
+    case BOOLEAN_TYPE:	   return boolean_type_class;
+    case POINTER_TYPE:	   return pointer_type_class;
+    case REFERENCE_TYPE:   return reference_type_class;
+    case OFFSET_TYPE:	   return offset_type_class;
+    case REAL_TYPE:	   return real_type_class;
+    case COMPLEX_TYPE:	   return complex_type_class;
+    case FUNCTION_TYPE:	   return function_type_class;
+    case METHOD_TYPE:	   return method_type_class;
+    case RECORD_TYPE:	   return record_type_class;
+    case UNION_TYPE:
+    case QUAL_UNION_TYPE:  return union_type_class;
+    case ARRAY_TYPE:	   return (TYPE_STRING_FLAG (type)
+				   ? string_type_class : array_type_class);
+    case LANG_TYPE:	   return lang_type_class;
+    default:		   return no_type_class;
+    }
+}
+
+/* Expand a call to __builtin_classify_type with arguments found in
+   ARGLIST.  */
+
+static rtx
+expand_builtin_classify_type (tree arglist)
+{
+  if (arglist != 0)
+    return GEN_INT (type_to_class (TREE_TYPE (TREE_VALUE (arglist))));
+  return GEN_INT (no_type_class);
+}
+
+/* This helper macro, meant to be used in mathfn_built_in below,
+   determines which among a set of three builtin math functions is
+   appropriate for a given type mode.  The `F' and `L' cases are
+   automatically generated from the `double' case.  */
+#define CASE_MATHFN(BUILT_IN_MATHFN) \
+  case BUILT_IN_MATHFN: case BUILT_IN_MATHFN##F: case BUILT_IN_MATHFN##L: \
+  fcode = BUILT_IN_MATHFN; fcodef = BUILT_IN_MATHFN##F ; \
+  fcodel = BUILT_IN_MATHFN##L ; break;
+
+/* Return mathematic function equivalent to FN but operating directly
+   on TYPE, if available.  If we can't do the conversion, return zero.  */
+tree
+mathfn_built_in (tree type, enum built_in_function fn)
+{
+  enum built_in_function fcode, fcodef, fcodel;
+
+  switch (fn)
+    {
+      CASE_MATHFN (BUILT_IN_ACOS)
+      CASE_MATHFN (BUILT_IN_ACOSH)
+      CASE_MATHFN (BUILT_IN_ASIN)
+      CASE_MATHFN (BUILT_IN_ASINH)
+      CASE_MATHFN (BUILT_IN_ATAN)
+      CASE_MATHFN (BUILT_IN_ATAN2)
+      CASE_MATHFN (BUILT_IN_ATANH)
+      CASE_MATHFN (BUILT_IN_CBRT)
+      CASE_MATHFN (BUILT_IN_CEIL)
+      CASE_MATHFN (BUILT_IN_COPYSIGN)
+      CASE_MATHFN (BUILT_IN_COS)
+      CASE_MATHFN (BUILT_IN_COSH)
+      CASE_MATHFN (BUILT_IN_DREM)
+      CASE_MATHFN (BUILT_IN_ERF)
+      CASE_MATHFN (BUILT_IN_ERFC)
+      CASE_MATHFN (BUILT_IN_EXP)
+      CASE_MATHFN (BUILT_IN_EXP10)
+      CASE_MATHFN (BUILT_IN_EXP2)
+      CASE_MATHFN (BUILT_IN_EXPM1)
+      CASE_MATHFN (BUILT_IN_FABS)
+      CASE_MATHFN (BUILT_IN_FDIM)
+      CASE_MATHFN (BUILT_IN_FLOOR)
+      CASE_MATHFN (BUILT_IN_FMA)
+      CASE_MATHFN (BUILT_IN_FMAX)
+      CASE_MATHFN (BUILT_IN_FMIN)
+      CASE_MATHFN (BUILT_IN_FMOD)
+      CASE_MATHFN (BUILT_IN_FREXP)
+      CASE_MATHFN (BUILT_IN_GAMMA)
+      CASE_MATHFN (BUILT_IN_HUGE_VAL)
+      CASE_MATHFN (BUILT_IN_HYPOT)
+      CASE_MATHFN (BUILT_IN_ILOGB)
+      CASE_MATHFN (BUILT_IN_INF)
+      CASE_MATHFN (BUILT_IN_J0)
+      CASE_MATHFN (BUILT_IN_J1)
+      CASE_MATHFN (BUILT_IN_JN)
+      CASE_MATHFN (BUILT_IN_LCEIL)
+      CASE_MATHFN (BUILT_IN_LDEXP)
+      CASE_MATHFN (BUILT_IN_LFLOOR)
+      CASE_MATHFN (BUILT_IN_LGAMMA)
+      CASE_MATHFN (BUILT_IN_LLCEIL)
+      CASE_MATHFN (BUILT_IN_LLFLOOR)
+      CASE_MATHFN (BUILT_IN_LLRINT)
+      CASE_MATHFN (BUILT_IN_LLROUND)
+      CASE_MATHFN (BUILT_IN_LOG)
+      CASE_MATHFN (BUILT_IN_LOG10)
+      CASE_MATHFN (BUILT_IN_LOG1P)
+      CASE_MATHFN (BUILT_IN_LOG2)
+      CASE_MATHFN (BUILT_IN_LOGB)
+      CASE_MATHFN (BUILT_IN_LRINT)
+      CASE_MATHFN (BUILT_IN_LROUND)
+      CASE_MATHFN (BUILT_IN_MODF)
+      CASE_MATHFN (BUILT_IN_NAN)
+      CASE_MATHFN (BUILT_IN_NANS)
+      CASE_MATHFN (BUILT_IN_NEARBYINT)
+      CASE_MATHFN (BUILT_IN_NEXTAFTER)
+      CASE_MATHFN (BUILT_IN_NEXTTOWARD)
+      CASE_MATHFN (BUILT_IN_POW)
+      CASE_MATHFN (BUILT_IN_POWI)
+      CASE_MATHFN (BUILT_IN_POW10)
+      CASE_MATHFN (BUILT_IN_REMAINDER)
+      CASE_MATHFN (BUILT_IN_REMQUO)
+      CASE_MATHFN (BUILT_IN_RINT)
+      CASE_MATHFN (BUILT_IN_ROUND)
+      CASE_MATHFN (BUILT_IN_SCALB)
+      CASE_MATHFN (BUILT_IN_SCALBLN)
+      CASE_MATHFN (BUILT_IN_SCALBN)
+      CASE_MATHFN (BUILT_IN_SIGNIFICAND)
+      CASE_MATHFN (BUILT_IN_SIN)
+      CASE_MATHFN (BUILT_IN_SINCOS)
+      CASE_MATHFN (BUILT_IN_SINH)
+      CASE_MATHFN (BUILT_IN_SQRT)
+      CASE_MATHFN (BUILT_IN_TAN)
+      CASE_MATHFN (BUILT_IN_TANH)
+      CASE_MATHFN (BUILT_IN_TGAMMA)
+      CASE_MATHFN (BUILT_IN_TRUNC)
+      CASE_MATHFN (BUILT_IN_Y0)
+      CASE_MATHFN (BUILT_IN_Y1)
+      CASE_MATHFN (BUILT_IN_YN)
+
+      default:
+	return 0;
+      }
+
+  if (TYPE_MAIN_VARIANT (type) == double_type_node)
+    return implicit_built_in_decls[fcode];
+  else if (TYPE_MAIN_VARIANT (type) == float_type_node)
+    return implicit_built_in_decls[fcodef];
+  else if (TYPE_MAIN_VARIANT (type) == long_double_type_node)
+    return implicit_built_in_decls[fcodel];
+  else
+    return 0;
+}
+
+/* If errno must be maintained, expand the RTL to check if the result,
+   TARGET, of a built-in function call, EXP, is NaN, and if so set
+   errno to EDOM.  */
+
+static void
+expand_errno_check (tree exp, rtx target)
+{
+  rtx lab = gen_label_rtx ();
+
+  /* Test the result; if it is NaN, set errno=EDOM because
+     the argument was not in the domain.  */
+  emit_cmp_and_jump_insns (target, target, EQ, 0, GET_MODE (target),
+			   0, lab);
+
+#ifdef TARGET_EDOM
+  /* If this built-in doesn't throw an exception, set errno directly.  */
+  if (TREE_NOTHROW (TREE_OPERAND (TREE_OPERAND (exp, 0), 0)))
+    {
+#ifdef GEN_ERRNO_RTX
+      rtx errno_rtx = GEN_ERRNO_RTX;
+#else
+      rtx errno_rtx
+	  = gen_rtx_MEM (word_mode, gen_rtx_SYMBOL_REF (Pmode, "errno"));
+#endif
+      emit_move_insn (errno_rtx, GEN_INT (TARGET_EDOM));
+      emit_label (lab);
+      return;
+    }
+#endif
+
+  /* We can't set errno=EDOM directly; let the library call do it.
+     Pop the arguments right away in case the call gets deleted.  */
+  NO_DEFER_POP;
+  expand_call (exp, target, 0);
+  OK_DEFER_POP;
+  emit_label (lab);
+}
+
+
+/* Expand a call to one of the builtin math functions (sqrt, exp, or log).
+   Return 0 if a normal call should be emitted rather than expanding the
+   function in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing one of EXP's operands.  */
+
+static rtx
+expand_builtin_mathfn (tree exp, rtx target, rtx subtarget)
+{
+  optab builtin_optab;
+  rtx op0, insns, before_call;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  enum machine_mode mode;
+  bool errno_set = false;
+  tree arg, narg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+
+  switch (DECL_FUNCTION_CODE (fndecl))
+    {
+    case BUILT_IN_SQRT:
+    case BUILT_IN_SQRTF:
+    case BUILT_IN_SQRTL:
+      errno_set = ! tree_expr_nonnegative_p (arg);
+      builtin_optab = sqrt_optab;
+      break;
+    case BUILT_IN_EXP:
+    case BUILT_IN_EXPF:
+    case BUILT_IN_EXPL:
+      errno_set = true; builtin_optab = exp_optab; break;
+    case BUILT_IN_EXP10:
+    case BUILT_IN_EXP10F:
+    case BUILT_IN_EXP10L:
+    case BUILT_IN_POW10:
+    case BUILT_IN_POW10F:
+    case BUILT_IN_POW10L:
+      errno_set = true; builtin_optab = exp10_optab; break;
+    case BUILT_IN_EXP2:
+    case BUILT_IN_EXP2F:
+    case BUILT_IN_EXP2L:
+      errno_set = true; builtin_optab = exp2_optab; break;
+    case BUILT_IN_EXPM1:
+    case BUILT_IN_EXPM1F:
+    case BUILT_IN_EXPM1L:
+      errno_set = true; builtin_optab = expm1_optab; break;
+    case BUILT_IN_LOGB:
+    case BUILT_IN_LOGBF:
+    case BUILT_IN_LOGBL:
+      errno_set = true; builtin_optab = logb_optab; break;
+    case BUILT_IN_ILOGB:
+    case BUILT_IN_ILOGBF:
+    case BUILT_IN_ILOGBL:
+      errno_set = true; builtin_optab = ilogb_optab; break;
+    case BUILT_IN_LOG:
+    case BUILT_IN_LOGF:
+    case BUILT_IN_LOGL:
+      errno_set = true; builtin_optab = log_optab; break;
+    case BUILT_IN_LOG10:
+    case BUILT_IN_LOG10F:
+    case BUILT_IN_LOG10L:
+      errno_set = true; builtin_optab = log10_optab; break;
+    case BUILT_IN_LOG2:
+    case BUILT_IN_LOG2F:
+    case BUILT_IN_LOG2L:
+      errno_set = true; builtin_optab = log2_optab; break;
+    case BUILT_IN_LOG1P:
+    case BUILT_IN_LOG1PF:
+    case BUILT_IN_LOG1PL:
+      errno_set = true; builtin_optab = log1p_optab; break;
+    case BUILT_IN_ASIN:
+    case BUILT_IN_ASINF:
+    case BUILT_IN_ASINL:
+      builtin_optab = asin_optab; break;
+    case BUILT_IN_ACOS:
+    case BUILT_IN_ACOSF:
+    case BUILT_IN_ACOSL:
+      builtin_optab = acos_optab; break;
+    case BUILT_IN_TAN:
+    case BUILT_IN_TANF:
+    case BUILT_IN_TANL:
+      builtin_optab = tan_optab; break;
+    case BUILT_IN_ATAN:
+    case BUILT_IN_ATANF:
+    case BUILT_IN_ATANL:
+      builtin_optab = atan_optab; break;
+    case BUILT_IN_FLOOR:
+    case BUILT_IN_FLOORF:
+    case BUILT_IN_FLOORL:
+      builtin_optab = floor_optab; break;
+    case BUILT_IN_CEIL:
+    case BUILT_IN_CEILF:
+    case BUILT_IN_CEILL:
+      builtin_optab = ceil_optab; break;
+    case BUILT_IN_TRUNC:
+    case BUILT_IN_TRUNCF:
+    case BUILT_IN_TRUNCL:
+      builtin_optab = btrunc_optab; break;
+    case BUILT_IN_ROUND:
+    case BUILT_IN_ROUNDF:
+    case BUILT_IN_ROUNDL:
+      builtin_optab = round_optab; break;
+    case BUILT_IN_NEARBYINT:
+    case BUILT_IN_NEARBYINTF:
+    case BUILT_IN_NEARBYINTL:
+      builtin_optab = nearbyint_optab; break;
+    case BUILT_IN_RINT:
+    case BUILT_IN_RINTF:
+    case BUILT_IN_RINTL:
+      builtin_optab = rint_optab; break;
+    case BUILT_IN_LRINT:
+    case BUILT_IN_LRINTF:
+    case BUILT_IN_LRINTL:
+    case BUILT_IN_LLRINT:
+    case BUILT_IN_LLRINTF:
+    case BUILT_IN_LLRINTL:
+      builtin_optab = lrint_optab; break;
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Make a suitable register to place result in.  */
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  if (! flag_errno_math || ! HONOR_NANS (mode))
+    errno_set = false;
+
+  /* Before working hard, check whether the instruction is available.  */
+  if (builtin_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    {
+      target = gen_reg_rtx (mode);
+
+      /* Wrap the computation of the argument in a SAVE_EXPR, as we may
+	 need to expand the argument again.  This way, we will not perform
+	 side-effects more the once.  */
+      narg = builtin_save_expr (arg);
+      if (narg != arg)
+	{
+	  arg = narg;
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  exp = build_function_call_expr (fndecl, arglist);
+	}
+
+      op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+
+      start_sequence ();
+
+      /* Compute into TARGET.
+	 Set TARGET to wherever the result comes back.  */
+      target = expand_unop (mode, builtin_optab, op0, target, 0);
+
+      if (target != 0)
+	{
+	  if (errno_set)
+	    expand_errno_check (exp, target);
+
+	  /* Output the entire sequence.  */
+	  insns = get_insns ();
+	  end_sequence ();
+	  emit_insn (insns);
+	  return target;
+	}
+
+      /* If we were unable to expand via the builtin, stop the sequence
+	 (without outputting the insns) and call to the library function
+	 with the stabilized argument list.  */
+      end_sequence ();
+    }
+
+  before_call = get_last_insn ();
+
+  target = expand_call (exp, target, target == const0_rtx);
+
+  /* If this is a sqrt operation and we don't care about errno, try to
+     attach a REG_EQUAL note with a SQRT rtx to the emitted libcall.
+     This allows the semantics of the libcall to be visible to the RTL
+     optimizers.  */
+  if (builtin_optab == sqrt_optab && !errno_set)
+    {
+      /* Search backwards through the insns emitted by expand_call looking
+	 for the instruction with the REG_RETVAL note.  */
+      rtx last = get_last_insn ();
+      while (last != before_call)
+	{
+	  if (find_reg_note (last, REG_RETVAL, NULL))
+	    {
+	      rtx note = find_reg_note (last, REG_EQUAL, NULL);
+	      /* Check that the REQ_EQUAL note is an EXPR_LIST with
+		 two elements, i.e. symbol_ref(sqrt) and the operand.  */
+	      if (note
+		  && GET_CODE (note) == EXPR_LIST
+		  && GET_CODE (XEXP (note, 0)) == EXPR_LIST
+		  && XEXP (XEXP (note, 0), 1) != NULL_RTX
+		  && XEXP (XEXP (XEXP (note, 0), 1), 1) == NULL_RTX)
+		{
+		  rtx operand = XEXP (XEXP (XEXP (note, 0), 1), 0);
+		  /* Check operand is a register with expected mode.  */
+		  if (operand
+		      && REG_P (operand)
+		      && GET_MODE (operand) == mode)
+		    {
+		      /* Replace the REG_EQUAL note with a SQRT rtx.  */
+		      rtx equiv = gen_rtx_SQRT (mode, operand);
+		      set_unique_reg_note (last, REG_EQUAL, equiv);
+		    }
+		}
+	      break;
+	    }
+	  last = PREV_INSN (last);
+	}
+    }
+
+  return target;
+}
+
+/* Expand a call to the builtin binary math functions (pow and atan2).
+   Return 0 if a normal call should be emitted rather than expanding the
+   function in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing one of EXP's
+   operands.  */
+
+static rtx
+expand_builtin_mathfn_2 (tree exp, rtx target, rtx subtarget)
+{
+  optab builtin_optab;
+  rtx op0, op1, insns;
+  int op1_type = REAL_TYPE;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree arg0, arg1, temp, narg;
+  enum machine_mode mode;
+  bool errno_set = true;
+  bool stable = true;
+
+  if ((DECL_FUNCTION_CODE (fndecl) == BUILT_IN_LDEXP)
+      || (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_LDEXPF)
+      || (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_LDEXPL))
+    op1_type = INTEGER_TYPE;
+
+  if (!validate_arglist (arglist, REAL_TYPE, op1_type, VOID_TYPE))
+    return 0;
+
+  arg0 = TREE_VALUE (arglist);
+  arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  switch (DECL_FUNCTION_CODE (fndecl))
+    {
+    case BUILT_IN_POW:
+    case BUILT_IN_POWF:
+    case BUILT_IN_POWL:
+      builtin_optab = pow_optab; break;
+    case BUILT_IN_ATAN2:
+    case BUILT_IN_ATAN2F:
+    case BUILT_IN_ATAN2L:
+      builtin_optab = atan2_optab; break;
+    case BUILT_IN_LDEXP:
+    case BUILT_IN_LDEXPF:
+    case BUILT_IN_LDEXPL:
+      builtin_optab = ldexp_optab; break;
+    case BUILT_IN_FMOD:
+    case BUILT_IN_FMODF:
+    case BUILT_IN_FMODL:
+      builtin_optab = fmod_optab; break;
+    case BUILT_IN_DREM:
+    case BUILT_IN_DREMF:
+    case BUILT_IN_DREML:
+      builtin_optab = drem_optab; break;
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Make a suitable register to place result in.  */
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  /* Before working hard, check whether the instruction is available.  */
+  if (builtin_optab->handlers[(int) mode].insn_code == CODE_FOR_nothing)
+    return 0;
+
+  target = gen_reg_rtx (mode);
+
+  if (! flag_errno_math || ! HONOR_NANS (mode))
+    errno_set = false;
+
+  /* Always stabilize the argument list.  */
+  narg = builtin_save_expr (arg1);
+  if (narg != arg1)
+    {
+      arg1 = narg;
+      temp = build_tree_list (NULL_TREE, narg);
+      stable = false;
+    }
+  else
+    temp = TREE_CHAIN (arglist);
+
+  narg = builtin_save_expr (arg0);
+  if (narg != arg0)
+    {
+      arg0 = narg;
+      arglist = tree_cons (NULL_TREE, narg, temp);
+      stable = false;
+    }
+  else if (! stable)
+    arglist = tree_cons (NULL_TREE, arg0, temp);
+
+  if (! stable)
+    exp = build_function_call_expr (fndecl, arglist);
+
+  op0 = expand_expr (arg0, subtarget, VOIDmode, 0);
+  op1 = expand_expr (arg1, 0, VOIDmode, 0);
+
+  start_sequence ();
+
+  /* Compute into TARGET.
+     Set TARGET to wherever the result comes back.  */
+  target = expand_binop (mode, builtin_optab, op0, op1,
+			 target, 0, OPTAB_DIRECT);
+
+  /* If we were unable to expand via the builtin, stop the sequence
+     (without outputting the insns) and call to the library function
+     with the stabilized argument list.  */
+  if (target == 0)
+    {
+      end_sequence ();
+      return expand_call (exp, target, target == const0_rtx);
+    }
+
+  if (errno_set)
+    expand_errno_check (exp, target);
+
+  /* Output the entire sequence.  */
+  insns = get_insns ();
+  end_sequence ();
+  emit_insn (insns);
+
+  return target;
+}
+
+/* Expand a call to the builtin sin and cos math functions.
+   Return 0 if a normal call should be emitted rather than expanding the
+   function in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing one of EXP's
+   operands.  */
+
+static rtx
+expand_builtin_mathfn_3 (tree exp, rtx target, rtx subtarget)
+{
+  optab builtin_optab;
+  rtx op0, insns;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  enum machine_mode mode;
+  bool errno_set = false;
+  tree arg, narg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+
+  switch (DECL_FUNCTION_CODE (fndecl))
+    {
+    case BUILT_IN_SIN:
+    case BUILT_IN_SINF:
+    case BUILT_IN_SINL:
+    case BUILT_IN_COS:
+    case BUILT_IN_COSF:
+    case BUILT_IN_COSL:
+      builtin_optab = sincos_optab; break;
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Make a suitable register to place result in.  */
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  if (! flag_errno_math || ! HONOR_NANS (mode))
+    errno_set = false;
+
+  /* Check if sincos insn is available, otherwise fallback
+     to sin or cos insn.  */
+  if (builtin_optab->handlers[(int) mode].insn_code == CODE_FOR_nothing) {
+    switch (DECL_FUNCTION_CODE (fndecl))
+      {
+      case BUILT_IN_SIN:
+      case BUILT_IN_SINF:
+      case BUILT_IN_SINL:
+	builtin_optab = sin_optab; break;
+      case BUILT_IN_COS:
+      case BUILT_IN_COSF:
+      case BUILT_IN_COSL:
+	builtin_optab = cos_optab; break;
+      default:
+	gcc_unreachable ();
+      }
+  }
+
+  /* Before working hard, check whether the instruction is available.  */
+  if (builtin_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    {
+      target = gen_reg_rtx (mode);
+
+      /* Wrap the computation of the argument in a SAVE_EXPR, as we may
+	 need to expand the argument again.  This way, we will not perform
+	 side-effects more the once.  */
+      narg = save_expr (arg);
+      if (narg != arg)
+	{
+	  arg = narg;
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  exp = build_function_call_expr (fndecl, arglist);
+	}
+
+      op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+
+      start_sequence ();
+
+      /* Compute into TARGET.
+	 Set TARGET to wherever the result comes back.  */
+      if (builtin_optab == sincos_optab)
+	{
+	  int result;
+
+	  switch (DECL_FUNCTION_CODE (fndecl))
+	    {
+	    case BUILT_IN_SIN:
+	    case BUILT_IN_SINF:
+	    case BUILT_IN_SINL:
+	      result = expand_twoval_unop (builtin_optab, op0, 0, target, 0);
+	      break;
+	    case BUILT_IN_COS:
+	    case BUILT_IN_COSF:
+	    case BUILT_IN_COSL:
+	      result = expand_twoval_unop (builtin_optab, op0, target, 0, 0);
+	      break;
+	    default:
+	      gcc_unreachable ();
+	    }
+	  gcc_assert (result);
+	}
+      else
+	{
+	  target = expand_unop (mode, builtin_optab, op0, target, 0);
+	}
+
+      if (target != 0)
+	{
+	  if (errno_set)
+	    expand_errno_check (exp, target);
+
+	  /* Output the entire sequence.  */
+	  insns = get_insns ();
+	  end_sequence ();
+	  emit_insn (insns);
+	  return target;
+	}
+
+      /* If we were unable to expand via the builtin, stop the sequence
+	 (without outputting the insns) and call to the library function
+	 with the stabilized argument list.  */
+      end_sequence ();
+    }
+
+  target = expand_call (exp, target, target == const0_rtx);
+
+  return target;
+}
+
+/* Expand a call to one of the builtin rounding functions (lfloor).
+   If expanding via optab fails, lower expression to (int)(floor(x)).
+   EXP is the expression that is a call to the builtin function;
+   if convenient, the result should be placed in TARGET.  SUBTARGET may
+   be used as the target for computing one of EXP's operands.  */
+
+static rtx
+expand_builtin_int_roundingfn (tree exp, rtx target, rtx subtarget)
+{
+  optab builtin_optab;
+  rtx op0, insns, tmp;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  enum built_in_function fallback_fn;
+  tree fallback_fndecl;
+  enum machine_mode mode;
+  tree arg, narg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    gcc_unreachable ();
+
+  arg = TREE_VALUE (arglist);
+
+  switch (DECL_FUNCTION_CODE (fndecl))
+    {
+    case BUILT_IN_LCEIL:
+    case BUILT_IN_LCEILF:
+    case BUILT_IN_LCEILL:
+    case BUILT_IN_LLCEIL:
+    case BUILT_IN_LLCEILF:
+    case BUILT_IN_LLCEILL:
+      builtin_optab = lceil_optab;
+      fallback_fn = BUILT_IN_CEIL;
+      break;
+
+    case BUILT_IN_LFLOOR:
+    case BUILT_IN_LFLOORF:
+    case BUILT_IN_LFLOORL:
+    case BUILT_IN_LLFLOOR:
+    case BUILT_IN_LLFLOORF:
+    case BUILT_IN_LLFLOORL:
+      builtin_optab = lfloor_optab;
+      fallback_fn = BUILT_IN_FLOOR;
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Make a suitable register to place result in.  */
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  /* Before working hard, check whether the instruction is available.  */
+  if (builtin_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    {
+      target = gen_reg_rtx (mode);
+
+      /* Wrap the computation of the argument in a SAVE_EXPR, as we may
+	 need to expand the argument again.  This way, we will not perform
+	 side-effects more the once.  */
+      narg = builtin_save_expr (arg);
+      if (narg != arg)
+	{
+	  arg = narg;
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  exp = build_function_call_expr (fndecl, arglist);
+	}
+
+      op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+
+      start_sequence ();
+
+      /* Compute into TARGET.
+	 Set TARGET to wherever the result comes back.  */
+      target = expand_unop (mode, builtin_optab, op0, target, 0);
+
+      if (target != 0)
+	{
+	  /* Output the entire sequence.  */
+	  insns = get_insns ();
+	  end_sequence ();
+	  emit_insn (insns);
+	  return target;
+	}
+
+      /* If we were unable to expand via the builtin, stop the sequence
+	 (without outputting the insns).  */
+      end_sequence ();
+    }
+
+  /* Fall back to floating point rounding optab.  */
+  fallback_fndecl = mathfn_built_in (TREE_TYPE (arg), fallback_fn);
+  /* We shouldn't get here on targets without TARGET_C99_FUNCTIONS.
+     ??? Perhaps convert (int)floorf(x) into (int)floor((double)x).  */
+  gcc_assert (fallback_fndecl != NULL_TREE);
+  exp = build_function_call_expr (fallback_fndecl, arglist);
+
+  tmp = expand_builtin_mathfn (exp, NULL_RTX, NULL_RTX);
+
+  /* Truncate the result of floating point optab to integer
+     via expand_fix ().  */
+  target = gen_reg_rtx (mode);
+  expand_fix (target, tmp, 0);
+
+  return target;
+}
+
+/* To evaluate powi(x,n), the floating point value x raised to the
+   constant integer exponent n, we use a hybrid algorithm that
+   combines the "window method" with look-up tables.  For an
+   introduction to exponentiation algorithms and "addition chains",
+   see section 4.6.3, "Evaluation of Powers" of Donald E. Knuth,
+   "Seminumerical Algorithms", Vol. 2, "The Art of Computer Programming",
+   3rd Edition, 1998, and Daniel M. Gordon, "A Survey of Fast Exponentiation
+   Methods", Journal of Algorithms, Vol. 27, pp. 129-146, 1998.  */
+
+/* Provide a default value for POWI_MAX_MULTS, the maximum number of
+   multiplications to inline before calling the system library's pow
+   function.  powi(x,n) requires at worst 2*bits(n)-2 multiplications,
+   so this default never requires calling pow, powf or powl.  */
+
+#ifndef POWI_MAX_MULTS
+#define POWI_MAX_MULTS  (2*HOST_BITS_PER_WIDE_INT-2)
+#endif
+
+/* The size of the "optimal power tree" lookup table.  All
+   exponents less than this value are simply looked up in the
+   powi_table below.  This threshold is also used to size the
+   cache of pseudo registers that hold intermediate results.  */
+#define POWI_TABLE_SIZE 256
+
+/* The size, in bits of the window, used in the "window method"
+   exponentiation algorithm.  This is equivalent to a radix of
+   (1<<POWI_WINDOW_SIZE) in the corresponding "m-ary method".  */
+#define POWI_WINDOW_SIZE 3
+
+/* The following table is an efficient representation of an
+   "optimal power tree".  For each value, i, the corresponding
+   value, j, in the table states than an optimal evaluation
+   sequence for calculating pow(x,i) can be found by evaluating
+   pow(x,j)*pow(x,i-j).  An optimal power tree for the first
+   100 integers is given in Knuth's "Seminumerical algorithms".  */
+
+static const unsigned char powi_table[POWI_TABLE_SIZE] =
+  {
+      0,   1,   1,   2,   2,   3,   3,   4,  /*   0 -   7 */
+      4,   6,   5,   6,   6,  10,   7,   9,  /*   8 -  15 */
+      8,  16,   9,  16,  10,  12,  11,  13,  /*  16 -  23 */
+     12,  17,  13,  18,  14,  24,  15,  26,  /*  24 -  31 */
+     16,  17,  17,  19,  18,  33,  19,  26,  /*  32 -  39 */
+     20,  25,  21,  40,  22,  27,  23,  44,  /*  40 -  47 */
+     24,  32,  25,  34,  26,  29,  27,  44,  /*  48 -  55 */
+     28,  31,  29,  34,  30,  60,  31,  36,  /*  56 -  63 */
+     32,  64,  33,  34,  34,  46,  35,  37,  /*  64 -  71 */
+     36,  65,  37,  50,  38,  48,  39,  69,  /*  72 -  79 */
+     40,  49,  41,  43,  42,  51,  43,  58,  /*  80 -  87 */
+     44,  64,  45,  47,  46,  59,  47,  76,  /*  88 -  95 */
+     48,  65,  49,  66,  50,  67,  51,  66,  /*  96 - 103 */
+     52,  70,  53,  74,  54, 104,  55,  74,  /* 104 - 111 */
+     56,  64,  57,  69,  58,  78,  59,  68,  /* 112 - 119 */
+     60,  61,  61,  80,  62,  75,  63,  68,  /* 120 - 127 */
+     64,  65,  65, 128,  66, 129,  67,  90,  /* 128 - 135 */
+     68,  73,  69, 131,  70,  94,  71,  88,  /* 136 - 143 */
+     72, 128,  73,  98,  74, 132,  75, 121,  /* 144 - 151 */
+     76, 102,  77, 124,  78, 132,  79, 106,  /* 152 - 159 */
+     80,  97,  81, 160,  82,  99,  83, 134,  /* 160 - 167 */
+     84,  86,  85,  95,  86, 160,  87, 100,  /* 168 - 175 */
+     88, 113,  89,  98,  90, 107,  91, 122,  /* 176 - 183 */
+     92, 111,  93, 102,  94, 126,  95, 150,  /* 184 - 191 */
+     96, 128,  97, 130,  98, 133,  99, 195,  /* 192 - 199 */
+    100, 128, 101, 123, 102, 164, 103, 138,  /* 200 - 207 */
+    104, 145, 105, 146, 106, 109, 107, 149,  /* 208 - 215 */
+    108, 200, 109, 146, 110, 170, 111, 157,  /* 216 - 223 */
+    112, 128, 113, 130, 114, 182, 115, 132,  /* 224 - 231 */
+    116, 200, 117, 132, 118, 158, 119, 206,  /* 232 - 239 */
+    120, 240, 121, 162, 122, 147, 123, 152,  /* 240 - 247 */
+    124, 166, 125, 214, 126, 138, 127, 153,  /* 248 - 255 */
+  };
+
+
+/* Return the number of multiplications required to calculate
+   powi(x,n) where n is less than POWI_TABLE_SIZE.  This is a
+   subroutine of powi_cost.  CACHE is an array indicating
+   which exponents have already been calculated.  */
+
+static int
+powi_lookup_cost (unsigned HOST_WIDE_INT n, bool *cache)
+{
+  /* If we've already calculated this exponent, then this evaluation
+     doesn't require any additional multiplications.  */
+  if (cache[n])
+    return 0;
+
+  cache[n] = true;
+  return powi_lookup_cost (n - powi_table[n], cache)
+	 + powi_lookup_cost (powi_table[n], cache) + 1;
+}
+
+/* Return the number of multiplications required to calculate
+   powi(x,n) for an arbitrary x, given the exponent N.  This
+   function needs to be kept in sync with expand_powi below.  */
+
+static int
+powi_cost (HOST_WIDE_INT n)
+{
+  bool cache[POWI_TABLE_SIZE];
+  unsigned HOST_WIDE_INT digit;
+  unsigned HOST_WIDE_INT val;
+  int result;
+
+  if (n == 0)
+    return 0;
+
+  /* Ignore the reciprocal when calculating the cost.  */
+  val = (n < 0) ? -n : n;
+
+  /* Initialize the exponent cache.  */
+  memset (cache, 0, POWI_TABLE_SIZE * sizeof (bool));
+  cache[1] = true;
+
+  result = 0;
+
+  while (val >= POWI_TABLE_SIZE)
+    {
+      if (val & 1)
+	{
+	  digit = val & ((1 << POWI_WINDOW_SIZE) - 1);
+	  result += powi_lookup_cost (digit, cache)
+		    + POWI_WINDOW_SIZE + 1;
+	  val >>= POWI_WINDOW_SIZE;
+	}
+      else
+	{
+	  val >>= 1;
+	  result++;
+	}
+    }
+
+  return result + powi_lookup_cost (val, cache);
+}
+
+/* Recursive subroutine of expand_powi.  This function takes the array,
+   CACHE, of already calculated exponents and an exponent N and returns
+   an RTX that corresponds to CACHE[1]**N, as calculated in mode MODE.  */
+
+static rtx
+expand_powi_1 (enum machine_mode mode, unsigned HOST_WIDE_INT n, rtx *cache)
+{
+  unsigned HOST_WIDE_INT digit;
+  rtx target, result;
+  rtx op0, op1;
+
+  if (n < POWI_TABLE_SIZE)
+    {
+      if (cache[n])
+        return cache[n];
+
+      target = gen_reg_rtx (mode);
+      cache[n] = target;
+
+      op0 = expand_powi_1 (mode, n - powi_table[n], cache);
+      op1 = expand_powi_1 (mode, powi_table[n], cache);
+    }
+  else if (n & 1)
+    {
+      target = gen_reg_rtx (mode);
+      digit = n & ((1 << POWI_WINDOW_SIZE) - 1);
+      op0 = expand_powi_1 (mode, n - digit, cache);
+      op1 = expand_powi_1 (mode, digit, cache);
+    }
+  else
+    {
+      target = gen_reg_rtx (mode);
+      op0 = expand_powi_1 (mode, n >> 1, cache);
+      op1 = op0;
+    }
+
+  result = expand_mult (mode, op0, op1, target, 0);
+  if (result != target)
+    emit_move_insn (target, result);
+  return target;
+}
+
+/* Expand the RTL to evaluate powi(x,n) in mode MODE.  X is the
+   floating point operand in mode MODE, and N is the exponent.  This
+   function needs to be kept in sync with powi_cost above.  */
+
+static rtx
+expand_powi (rtx x, enum machine_mode mode, HOST_WIDE_INT n)
+{
+  unsigned HOST_WIDE_INT val;
+  rtx cache[POWI_TABLE_SIZE];
+  rtx result;
+
+  if (n == 0)
+    return CONST1_RTX (mode);
+
+  val = (n < 0) ? -n : n;
+
+  memset (cache, 0, sizeof (cache));
+  cache[1] = x;
+
+  result = expand_powi_1 (mode, (n < 0) ? -n : n, cache);
+
+  /* If the original exponent was negative, reciprocate the result.  */
+  if (n < 0)
+    result = expand_binop (mode, sdiv_optab, CONST1_RTX (mode),
+			   result, NULL_RTX, 0, OPTAB_LIB_WIDEN);
+
+  return result;
+}
+
+/* Expand a call to the pow built-in mathematical function.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.  */
+
+static rtx
+expand_builtin_pow (tree exp, rtx target, rtx subtarget)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree arg0, arg1;
+
+  if (! validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg0 = TREE_VALUE (arglist);
+  arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  if (TREE_CODE (arg1) == REAL_CST
+      && ! TREE_CONSTANT_OVERFLOW (arg1))
+    {
+      REAL_VALUE_TYPE cint;
+      REAL_VALUE_TYPE c;
+      HOST_WIDE_INT n;
+
+      c = TREE_REAL_CST (arg1);
+      n = real_to_integer (&c);
+      real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);
+      if (real_identical (&c, &cint))
+	{
+	  /* If the exponent is -1, 0, 1 or 2, then expand_powi is exact.
+	     Otherwise, check the number of multiplications required.
+	     Note that pow never sets errno for an integer exponent.  */
+	  if ((n >= -1 && n <= 2)
+	      || (flag_unsafe_math_optimizations
+		  && ! optimize_size
+		  && powi_cost (n) <= POWI_MAX_MULTS))
+	    {
+	      enum machine_mode mode = TYPE_MODE (TREE_TYPE (exp));
+	      rtx op = expand_expr (arg0, subtarget, VOIDmode, 0);
+	      op = force_reg (mode, op);
+	      return expand_powi (op, mode, n);
+	    }
+	}
+    }
+
+  if (! flag_unsafe_math_optimizations)
+    return NULL_RTX;
+  return expand_builtin_mathfn_2 (exp, target, subtarget);
+}
+
+/* Expand a call to the powi built-in mathematical function.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.  */
+
+static rtx
+expand_builtin_powi (tree exp, rtx target, rtx subtarget)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree arg0, arg1;
+  rtx op0, op1;
+  enum machine_mode mode;
+  enum machine_mode mode2;
+
+  if (! validate_arglist (arglist, REAL_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg0 = TREE_VALUE (arglist);
+  arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  /* Handle constant power.  */
+
+  if (TREE_CODE (arg1) == INTEGER_CST
+      && ! TREE_CONSTANT_OVERFLOW (arg1))
+    {
+      HOST_WIDE_INT n = TREE_INT_CST_LOW (arg1);
+
+      /* If the exponent is -1, 0, 1 or 2, then expand_powi is exact.
+	 Otherwise, check the number of multiplications required.  */
+      if ((TREE_INT_CST_HIGH (arg1) == 0
+	   || TREE_INT_CST_HIGH (arg1) == -1)
+	  && ((n >= -1 && n <= 2)
+	      || (! optimize_size
+		  && powi_cost (n) <= POWI_MAX_MULTS)))
+	{
+	  op0 = expand_expr (arg0, subtarget, VOIDmode, 0);
+	  op0 = force_reg (mode, op0);
+	  return expand_powi (op0, mode, n);
+	}
+    }
+
+  /* Emit a libcall to libgcc.  */
+
+  /* Mode of the 2nd argument must match that of an int. */
+  mode2 = mode_for_size (INT_TYPE_SIZE, MODE_INT, 0);
+
+  if (target == NULL_RTX)
+    target = gen_reg_rtx (mode);
+
+  op0 = expand_expr (arg0, subtarget, mode, 0);
+  if (GET_MODE (op0) != mode)
+    op0 = convert_to_mode (mode, op0, 0);
+  op1 = expand_expr (arg1, 0, mode2, 0);
+  if (GET_MODE (op1) != mode2)
+    op1 = convert_to_mode (mode2, op1, 0);
+
+  target = emit_library_call_value (powi_optab->handlers[(int) mode].libfunc,
+				    target, LCT_CONST_MAKE_BLOCK, mode, 2,
+				    op0, mode, op1, mode2);
+
+  return target;
+}
+
+/* Expand expression EXP which is a call to the strlen builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise
+   try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strlen (tree arglist, rtx target,
+		       enum machine_mode target_mode)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      rtx pat;
+      tree len, src = TREE_VALUE (arglist);
+      rtx result, src_reg, char_rtx, before_strlen;
+      enum machine_mode insn_mode = target_mode, char_mode;
+      enum insn_code icode = CODE_FOR_nothing;
+      int align;
+
+      /* If the length can be computed at compile-time, return it.  */
+      len = c_strlen (src, 0);
+      if (len)
+	return expand_expr (len, target, target_mode, EXPAND_NORMAL);
+
+      /* If the length can be computed at compile-time and is constant
+	 integer, but there are side-effects in src, evaluate
+	 src for side-effects, then return len.
+	 E.g. x = strlen (i++ ? "xfoo" + 1 : "bar");
+	 can be optimized into: i++; x = 3;  */
+      len = c_strlen (src, 1);
+      if (len && TREE_CODE (len) == INTEGER_CST)
+	{
+	  expand_expr (src, const0_rtx, VOIDmode, EXPAND_NORMAL);
+	  return expand_expr (len, target, target_mode, EXPAND_NORMAL);
+	}
+
+      align = get_pointer_alignment (src, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+
+      /* If SRC is not a pointer type, don't do this operation inline.  */
+      if (align == 0)
+	return 0;
+
+      /* Bail out if we can't compute strlen in the right mode.  */
+      while (insn_mode != VOIDmode)
+	{
+	  icode = strlen_optab->handlers[(int) insn_mode].insn_code;
+	  if (icode != CODE_FOR_nothing)
+	    break;
+
+	  insn_mode = GET_MODE_WIDER_MODE (insn_mode);
+	}
+      if (insn_mode == VOIDmode)
+	return 0;
+
+      /* Make a place to write the result of the instruction.  */
+      result = target;
+      if (! (result != 0
+	     && REG_P (result)
+	     && GET_MODE (result) == insn_mode
+	     && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+	result = gen_reg_rtx (insn_mode);
+
+      /* Make a place to hold the source address.  We will not expand
+	 the actual source until we are sure that the expansion will
+	 not fail -- there are trees that cannot be expanded twice.  */
+      src_reg = gen_reg_rtx (Pmode);
+
+      /* Mark the beginning of the strlen sequence so we can emit the
+	 source operand later.  */
+      before_strlen = get_last_insn ();
+
+      char_rtx = const0_rtx;
+      char_mode = insn_data[(int) icode].operand[2].mode;
+      if (! (*insn_data[(int) icode].operand[2].predicate) (char_rtx,
+							    char_mode))
+	char_rtx = copy_to_mode_reg (char_mode, char_rtx);
+
+      pat = GEN_FCN (icode) (result, gen_rtx_MEM (BLKmode, src_reg),
+			     char_rtx, GEN_INT (align));
+      if (! pat)
+	return 0;
+      emit_insn (pat);
+
+      /* Now that we are assured of success, expand the source.  */
+      start_sequence ();
+      pat = expand_expr (src, src_reg, ptr_mode, EXPAND_NORMAL);
+      if (pat != src_reg)
+	emit_move_insn (src_reg, pat);
+      pat = get_insns ();
+      end_sequence ();
+
+      if (before_strlen)
+	emit_insn_after (pat, before_strlen);
+      else
+	emit_insn_before (pat, get_insns ());
+
+      /* Return the value in the proper mode for this function.  */
+      if (GET_MODE (result) == target_mode)
+	target = result;
+      else if (target != 0)
+	convert_move (target, result, 0);
+      else
+	target = convert_to_mode (target_mode, result, 0);
+
+      return target;
+    }
+}
+
+/* Expand a call to the strstr builtin.  Return 0 if we failed the
+   caller should emit a normal call, otherwise try to get the result
+   in TARGET, if convenient (and in mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_strstr (tree arglist, tree type, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strstr (arglist, type);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand a call to the strchr builtin.  Return 0 if we failed the
+   caller should emit a normal call, otherwise try to get the result
+   in TARGET, if convenient (and in mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_strchr (tree arglist, tree type, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strchr (arglist, type);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      /* FIXME: Should use strchrM optab so that ports can optimize this.  */
+    }
+  return 0;
+}
+
+/* Expand a call to the strrchr builtin.  Return 0 if we failed the
+   caller should emit a normal call, otherwise try to get the result
+   in TARGET, if convenient (and in mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_strrchr (tree arglist, tree type, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strrchr (arglist, type);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand a call to the strpbrk builtin.  Return 0 if we failed the
+   caller should emit a normal call, otherwise try to get the result
+   in TARGET, if convenient (and in mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_strpbrk (tree arglist, tree type, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strpbrk (arglist, type);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
+   bytes from constant string DATA + OFFSET and return it as target
+   constant.  */
+
+static rtx
+builtin_memcpy_read_str (void *data, HOST_WIDE_INT offset,
+			 enum machine_mode mode)
+{
+  const char *str = (const char *) data;
+
+  gcc_assert (offset >= 0
+	      && ((unsigned HOST_WIDE_INT) offset + GET_MODE_SIZE (mode)
+		  <= strlen (str) + 1));
+
+  return c_readstr (str + offset, mode);
+}
+
+/* Expand a call to the memcpy builtin, with arguments in ARGLIST.
+   Return 0 if we failed, the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient (and in
+   mode MODE if that's convenient).  */
+static rtx
+expand_builtin_memcpy (tree exp, rtx target, enum machine_mode mode)
+{
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      const char *src_str;
+      unsigned int src_align = get_pointer_alignment (src, BIGGEST_ALIGNMENT);
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+      rtx dest_mem, src_mem, dest_addr, len_rtx;
+      tree result = fold_builtin_memcpy (fndecl, arglist);
+
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      /* If DEST is not a pointer type, call the normal function.  */
+      if (dest_align == 0)
+	return 0;
+
+      /* If either SRC is not a pointer type, don't do this
+         operation in-line.  */
+      if (src_align == 0)
+	return 0;
+
+      dest_mem = get_memory_rtx (dest, len);
+      set_mem_align (dest_mem, dest_align);
+      len_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+      src_str = c_getstr (src);
+
+      /* If SRC is a string constant and block move would be done
+	 by pieces, we can avoid loading the string from memory
+	 and only stored the computed constants.  */
+      if (src_str
+	  && GET_CODE (len_rtx) == CONST_INT
+	  && (unsigned HOST_WIDE_INT) INTVAL (len_rtx) <= strlen (src_str) + 1
+	  && can_store_by_pieces (INTVAL (len_rtx), builtin_memcpy_read_str,
+				  (void *) src_str, dest_align))
+	{
+	  dest_mem = store_by_pieces (dest_mem, INTVAL (len_rtx),
+				      builtin_memcpy_read_str,
+				      (void *) src_str, dest_align, 0);
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      src_mem = get_memory_rtx (src, len);
+      set_mem_align (src_mem, src_align);
+
+      /* Copy word part most expediently.  */
+      dest_addr = emit_block_move (dest_mem, src_mem, len_rtx,
+				   CALL_EXPR_TAILCALL (exp)
+				   ? BLOCK_OP_TAILCALL : BLOCK_OP_NORMAL);
+
+      if (dest_addr == 0)
+	{
+	  dest_addr = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_addr = convert_memory_address (ptr_mode, dest_addr);
+	}
+      return dest_addr;
+    }
+}
+
+/* Expand a call to the mempcpy builtin, with arguments in ARGLIST.
+   Return 0 if we failed; the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient (and in
+   mode MODE if that's convenient).  If ENDP is 0 return the
+   destination pointer, if ENDP is 1 return the end pointer ala
+   mempcpy, and if ENDP is 2 return the end pointer minus one ala
+   stpcpy.  */
+
+static rtx
+expand_builtin_mempcpy (tree arglist, tree type, rtx target, enum machine_mode mode,
+			int endp)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  /* If return value is ignored, transform mempcpy into memcpy.  */
+  else if (target == const0_rtx)
+    {
+      tree fn = implicit_built_in_decls[BUILT_IN_MEMCPY];
+
+      if (!fn)
+	return 0;
+
+      return expand_expr (build_function_call_expr (fn, arglist),
+			  target, mode, EXPAND_NORMAL);
+    }
+  else
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      const char *src_str;
+      unsigned int src_align = get_pointer_alignment (src, BIGGEST_ALIGNMENT);
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+      rtx dest_mem, src_mem, len_rtx;
+      tree result = fold_builtin_mempcpy (arglist, type, endp);
+
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+      
+      /* If either SRC or DEST is not a pointer type, don't do this
+         operation in-line.  */
+      if (dest_align == 0 || src_align == 0)
+	return 0;
+
+      /* If LEN is not constant, call the normal function.  */
+      if (! host_integerp (len, 1))
+	return 0;
+
+      len_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+      src_str = c_getstr (src);
+
+      /* If SRC is a string constant and block move would be done
+	 by pieces, we can avoid loading the string from memory
+	 and only stored the computed constants.  */
+      if (src_str
+	  && GET_CODE (len_rtx) == CONST_INT
+	  && (unsigned HOST_WIDE_INT) INTVAL (len_rtx) <= strlen (src_str) + 1
+	  && can_store_by_pieces (INTVAL (len_rtx), builtin_memcpy_read_str,
+				  (void *) src_str, dest_align))
+	{
+	  dest_mem = get_memory_rtx (dest, len);
+	  set_mem_align (dest_mem, dest_align);
+	  dest_mem = store_by_pieces (dest_mem, INTVAL (len_rtx),
+				      builtin_memcpy_read_str,
+				      (void *) src_str, dest_align, endp);
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      if (GET_CODE (len_rtx) == CONST_INT
+	  && can_move_by_pieces (INTVAL (len_rtx),
+				 MIN (dest_align, src_align)))
+	{
+	  dest_mem = get_memory_rtx (dest, len);
+	  set_mem_align (dest_mem, dest_align);
+	  src_mem = get_memory_rtx (src, len);
+	  set_mem_align (src_mem, src_align);
+	  dest_mem = move_by_pieces (dest_mem, src_mem, INTVAL (len_rtx),
+				     MIN (dest_align, src_align), endp);
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      return 0;
+    }
+}
+
+/* Expand expression EXP, which is a call to the memmove builtin.  Return 0
+   if we failed; the caller should emit a normal call.  */
+
+static rtx
+expand_builtin_memmove (tree arglist, tree type, rtx target,
+			enum machine_mode mode, tree orig_exp)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+      unsigned int src_align = get_pointer_alignment (src, BIGGEST_ALIGNMENT);
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+      tree result = fold_builtin_memmove (arglist, type);
+
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      /* If DEST is not a pointer type, call the normal function.  */
+      if (dest_align == 0)
+	return 0;
+
+      /* If either SRC is not a pointer type, don't do this
+         operation in-line.  */
+      if (src_align == 0)
+	return 0;
+
+      /* If src is categorized for a readonly section we can use
+	 normal memcpy.  */
+      if (readonly_data_expr (src))
+        {
+	  tree fn = implicit_built_in_decls[BUILT_IN_MEMCPY];
+	  if (!fn)
+	    return 0;
+	  fn = build_function_call_expr (fn, arglist);
+	  if (TREE_CODE (fn) == CALL_EXPR)
+	    CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (orig_exp);
+	  return expand_expr (fn, target, mode, EXPAND_NORMAL);
+	}
+
+      /* If length is 1 and we can expand memcpy call inline,
+	 it is ok to use memcpy as well.  */
+      if (integer_onep (len))
+        {
+	  rtx ret = expand_builtin_mempcpy (arglist, type, target, mode,
+					    /*endp=*/0);
+	  if (ret)
+	    return ret;
+        }
+
+      /* Otherwise, call the normal function.  */
+      return 0;
+   }
+}
+
+/* Expand expression EXP, which is a call to the bcopy builtin.  Return 0
+   if we failed the caller should emit a normal call.  */
+
+static rtx
+expand_builtin_bcopy (tree exp)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree type = TREE_TYPE (exp);
+  tree src, dest, size, newarglist;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  src = TREE_VALUE (arglist);
+  dest = TREE_VALUE (TREE_CHAIN (arglist));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* New argument list transforming bcopy(ptr x, ptr y, int z) to
+     memmove(ptr y, ptr x, size_t z).   This is done this way
+     so that if it isn't expanded inline, we fallback to
+     calling bcopy instead of memmove.  */
+
+  newarglist = build_tree_list (NULL_TREE, fold_convert (sizetype, size));
+  newarglist = tree_cons (NULL_TREE, src, newarglist);
+  newarglist = tree_cons (NULL_TREE, dest, newarglist);
+
+  return expand_builtin_memmove (newarglist, type, const0_rtx, VOIDmode, exp);
+}
+
+#ifndef HAVE_movstr
+# define HAVE_movstr 0
+# define CODE_FOR_movstr CODE_FOR_nothing
+#endif
+
+/* Expand into a movstr instruction, if one is available.  Return 0 if
+   we failed, the caller should emit a normal call, otherwise try to
+   get the result in TARGET, if convenient.  If ENDP is 0 return the
+   destination pointer, if ENDP is 1 return the end pointer ala
+   mempcpy, and if ENDP is 2 return the end pointer minus one ala
+   stpcpy.  */
+
+static rtx
+expand_movstr (tree dest, tree src, rtx target, int endp)
+{
+  rtx end;
+  rtx dest_mem;
+  rtx src_mem;
+  rtx insn;
+  const struct insn_data * data;
+
+  if (!HAVE_movstr)
+    return 0;
+
+  dest_mem = get_memory_rtx (dest, NULL);
+  src_mem = get_memory_rtx (src, NULL);
+  if (!endp)
+    {
+      target = force_reg (Pmode, XEXP (dest_mem, 0));
+      dest_mem = replace_equiv_address (dest_mem, target);
+      end = gen_reg_rtx (Pmode);
+    }
+  else
+    {
+      if (target == 0 || target == const0_rtx)
+	{
+	  end = gen_reg_rtx (Pmode);
+	  if (target == 0)
+	    target = end;
+	}
+      else
+	end = target;
+    }
+
+  data = insn_data + CODE_FOR_movstr;
+
+  if (data->operand[0].mode != VOIDmode)
+    end = gen_lowpart (data->operand[0].mode, end);
+
+  insn = data->genfun (end, dest_mem, src_mem);
+
+  gcc_assert (insn);
+
+  emit_insn (insn);
+
+  /* movstr is supposed to set end to the address of the NUL
+     terminator.  If the caller requested a mempcpy-like return value,
+     adjust it.  */
+  if (endp == 1 && target != const0_rtx)
+    {
+      rtx tem = plus_constant (gen_lowpart (GET_MODE (target), end), 1);
+      emit_move_insn (target, force_operand (tem, NULL_RTX));
+    }
+
+  return target;
+}
+
+/* Expand expression EXP, which is a call to the strcpy builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient (and in mode MODE if that's
+   convenient).  */
+
+static rtx
+expand_builtin_strcpy (tree fndecl, tree arglist, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strcpy (fndecl, arglist, 0);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      return expand_movstr (TREE_VALUE (arglist),
+			    TREE_VALUE (TREE_CHAIN (arglist)),
+			    target, /*endp=*/0);
+    }
+  return 0;
+}
+
+/* Expand a call to the stpcpy builtin, with arguments in ARGLIST.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient (and in
+   mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_stpcpy (tree exp, rtx target, enum machine_mode mode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  /* If return value is ignored, transform stpcpy into strcpy.  */
+  if (target == const0_rtx)
+    {
+      tree fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+      if (!fn)
+	return 0;
+
+      return expand_expr (build_function_call_expr (fn, arglist),
+			  target, mode, EXPAND_NORMAL);
+    }
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dst, src, len, lenp1;
+      tree narglist;
+      rtx ret;
+
+      /* Ensure we get an actual string whose length can be evaluated at
+         compile-time, not an expression containing a string.  This is
+         because the latter will potentially produce pessimized code
+         when used to produce the return value.  */
+      src = TREE_VALUE (TREE_CHAIN (arglist));
+      if (! c_getstr (src) || ! (len = c_strlen (src, 0)))
+	return expand_movstr (TREE_VALUE (arglist),
+			      TREE_VALUE (TREE_CHAIN (arglist)),
+			      target, /*endp=*/2);
+
+      dst = TREE_VALUE (arglist);
+      lenp1 = size_binop (PLUS_EXPR, len, ssize_int (1));
+      narglist = build_tree_list (NULL_TREE, lenp1);
+      narglist = tree_cons (NULL_TREE, src, narglist);
+      narglist = tree_cons (NULL_TREE, dst, narglist);
+      ret = expand_builtin_mempcpy (narglist, TREE_TYPE (exp),
+				    target, mode, /*endp=*/2);
+
+      if (ret)
+	return ret;
+
+      if (TREE_CODE (len) == INTEGER_CST)
+	{
+	  rtx len_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+
+	  if (GET_CODE (len_rtx) == CONST_INT)
+	    {
+	      ret = expand_builtin_strcpy (get_callee_fndecl (exp), 
+					   arglist, target, mode);
+
+	      if (ret)
+		{
+		  if (! target)
+		    {
+		      if (mode != VOIDmode)
+			target = gen_reg_rtx (mode);
+		      else
+			target = gen_reg_rtx (GET_MODE (ret));
+		    }
+		  if (GET_MODE (target) != GET_MODE (ret))
+		    ret = gen_lowpart (GET_MODE (target), ret);
+
+		  ret = plus_constant (ret, INTVAL (len_rtx));
+		  ret = emit_move_insn (target, force_operand (ret, NULL_RTX));
+		  gcc_assert (ret);
+
+		  return target;
+		}
+	    }
+	}
+
+      return expand_movstr (TREE_VALUE (arglist),
+			    TREE_VALUE (TREE_CHAIN (arglist)),
+			    target, /*endp=*/2);
+    }
+}
+
+/* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
+   bytes from constant string DATA + OFFSET and return it as target
+   constant.  */
+
+static rtx
+builtin_strncpy_read_str (void *data, HOST_WIDE_INT offset,
+			  enum machine_mode mode)
+{
+  const char *str = (const char *) data;
+
+  if ((unsigned HOST_WIDE_INT) offset > strlen (str))
+    return const0_rtx;
+
+  return c_readstr (str + offset, mode);
+}
+
+/* Expand expression EXP, which is a call to the strncpy builtin.  Return 0
+   if we failed the caller should emit a normal call.  */
+
+static rtx
+expand_builtin_strncpy (tree exp, rtx target, enum machine_mode mode)
+{
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  if (validate_arglist (arglist,
+			POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree slen = c_strlen (TREE_VALUE (TREE_CHAIN (arglist)), 1);
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      tree result = fold_builtin_strncpy (fndecl, arglist, slen);
+      
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      /* We must be passed a constant len and src parameter.  */
+      if (!host_integerp (len, 1) || !slen || !host_integerp (slen, 1))
+	return 0;
+
+      slen = size_binop (PLUS_EXPR, slen, ssize_int (1));
+
+      /* We're required to pad with trailing zeros if the requested
+         len is greater than strlen(s2)+1.  In that case try to
+	 use store_by_pieces, if it fails, punt.  */
+      if (tree_int_cst_lt (slen, len))
+	{
+	  tree dest = TREE_VALUE (arglist);
+	  unsigned int dest_align
+	    = get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+	  const char *p = c_getstr (TREE_VALUE (TREE_CHAIN (arglist)));
+	  rtx dest_mem;
+
+	  if (!p || dest_align == 0 || !host_integerp (len, 1)
+	      || !can_store_by_pieces (tree_low_cst (len, 1),
+				       builtin_strncpy_read_str,
+				       (void *) p, dest_align))
+	    return 0;
+
+	  dest_mem = get_memory_rtx (dest, len);
+	  store_by_pieces (dest_mem, tree_low_cst (len, 1),
+			   builtin_strncpy_read_str,
+			   (void *) p, dest_align, 0);
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+    }
+  return 0;
+}
+
+/* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
+   bytes from constant string DATA + OFFSET and return it as target
+   constant.  */
+
+static rtx
+builtin_memset_read_str (void *data, HOST_WIDE_INT offset ATTRIBUTE_UNUSED,
+			 enum machine_mode mode)
+{
+  const char *c = (const char *) data;
+  char *p = alloca (GET_MODE_SIZE (mode));
+
+  memset (p, *c, GET_MODE_SIZE (mode));
+
+  return c_readstr (p, mode);
+}
+
+/* Callback routine for store_by_pieces.  Return the RTL of a register
+   containing GET_MODE_SIZE (MODE) consecutive copies of the unsigned
+   char value given in the RTL register data.  For example, if mode is
+   4 bytes wide, return the RTL for 0x01010101*data.  */
+
+static rtx
+builtin_memset_gen_str (void *data, HOST_WIDE_INT offset ATTRIBUTE_UNUSED,
+			enum machine_mode mode)
+{
+  rtx target, coeff;
+  size_t size;
+  char *p;
+
+  size = GET_MODE_SIZE (mode);
+  if (size == 1)
+    return (rtx) data;
+
+  p = alloca (size);
+  memset (p, 1, size);
+  coeff = c_readstr (p, mode);
+
+  target = convert_to_mode (mode, (rtx) data, 1);
+  target = expand_mult (mode, target, coeff, NULL_RTX, 1);
+  return force_reg (mode, target);
+}
+
+/* Expand expression EXP, which is a call to the memset builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient (and in mode MODE if that's
+   convenient).  */
+
+static rtx
+expand_builtin_memset (tree arglist, rtx target, enum machine_mode mode,
+		       tree orig_exp)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, INTEGER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree val = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      char c;
+
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+      rtx dest_mem, dest_addr, len_rtx;
+
+      /* If DEST is not a pointer type, don't do this
+	 operation in-line.  */
+      if (dest_align == 0)
+	return 0;
+
+      /* If the LEN parameter is zero, return DEST.  */
+      if (integer_zerop (len))
+	{
+	  /* Evaluate and ignore VAL in case it has side-effects.  */
+	  expand_expr (val, const0_rtx, VOIDmode, EXPAND_NORMAL);
+	  return expand_expr (dest, target, mode, EXPAND_NORMAL);
+	}
+
+      len_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+      dest_mem = get_memory_rtx (dest, len);
+
+      if (TREE_CODE (val) != INTEGER_CST)
+	{
+	  rtx val_rtx;
+
+	  val = fold_build1 (CONVERT_EXPR, unsigned_char_type_node, val);
+	  val_rtx = expand_expr (val, NULL_RTX, VOIDmode, 0);
+
+	  /* Assume that we can memset by pieces if we can store the
+	   * the coefficients by pieces (in the required modes).
+	   * We can't pass builtin_memset_gen_str as that emits RTL.  */
+	  c = 1;
+	  if (host_integerp (len, 1)
+	      && !(optimize_size && tree_low_cst (len, 1) > 1)
+	      && can_store_by_pieces (tree_low_cst (len, 1),
+				      builtin_memset_read_str, &c, dest_align))
+	    {
+	      val_rtx = force_reg (TYPE_MODE (unsigned_char_type_node), 
+				   val_rtx);
+	      store_by_pieces (dest_mem, tree_low_cst (len, 1),
+			       builtin_memset_gen_str, val_rtx, dest_align, 0);
+	    }
+	  else if (!set_storage_via_setmem(dest_mem, len_rtx, val_rtx, 
+					   dest_align))
+	    return 0;
+
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      if (target_char_cast (val, &c))
+	return 0;
+
+      if (c)
+	{
+	  if (host_integerp (len, 1)
+	      && !(optimize_size && tree_low_cst (len, 1) > 1)
+	      && can_store_by_pieces (tree_low_cst (len, 1),
+				      builtin_memset_read_str, &c, dest_align))
+	    store_by_pieces (dest_mem, tree_low_cst (len, 1),
+			     builtin_memset_read_str, &c, dest_align, 0);
+	  else if (!set_storage_via_setmem (dest_mem, len_rtx, GEN_INT (c),
+					    dest_align))
+	    return 0;
+
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      set_mem_align (dest_mem, dest_align);
+      dest_addr = clear_storage (dest_mem, len_rtx,
+				 CALL_EXPR_TAILCALL (orig_exp)
+				 ? BLOCK_OP_TAILCALL : BLOCK_OP_NORMAL);
+
+      if (dest_addr == 0)
+	{
+	  dest_addr = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_addr = convert_memory_address (ptr_mode, dest_addr);
+	}
+
+      return dest_addr;
+    }
+}
+
+/* Expand expression EXP, which is a call to the bzero builtin.  Return 0
+   if we failed the caller should emit a normal call.  */
+
+static rtx
+expand_builtin_bzero (tree exp)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree dest, size, newarglist;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  dest = TREE_VALUE (arglist);
+  size = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* New argument list transforming bzero(ptr x, int y) to
+     memset(ptr x, int 0, size_t y).   This is done this way
+     so that if it isn't expanded inline, we fallback to
+     calling bzero instead of memset.  */
+
+  newarglist = build_tree_list (NULL_TREE, fold_convert (sizetype, size));
+  newarglist = tree_cons (NULL_TREE, integer_zero_node, newarglist);
+  newarglist = tree_cons (NULL_TREE, dest, newarglist);
+
+  return expand_builtin_memset (newarglist, const0_rtx, VOIDmode, exp);
+}
+
+/* Expand expression EXP, which is a call to the memcmp built-in function.
+   ARGLIST is the argument list for this call.  Return 0 if we failed and the
+   caller should emit a normal call, otherwise try to get the result in
+   TARGET, if convenient (and in mode MODE, if that's convenient).  */
+
+static rtx
+expand_builtin_memcmp (tree exp ATTRIBUTE_UNUSED, tree arglist, rtx target,
+		       enum machine_mode mode)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree result = fold_builtin_memcmp (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+
+#if defined HAVE_cmpmemsi || defined HAVE_cmpstrnsi
+  {
+    tree arg1 = TREE_VALUE (arglist);
+    tree arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+    tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+    rtx arg1_rtx, arg2_rtx, arg3_rtx;
+    rtx result;
+    rtx insn;
+
+    int arg1_align
+      = get_pointer_alignment (arg1, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+    int arg2_align
+      = get_pointer_alignment (arg2, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+    enum machine_mode insn_mode;
+
+#ifdef HAVE_cmpmemsi
+    if (HAVE_cmpmemsi)
+      insn_mode = insn_data[(int) CODE_FOR_cmpmemsi].operand[0].mode;
+    else
+#endif
+#ifdef HAVE_cmpstrnsi
+    if (HAVE_cmpstrnsi)
+      insn_mode = insn_data[(int) CODE_FOR_cmpstrnsi].operand[0].mode;
+    else
+#endif
+      return 0;
+
+    /* If we don't have POINTER_TYPE, call the function.  */
+    if (arg1_align == 0 || arg2_align == 0)
+      return 0;
+
+    /* Make a place to write the result of the instruction.  */
+    result = target;
+    if (! (result != 0
+	   && REG_P (result) && GET_MODE (result) == insn_mode
+	   && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+      result = gen_reg_rtx (insn_mode);
+
+    arg1_rtx = get_memory_rtx (arg1, len);
+    arg2_rtx = get_memory_rtx (arg2, len);
+    arg3_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+
+    /* Set MEM_SIZE as appropriate.  */
+    if (GET_CODE (arg3_rtx) == CONST_INT)
+      {
+	set_mem_size (arg1_rtx, arg3_rtx);
+	set_mem_size (arg2_rtx, arg3_rtx);
+      }
+
+#ifdef HAVE_cmpmemsi
+    if (HAVE_cmpmemsi)
+      insn = gen_cmpmemsi (result, arg1_rtx, arg2_rtx, arg3_rtx,
+			   GEN_INT (MIN (arg1_align, arg2_align)));
+    else
+#endif
+#ifdef HAVE_cmpstrnsi
+    if (HAVE_cmpstrnsi)
+      insn = gen_cmpstrnsi (result, arg1_rtx, arg2_rtx, arg3_rtx,
+			    GEN_INT (MIN (arg1_align, arg2_align)));
+    else
+#endif
+      gcc_unreachable ();
+
+    if (insn)
+      emit_insn (insn);
+    else
+      emit_library_call_value (memcmp_libfunc, result, LCT_PURE_MAKE_BLOCK,
+			       TYPE_MODE (integer_type_node), 3,
+			       XEXP (arg1_rtx, 0), Pmode,
+			       XEXP (arg2_rtx, 0), Pmode,
+			       convert_to_mode (TYPE_MODE (sizetype), arg3_rtx,
+						TYPE_UNSIGNED (sizetype)),
+			       TYPE_MODE (sizetype));
+
+    /* Return the value in the proper mode for this function.  */
+    mode = TYPE_MODE (TREE_TYPE (exp));
+    if (GET_MODE (result) == mode)
+      return result;
+    else if (target != 0)
+      {
+	convert_move (target, result, 0);
+	return target;
+      }
+    else
+      return convert_to_mode (mode, result, 0);
+  }
+#endif
+
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strcmp builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strcmp (tree exp, rtx target, enum machine_mode mode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree result = fold_builtin_strcmp (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+
+#if defined HAVE_cmpstrsi || defined HAVE_cmpstrnsi
+  if (cmpstr_optab[SImode] != CODE_FOR_nothing
+      || cmpstrn_optab[SImode] != CODE_FOR_nothing)
+    {
+      rtx arg1_rtx, arg2_rtx;
+      rtx result, insn = NULL_RTX;
+      tree fndecl, fn;
+      
+      tree arg1 = TREE_VALUE (arglist);
+      tree arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+      int arg1_align
+	= get_pointer_alignment (arg1, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+      int arg2_align
+	= get_pointer_alignment (arg2, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+
+      /* If we don't have POINTER_TYPE, call the function.  */
+      if (arg1_align == 0 || arg2_align == 0)
+	return 0;
+
+      /* Stabilize the arguments in case gen_cmpstr(n)si fail.  */
+      arg1 = builtin_save_expr (arg1);
+      arg2 = builtin_save_expr (arg2);
+
+      arg1_rtx = get_memory_rtx (arg1, NULL);
+      arg2_rtx = get_memory_rtx (arg2, NULL);
+
+#ifdef HAVE_cmpstrsi
+      /* Try to call cmpstrsi.  */
+      if (HAVE_cmpstrsi)
+	{
+	  enum machine_mode insn_mode 
+	    = insn_data[(int) CODE_FOR_cmpstrsi].operand[0].mode;
+
+	  /* Make a place to write the result of the instruction.  */
+	  result = target;
+	  if (! (result != 0
+		 && REG_P (result) && GET_MODE (result) == insn_mode
+		 && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+	    result = gen_reg_rtx (insn_mode);
+
+	  insn = gen_cmpstrsi (result, arg1_rtx, arg2_rtx,
+			       GEN_INT (MIN (arg1_align, arg2_align)));
+	}
+#endif
+#if HAVE_cmpstrnsi 
+      /* Try to determine at least one length and call cmpstrnsi.  */
+      if (!insn && HAVE_cmpstrnsi) 
+	{
+	  tree len;
+	  rtx arg3_rtx;
+
+	  enum machine_mode insn_mode 
+	    = insn_data[(int) CODE_FOR_cmpstrnsi].operand[0].mode;
+	  tree len1 = c_strlen (arg1, 1);
+	  tree len2 = c_strlen (arg2, 1);
+
+	  if (len1)
+	    len1 = size_binop (PLUS_EXPR, ssize_int (1), len1);
+	  if (len2)
+	    len2 = size_binop (PLUS_EXPR, ssize_int (1), len2);
+
+	  /* If we don't have a constant length for the first, use the length
+	     of the second, if we know it.  We don't require a constant for
+	     this case; some cost analysis could be done if both are available
+	     but neither is constant.  For now, assume they're equally cheap,
+	     unless one has side effects.  If both strings have constant lengths,
+	     use the smaller.  */
+
+	  if (!len1)
+	    len = len2;
+	  else if (!len2)
+	    len = len1;
+	  else if (TREE_SIDE_EFFECTS (len1))
+	    len = len2;
+	  else if (TREE_SIDE_EFFECTS (len2))
+	    len = len1;
+	  else if (TREE_CODE (len1) != INTEGER_CST)
+	    len = len2;
+	  else if (TREE_CODE (len2) != INTEGER_CST)
+	    len = len1;
+	  else if (tree_int_cst_lt (len1, len2))
+	    len = len1;
+	  else
+	    len = len2;
+
+	  /* If both arguments have side effects, we cannot optimize.  */
+	  if (!len || TREE_SIDE_EFFECTS (len))
+	    return 0;
+
+	  /* Stabilize the arguments in case gen_cmpstrnsi fails.  */
+	  arg3_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+
+	  /* Make a place to write the result of the instruction.  */
+	  result = target;
+	  if (! (result != 0
+		 && REG_P (result) && GET_MODE (result) == insn_mode
+		 && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+	    result = gen_reg_rtx (insn_mode);
+
+	  insn = gen_cmpstrnsi (result, arg1_rtx, arg2_rtx, arg3_rtx,
+				GEN_INT (MIN (arg1_align, arg2_align)));
+	}
+#endif
+
+      if (insn)
+	{
+	  emit_insn (insn);
+
+	  /* Return the value in the proper mode for this function.  */
+	  mode = TYPE_MODE (TREE_TYPE (exp));
+	  if (GET_MODE (result) == mode)
+	    return result;
+	  if (target == 0)
+	    return convert_to_mode (mode, result, 0);
+	  convert_move (target, result, 0);
+	  return target;
+	}
+
+      /* Expand the library call ourselves using a stabilized argument
+	 list to avoid re-evaluating the function's arguments twice.  */
+      arglist = build_tree_list (NULL_TREE, arg2);
+      arglist = tree_cons (NULL_TREE, arg1, arglist);
+      fndecl = get_callee_fndecl (exp);
+      fn = build_function_call_expr (fndecl, arglist);
+      if (TREE_CODE (fn) == CALL_EXPR)
+	CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+      return expand_call (fn, target, target == const0_rtx);
+    }
+#endif
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strncmp builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strncmp (tree exp, rtx target, enum machine_mode mode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree result = fold_builtin_strncmp (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+
+  /* If c_strlen can determine an expression for one of the string
+     lengths, and it doesn't have side effects, then emit cmpstrnsi
+     using length MIN(strlen(string)+1, arg3).  */
+#ifdef HAVE_cmpstrnsi
+  if (HAVE_cmpstrnsi)
+  {
+    tree arg1 = TREE_VALUE (arglist);
+    tree arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+    tree arg3 = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+    tree len, len1, len2;
+    rtx arg1_rtx, arg2_rtx, arg3_rtx;
+    rtx result, insn;
+    tree fndecl, fn;
+
+    int arg1_align
+      = get_pointer_alignment (arg1, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+    int arg2_align
+      = get_pointer_alignment (arg2, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+    enum machine_mode insn_mode
+      = insn_data[(int) CODE_FOR_cmpstrnsi].operand[0].mode;
+
+    len1 = c_strlen (arg1, 1);
+    len2 = c_strlen (arg2, 1);
+
+    if (len1)
+      len1 = size_binop (PLUS_EXPR, ssize_int (1), len1);
+    if (len2)
+      len2 = size_binop (PLUS_EXPR, ssize_int (1), len2);
+
+    /* If we don't have a constant length for the first, use the length
+       of the second, if we know it.  We don't require a constant for
+       this case; some cost analysis could be done if both are available
+       but neither is constant.  For now, assume they're equally cheap,
+       unless one has side effects.  If both strings have constant lengths,
+       use the smaller.  */
+
+    if (!len1)
+      len = len2;
+    else if (!len2)
+      len = len1;
+    else if (TREE_SIDE_EFFECTS (len1))
+      len = len2;
+    else if (TREE_SIDE_EFFECTS (len2))
+      len = len1;
+    else if (TREE_CODE (len1) != INTEGER_CST)
+      len = len2;
+    else if (TREE_CODE (len2) != INTEGER_CST)
+      len = len1;
+    else if (tree_int_cst_lt (len1, len2))
+      len = len1;
+    else
+      len = len2;
+
+    /* If both arguments have side effects, we cannot optimize.  */
+    if (!len || TREE_SIDE_EFFECTS (len))
+      return 0;
+
+    /* The actual new length parameter is MIN(len,arg3).  */
+    len = fold_build2 (MIN_EXPR, TREE_TYPE (len), len,
+		       fold_convert (TREE_TYPE (len), arg3));
+
+    /* If we don't have POINTER_TYPE, call the function.  */
+    if (arg1_align == 0 || arg2_align == 0)
+      return 0;
+
+    /* Make a place to write the result of the instruction.  */
+    result = target;
+    if (! (result != 0
+	   && REG_P (result) && GET_MODE (result) == insn_mode
+	   && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+      result = gen_reg_rtx (insn_mode);
+
+    /* Stabilize the arguments in case gen_cmpstrnsi fails.  */
+    arg1 = builtin_save_expr (arg1);
+    arg2 = builtin_save_expr (arg2);
+    len = builtin_save_expr (len);
+
+    arg1_rtx = get_memory_rtx (arg1, len);
+    arg2_rtx = get_memory_rtx (arg2, len);
+    arg3_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+    insn = gen_cmpstrnsi (result, arg1_rtx, arg2_rtx, arg3_rtx,
+			  GEN_INT (MIN (arg1_align, arg2_align)));
+    if (insn)
+      {
+	emit_insn (insn);
+
+	/* Return the value in the proper mode for this function.  */
+	mode = TYPE_MODE (TREE_TYPE (exp));
+	if (GET_MODE (result) == mode)
+	  return result;
+	if (target == 0)
+	  return convert_to_mode (mode, result, 0);
+	convert_move (target, result, 0);
+	return target;
+      }
+
+    /* Expand the library call ourselves using a stabilized argument
+       list to avoid re-evaluating the function's arguments twice.  */
+    arglist = build_tree_list (NULL_TREE, len);
+    arglist = tree_cons (NULL_TREE, arg2, arglist);
+    arglist = tree_cons (NULL_TREE, arg1, arglist);
+    fndecl = get_callee_fndecl (exp);
+    fn = build_function_call_expr (fndecl, arglist);
+    if (TREE_CODE (fn) == CALL_EXPR)
+      CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+    return expand_call (fn, target, target == const0_rtx);
+  }
+#endif
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strcat builtin.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strcat (tree fndecl, tree arglist, rtx target, enum machine_mode mode)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dst = TREE_VALUE (arglist),
+      src = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p = c_getstr (src);
+
+      /* If the string length is zero, return the dst parameter.  */
+      if (p && *p == '\0')	  
+	return expand_expr (dst, target, mode, EXPAND_NORMAL);
+      
+      if (!optimize_size)
+	{
+	  /* See if we can store by pieces into (dst + strlen(dst)).  */
+	  tree newsrc, newdst,
+	    strlen_fn = implicit_built_in_decls[BUILT_IN_STRLEN];
+	  rtx insns;
+
+	  /* Stabilize the argument list.  */
+	  newsrc = builtin_save_expr (src);
+	  if (newsrc != src)
+	    arglist = build_tree_list (NULL_TREE, newsrc);
+	  else 
+	    arglist = TREE_CHAIN (arglist); /* Reusing arglist if safe.  */
+
+	  dst = builtin_save_expr (dst);
+
+	  start_sequence ();
+
+	  /* Create strlen (dst).  */
+	  newdst =
+	    build_function_call_expr (strlen_fn,
+				      build_tree_list (NULL_TREE, dst));
+	  /* Create (dst + (cast) strlen (dst)).  */
+	  newdst = fold_convert (TREE_TYPE (dst), newdst);
+	  newdst = fold_build2 (PLUS_EXPR, TREE_TYPE (dst), dst, newdst);
+
+	  newdst = builtin_save_expr (newdst);
+	  arglist = tree_cons (NULL_TREE, newdst, arglist);
+
+	  if (!expand_builtin_strcpy (fndecl, arglist, target, mode))
+	    {
+	      end_sequence (); /* Stop sequence.  */
+	      return 0;
+	    }
+	  
+	  /* Output the entire sequence.  */
+	  insns = get_insns ();
+	  end_sequence ();
+	  emit_insn (insns);
+	  
+	  return expand_expr (dst, target, mode, EXPAND_NORMAL);
+	}
+
+      return 0;
+    }
+}
+
+/* Expand expression EXP, which is a call to the strncat builtin.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strncat (tree arglist, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist,
+			POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strncat (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strspn builtin.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strspn (tree arglist, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strspn (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strcspn builtin.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strcspn (tree arglist, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strcspn (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand a call to __builtin_saveregs, generating the result in TARGET,
+   if that's convenient.  */
+
+rtx
+expand_builtin_saveregs (void)
+{
+  rtx val, seq;
+
+  /* Don't do __builtin_saveregs more than once in a function.
+     Save the result of the first call and reuse it.  */
+  if (saveregs_value != 0)
+    return saveregs_value;
+
+  /* When this function is called, it means that registers must be
+     saved on entry to this function.  So we migrate the call to the
+     first insn of this function.  */
+
+  start_sequence ();
+
+  /* Do whatever the machine needs done in this case.  */
+  val = targetm.calls.expand_builtin_saveregs ();
+
+  seq = get_insns ();
+  end_sequence ();
+
+  saveregs_value = val;
+
+  /* Put the insns after the NOTE that starts the function.  If this
+     is inside a start_sequence, make the outer-level insn chain current, so
+     the code is placed at the start of the function.  */
+  push_topmost_sequence ();
+  emit_insn_after (seq, entry_of_function ());
+  pop_topmost_sequence ();
+
+  return val;
+}
+
+/* __builtin_args_info (N) returns word N of the arg space info
+   for the current function.  The number and meanings of words
+   is controlled by the definition of CUMULATIVE_ARGS.  */
+
+static rtx
+expand_builtin_args_info (tree arglist)
+{
+  int nwords = sizeof (CUMULATIVE_ARGS) / sizeof (int);
+  int *word_ptr = (int *) &current_function_args_info;
+
+  gcc_assert (sizeof (CUMULATIVE_ARGS) % sizeof (int) == 0);
+
+  if (arglist != 0)
+    {
+      if (!host_integerp (TREE_VALUE (arglist), 0))
+	error ("argument of %<__builtin_args_info%> must be constant");
+      else
+	{
+	  HOST_WIDE_INT wordnum = tree_low_cst (TREE_VALUE (arglist), 0);
+
+	  if (wordnum < 0 || wordnum >= nwords)
+	    error ("argument of %<__builtin_args_info%> out of range");
+	  else
+	    return GEN_INT (word_ptr[wordnum]);
+	}
+    }
+  else
+    error ("missing argument in %<__builtin_args_info%>");
+
+  return const0_rtx;
+}
+
+/* Expand a call to __builtin_next_arg.  */
+
+static rtx
+expand_builtin_next_arg (void)
+{
+  /* Checking arguments is already done in fold_builtin_next_arg
+     that must be called before this function.  */
+  return expand_binop (Pmode, add_optab,
+		       current_function_internal_arg_pointer,
+		       current_function_arg_offset_rtx,
+		       NULL_RTX, 0, OPTAB_LIB_WIDEN);
+}
+
+/* Make it easier for the backends by protecting the valist argument
+   from multiple evaluations.  */
+
+static tree
+stabilize_va_list (tree valist, int needs_lvalue)
+{
+  if (TREE_CODE (va_list_type_node) == ARRAY_TYPE)
+    {
+      if (TREE_SIDE_EFFECTS (valist))
+	valist = save_expr (valist);
+
+      /* For this case, the backends will be expecting a pointer to
+	 TREE_TYPE (va_list_type_node), but it's possible we've
+	 actually been given an array (an actual va_list_type_node).
+	 So fix it.  */
+      if (TREE_CODE (TREE_TYPE (valist)) == ARRAY_TYPE)
+	{
+	  tree p1 = build_pointer_type (TREE_TYPE (va_list_type_node));
+	  valist = build_fold_addr_expr_with_type (valist, p1);
+	}
+    }
+  else
+    {
+      tree pt;
+
+      if (! needs_lvalue)
+	{
+	  if (! TREE_SIDE_EFFECTS (valist))
+	    return valist;
+
+	  pt = build_pointer_type (va_list_type_node);
+	  valist = fold_build1 (ADDR_EXPR, pt, valist);
+	  TREE_SIDE_EFFECTS (valist) = 1;
+	}
+
+      if (TREE_SIDE_EFFECTS (valist))
+	valist = save_expr (valist);
+      valist = build_fold_indirect_ref (valist);
+    }
+
+  return valist;
+}
+
+/* The "standard" definition of va_list is void*.  */
+
+tree
+std_build_builtin_va_list (void)
+{
+  return ptr_type_node;
+}
+
+/* The "standard" implementation of va_start: just assign `nextarg' to
+   the variable.  */
+
+void
+std_expand_builtin_va_start (tree valist, rtx nextarg)
+{
+  tree t;
+
+  t = build2 (MODIFY_EXPR, TREE_TYPE (valist), valist,
+	      make_tree (ptr_type_node, nextarg));
+  TREE_SIDE_EFFECTS (t) = 1;
+
+  expand_expr (t, const0_rtx, VOIDmode, EXPAND_NORMAL);
+}
+
+/* Expand ARGLIST, from a call to __builtin_va_start.  */
+
+static rtx
+expand_builtin_va_start (tree arglist)
+{
+  rtx nextarg;
+  tree chain, valist;
+
+  chain = TREE_CHAIN (arglist);
+
+  if (!chain)
+    {
+      error ("too few arguments to function %<va_start%>");
+      return const0_rtx;
+    }
+
+  if (fold_builtin_next_arg (chain))
+    return const0_rtx;
+
+  nextarg = expand_builtin_next_arg ();
+  valist = stabilize_va_list (TREE_VALUE (arglist), 1);
+
+#ifdef EXPAND_BUILTIN_VA_START
+  EXPAND_BUILTIN_VA_START (valist, nextarg);
+#else
+  std_expand_builtin_va_start (valist, nextarg);
+#endif
+
+  return const0_rtx;
+}
+
+/* The "standard" implementation of va_arg: read the value from the
+   current (padded) address and increment by the (padded) size.  */
+
+tree
+std_gimplify_va_arg_expr (tree valist, tree type, tree *pre_p, tree *post_p)
+{
+  tree addr, t, type_size, rounded_size, valist_tmp;
+  unsigned HOST_WIDE_INT align, boundary;
+  bool indirect;
+
+#ifdef ARGS_GROW_DOWNWARD
+  /* All of the alignment and movement below is for args-grow-up machines.
+     As of 2004, there are only 3 ARGS_GROW_DOWNWARD targets, and they all
+     implement their own specialized gimplify_va_arg_expr routines.  */
+  gcc_unreachable ();
+#endif
+
+  indirect = pass_by_reference (NULL, TYPE_MODE (type), type, false);
+  if (indirect)
+    type = build_pointer_type (type);
+
+  align = PARM_BOUNDARY / BITS_PER_UNIT;
+  boundary = FUNCTION_ARG_BOUNDARY (TYPE_MODE (type), type) / BITS_PER_UNIT;
+
+  /* Hoist the valist value into a temporary for the moment.  */
+  valist_tmp = get_initialized_tmp_var (valist, pre_p, NULL);
+
+  /* va_list pointer is aligned to PARM_BOUNDARY.  If argument actually
+     requires greater alignment, we must perform dynamic alignment.  */
+  if (boundary > align)
+    {
+      t = fold_convert (TREE_TYPE (valist), size_int (boundary - 1));
+      t = build2 (MODIFY_EXPR, TREE_TYPE (valist), valist_tmp,
+		  build2 (PLUS_EXPR, TREE_TYPE (valist), valist_tmp, t));
+      gimplify_and_add (t, pre_p);
+
+      t = fold_convert (TREE_TYPE (valist), size_int (-boundary));
+      t = build2 (MODIFY_EXPR, TREE_TYPE (valist), valist_tmp,
+		  build2 (BIT_AND_EXPR, TREE_TYPE (valist), valist_tmp, t));
+      gimplify_and_add (t, pre_p);
+    }
+  else
+    boundary = align;
+
+  /* If the actual alignment is less than the alignment of the type,
+     adjust the type accordingly so that we don't assume strict alignment
+     when deferencing the pointer.  */
+  boundary *= BITS_PER_UNIT;
+  if (boundary < TYPE_ALIGN (type))
+    {
+      type = build_variant_type_copy (type);
+      TYPE_ALIGN (type) = boundary;
+    }
+
+  /* Compute the rounded size of the type.  */
+  type_size = size_in_bytes (type);
+  rounded_size = round_up (type_size, align);
+
+  /* Reduce rounded_size so it's sharable with the postqueue.  */
+  gimplify_expr (&rounded_size, pre_p, post_p, is_gimple_val, fb_rvalue);
+
+  /* Get AP.  */
+  addr = valist_tmp;
+  if (PAD_VARARGS_DOWN && !integer_zerop (rounded_size))
+    {
+      /* Small args are padded downward.  */
+      t = fold_build2 (GT_EXPR, sizetype, rounded_size, size_int (align));
+      t = fold_build3 (COND_EXPR, sizetype, t, size_zero_node,
+		       size_binop (MINUS_EXPR, rounded_size, type_size));
+      t = fold_convert (TREE_TYPE (addr), t);
+      addr = fold_build2 (PLUS_EXPR, TREE_TYPE (addr), addr, t);
+    }
+
+  /* Compute new value for AP.  */
+  t = fold_convert (TREE_TYPE (valist), rounded_size);
+  t = build2 (PLUS_EXPR, TREE_TYPE (valist), valist_tmp, t);
+  t = build2 (MODIFY_EXPR, TREE_TYPE (valist), valist, t);
+  gimplify_and_add (t, pre_p);
+
+  addr = fold_convert (build_pointer_type (type), addr);
+
+  if (indirect)
+    addr = build_va_arg_indirect_ref (addr);
+
+  return build_va_arg_indirect_ref (addr);
+}
+
+/* Build an indirect-ref expression over the given TREE, which represents a
+   piece of a va_arg() expansion.  */
+tree
+build_va_arg_indirect_ref (tree addr)
+{
+  addr = build_fold_indirect_ref (addr);
+
+  if (flag_mudflap) /* Don't instrument va_arg INDIRECT_REF.  */
+    mf_mark (addr);
+
+  return addr;
+}
+
+/* Return a dummy expression of type TYPE in order to keep going after an
+   error.  */
+
+static tree
+dummy_object (tree type)
+{
+  tree t = convert (build_pointer_type (type), null_pointer_node);
+  return build1 (INDIRECT_REF, type, t);
+}
+
+/* Gimplify __builtin_va_arg, aka VA_ARG_EXPR, which is not really a
+   builtin function, but a very special sort of operator.  */
+
+enum gimplify_status
+gimplify_va_arg_expr (tree *expr_p, tree *pre_p, tree *post_p)
+{
+  tree promoted_type, want_va_type, have_va_type;
+  tree valist = TREE_OPERAND (*expr_p, 0);
+  tree type = TREE_TYPE (*expr_p);
+  tree t;
+
+  /* Verify that valist is of the proper type.  */
+  want_va_type = va_list_type_node;
+  have_va_type = TREE_TYPE (valist);
+
+  if (have_va_type == error_mark_node)
+    return GS_ERROR;
+
+  if (TREE_CODE (want_va_type) == ARRAY_TYPE)
+    {
+      /* If va_list is an array type, the argument may have decayed
+	 to a pointer type, e.g. by being passed to another function.
+         In that case, unwrap both types so that we can compare the
+	 underlying records.  */
+      if (TREE_CODE (have_va_type) == ARRAY_TYPE
+	  || POINTER_TYPE_P (have_va_type))
+	{
+	  want_va_type = TREE_TYPE (want_va_type);
+	  have_va_type = TREE_TYPE (have_va_type);
+	}
+    }
+
+  if (TYPE_MAIN_VARIANT (want_va_type) != TYPE_MAIN_VARIANT (have_va_type))
+    {
+      error ("first argument to %<va_arg%> not of type %<va_list%>");
+      return GS_ERROR;
+    }
+
+  /* Generate a diagnostic for requesting data of a type that cannot
+     be passed through `...' due to type promotion at the call site.  */
+  else if ((promoted_type = lang_hooks.types.type_promotes_to (type))
+	   != type)
+    {
+      static bool gave_help;
+
+      /* Unfortunately, this is merely undefined, rather than a constraint
+	 violation, so we cannot make this an error.  If this call is never
+	 executed, the program is still strictly conforming.  */
+      warning (0, "%qT is promoted to %qT when passed through %<...%>",
+	       type, promoted_type);
+      if (! gave_help)
+	{
+	  gave_help = true;
+	  warning (0, "(so you should pass %qT not %qT to %<va_arg%>)",
+		   promoted_type, type);
+	}
+
+      /* We can, however, treat "undefined" any way we please.
+	 Call abort to encourage the user to fix the program.  */
+      inform ("if this code is reached, the program will abort");
+      t = build_function_call_expr (implicit_built_in_decls[BUILT_IN_TRAP],
+				    NULL);
+      append_to_statement_list (t, pre_p);
+
+      /* This is dead code, but go ahead and finish so that the
+	 mode of the result comes out right.  */
+      *expr_p = dummy_object (type);
+      return GS_ALL_DONE;
+    }
+  else
+    {
+      /* Make it easier for the backends by protecting the valist argument
+         from multiple evaluations.  */
+      if (TREE_CODE (va_list_type_node) == ARRAY_TYPE)
+	{
+	  /* For this case, the backends will be expecting a pointer to
+	     TREE_TYPE (va_list_type_node), but it's possible we've
+	     actually been given an array (an actual va_list_type_node).
+	     So fix it.  */
+	  if (TREE_CODE (TREE_TYPE (valist)) == ARRAY_TYPE)
+	    {
+	      tree p1 = build_pointer_type (TREE_TYPE (va_list_type_node));
+	      valist = build_fold_addr_expr_with_type (valist, p1);
+	    }
+	  gimplify_expr (&valist, pre_p, post_p, is_gimple_val, fb_rvalue);
+	}
+      else
+	gimplify_expr (&valist, pre_p, post_p, is_gimple_min_lval, fb_lvalue);
+
+      if (!targetm.gimplify_va_arg_expr)
+	/* FIXME:Once most targets are converted we should merely
+	   assert this is non-null.  */
+	return GS_ALL_DONE;
+
+      *expr_p = targetm.gimplify_va_arg_expr (valist, type, pre_p, post_p);
+      return GS_OK;
+    }
+}
+
+/* Expand ARGLIST, from a call to __builtin_va_end.  */
+
+static rtx
+expand_builtin_va_end (tree arglist)
+{
+  tree valist = TREE_VALUE (arglist);
+
+  /* Evaluate for side effects, if needed.  I hate macros that don't
+     do that.  */
+  if (TREE_SIDE_EFFECTS (valist))
+    expand_expr (valist, const0_rtx, VOIDmode, EXPAND_NORMAL);
+
+  return const0_rtx;
+}
+
+/* Expand ARGLIST, from a call to __builtin_va_copy.  We do this as a
+   builtin rather than just as an assignment in stdarg.h because of the
+   nastiness of array-type va_list types.  */
+
+static rtx
+expand_builtin_va_copy (tree arglist)
+{
+  tree dst, src, t;
+
+  dst = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+
+  dst = stabilize_va_list (dst, 1);
+  src = stabilize_va_list (src, 0);
+
+  if (TREE_CODE (va_list_type_node) != ARRAY_TYPE)
+    {
+      t = build2 (MODIFY_EXPR, va_list_type_node, dst, src);
+      TREE_SIDE_EFFECTS (t) = 1;
+      expand_expr (t, const0_rtx, VOIDmode, EXPAND_NORMAL);
+    }
+  else
+    {
+      rtx dstb, srcb, size;
+
+      /* Evaluate to pointers.  */
+      dstb = expand_expr (dst, NULL_RTX, Pmode, EXPAND_NORMAL);
+      srcb = expand_expr (src, NULL_RTX, Pmode, EXPAND_NORMAL);
+      size = expand_expr (TYPE_SIZE_UNIT (va_list_type_node), NULL_RTX,
+			  VOIDmode, EXPAND_NORMAL);
+
+      dstb = convert_memory_address (Pmode, dstb);
+      srcb = convert_memory_address (Pmode, srcb);
+
+      /* "Dereference" to BLKmode memories.  */
+      dstb = gen_rtx_MEM (BLKmode, dstb);
+      set_mem_alias_set (dstb, get_alias_set (TREE_TYPE (TREE_TYPE (dst))));
+      set_mem_align (dstb, TYPE_ALIGN (va_list_type_node));
+      srcb = gen_rtx_MEM (BLKmode, srcb);
+      set_mem_alias_set (srcb, get_alias_set (TREE_TYPE (TREE_TYPE (src))));
+      set_mem_align (srcb, TYPE_ALIGN (va_list_type_node));
+
+      /* Copy.  */
+      emit_block_move (dstb, srcb, size, BLOCK_OP_NORMAL);
+    }
+
+  return const0_rtx;
+}
+
+/* Expand a call to one of the builtin functions __builtin_frame_address or
+   __builtin_return_address.  */
+
+static rtx
+expand_builtin_frame_address (tree fndecl, tree arglist)
+{
+  /* The argument must be a nonnegative integer constant.
+     It counts the number of frames to scan up the stack.
+     The value is the return address saved in that frame.  */
+  if (arglist == 0)
+    /* Warning about missing arg was already issued.  */
+    return const0_rtx;
+  else if (! host_integerp (TREE_VALUE (arglist), 1))
+    {
+      if (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_FRAME_ADDRESS)
+	error ("invalid argument to %<__builtin_frame_address%>");
+      else
+	error ("invalid argument to %<__builtin_return_address%>");
+      return const0_rtx;
+    }
+  else
+    {
+      rtx tem
+	= expand_builtin_return_addr (DECL_FUNCTION_CODE (fndecl),
+				      tree_low_cst (TREE_VALUE (arglist), 1));
+
+      /* Some ports cannot access arbitrary stack frames.  */
+      if (tem == NULL)
+	{
+	  if (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_FRAME_ADDRESS)
+	    warning (0, "unsupported argument to %<__builtin_frame_address%>");
+	  else
+	    warning (0, "unsupported argument to %<__builtin_return_address%>");
+	  return const0_rtx;
+	}
+
+      /* For __builtin_frame_address, return what we've got.  */
+      if (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_FRAME_ADDRESS)
+	return tem;
+
+      if (!REG_P (tem)
+	  && ! CONSTANT_P (tem))
+	tem = copy_to_mode_reg (Pmode, tem);
+      return tem;
+    }
+}
+
+/* Expand a call to the alloca builtin, with arguments ARGLIST.  Return 0 if
+   we failed and the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_alloca (tree arglist, rtx target)
+{
+  rtx op0;
+  rtx result;
+
+  /* In -fmudflap-instrumented code, alloca() and __builtin_alloca()
+     should always expand to function calls.  These can be intercepted
+     in libmudflap.  */
+  if (flag_mudflap)
+    return 0;
+
+  if (!validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Compute the argument.  */
+  op0 = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);
+
+  /* Allocate the desired space.  */
+  result = allocate_dynamic_stack_space (op0, target, BITS_PER_UNIT);
+  result = convert_memory_address (ptr_mode, result);
+
+  return result;
+}
+
+/* Expand a call to a unary builtin.  The arguments are in ARGLIST.
+   Return 0 if a normal call should be emitted rather than expanding the
+   function in-line.  If convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing one of EXP's operands.  */
+
+static rtx
+expand_builtin_unop (enum machine_mode target_mode, tree arglist, rtx target,
+		     rtx subtarget, optab op_optab)
+{
+  rtx op0;
+  if (!validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Compute the argument.  */
+  op0 = expand_expr (TREE_VALUE (arglist), subtarget, VOIDmode, 0);
+  /* Compute op, into TARGET if possible.
+     Set TARGET to wherever the result comes back.  */
+  target = expand_unop (TYPE_MODE (TREE_TYPE (TREE_VALUE (arglist))),
+			op_optab, op0, target, 1);
+  gcc_assert (target);
+
+  return convert_to_mode (target_mode, target, 0);
+}
+
+/* If the string passed to fputs is a constant and is one character
+   long, we attempt to transform this call into __builtin_fputc().  */
+
+static rtx
+expand_builtin_fputs (tree arglist, rtx target, bool unlocked)
+{
+  /* Verify the arguments in the original call.  */
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_fputs (arglist, (target == const0_rtx),
+					unlocked, NULL_TREE);
+      if (result)
+	return expand_expr (result, target, VOIDmode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand a call to __builtin_expect.  We return our argument and emit a
+   NOTE_INSN_EXPECTED_VALUE note.  This is the expansion of __builtin_expect in
+   a non-jump context.  */
+
+static rtx
+expand_builtin_expect (tree arglist, rtx target)
+{
+  tree exp, c;
+  rtx note, rtx_c;
+
+  if (arglist == NULL_TREE
+      || TREE_CHAIN (arglist) == NULL_TREE)
+    return const0_rtx;
+  exp = TREE_VALUE (arglist);
+  c = TREE_VALUE (TREE_CHAIN (arglist));
+
+  if (TREE_CODE (c) != INTEGER_CST)
+    {
+      error ("second argument to %<__builtin_expect%> must be a constant");
+      c = integer_zero_node;
+    }
+
+  target = expand_expr (exp, target, VOIDmode, EXPAND_NORMAL);
+
+  /* Don't bother with expected value notes for integral constants.  */
+  if (flag_guess_branch_prob && GET_CODE (target) != CONST_INT)
+    {
+      /* We do need to force this into a register so that we can be
+	 moderately sure to be able to correctly interpret the branch
+	 condition later.  */
+      target = force_reg (GET_MODE (target), target);
+
+      rtx_c = expand_expr (c, NULL_RTX, GET_MODE (target), EXPAND_NORMAL);
+
+      note = emit_note (NOTE_INSN_EXPECTED_VALUE);
+      NOTE_EXPECTED_VALUE (note) = gen_rtx_EQ (VOIDmode, target, rtx_c);
+    }
+
+  return target;
+}
+
+/* Like expand_builtin_expect, except do this in a jump context.  This is
+   called from do_jump if the conditional is a __builtin_expect.  Return either
+   a list of insns to emit the jump or NULL if we cannot optimize
+   __builtin_expect.  We need to optimize this at jump time so that machines
+   like the PowerPC don't turn the test into a SCC operation, and then jump
+   based on the test being 0/1.  */
+
+rtx
+expand_builtin_expect_jump (tree exp, rtx if_false_label, rtx if_true_label)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree arg0 = TREE_VALUE (arglist);
+  tree arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+  rtx ret = NULL_RTX;
+
+  /* Only handle __builtin_expect (test, 0) and
+     __builtin_expect (test, 1).  */
+  if (TREE_CODE (TREE_TYPE (arg1)) == INTEGER_TYPE
+      && (integer_zerop (arg1) || integer_onep (arg1)))
+    {
+      rtx insn, drop_through_label, temp;
+
+      /* Expand the jump insns.  */
+      start_sequence ();
+      do_jump (arg0, if_false_label, if_true_label);
+      ret = get_insns ();
+
+      drop_through_label = get_last_insn ();
+      if (drop_through_label && NOTE_P (drop_through_label))
+	drop_through_label = prev_nonnote_insn (drop_through_label);
+      if (drop_through_label && !LABEL_P (drop_through_label))
+	drop_through_label = NULL_RTX;
+      end_sequence ();
+
+      if (! if_true_label)
+	if_true_label = drop_through_label;
+      if (! if_false_label)
+	if_false_label = drop_through_label;
+
+      /* Go through and add the expect's to each of the conditional jumps.  */
+      insn = ret;
+      while (insn != NULL_RTX)
+	{
+	  rtx next = NEXT_INSN (insn);
+
+	  if (JUMP_P (insn) && any_condjump_p (insn))
+	    {
+	      rtx ifelse = SET_SRC (pc_set (insn));
+	      rtx then_dest = XEXP (ifelse, 1);
+	      rtx else_dest = XEXP (ifelse, 2);
+	      int taken = -1;
+
+	      /* First check if we recognize any of the labels.  */
+	      if (GET_CODE (then_dest) == LABEL_REF
+		  && XEXP (then_dest, 0) == if_true_label)
+		taken = 1;
+	      else if (GET_CODE (then_dest) == LABEL_REF
+		       && XEXP (then_dest, 0) == if_false_label)
+		taken = 0;
+	      else if (GET_CODE (else_dest) == LABEL_REF
+		       && XEXP (else_dest, 0) == if_false_label)
+		taken = 1;
+	      else if (GET_CODE (else_dest) == LABEL_REF
+		       && XEXP (else_dest, 0) == if_true_label)
+		taken = 0;
+	      /* Otherwise check where we drop through.  */
+	      else if (else_dest == pc_rtx)
+		{
+		  if (next && NOTE_P (next))
+		    next = next_nonnote_insn (next);
+
+		  if (next && JUMP_P (next)
+		      && any_uncondjump_p (next))
+		    temp = XEXP (SET_SRC (pc_set (next)), 0);
+		  else
+		    temp = next;
+
+		  /* TEMP is either a CODE_LABEL, NULL_RTX or something
+		     else that can't possibly match either target label.  */
+		  if (temp == if_false_label)
+		    taken = 1;
+		  else if (temp == if_true_label)
+		    taken = 0;
+		}
+	      else if (then_dest == pc_rtx)
+		{
+		  if (next && NOTE_P (next))
+		    next = next_nonnote_insn (next);
+
+		  if (next && JUMP_P (next)
+		      && any_uncondjump_p (next))
+		    temp = XEXP (SET_SRC (pc_set (next)), 0);
+		  else
+		    temp = next;
+
+		  if (temp == if_false_label)
+		    taken = 0;
+		  else if (temp == if_true_label)
+		    taken = 1;
+		}
+
+	      if (taken != -1)
+		{
+		  /* If the test is expected to fail, reverse the
+		     probabilities.  */
+		  if (integer_zerop (arg1))
+		    taken = 1 - taken;
+	          predict_insn_def (insn, PRED_BUILTIN_EXPECT, taken);
+		}
+	    }
+
+	  insn = next;
+	}
+    }
+
+  return ret;
+}
+
+void
+expand_builtin_trap (void)
+{
+#ifdef HAVE_trap
+  if (HAVE_trap)
+    emit_insn (gen_trap ());
+  else
+#endif
+    emit_library_call (abort_libfunc, LCT_NORETURN, VOIDmode, 0);
+  emit_barrier ();
+}
+
+/* Expand a call to fabs, fabsf or fabsl with arguments ARGLIST.
+   Return 0 if a normal call should be emitted rather than expanding
+   the function inline.  If convenient, the result should be placed
+   in TARGET.  SUBTARGET may be used as the target for computing
+   the operand.  */
+
+static rtx
+expand_builtin_fabs (tree arglist, rtx target, rtx subtarget)
+{
+  enum machine_mode mode;
+  tree arg;
+  rtx op0;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  mode = TYPE_MODE (TREE_TYPE (arg));
+  op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+  return expand_abs (mode, op0, target, 0, safe_from_p (target, arg, 1));
+}
+
+/* Expand a call to copysign, copysignf, or copysignl with arguments ARGLIST.
+   Return NULL is a normal call should be emitted rather than expanding the
+   function inline.  If convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing the operand.  */
+
+static rtx
+expand_builtin_copysign (tree arglist, rtx target, rtx subtarget)
+{
+  rtx op0, op1;
+  tree arg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+
+  arg = TREE_VALUE (TREE_CHAIN (arglist));
+  op1 = expand_expr (arg, NULL, VOIDmode, 0);
+
+  return expand_copysign (op0, op1, target);
+}
+
+/* Create a new constant string literal and return a char* pointer to it.
+   The STRING_CST value is the LEN characters at STR.  */
+static tree
+build_string_literal (int len, const char *str)
+{
+  tree t, elem, index, type;
+
+  t = build_string (len, str);
+  elem = build_type_variant (char_type_node, 1, 0);
+  index = build_index_type (build_int_cst (NULL_TREE, len - 1));
+  type = build_array_type (elem, index);
+  TREE_TYPE (t) = type;
+  TREE_CONSTANT (t) = 1;
+  TREE_INVARIANT (t) = 1;
+  TREE_READONLY (t) = 1;
+  TREE_STATIC (t) = 1;
+
+  type = build_pointer_type (type);
+  t = build1 (ADDR_EXPR, type, t);
+
+  type = build_pointer_type (elem);
+  t = build1 (NOP_EXPR, type, t);
+  return t;
+}
+
+/* Expand EXP, a call to printf or printf_unlocked.
+   Return 0 if a normal call should be emitted rather than transforming
+   the function inline.  If convenient, the result should be placed in
+   TARGET with mode MODE.  UNLOCKED indicates this is a printf_unlocked
+   call.  */
+static rtx
+expand_builtin_printf (tree exp, rtx target, enum machine_mode mode,
+		       bool unlocked)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  /* If we're using an unlocked function, assume the other unlocked
+     functions exist explicitly.  */
+  tree const fn_putchar = unlocked ? built_in_decls[BUILT_IN_PUTCHAR_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_PUTCHAR];
+  tree const fn_puts = unlocked ? built_in_decls[BUILT_IN_PUTS_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_PUTS];
+  const char *fmt_str;
+  tree fn, fmt, arg;
+
+  /* If the return value is used, don't do the transformation.  */
+  if (target != const0_rtx)
+    return 0;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return 0;
+
+  if (!init_target_chars())
+    return 0;
+  
+  /* If the format specifier was "%s\n", call __builtin_puts(arg).  */
+  if (strcmp (fmt_str, target_percent_s_newline) == 0)
+    {
+      if (! arglist
+          || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	  || TREE_CHAIN (arglist))
+	return 0;
+      fn = fn_puts;
+    }
+  /* If the format specifier was "%c", call __builtin_putchar(arg).  */
+  else if (strcmp (fmt_str, target_percent_c) == 0)
+    {
+      if (! arglist
+	  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != INTEGER_TYPE
+	  || TREE_CHAIN (arglist))
+	return 0;
+      fn = fn_putchar;
+    }
+  else
+    {
+      /* We can't handle anything else with % args or %% ... yet.  */
+      if (strchr (fmt_str, target_percent))
+        return 0;
+
+      if (arglist)
+	return 0;
+
+      /* If the format specifier was "", printf does nothing.  */
+      if (fmt_str[0] == '\0')
+	return const0_rtx;
+      /* If the format specifier has length of 1, call putchar.  */
+      if (fmt_str[1] == '\0')
+	{
+	  /* Given printf("c"), (where c is any one character,)
+	     convert "c"[0] to an int and pass that to the replacement
+	     function.  */
+	  arg = build_int_cst (NULL_TREE, fmt_str[0]);
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  fn = fn_putchar;
+	}
+      else
+	{
+	  /* If the format specifier was "string\n", call puts("string").  */
+	  size_t len = strlen (fmt_str);
+	  if ((unsigned char)fmt_str[len - 1] == target_newline)
+	    {
+	      /* Create a NUL-terminated string that's one char shorter
+		 than the original, stripping off the trailing '\n'.  */
+	      char *newstr = alloca (len);
+	      memcpy (newstr, fmt_str, len - 1);
+	      newstr[len - 1] = 0;
+
+	      arg = build_string_literal (len, newstr);
+	      arglist = build_tree_list (NULL_TREE, arg);
+	      fn = fn_puts;
+	    }
+	  else
+	    /* We'd like to arrange to call fputs(string,stdout) here,
+	       but we need stdout and don't have a way to get it yet.  */
+	    return 0;
+	}
+    }
+
+  if (!fn)
+    return 0;
+  fn = build_function_call_expr (fn, arglist);
+  if (TREE_CODE (fn) == CALL_EXPR)
+    CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+  return expand_expr (fn, target, mode, EXPAND_NORMAL);
+}
+
+/* Expand EXP, a call to fprintf or fprintf_unlocked.
+   Return 0 if a normal call should be emitted rather than transforming
+   the function inline.  If convenient, the result should be placed in
+   TARGET with mode MODE.  UNLOCKED indicates this is a fprintf_unlocked
+   call.  */
+static rtx
+expand_builtin_fprintf (tree exp, rtx target, enum machine_mode mode,
+		        bool unlocked)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  /* If we're using an unlocked function, assume the other unlocked
+     functions exist explicitly.  */
+  tree const fn_fputc = unlocked ? built_in_decls[BUILT_IN_FPUTC_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_FPUTC];
+  tree const fn_fputs = unlocked ? built_in_decls[BUILT_IN_FPUTS_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_FPUTS];
+  const char *fmt_str;
+  tree fn, fmt, fp, arg;
+
+  /* If the return value is used, don't do the transformation.  */
+  if (target != const0_rtx)
+    return 0;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  fp = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fp)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return 0;
+
+  if (!init_target_chars())
+    return 0;
+  
+  /* If the format specifier was "%s", call __builtin_fputs(arg,fp).  */
+  if (strcmp (fmt_str, target_percent_s) == 0)
+    {
+      if (! arglist
+          || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	  || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, arg, arglist);
+      fn = fn_fputs;
+    }
+  /* If the format specifier was "%c", call __builtin_fputc(arg,fp).  */
+  else if (strcmp (fmt_str, target_percent_c) == 0)
+    {
+      if (! arglist
+	  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != INTEGER_TYPE
+	  || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, arg, arglist);
+      fn = fn_fputc;
+    }
+  else
+    {
+      /* We can't handle anything else with % args or %% ... yet.  */
+      if (strchr (fmt_str, target_percent))
+        return 0;
+
+      if (arglist)
+	return 0;
+
+      /* If the format specifier was "", fprintf does nothing.  */
+      if (fmt_str[0] == '\0')
+	{
+	  /* Evaluate and ignore FILE* argument for side-effects.  */
+	  expand_expr (fp, const0_rtx, VOIDmode, EXPAND_NORMAL);
+	  return const0_rtx;
+	}
+
+      /* When "string" doesn't contain %, replace all cases of
+	 fprintf(stream,string) with fputs(string,stream).  The fputs
+	 builtin will take care of special cases like length == 1.  */
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, fmt, arglist);
+      fn = fn_fputs;
+    }
+
+  if (!fn)
+    return 0;
+  fn = build_function_call_expr (fn, arglist);
+  if (TREE_CODE (fn) == CALL_EXPR)
+    CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+  return expand_expr (fn, target, mode, EXPAND_NORMAL);
+}
+
+/* Expand a call to sprintf with argument list ARGLIST.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   inline.  If convenient, the result should be placed in TARGET with
+   mode MODE.  */
+
+static rtx
+expand_builtin_sprintf (tree arglist, rtx target, enum machine_mode mode)
+{
+  tree orig_arglist, dest, fmt;
+  const char *fmt_str;
+
+  orig_arglist = arglist;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  dest = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (dest)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return 0;
+
+  if (!init_target_chars())
+    return 0;
+
+  /* If the format doesn't contain % args or %%, use strcpy.  */
+  if (strchr (fmt_str, target_percent) == 0)
+    {
+      tree fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+      tree exp;
+
+      if (arglist || ! fn)
+	return 0;
+      expand_expr (build_function_call_expr (fn, orig_arglist),
+		   const0_rtx, VOIDmode, EXPAND_NORMAL);
+      if (target == const0_rtx)
+	return const0_rtx;
+      exp = build_int_cst (NULL_TREE, strlen (fmt_str));
+      return expand_expr (exp, target, mode, EXPAND_NORMAL);
+    }
+  /* If the format is "%s", use strcpy if the result isn't used.  */
+  else if (strcmp (fmt_str, target_percent_s) == 0)
+    {
+      tree fn, arg, len;
+      fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+
+      if (! fn)
+	return 0;
+
+      if (! arglist || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      if (! POINTER_TYPE_P (TREE_TYPE (arg)))
+	return 0;
+
+      if (target != const0_rtx)
+	{
+	  len = c_strlen (arg, 1);
+	  if (! len || TREE_CODE (len) != INTEGER_CST)
+	    return 0;
+	}
+      else
+	len = NULL_TREE;
+
+      arglist = build_tree_list (NULL_TREE, arg);
+      arglist = tree_cons (NULL_TREE, dest, arglist);
+      expand_expr (build_function_call_expr (fn, arglist),
+		   const0_rtx, VOIDmode, EXPAND_NORMAL);
+
+      if (target == const0_rtx)
+	return const0_rtx;
+      return expand_expr (len, target, mode, EXPAND_NORMAL);
+    }
+
+  return 0;
+}
+
+/* Expand a call to either the entry or exit function profiler.  */
+
+static rtx
+expand_builtin_profile_func (bool exitp)
+{
+  rtx this, which;
+
+  this = DECL_RTL (current_function_decl);
+  gcc_assert (MEM_P (this));
+  this = XEXP (this, 0);
+
+  if (exitp)
+    which = profile_function_exit_libfunc;
+  else
+    which = profile_function_entry_libfunc;
+
+  emit_library_call (which, LCT_NORMAL, VOIDmode, 2, this, Pmode,
+		     expand_builtin_return_addr (BUILT_IN_RETURN_ADDRESS,
+						 0),
+		     Pmode);
+
+  return const0_rtx;
+}
+
+/* Given a trampoline address, make sure it satisfies TRAMPOLINE_ALIGNMENT.  */
+
+static rtx
+round_trampoline_addr (rtx tramp)
+{
+  rtx temp, addend, mask;
+
+  /* If we don't need too much alignment, we'll have been guaranteed
+     proper alignment by get_trampoline_type.  */
+  if (TRAMPOLINE_ALIGNMENT <= STACK_BOUNDARY)
+    return tramp;
+
+  /* Round address up to desired boundary.  */
+  temp = gen_reg_rtx (Pmode);
+  addend = GEN_INT (TRAMPOLINE_ALIGNMENT / BITS_PER_UNIT - 1);
+  mask = GEN_INT (-TRAMPOLINE_ALIGNMENT / BITS_PER_UNIT);
+
+  temp  = expand_simple_binop (Pmode, PLUS, tramp, addend,
+			       temp, 0, OPTAB_LIB_WIDEN);
+  tramp = expand_simple_binop (Pmode, AND, temp, mask,
+			       temp, 0, OPTAB_LIB_WIDEN);
+
+  return tramp;
+}
+
+static rtx
+expand_builtin_init_trampoline (tree arglist)
+{
+  tree t_tramp, t_func, t_chain;
+  rtx r_tramp, r_func, r_chain;
+#ifdef TRAMPOLINE_TEMPLATE
+  rtx blktramp;
+#endif
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE,
+			 POINTER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  t_tramp = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  t_func = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  t_chain = TREE_VALUE (arglist);
+
+  r_tramp = expand_expr (t_tramp, NULL_RTX, VOIDmode, 0);
+  r_func = expand_expr (t_func, NULL_RTX, VOIDmode, 0);
+  r_chain = expand_expr (t_chain, NULL_RTX, VOIDmode, 0);
+
+  /* Generate insns to initialize the trampoline.  */
+  r_tramp = round_trampoline_addr (r_tramp);
+#ifdef TRAMPOLINE_TEMPLATE
+  blktramp = gen_rtx_MEM (BLKmode, r_tramp);
+  set_mem_align (blktramp, TRAMPOLINE_ALIGNMENT);
+  emit_block_move (blktramp, assemble_trampoline_template (),
+		   GEN_INT (TRAMPOLINE_SIZE), BLOCK_OP_NORMAL);
+#endif
+  trampolines_created = 1;
+  INITIALIZE_TRAMPOLINE (r_tramp, r_func, r_chain);
+
+  return const0_rtx;
+}
+
+static rtx
+expand_builtin_adjust_trampoline (tree arglist)
+{
+  rtx tramp;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  tramp = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);
+  tramp = round_trampoline_addr (tramp);
+#ifdef TRAMPOLINE_ADJUST_ADDRESS
+  TRAMPOLINE_ADJUST_ADDRESS (tramp);
+#endif
+
+  return tramp;
+}
+
+/* Expand a call to the built-in signbit, signbitf or signbitl function.
+   Return NULL_RTX if a normal call should be emitted rather than expanding
+   the function in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.  */
+
+static rtx
+expand_builtin_signbit (tree exp, rtx target)
+{
+  const struct real_format *fmt;
+  enum machine_mode fmode, imode, rmode;
+  HOST_WIDE_INT hi, lo;
+  tree arg, arglist;
+  int word, bitpos;
+  rtx temp;
+
+  arglist = TREE_OPERAND (exp, 1);
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  fmode = TYPE_MODE (TREE_TYPE (arg));
+  rmode = TYPE_MODE (TREE_TYPE (exp));
+  fmt = REAL_MODE_FORMAT (fmode);
+
+  /* For floating point formats without a sign bit, implement signbit
+     as "ARG < 0.0".  */
+  bitpos = fmt->signbit_ro;
+  if (bitpos < 0)
+  {
+    /* But we can't do this if the format supports signed zero.  */
+    if (fmt->has_signed_zero && HONOR_SIGNED_ZEROS (fmode))
+      return 0;
+
+    arg = fold_build2 (LT_EXPR, TREE_TYPE (exp), arg,
+		       build_real (TREE_TYPE (arg), dconst0));
+    return expand_expr (arg, target, VOIDmode, EXPAND_NORMAL);
+  }
+
+  temp = expand_expr (arg, NULL_RTX, VOIDmode, 0);
+  if (GET_MODE_SIZE (fmode) <= UNITS_PER_WORD)
+    {
+      imode = int_mode_for_mode (fmode);
+      if (imode == BLKmode)
+	return 0;
+      temp = gen_lowpart (imode, temp);
+    }
+  else
+    {
+      imode = word_mode;
+      /* Handle targets with different FP word orders.  */
+      if (FLOAT_WORDS_BIG_ENDIAN)
+        word = (GET_MODE_BITSIZE (fmode) - bitpos) / BITS_PER_WORD;
+      else
+        word = bitpos / BITS_PER_WORD;
+      temp = operand_subword_force (temp, word, fmode);
+      bitpos = bitpos % BITS_PER_WORD;
+    }
+
+  /* Force the intermediate word_mode (or narrower) result into a
+     register.  This avoids attempting to create paradoxical SUBREGs
+     of floating point modes below.  */
+  temp = force_reg (imode, temp);
+
+  /* If the bitpos is within the "result mode" lowpart, the operation
+     can be implement with a single bitwise AND.  Otherwise, we need
+     a right shift and an AND.  */
+
+  if (bitpos < GET_MODE_BITSIZE (rmode))
+    {
+      if (bitpos < HOST_BITS_PER_WIDE_INT)
+	{
+	  hi = 0;
+	  lo = (HOST_WIDE_INT) 1 << bitpos;
+	}
+      else
+	{
+	  hi = (HOST_WIDE_INT) 1 << (bitpos - HOST_BITS_PER_WIDE_INT);
+	  lo = 0;
+	}
+
+      if (imode != rmode)
+	temp = gen_lowpart (rmode, temp);
+      temp = expand_binop (rmode, and_optab, temp,
+			   immed_double_const (lo, hi, rmode),
+			   NULL_RTX, 1, OPTAB_LIB_WIDEN);
+    }
+  else
+    {
+      /* Perform a logical right shift to place the signbit in the least
+         significant bit, then truncate the result to the desired mode
+	 and mask just this bit.  */
+      temp = expand_shift (RSHIFT_EXPR, imode, temp,
+			   build_int_cst (NULL_TREE, bitpos), NULL_RTX, 1);
+      temp = gen_lowpart (rmode, temp);
+      temp = expand_binop (rmode, and_optab, temp, const1_rtx,
+			   NULL_RTX, 1, OPTAB_LIB_WIDEN);
+    }
+
+  return temp;
+}
+
+/* Expand fork or exec calls.  TARGET is the desired target of the
+   call.  ARGLIST is the list of arguments of the call.  FN is the
+   identificator of the actual function.  IGNORE is nonzero if the
+   value is to be ignored.  */
+
+static rtx
+expand_builtin_fork_or_exec (tree fn, tree arglist, rtx target, int ignore)
+{
+  tree id, decl;
+  tree call;
+
+  /* If we are not profiling, just call the function.  */
+  if (!profile_arc_flag)
+    return NULL_RTX;
+
+  /* Otherwise call the wrapper.  This should be equivalent for the rest of
+     compiler, so the code does not diverge, and the wrapper may run the
+     code necessary for keeping the profiling sane.  */
+
+  switch (DECL_FUNCTION_CODE (fn))
+    {
+    case BUILT_IN_FORK:
+      id = get_identifier ("__gcov_fork");
+      break;
+
+    case BUILT_IN_EXECL:
+      id = get_identifier ("__gcov_execl");
+      break;
+
+    case BUILT_IN_EXECV:
+      id = get_identifier ("__gcov_execv");
+      break;
+
+    case BUILT_IN_EXECLP:
+      id = get_identifier ("__gcov_execlp");
+      break;
+
+    case BUILT_IN_EXECLE:
+      id = get_identifier ("__gcov_execle");
+      break;
+
+    case BUILT_IN_EXECVP:
+      id = get_identifier ("__gcov_execvp");
+      break;
+
+    case BUILT_IN_EXECVE:
+      id = get_identifier ("__gcov_execve");
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  decl = build_decl (FUNCTION_DECL, id, TREE_TYPE (fn));
+  DECL_EXTERNAL (decl) = 1;
+  TREE_PUBLIC (decl) = 1;
+  DECL_ARTIFICIAL (decl) = 1;
+  TREE_NOTHROW (decl) = 1;
+  call = build_function_call_expr (decl, arglist);
+
+  return expand_call (call, target, ignore);
+}
+
+
+/* Reconstitute a mode for a __sync intrinsic operation.  Since the type of
+   the pointer in these functions is void*, the tree optimizers may remove
+   casts.  The mode computed in expand_builtin isn't reliable either, due
+   to __sync_bool_compare_and_swap.
+
+   FCODE_DIFF should be fcode - base, where base is the FOO_1 code for the
+   group of builtins.  This gives us log2 of the mode size.  */
+
+static inline enum machine_mode
+get_builtin_sync_mode (int fcode_diff)
+{
+  /* The size is not negotiable, so ask not to get BLKmode in return
+     if the target indicates that a smaller size would be better.  */
+  return mode_for_size (BITS_PER_UNIT << fcode_diff, MODE_INT, 0);
+}
+
+/* Expand the __sync_xxx_and_fetch and __sync_fetch_and_xxx intrinsics.
+   ARGLIST is the operands list to the function.  CODE is the rtx code 
+   that corresponds to the arithmetic or logical operation from the name;
+   an exception here is that NOT actually means NAND.  TARGET is an optional
+   place for us to store the results; AFTER is true if this is the
+   fetch_and_xxx form.  IGNORE is true if we don't actually care about
+   the result of the operation at all.  */
+
+static rtx
+expand_builtin_sync_operation (enum machine_mode mode, tree arglist,
+			       enum rtx_code code, bool after,
+			       rtx target, bool ignore)
+{
+  rtx addr, val, mem;
+
+  /* Expand the operands.  */
+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_SUM);
+
+  arglist = TREE_CHAIN (arglist);
+  val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);
+
+  /* Note that we explicitly do not want any alias information for this
+     memory, so that we kill all other live memories.  Otherwise we don't
+     satisfy the full barrier semantics of the intrinsic.  */
+  mem = validize_mem (gen_rtx_MEM (mode, addr));
+  MEM_VOLATILE_P (mem) = 1;
+
+  if (ignore)
+    return expand_sync_operation (mem, val, code);
+  else
+    return expand_sync_fetch_operation (mem, val, code, after, target);
+}
+
+/* Expand the __sync_val_compare_and_swap and __sync_bool_compare_and_swap
+   intrinsics.  ARGLIST is the operands list to the function.  IS_BOOL is
+   true if this is the boolean form.  TARGET is a place for us to store the
+   results; this is NOT optional if IS_BOOL is true.  */
+
+static rtx
+expand_builtin_compare_and_swap (enum machine_mode mode, tree arglist,
+				 bool is_bool, rtx target)
+{
+  rtx addr, old_val, new_val, mem;
+
+  /* Expand the operands.  */
+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_SUM);
+
+  arglist = TREE_CHAIN (arglist);
+  old_val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);
+
+  arglist = TREE_CHAIN (arglist);
+  new_val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);
+
+  /* Note that we explicitly do not want any alias information for this
+     memory, so that we kill all other live memories.  Otherwise we don't
+     satisfy the full barrier semantics of the intrinsic.  */
+  mem = validize_mem (gen_rtx_MEM (mode, addr));
+  MEM_VOLATILE_P (mem) = 1;
+
+  if (is_bool)
+    return expand_bool_compare_and_swap (mem, old_val, new_val, target);
+  else
+    return expand_val_compare_and_swap (mem, old_val, new_val, target);
+}
+
+/* Expand the __sync_lock_test_and_set intrinsic.  Note that the most
+   general form is actually an atomic exchange, and some targets only
+   support a reduced form with the second argument being a constant 1.
+   ARGLIST is the operands list to the function; TARGET is an optional
+   place for us to store the results.  */
+
+static rtx
+expand_builtin_lock_test_and_set (enum machine_mode mode, tree arglist,
+				  rtx target)
+{
+  rtx addr, val, mem;
+
+  /* Expand the operands.  */
+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_NORMAL);
+
+  arglist = TREE_CHAIN (arglist);
+  val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);
+
+  /* Note that we explicitly do not want any alias information for this
+     memory, so that we kill all other live memories.  Otherwise we don't
+     satisfy the barrier semantics of the intrinsic.  */
+  mem = validize_mem (gen_rtx_MEM (mode, addr));
+  MEM_VOLATILE_P (mem) = 1;
+
+  return expand_sync_lock_test_and_set (mem, val, target);
+}
+
+/* Expand the __sync_synchronize intrinsic.  */
+
+static void
+expand_builtin_synchronize (void)
+{
+  tree x;
+
+#ifdef HAVE_memory_barrier
+  if (HAVE_memory_barrier)
+    {
+      emit_insn (gen_memory_barrier ());
+      return;
+    }
+#endif
+
+  /* If no explicit memory barrier instruction is available, create an
+     empty asm stmt with a memory clobber.  */
+  x = build4 (ASM_EXPR, void_type_node, build_string (0, ""), NULL, NULL,
+	      tree_cons (NULL, build_string (6, "memory"), NULL));
+  ASM_VOLATILE_P (x) = 1;
+  expand_asm_expr (x);
+}
+
+/* Expand the __sync_lock_release intrinsic.  ARGLIST is the operands list
+   to the function.  */
+
+static void
+expand_builtin_lock_release (enum machine_mode mode, tree arglist)
+{
+  enum insn_code icode;
+  rtx addr, mem, insn;
+  rtx val = const0_rtx;
+
+  /* Expand the operands.  */
+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_NORMAL);
+
+  /* Note that we explicitly do not want any alias information for this
+     memory, so that we kill all other live memories.  Otherwise we don't
+     satisfy the barrier semantics of the intrinsic.  */
+  mem = validize_mem (gen_rtx_MEM (mode, addr));
+  MEM_VOLATILE_P (mem) = 1;
+
+  /* If there is an explicit operation in the md file, use it.  */
+  icode = sync_lock_release[mode];
+  if (icode != CODE_FOR_nothing)
+    {
+      if (!insn_data[icode].operand[1].predicate (val, mode))
+	val = force_reg (mode, val);
+
+      insn = GEN_FCN (icode) (mem, val);
+      if (insn)
+	{
+	  emit_insn (insn);
+	  return;
+	}
+    }
+
+  /* Otherwise we can implement this operation by emitting a barrier
+     followed by a store of zero.  */
+  expand_builtin_synchronize ();
+  emit_move_insn (mem, val);
+}
+
+/* Expand an expression EXP that calls a built-in function,
+   with result going to TARGET if that's convenient
+   (and in mode MODE if that's convenient).
+   SUBTARGET may be used as the target for computing one of EXP's operands.
+   IGNORE is nonzero if the value is to be ignored.  */
+
+rtx
+expand_builtin (tree exp, rtx target, rtx subtarget, enum machine_mode mode,
+		int ignore)
+{
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  enum built_in_function fcode = DECL_FUNCTION_CODE (fndecl);
+  enum machine_mode target_mode = TYPE_MODE (TREE_TYPE (exp));
+
+  if (DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_MD)
+    return targetm.expand_builtin (exp, target, subtarget, mode, ignore);
+
+  /* When not optimizing, generate calls to library functions for a certain
+     set of builtins.  */
+  if (!optimize
+      && !called_as_built_in (fndecl)
+      && DECL_ASSEMBLER_NAME_SET_P (fndecl)
+      && fcode != BUILT_IN_ALLOCA)
+    return expand_call (exp, target, ignore);
+
+  /* The built-in function expanders test for target == const0_rtx
+     to determine whether the function's result will be ignored.  */
+  if (ignore)
+    target = const0_rtx;
+
+  /* If the result of a pure or const built-in function is ignored, and
+     none of its arguments are volatile, we can avoid expanding the
+     built-in call and just evaluate the arguments for side-effects.  */
+  if (target == const0_rtx
+      && (DECL_IS_PURE (fndecl) || TREE_READONLY (fndecl)))
+    {
+      bool volatilep = false;
+      tree arg;
+
+      for (arg = arglist; arg; arg = TREE_CHAIN (arg))
+	if (TREE_THIS_VOLATILE (TREE_VALUE (arg)))
+	  {
+	    volatilep = true;
+	    break;
+	  }
+
+      if (! volatilep)
+	{
+	  for (arg = arglist; arg; arg = TREE_CHAIN (arg))
+	    expand_expr (TREE_VALUE (arg), const0_rtx,
+			 VOIDmode, EXPAND_NORMAL);
+	  return const0_rtx;
+	}
+    }
+
+  switch (fcode)
+    {
+    case BUILT_IN_FABS:
+    case BUILT_IN_FABSF:
+    case BUILT_IN_FABSL:
+      target = expand_builtin_fabs (arglist, target, subtarget);
+      if (target)
+        return target;
+      break;
+
+    case BUILT_IN_COPYSIGN:
+    case BUILT_IN_COPYSIGNF:
+    case BUILT_IN_COPYSIGNL:
+      target = expand_builtin_copysign (arglist, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+      /* Just do a normal library call if we were unable to fold
+	 the values.  */
+    case BUILT_IN_CABS:
+    case BUILT_IN_CABSF:
+    case BUILT_IN_CABSL:
+      break;
+
+    case BUILT_IN_EXP:
+    case BUILT_IN_EXPF:
+    case BUILT_IN_EXPL:
+    case BUILT_IN_EXP10:
+    case BUILT_IN_EXP10F:
+    case BUILT_IN_EXP10L:
+    case BUILT_IN_POW10:
+    case BUILT_IN_POW10F:
+    case BUILT_IN_POW10L:
+    case BUILT_IN_EXP2:
+    case BUILT_IN_EXP2F:
+    case BUILT_IN_EXP2L:
+    case BUILT_IN_EXPM1:
+    case BUILT_IN_EXPM1F:
+    case BUILT_IN_EXPM1L:
+    case BUILT_IN_LOGB:
+    case BUILT_IN_LOGBF:
+    case BUILT_IN_LOGBL:
+    case BUILT_IN_ILOGB:
+    case BUILT_IN_ILOGBF:
+    case BUILT_IN_ILOGBL:
+    case BUILT_IN_LOG:
+    case BUILT_IN_LOGF:
+    case BUILT_IN_LOGL:
+    case BUILT_IN_LOG10:
+    case BUILT_IN_LOG10F:
+    case BUILT_IN_LOG10L:
+    case BUILT_IN_LOG2:
+    case BUILT_IN_LOG2F:
+    case BUILT_IN_LOG2L:
+    case BUILT_IN_LOG1P:
+    case BUILT_IN_LOG1PF:
+    case BUILT_IN_LOG1PL:
+    case BUILT_IN_TAN:
+    case BUILT_IN_TANF:
+    case BUILT_IN_TANL:
+    case BUILT_IN_ASIN:
+    case BUILT_IN_ASINF:
+    case BUILT_IN_ASINL:
+    case BUILT_IN_ACOS:
+    case BUILT_IN_ACOSF:
+    case BUILT_IN_ACOSL:
+    case BUILT_IN_ATAN:
+    case BUILT_IN_ATANF:
+    case BUILT_IN_ATANL:
+      /* Treat these like sqrt only if unsafe math optimizations are allowed,
+	 because of possible accuracy problems.  */
+      if (! flag_unsafe_math_optimizations)
+	break;
+    case BUILT_IN_SQRT:
+    case BUILT_IN_SQRTF:
+    case BUILT_IN_SQRTL:
+    case BUILT_IN_FLOOR:
+    case BUILT_IN_FLOORF:
+    case BUILT_IN_FLOORL:
+    case BUILT_IN_CEIL:
+    case BUILT_IN_CEILF:
+    case BUILT_IN_CEILL:
+    case BUILT_IN_TRUNC:
+    case BUILT_IN_TRUNCF:
+    case BUILT_IN_TRUNCL:
+    case BUILT_IN_ROUND:
+    case BUILT_IN_ROUNDF:
+    case BUILT_IN_ROUNDL:
+    case BUILT_IN_NEARBYINT:
+    case BUILT_IN_NEARBYINTF:
+    case BUILT_IN_NEARBYINTL:
+    case BUILT_IN_RINT:
+    case BUILT_IN_RINTF:
+    case BUILT_IN_RINTL:
+    case BUILT_IN_LRINT:
+    case BUILT_IN_LRINTF:
+    case BUILT_IN_LRINTL:
+    case BUILT_IN_LLRINT:
+    case BUILT_IN_LLRINTF:
+    case BUILT_IN_LLRINTL:
+      target = expand_builtin_mathfn (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_LCEIL:
+    case BUILT_IN_LCEILF:
+    case BUILT_IN_LCEILL:
+    case BUILT_IN_LLCEIL:
+    case BUILT_IN_LLCEILF:
+    case BUILT_IN_LLCEILL:
+    case BUILT_IN_LFLOOR:
+    case BUILT_IN_LFLOORF:
+    case BUILT_IN_LFLOORL:
+    case BUILT_IN_LLFLOOR:
+    case BUILT_IN_LLFLOORF:
+    case BUILT_IN_LLFLOORL:
+      target = expand_builtin_int_roundingfn (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_POW:
+    case BUILT_IN_POWF:
+    case BUILT_IN_POWL:
+      target = expand_builtin_pow (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_POWI:
+    case BUILT_IN_POWIF:
+    case BUILT_IN_POWIL:
+      target = expand_builtin_powi (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_ATAN2:
+    case BUILT_IN_ATAN2F:
+    case BUILT_IN_ATAN2L:
+    case BUILT_IN_LDEXP:
+    case BUILT_IN_LDEXPF:
+    case BUILT_IN_LDEXPL:
+    case BUILT_IN_FMOD:
+    case BUILT_IN_FMODF:
+    case BUILT_IN_FMODL:
+    case BUILT_IN_DREM:
+    case BUILT_IN_DREMF:
+    case BUILT_IN_DREML:
+      if (! flag_unsafe_math_optimizations)
+	break;
+      target = expand_builtin_mathfn_2 (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SIN:
+    case BUILT_IN_SINF:
+    case BUILT_IN_SINL:
+    case BUILT_IN_COS:
+    case BUILT_IN_COSF:
+    case BUILT_IN_COSL:
+      if (! flag_unsafe_math_optimizations)
+	break;
+      target = expand_builtin_mathfn_3 (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_APPLY_ARGS:
+      return expand_builtin_apply_args ();
+
+      /* __builtin_apply (FUNCTION, ARGUMENTS, ARGSIZE) invokes
+	 FUNCTION with a copy of the parameters described by
+	 ARGUMENTS, and ARGSIZE.  It returns a block of memory
+	 allocated on the stack into which is stored all the registers
+	 that might possibly be used for returning the result of a
+	 function.  ARGUMENTS is the value returned by
+	 __builtin_apply_args.  ARGSIZE is the number of bytes of
+	 arguments that must be copied.  ??? How should this value be
+	 computed?  We'll also need a safe worst case value for varargs
+	 functions.  */
+    case BUILT_IN_APPLY:
+      if (!validate_arglist (arglist, POINTER_TYPE,
+			     POINTER_TYPE, INTEGER_TYPE, VOID_TYPE)
+	  && !validate_arglist (arglist, REFERENCE_TYPE,
+				POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+	return const0_rtx;
+      else
+	{
+	  int i;
+	  tree t;
+	  rtx ops[3];
+
+	  for (t = arglist, i = 0; t; t = TREE_CHAIN (t), i++)
+	    ops[i] = expand_expr (TREE_VALUE (t), NULL_RTX, VOIDmode, 0);
+
+	  return expand_builtin_apply (ops[0], ops[1], ops[2]);
+	}
+
+      /* __builtin_return (RESULT) causes the function to return the
+	 value described by RESULT.  RESULT is address of the block of
+	 memory returned by __builtin_apply.  */
+    case BUILT_IN_RETURN:
+      if (validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+	expand_builtin_return (expand_expr (TREE_VALUE (arglist),
+					    NULL_RTX, VOIDmode, 0));
+      return const0_rtx;
+
+    case BUILT_IN_SAVEREGS:
+      return expand_builtin_saveregs ();
+
+    case BUILT_IN_ARGS_INFO:
+      return expand_builtin_args_info (arglist);
+
+      /* Return the address of the first anonymous stack arg.  */
+    case BUILT_IN_NEXT_ARG:
+      if (fold_builtin_next_arg (arglist))
+        return const0_rtx;
+      return expand_builtin_next_arg ();
+
+    case BUILT_IN_CLASSIFY_TYPE:
+      return expand_builtin_classify_type (arglist);
+
+    case BUILT_IN_CONSTANT_P:
+      return const0_rtx;
+
+    case BUILT_IN_FRAME_ADDRESS:
+    case BUILT_IN_RETURN_ADDRESS:
+      return expand_builtin_frame_address (fndecl, arglist);
+
+    /* Returns the address of the area where the structure is returned.
+       0 otherwise.  */
+    case BUILT_IN_AGGREGATE_INCOMING_ADDRESS:
+      if (arglist != 0
+	  || ! AGGREGATE_TYPE_P (TREE_TYPE (TREE_TYPE (current_function_decl)))
+	  || !MEM_P (DECL_RTL (DECL_RESULT (current_function_decl))))
+	return const0_rtx;
+      else
+	return XEXP (DECL_RTL (DECL_RESULT (current_function_decl)), 0);
+
+    case BUILT_IN_ALLOCA:
+      target = expand_builtin_alloca (arglist, target);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STACK_SAVE:
+      return expand_stack_save ();
+
+    case BUILT_IN_STACK_RESTORE:
+      expand_stack_restore (TREE_VALUE (arglist));
+      return const0_rtx;
+
+    case BUILT_IN_FFS:
+    case BUILT_IN_FFSL:
+    case BUILT_IN_FFSLL:
+    case BUILT_IN_FFSIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, ffs_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_CLZ:
+    case BUILT_IN_CLZL:
+    case BUILT_IN_CLZLL:
+    case BUILT_IN_CLZIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, clz_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_CTZ:
+    case BUILT_IN_CTZL:
+    case BUILT_IN_CTZLL:
+    case BUILT_IN_CTZIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, ctz_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_POPCOUNT:
+    case BUILT_IN_POPCOUNTL:
+    case BUILT_IN_POPCOUNTLL:
+    case BUILT_IN_POPCOUNTIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, popcount_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_PARITY:
+    case BUILT_IN_PARITYL:
+    case BUILT_IN_PARITYLL:
+    case BUILT_IN_PARITYIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, parity_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRLEN:
+      target = expand_builtin_strlen (arglist, target, target_mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCPY:
+      target = expand_builtin_strcpy (fndecl, arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRNCPY:
+      target = expand_builtin_strncpy (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STPCPY:
+      target = expand_builtin_stpcpy (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCAT:
+      target = expand_builtin_strcat (fndecl, arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRNCAT:
+      target = expand_builtin_strncat (arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRSPN:
+      target = expand_builtin_strspn (arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCSPN:
+      target = expand_builtin_strcspn (arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRSTR:
+      target = expand_builtin_strstr (arglist, TREE_TYPE (exp), target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRPBRK:
+      target = expand_builtin_strpbrk (arglist, TREE_TYPE (exp), target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_INDEX:
+    case BUILT_IN_STRCHR:
+      target = expand_builtin_strchr (arglist, TREE_TYPE (exp), target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_RINDEX:
+    case BUILT_IN_STRRCHR:
+      target = expand_builtin_strrchr (arglist, TREE_TYPE (exp), target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_MEMCPY:
+      target = expand_builtin_memcpy (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_MEMPCPY:
+      target = expand_builtin_mempcpy (arglist, TREE_TYPE (exp), target, mode, /*endp=*/ 1);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_MEMMOVE:
+      target = expand_builtin_memmove (arglist, TREE_TYPE (exp), target,
+				       mode, exp);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_BCOPY:
+      target = expand_builtin_bcopy (exp);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_MEMSET:
+      target = expand_builtin_memset (arglist, target, mode, exp);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_BZERO:
+      target = expand_builtin_bzero (exp);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCMP:
+      target = expand_builtin_strcmp (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRNCMP:
+      target = expand_builtin_strncmp (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_BCMP:
+    case BUILT_IN_MEMCMP:
+      target = expand_builtin_memcmp (exp, arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SETJMP:
+      target = expand_builtin_setjmp (arglist, target);
+      if (target)
+	return target;
+      break;
+
+      /* __builtin_longjmp is passed a pointer to an array of five words.
+	 It's similar to the C library longjmp function but works with
+	 __builtin_setjmp above.  */
+    case BUILT_IN_LONGJMP:
+      if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+	break;
+      else
+	{
+	  rtx buf_addr = expand_expr (TREE_VALUE (arglist), subtarget,
+				      VOIDmode, 0);
+	  rtx value = expand_expr (TREE_VALUE (TREE_CHAIN (arglist)),
+				   NULL_RTX, VOIDmode, 0);
+
+	  if (value != const1_rtx)
+	    {
+	      error ("%<__builtin_longjmp%> second argument must be 1");
+	      return const0_rtx;
+	    }
+
+	  expand_builtin_longjmp (buf_addr, value);
+	  return const0_rtx;
+	}
+
+    case BUILT_IN_NONLOCAL_GOTO:
+      target = expand_builtin_nonlocal_goto (arglist);
+      if (target)
+	return target;
+      break;
+
+      /* This updates the setjmp buffer that is its argument with the value
+	 of the current stack pointer.  */
+    case BUILT_IN_UPDATE_SETJMP_BUF:
+      if (validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+	{
+	  rtx buf_addr
+	    = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);
+
+	  expand_builtin_update_setjmp_buf (buf_addr);
+	  return const0_rtx;
+	}
+      break;
+
+    case BUILT_IN_TRAP:
+      expand_builtin_trap ();
+      return const0_rtx;
+
+    case BUILT_IN_PRINTF:
+      target = expand_builtin_printf (exp, target, mode, false);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_PRINTF_UNLOCKED:
+      target = expand_builtin_printf (exp, target, mode, true);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FPUTS:
+      target = expand_builtin_fputs (arglist, target, false);
+      if (target)
+	return target;
+      break;
+    case BUILT_IN_FPUTS_UNLOCKED:
+      target = expand_builtin_fputs (arglist, target, true);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FPRINTF:
+      target = expand_builtin_fprintf (exp, target, mode, false);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FPRINTF_UNLOCKED:
+      target = expand_builtin_fprintf (exp, target, mode, true);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SPRINTF:
+      target = expand_builtin_sprintf (arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SIGNBIT:
+    case BUILT_IN_SIGNBITF:
+    case BUILT_IN_SIGNBITL:
+      target = expand_builtin_signbit (exp, target);
+      if (target)
+	return target;
+      break;
+
+      /* Various hooks for the DWARF 2 __throw routine.  */
+    case BUILT_IN_UNWIND_INIT:
+      expand_builtin_unwind_init ();
+      return const0_rtx;
+    case BUILT_IN_DWARF_CFA:
+      return virtual_cfa_rtx;
+#ifdef DWARF2_UNWIND_INFO
+    case BUILT_IN_DWARF_SP_COLUMN:
+      return expand_builtin_dwarf_sp_column ();
+    case BUILT_IN_INIT_DWARF_REG_SIZES:
+      expand_builtin_init_dwarf_reg_sizes (TREE_VALUE (arglist));
+      return const0_rtx;
+#endif
+    case BUILT_IN_FROB_RETURN_ADDR:
+      return expand_builtin_frob_return_addr (TREE_VALUE (arglist));
+    case BUILT_IN_EXTRACT_RETURN_ADDR:
+      return expand_builtin_extract_return_addr (TREE_VALUE (arglist));
+    case BUILT_IN_EH_RETURN:
+      expand_builtin_eh_return (TREE_VALUE (arglist),
+				TREE_VALUE (TREE_CHAIN (arglist)));
+      return const0_rtx;
+#ifdef EH_RETURN_DATA_REGNO
+    case BUILT_IN_EH_RETURN_DATA_REGNO:
+      return expand_builtin_eh_return_data_regno (arglist);
+#endif
+    case BUILT_IN_EXTEND_POINTER:
+      return expand_builtin_extend_pointer (TREE_VALUE (arglist));
+
+    case BUILT_IN_VA_START:
+    case BUILT_IN_STDARG_START:
+      return expand_builtin_va_start (arglist);
+    case BUILT_IN_VA_END:
+      return expand_builtin_va_end (arglist);
+    case BUILT_IN_VA_COPY:
+      return expand_builtin_va_copy (arglist);
+    case BUILT_IN_EXPECT:
+      return expand_builtin_expect (arglist, target);
+    case BUILT_IN_PREFETCH:
+      expand_builtin_prefetch (arglist);
+      return const0_rtx;
+
+    case BUILT_IN_PROFILE_FUNC_ENTER:
+      return expand_builtin_profile_func (false);
+    case BUILT_IN_PROFILE_FUNC_EXIT:
+      return expand_builtin_profile_func (true);
+
+    case BUILT_IN_INIT_TRAMPOLINE:
+      return expand_builtin_init_trampoline (arglist);
+    case BUILT_IN_ADJUST_TRAMPOLINE:
+      return expand_builtin_adjust_trampoline (arglist);
+
+    case BUILT_IN_FORK:
+    case BUILT_IN_EXECL:
+    case BUILT_IN_EXECV:
+    case BUILT_IN_EXECLP:
+    case BUILT_IN_EXECLE:
+    case BUILT_IN_EXECVP:
+    case BUILT_IN_EXECVE:
+      target = expand_builtin_fork_or_exec (fndecl, arglist, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_ADD_1:
+    case BUILT_IN_FETCH_AND_ADD_2:
+    case BUILT_IN_FETCH_AND_ADD_4:
+    case BUILT_IN_FETCH_AND_ADD_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_ADD_1);
+      target = expand_builtin_sync_operation (mode, arglist, PLUS,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_SUB_1:
+    case BUILT_IN_FETCH_AND_SUB_2:
+    case BUILT_IN_FETCH_AND_SUB_4:
+    case BUILT_IN_FETCH_AND_SUB_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_SUB_1);
+      target = expand_builtin_sync_operation (mode, arglist, MINUS,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_OR_1:
+    case BUILT_IN_FETCH_AND_OR_2:
+    case BUILT_IN_FETCH_AND_OR_4:
+    case BUILT_IN_FETCH_AND_OR_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_OR_1);
+      target = expand_builtin_sync_operation (mode, arglist, IOR,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_AND_1:
+    case BUILT_IN_FETCH_AND_AND_2:
+    case BUILT_IN_FETCH_AND_AND_4:
+    case BUILT_IN_FETCH_AND_AND_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_AND_1);
+      target = expand_builtin_sync_operation (mode, arglist, AND,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_XOR_1:
+    case BUILT_IN_FETCH_AND_XOR_2:
+    case BUILT_IN_FETCH_AND_XOR_4:
+    case BUILT_IN_FETCH_AND_XOR_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_XOR_1);
+      target = expand_builtin_sync_operation (mode, arglist, XOR,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_NAND_1:
+    case BUILT_IN_FETCH_AND_NAND_2:
+    case BUILT_IN_FETCH_AND_NAND_4:
+    case BUILT_IN_FETCH_AND_NAND_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_NAND_1);
+      target = expand_builtin_sync_operation (mode, arglist, NOT,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_ADD_AND_FETCH_1:
+    case BUILT_IN_ADD_AND_FETCH_2:
+    case BUILT_IN_ADD_AND_FETCH_4:
+    case BUILT_IN_ADD_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_ADD_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, PLUS,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SUB_AND_FETCH_1:
+    case BUILT_IN_SUB_AND_FETCH_2:
+    case BUILT_IN_SUB_AND_FETCH_4:
+    case BUILT_IN_SUB_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_SUB_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, MINUS,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_OR_AND_FETCH_1:
+    case BUILT_IN_OR_AND_FETCH_2:
+    case BUILT_IN_OR_AND_FETCH_4:
+    case BUILT_IN_OR_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_OR_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, IOR,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_AND_AND_FETCH_1:
+    case BUILT_IN_AND_AND_FETCH_2:
+    case BUILT_IN_AND_AND_FETCH_4:
+    case BUILT_IN_AND_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_AND_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, AND,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_XOR_AND_FETCH_1:
+    case BUILT_IN_XOR_AND_FETCH_2:
+    case BUILT_IN_XOR_AND_FETCH_4:
+    case BUILT_IN_XOR_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_XOR_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, XOR,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_NAND_AND_FETCH_1:
+    case BUILT_IN_NAND_AND_FETCH_2:
+    case BUILT_IN_NAND_AND_FETCH_4:
+    case BUILT_IN_NAND_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_NAND_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, NOT,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_1:
+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_2:
+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_4:
+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_8:
+      if (mode == VOIDmode)
+	mode = TYPE_MODE (boolean_type_node);
+      if (!target || !register_operand (target, mode))
+	target = gen_reg_rtx (mode);
+
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_BOOL_COMPARE_AND_SWAP_1);
+      target = expand_builtin_compare_and_swap (mode, arglist, true, target);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_VAL_COMPARE_AND_SWAP_1:
+    case BUILT_IN_VAL_COMPARE_AND_SWAP_2:
+    case BUILT_IN_VAL_COMPARE_AND_SWAP_4:
+    case BUILT_IN_VAL_COMPARE_AND_SWAP_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_VAL_COMPARE_AND_SWAP_1);
+      target = expand_builtin_compare_and_swap (mode, arglist, false, target);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_LOCK_TEST_AND_SET_1:
+    case BUILT_IN_LOCK_TEST_AND_SET_2:
+    case BUILT_IN_LOCK_TEST_AND_SET_4:
+    case BUILT_IN_LOCK_TEST_AND_SET_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_LOCK_TEST_AND_SET_1);
+      target = expand_builtin_lock_test_and_set (mode, arglist, target);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_LOCK_RELEASE_1:
+    case BUILT_IN_LOCK_RELEASE_2:
+    case BUILT_IN_LOCK_RELEASE_4:
+    case BUILT_IN_LOCK_RELEASE_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_LOCK_RELEASE_1);
+      expand_builtin_lock_release (mode, arglist);
+      return const0_rtx;
+
+    case BUILT_IN_SYNCHRONIZE:
+      expand_builtin_synchronize ();
+      return const0_rtx;
+
+    case BUILT_IN_OBJECT_SIZE:
+      return expand_builtin_object_size (exp);
+
+    case BUILT_IN_MEMCPY_CHK:
+    case BUILT_IN_MEMPCPY_CHK:
+    case BUILT_IN_MEMMOVE_CHK:
+    case BUILT_IN_MEMSET_CHK:
+      target = expand_builtin_memory_chk (exp, target, mode, fcode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCPY_CHK:
+    case BUILT_IN_STPCPY_CHK:
+    case BUILT_IN_STRNCPY_CHK:
+    case BUILT_IN_STRCAT_CHK:
+    case BUILT_IN_SNPRINTF_CHK:
+    case BUILT_IN_VSNPRINTF_CHK:
+      maybe_emit_chk_warning (exp, fcode);
+      break;
+
+    case BUILT_IN_SPRINTF_CHK:
+    case BUILT_IN_VSPRINTF_CHK:
+      maybe_emit_sprintf_chk_warning (exp, fcode);
+      break;
+
+    default:	/* just do library call, if unknown builtin */
+      break;
+    }
+
+  /* The switch statement above can drop through to cause the function
+     to be called normally.  */
+  return expand_call (exp, target, ignore);
+}
+
+/* Determine whether a tree node represents a call to a built-in
+   function.  If the tree T is a call to a built-in function with
+   the right number of arguments of the appropriate types, return
+   the DECL_FUNCTION_CODE of the call, e.g. BUILT_IN_SQRT.
+   Otherwise the return value is END_BUILTINS.  */
+
+enum built_in_function
+builtin_mathfn_code (tree t)
+{
+  tree fndecl, arglist, parmlist;
+  tree argtype, parmtype;
+
+  if (TREE_CODE (t) != CALL_EXPR
+      || TREE_CODE (TREE_OPERAND (t, 0)) != ADDR_EXPR)
+    return END_BUILTINS;
+
+  fndecl = get_callee_fndecl (t);
+  if (fndecl == NULL_TREE
+      || TREE_CODE (fndecl) != FUNCTION_DECL
+      || ! DECL_BUILT_IN (fndecl)
+      || DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_MD)
+    return END_BUILTINS;
+
+  arglist = TREE_OPERAND (t, 1);
+  parmlist = TYPE_ARG_TYPES (TREE_TYPE (fndecl));
+  for (; parmlist; parmlist = TREE_CHAIN (parmlist))
+    {
+      /* If a function doesn't take a variable number of arguments,
+	 the last element in the list will have type `void'.  */
+      parmtype = TREE_VALUE (parmlist);
+      if (VOID_TYPE_P (parmtype))
+	{
+	  if (arglist)
+	    return END_BUILTINS;
+	  return DECL_FUNCTION_CODE (fndecl);
+	}
+
+      if (! arglist)
+	return END_BUILTINS;
+
+      argtype = TREE_TYPE (TREE_VALUE (arglist));
+
+      if (SCALAR_FLOAT_TYPE_P (parmtype))
+	{
+	  if (! SCALAR_FLOAT_TYPE_P (argtype))
+	    return END_BUILTINS;
+	}
+      else if (COMPLEX_FLOAT_TYPE_P (parmtype))
+	{
+	  if (! COMPLEX_FLOAT_TYPE_P (argtype))
+	    return END_BUILTINS;
+	}
+      else if (POINTER_TYPE_P (parmtype))
+	{
+	  if (! POINTER_TYPE_P (argtype))
+	    return END_BUILTINS;
+	}
+      else if (INTEGRAL_TYPE_P (parmtype))
+	{
+	  if (! INTEGRAL_TYPE_P (argtype))
+	    return END_BUILTINS;
+	}
+      else
+	return END_BUILTINS;
+
+      arglist = TREE_CHAIN (arglist);
+    }
+
+  /* Variable-length argument list.  */
+  return DECL_FUNCTION_CODE (fndecl);
+}
+
+/* Fold a call to __builtin_constant_p, if we know it will evaluate to a
+   constant.  ARGLIST is the argument list of the call.  */
+
+static tree
+fold_builtin_constant_p (tree arglist)
+{
+  if (arglist == 0)
+    return 0;
+
+  arglist = TREE_VALUE (arglist);
+
+  /* We return 1 for a numeric type that's known to be a constant
+     value at compile-time or for an aggregate type that's a
+     literal constant.  */
+  STRIP_NOPS (arglist);
+
+  /* If we know this is a constant, emit the constant of one.  */
+  if (CONSTANT_CLASS_P (arglist)
+      || (TREE_CODE (arglist) == CONSTRUCTOR
+	  && TREE_CONSTANT (arglist)))
+    return integer_one_node;
+  if (TREE_CODE (arglist) == ADDR_EXPR)
+    {
+       tree op = TREE_OPERAND (arglist, 0);
+       if (TREE_CODE (op) == STRING_CST
+	   || (TREE_CODE (op) == ARRAY_REF
+	       && integer_zerop (TREE_OPERAND (op, 1))
+	       && TREE_CODE (TREE_OPERAND (op, 0)) == STRING_CST))
+	 return integer_one_node;
+    }
+
+  /* If this expression has side effects, show we don't know it to be a
+     constant.  Likewise if it's a pointer or aggregate type since in
+     those case we only want literals, since those are only optimized
+     when generating RTL, not later.
+     And finally, if we are compiling an initializer, not code, we
+     need to return a definite result now; there's not going to be any
+     more optimization done.  */
+  if (TREE_SIDE_EFFECTS (arglist)
+      || AGGREGATE_TYPE_P (TREE_TYPE (arglist))
+      || POINTER_TYPE_P (TREE_TYPE (arglist))
+      || cfun == 0)
+    return integer_zero_node;
+
+  return 0;
+}
+
+/* Fold a call to __builtin_expect, if we expect that a comparison against
+   the argument will fold to a constant.  In practice, this means a true
+   constant or the address of a non-weak symbol.  ARGLIST is the argument
+   list of the call.  */
+
+static tree
+fold_builtin_expect (tree arglist)
+{
+  tree arg, inner;
+
+  if (arglist == 0)
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+
+  /* If the argument isn't invariant, then there's nothing we can do.  */
+  if (!TREE_INVARIANT (arg))
+    return 0;
+
+  /* If we're looking at an address of a weak decl, then do not fold.  */
+  inner = arg;
+  STRIP_NOPS (inner);
+  if (TREE_CODE (inner) == ADDR_EXPR)
+    {
+      do
+	{
+	  inner = TREE_OPERAND (inner, 0);
+	}
+      while (TREE_CODE (inner) == COMPONENT_REF
+	     || TREE_CODE (inner) == ARRAY_REF);
+      if (DECL_P (inner) && DECL_WEAK (inner))
+	return 0;
+    }
+
+  /* Otherwise, ARG already has the proper type for the return value.  */
+  return arg;
+}
+
+/* Fold a call to __builtin_classify_type.  */
+
+static tree
+fold_builtin_classify_type (tree arglist)
+{
+  if (arglist == 0)
+    return build_int_cst (NULL_TREE, no_type_class);
+
+  return build_int_cst (NULL_TREE,
+			type_to_class (TREE_TYPE (TREE_VALUE (arglist))));
+}
+
+/* Fold a call to __builtin_strlen.  */
+
+static tree
+fold_builtin_strlen (tree arglist)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return NULL_TREE;
+  else
+    {
+      tree len = c_strlen (TREE_VALUE (arglist), 0);
+
+      if (len)
+	{
+	  /* Convert from the internal "sizetype" type to "size_t".  */
+	  if (size_type_node)
+	    len = fold_convert (size_type_node, len);
+	  return len;
+	}
+
+      return NULL_TREE;
+    }
+}
+
+/* Fold a call to __builtin_inf or __builtin_huge_val.  */
+
+static tree
+fold_builtin_inf (tree type, int warn)
+{
+  REAL_VALUE_TYPE real;
+
+  /* __builtin_inff is intended to be usable to define INFINITY on all
+     targets.  If an infinity is not available, INFINITY expands "to a
+     positive constant of type float that overflows at translation
+     time", footnote "In this case, using INFINITY will violate the
+     constraint in 6.4.4 and thus require a diagnostic." (C99 7.12#4).
+     Thus we pedwarn to ensure this constraint violation is
+     diagnosed.  */
+  if (!MODE_HAS_INFINITIES (TYPE_MODE (type)) && warn)
+    pedwarn ("target format does not support infinity");
+
+  real_inf (&real);
+  return build_real (type, real);
+}
+
+/* Fold a call to __builtin_nan or __builtin_nans.  */
+
+static tree
+fold_builtin_nan (tree arglist, tree type, int quiet)
+{
+  REAL_VALUE_TYPE real;
+  const char *str;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  str = c_getstr (TREE_VALUE (arglist));
+  if (!str)
+    return 0;
+
+  if (!real_nan (&real, str, quiet, TYPE_MODE (type)))
+    return 0;
+
+  return build_real (type, real);
+}
+
+/* Return true if the floating point expression T has an integer value.
+   We also allow +Inf, -Inf and NaN to be considered integer values.  */
+
+static bool
+integer_valued_real_p (tree t)
+{
+  switch (TREE_CODE (t))
+    {
+    case FLOAT_EXPR:
+      return true;
+
+    case ABS_EXPR:
+    case SAVE_EXPR:
+    case NON_LVALUE_EXPR:
+      return integer_valued_real_p (TREE_OPERAND (t, 0));
+
+    case COMPOUND_EXPR:
+    case MODIFY_EXPR:
+    case BIND_EXPR:
+      return integer_valued_real_p (TREE_OPERAND (t, 1));
+
+    case PLUS_EXPR:
+    case MINUS_EXPR:
+    case MULT_EXPR:
+    case MIN_EXPR:
+    case MAX_EXPR:
+      return integer_valued_real_p (TREE_OPERAND (t, 0))
+	     && integer_valued_real_p (TREE_OPERAND (t, 1));
+
+    case COND_EXPR:
+      return integer_valued_real_p (TREE_OPERAND (t, 1))
+	     && integer_valued_real_p (TREE_OPERAND (t, 2));
+
+    case REAL_CST:
+      if (! TREE_CONSTANT_OVERFLOW (t))
+      {
+        REAL_VALUE_TYPE c, cint;
+
+	c = TREE_REAL_CST (t);
+	real_trunc (&cint, TYPE_MODE (TREE_TYPE (t)), &c);
+	return real_identical (&c, &cint);
+      }
+      break;
+
+    case NOP_EXPR:
+      {
+	tree type = TREE_TYPE (TREE_OPERAND (t, 0));
+	if (TREE_CODE (type) == INTEGER_TYPE)
+	  return true;
+	if (TREE_CODE (type) == REAL_TYPE)
+	  return integer_valued_real_p (TREE_OPERAND (t, 0));
+	break;
+      }
+
+    case CALL_EXPR:
+      switch (builtin_mathfn_code (t))
+	{
+	case BUILT_IN_CEIL:
+	case BUILT_IN_CEILF:
+	case BUILT_IN_CEILL:
+	case BUILT_IN_FLOOR:
+	case BUILT_IN_FLOORF:
+	case BUILT_IN_FLOORL:
+	case BUILT_IN_NEARBYINT:
+	case BUILT_IN_NEARBYINTF:
+	case BUILT_IN_NEARBYINTL:
+	case BUILT_IN_RINT:
+	case BUILT_IN_RINTF:
+	case BUILT_IN_RINTL:
+	case BUILT_IN_ROUND:
+	case BUILT_IN_ROUNDF:
+	case BUILT_IN_ROUNDL:
+	case BUILT_IN_TRUNC:
+	case BUILT_IN_TRUNCF:
+	case BUILT_IN_TRUNCL:
+	  return true;
+
+	default:
+	  break;
+	}
+      break;
+
+    default:
+      break;
+    }
+  return false;
+}
+
+/* EXP is assumed to be builtin call where truncation can be propagated
+   across (for instance floor((double)f) == (double)floorf (f).
+   Do the transformation.  */
+
+static tree
+fold_trunc_transparent_mathfn (tree fndecl, tree arglist)
+{
+  enum built_in_function fcode = DECL_FUNCTION_CODE (fndecl);
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  /* Integer rounding functions are idempotent.  */
+  if (fcode == builtin_mathfn_code (arg))
+    return arg;
+
+  /* If argument is already integer valued, and we don't need to worry
+     about setting errno, there's no need to perform rounding.  */
+  if (! flag_errno_math && integer_valued_real_p (arg))
+    return arg;
+
+  if (optimize)
+    {
+      tree arg0 = strip_float_extensions (arg);
+      tree ftype = TREE_TYPE (TREE_TYPE (fndecl));
+      tree newtype = TREE_TYPE (arg0);
+      tree decl;
+
+      if (TYPE_PRECISION (newtype) < TYPE_PRECISION (ftype)
+	  && (decl = mathfn_built_in (newtype, fcode)))
+	{
+	  arglist =
+	    build_tree_list (NULL_TREE, fold_convert (newtype, arg0));
+	  return fold_convert (ftype,
+			       build_function_call_expr (decl, arglist));
+	}
+    }
+  return 0;
+}
+
+/* EXP is assumed to be builtin call which can narrow the FP type of
+   the argument, for instance lround((double)f) -> lroundf (f).  */
+
+static tree
+fold_fixed_mathfn (tree fndecl, tree arglist)
+{
+  enum built_in_function fcode = DECL_FUNCTION_CODE (fndecl);
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+
+  /* If argument is already integer valued, and we don't need to worry
+     about setting errno, there's no need to perform rounding.  */
+  if (! flag_errno_math && integer_valued_real_p (arg))
+    return fold_build1 (FIX_TRUNC_EXPR, TREE_TYPE (TREE_TYPE (fndecl)), arg);
+
+  if (optimize)
+    {
+      tree ftype = TREE_TYPE (arg);
+      tree arg0 = strip_float_extensions (arg);
+      tree newtype = TREE_TYPE (arg0);
+      tree decl;
+
+      if (TYPE_PRECISION (newtype) < TYPE_PRECISION (ftype)
+	  && (decl = mathfn_built_in (newtype, fcode)))
+	{
+	  arglist =
+	    build_tree_list (NULL_TREE, fold_convert (newtype, arg0));
+	  return build_function_call_expr (decl, arglist);
+	}
+    }
+  return 0;
+}
+
+/* Fold function call to builtin cabs, cabsf or cabsl.  ARGLIST
+   is the argument list and TYPE is the return type.  Return
+   NULL_TREE if no if no simplification can be made.  */
+
+static tree
+fold_builtin_cabs (tree arglist, tree type)
+{
+  tree arg;
+
+  if (!arglist || TREE_CHAIN (arglist))
+    return NULL_TREE;
+
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (arg)) != COMPLEX_TYPE
+      || TREE_CODE (TREE_TYPE (TREE_TYPE (arg))) != REAL_TYPE)
+    return NULL_TREE;
+
+  /* Evaluate cabs of a constant at compile-time.  */
+  if (flag_unsafe_math_optimizations
+      && TREE_CODE (arg) == COMPLEX_CST
+      && TREE_CODE (TREE_REALPART (arg)) == REAL_CST
+      && TREE_CODE (TREE_IMAGPART (arg)) == REAL_CST
+      && ! TREE_CONSTANT_OVERFLOW (TREE_REALPART (arg))
+      && ! TREE_CONSTANT_OVERFLOW (TREE_IMAGPART (arg)))
+    {
+      REAL_VALUE_TYPE r, i;
+
+      r = TREE_REAL_CST (TREE_REALPART (arg));
+      i = TREE_REAL_CST (TREE_IMAGPART (arg));
+
+      real_arithmetic (&r, MULT_EXPR, &r, &r);
+      real_arithmetic (&i, MULT_EXPR, &i, &i);
+      real_arithmetic (&r, PLUS_EXPR, &r, &i);
+      if (real_sqrt (&r, TYPE_MODE (type), &r)
+	  || ! flag_trapping_math)
+	return build_real (type, r);
+    }
+
+  /* If either part is zero, cabs is fabs of the other.  */
+  if (TREE_CODE (arg) == COMPLEX_EXPR
+      && real_zerop (TREE_OPERAND (arg, 0)))
+    return fold_build1 (ABS_EXPR, type, TREE_OPERAND (arg, 1));
+  if (TREE_CODE (arg) == COMPLEX_EXPR
+      && real_zerop (TREE_OPERAND (arg, 1)))
+    return fold_build1 (ABS_EXPR, type, TREE_OPERAND (arg, 0));
+
+  /* Don't do this when optimizing for size.  */
+  if (flag_unsafe_math_optimizations
+      && optimize && !optimize_size)
+    {
+      tree sqrtfn = mathfn_built_in (type, BUILT_IN_SQRT);
+
+      if (sqrtfn != NULL_TREE)
+	{
+	  tree rpart, ipart, result, arglist;
+
+	  arg = builtin_save_expr (arg);
+
+	  rpart = fold_build1 (REALPART_EXPR, type, arg);
+	  ipart = fold_build1 (IMAGPART_EXPR, type, arg);
+
+	  rpart = builtin_save_expr (rpart);
+	  ipart = builtin_save_expr (ipart);
+
+	  result = fold_build2 (PLUS_EXPR, type,
+				fold_build2 (MULT_EXPR, type,
+					     rpart, rpart),
+				fold_build2 (MULT_EXPR, type,
+					     ipart, ipart));
+
+	  arglist = build_tree_list (NULL_TREE, result);
+	  return build_function_call_expr (sqrtfn, arglist);
+	}
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold a builtin function call to sqrt, sqrtf, or sqrtl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_sqrt (tree arglist, tree type)
+{
+
+  enum built_in_function fcode;
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize sqrt of constant value.  */
+  if (TREE_CODE (arg) == REAL_CST
+      && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE r, x;
+
+      x = TREE_REAL_CST (arg);
+      if (real_sqrt (&r, TYPE_MODE (type), &x)
+	  || (!flag_trapping_math && !flag_errno_math))
+	return build_real (type, r);
+    }
+
+  /* Optimize sqrt(expN(x)) = expN(x*0.5).  */
+  fcode = builtin_mathfn_code (arg);
+  if (flag_unsafe_math_optimizations && BUILTIN_EXPONENT_P (fcode))
+    {
+      tree expfn = TREE_OPERAND (TREE_OPERAND (arg, 0), 0);
+      arg = fold_build2 (MULT_EXPR, type,
+			 TREE_VALUE (TREE_OPERAND (arg, 1)),
+			 build_real (type, dconsthalf));
+      arglist = build_tree_list (NULL_TREE, arg);
+      return build_function_call_expr (expfn, arglist);
+    }
+
+  /* Optimize sqrt(Nroot(x)) -> pow(x,1/(2*N)).  */
+  if (flag_unsafe_math_optimizations && BUILTIN_ROOT_P (fcode))
+    {
+      tree powfn = mathfn_built_in (type, BUILT_IN_POW);
+
+      if (powfn)
+	{
+	  tree arg0 = TREE_VALUE (TREE_OPERAND (arg, 1));
+	  tree tree_root;
+	  /* The inner root was either sqrt or cbrt.  */
+	  REAL_VALUE_TYPE dconstroot =
+	    BUILTIN_SQRT_P (fcode) ? dconsthalf : dconstthird;
+
+	  /* Adjust for the outer root.  */
+	  SET_REAL_EXP (&dconstroot, REAL_EXP (&dconstroot) - 1);
+	  dconstroot = real_value_truncate (TYPE_MODE (type), dconstroot);
+	  tree_root = build_real (type, dconstroot);
+	  arglist = tree_cons (NULL_TREE, arg0,
+			       build_tree_list (NULL_TREE, tree_root));
+	  return build_function_call_expr (powfn, arglist);
+	}
+    }
+
+  /* Optimize sqrt(pow(x,y)) = pow(|x|,y*0.5).  */
+  if (flag_unsafe_math_optimizations
+      && (fcode == BUILT_IN_POW
+	  || fcode == BUILT_IN_POWF
+	  || fcode == BUILT_IN_POWL))
+    {
+      tree powfn = TREE_OPERAND (TREE_OPERAND (arg, 0), 0);
+      tree arg0 = TREE_VALUE (TREE_OPERAND (arg, 1));
+      tree arg1 = TREE_VALUE (TREE_CHAIN (TREE_OPERAND (arg, 1)));
+      tree narg1;
+      if (!tree_expr_nonnegative_p (arg0))
+	arg0 = build1 (ABS_EXPR, type, arg0);
+      narg1 = fold_build2 (MULT_EXPR, type, arg1,
+			   build_real (type, dconsthalf));
+      arglist = tree_cons (NULL_TREE, arg0,
+			   build_tree_list (NULL_TREE, narg1));
+      return build_function_call_expr (powfn, arglist);
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold a builtin function call to cbrt, cbrtf, or cbrtl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_cbrt (tree arglist, tree type)
+{
+  tree arg = TREE_VALUE (arglist);
+  const enum built_in_function fcode = builtin_mathfn_code (arg);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize cbrt of constant value.  */
+  if (real_zerop (arg) || real_onep (arg) || real_minus_onep (arg))
+    return arg;
+
+  if (flag_unsafe_math_optimizations)
+    {
+      /* Optimize cbrt(expN(x)) -> expN(x/3).  */
+      if (BUILTIN_EXPONENT_P (fcode))
+        {
+	  tree expfn = TREE_OPERAND (TREE_OPERAND (arg, 0), 0);
+	  const REAL_VALUE_TYPE third_trunc =
+	    real_value_truncate (TYPE_MODE (type), dconstthird);
+	  arg = fold_build2 (MULT_EXPR, type,
+			     TREE_VALUE (TREE_OPERAND (arg, 1)),
+			     build_real (type, third_trunc));
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  return build_function_call_expr (expfn, arglist);
+	}
+
+      /* Optimize cbrt(sqrt(x)) -> pow(x,1/6).  */
+      if (BUILTIN_SQRT_P (fcode))
+        {
+	  tree powfn = mathfn_built_in (type, BUILT_IN_POW);
+
+	  if (powfn)
+	    {
+	      tree arg0 = TREE_VALUE (TREE_OPERAND (arg, 1));
+	      tree tree_root;
+	      REAL_VALUE_TYPE dconstroot = dconstthird;
+
+	      SET_REAL_EXP (&dconstroot, REAL_EXP (&dconstroot) - 1);
+	      dconstroot = real_value_truncate (TYPE_MODE (type), dconstroot);
+	      tree_root = build_real (type, dconstroot);
+	      arglist = tree_cons (NULL_TREE, arg0,
+				   build_tree_list (NULL_TREE, tree_root));
+	      return build_function_call_expr (powfn, arglist);
+	    }
+	}
+
+      /* Optimize cbrt(cbrt(x)) -> pow(x,1/9) iff x is nonnegative.  */
+      if (BUILTIN_CBRT_P (fcode))
+        {
+	  tree arg0 = TREE_VALUE (TREE_OPERAND (arg, 1));
+	  if (tree_expr_nonnegative_p (arg0))
+	    {
+	      tree powfn = mathfn_built_in (type, BUILT_IN_POW);
+
+	      if (powfn)
+	        {
+		  tree tree_root;
+		  REAL_VALUE_TYPE dconstroot;
+	      
+		  real_arithmetic (&dconstroot, MULT_EXPR, &dconstthird, &dconstthird);
+		  dconstroot = real_value_truncate (TYPE_MODE (type), dconstroot);
+		  tree_root = build_real (type, dconstroot);
+		  arglist = tree_cons (NULL_TREE, arg0,
+				       build_tree_list (NULL_TREE, tree_root));
+		  return build_function_call_expr (powfn, arglist);
+		}
+	    }
+	}
+      
+      /* Optimize cbrt(pow(x,y)) -> pow(x,y/3) iff x is nonnegative.  */
+      if (fcode == BUILT_IN_POW || fcode == BUILT_IN_POWF
+	  || fcode == BUILT_IN_POWL)
+        {
+	  tree arg00 = TREE_VALUE (TREE_OPERAND (arg, 1));
+	  tree arg01 = TREE_VALUE (TREE_CHAIN (TREE_OPERAND (arg, 1)));
+	  if (tree_expr_nonnegative_p (arg00))
+	    {
+	      tree powfn = TREE_OPERAND (TREE_OPERAND (arg, 0), 0);
+	      const REAL_VALUE_TYPE dconstroot
+		= real_value_truncate (TYPE_MODE (type), dconstthird);
+	      tree narg01 = fold_build2 (MULT_EXPR, type, arg01,
+					 build_real (type, dconstroot));
+	      arglist = tree_cons (NULL_TREE, arg00,
+				   build_tree_list (NULL_TREE, narg01));
+	      return build_function_call_expr (powfn, arglist);
+	    }
+	}
+    }
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin sin, sinf, or sinl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_sin (tree arglist)
+{
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize sin (0.0) = 0.0.  */
+  if (real_zerop (arg))
+    return arg;
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin cos, cosf, or cosl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_cos (tree arglist, tree type, tree fndecl)
+{
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize cos (0.0) = 1.0.  */
+  if (real_zerop (arg))
+    return build_real (type, dconst1);
+
+  /* Optimize cos(-x) into cos (x).  */
+  if (TREE_CODE (arg) == NEGATE_EXPR)
+    {
+      tree args = build_tree_list (NULL_TREE,
+				   TREE_OPERAND (arg, 0));
+      return build_function_call_expr (fndecl, args);
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin tan, tanf, or tanl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_tan (tree arglist)
+{
+  enum built_in_function fcode;
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize tan(0.0) = 0.0.  */
+  if (real_zerop (arg))
+    return arg;
+
+  /* Optimize tan(atan(x)) = x.  */
+  fcode = builtin_mathfn_code (arg);
+  if (flag_unsafe_math_optimizations
+      && (fcode == BUILT_IN_ATAN
+	  || fcode == BUILT_IN_ATANF
+	  || fcode == BUILT_IN_ATANL))
+    return TREE_VALUE (TREE_OPERAND (arg, 1));
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin atan, atanf, or atanl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_atan (tree arglist, tree type)
+{
+
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize atan(0.0) = 0.0.  */
+  if (real_zerop (arg))
+    return arg;
+
+  /* Optimize atan(1.0) = pi/4.  */
+  if (real_onep (arg))
+    {
+      REAL_VALUE_TYPE cst;
+
+      real_convert (&cst, TYPE_MODE (type), &dconstpi);
+      SET_REAL_EXP (&cst, REAL_EXP (&cst) - 2);
+      return build_real (type, cst);
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin trunc, truncf or truncl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_trunc (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize trunc of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE r, x;
+      tree type = TREE_TYPE (TREE_TYPE (fndecl));
+
+      x = TREE_REAL_CST (arg);
+      real_trunc (&r, TYPE_MODE (type), &x);
+      return build_real (type, r);
+    }
+
+  return fold_trunc_transparent_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin floor, floorf or floorl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_floor (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize floor of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE x;
+
+      x = TREE_REAL_CST (arg);
+      if (! REAL_VALUE_ISNAN (x) || ! flag_errno_math)
+	{
+	  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+	  REAL_VALUE_TYPE r;
+
+	  real_floor (&r, TYPE_MODE (type), &x);
+	  return build_real (type, r);
+	}
+    }
+
+  return fold_trunc_transparent_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin ceil, ceilf or ceill.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_ceil (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize ceil of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE x;
+
+      x = TREE_REAL_CST (arg);
+      if (! REAL_VALUE_ISNAN (x) || ! flag_errno_math)
+	{
+	  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+	  REAL_VALUE_TYPE r;
+
+	  real_ceil (&r, TYPE_MODE (type), &x);
+	  return build_real (type, r);
+	}
+    }
+
+  return fold_trunc_transparent_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin round, roundf or roundl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_round (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize round of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE x;
+
+      x = TREE_REAL_CST (arg);
+      if (! REAL_VALUE_ISNAN (x) || ! flag_errno_math)
+	{
+	  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+	  REAL_VALUE_TYPE r;
+
+	  real_round (&r, TYPE_MODE (type), &x);
+	  return build_real (type, r);
+	}
+    }
+
+  return fold_trunc_transparent_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin lround, lroundf or lroundl (or the
+   corresponding long long versions) and other rounding functions.
+   Return NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_int_roundingfn (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize lround of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      const REAL_VALUE_TYPE x = TREE_REAL_CST (arg);
+
+      if (! REAL_VALUE_ISNAN (x) && ! REAL_VALUE_ISINF (x))
+	{
+	  tree itype = TREE_TYPE (TREE_TYPE (fndecl));
+	  tree ftype = TREE_TYPE (arg), result;
+	  HOST_WIDE_INT hi, lo;
+	  REAL_VALUE_TYPE r;
+
+	  switch (DECL_FUNCTION_CODE (fndecl))
+	    {
+	    case BUILT_IN_LFLOOR:
+	    case BUILT_IN_LFLOORF:
+	    case BUILT_IN_LFLOORL:
+	    case BUILT_IN_LLFLOOR:
+	    case BUILT_IN_LLFLOORF:
+	    case BUILT_IN_LLFLOORL:
+	      real_floor (&r, TYPE_MODE (ftype), &x);
+	      break;
+
+	    case BUILT_IN_LCEIL:
+	    case BUILT_IN_LCEILF:
+	    case BUILT_IN_LCEILL:
+	    case BUILT_IN_LLCEIL:
+	    case BUILT_IN_LLCEILF:
+	    case BUILT_IN_LLCEILL:
+	      real_ceil (&r, TYPE_MODE (ftype), &x);
+	      break;
+
+	    case BUILT_IN_LROUND:
+	    case BUILT_IN_LROUNDF:
+	    case BUILT_IN_LROUNDL:
+	    case BUILT_IN_LLROUND:
+	    case BUILT_IN_LLROUNDF:
+	    case BUILT_IN_LLROUNDL:
+	      real_round (&r, TYPE_MODE (ftype), &x);
+	      break;
+
+	    default:
+	      gcc_unreachable ();
+	    }
+
+	  REAL_VALUE_TO_INT (&lo, &hi, r);
+	  result = build_int_cst_wide (NULL_TREE, lo, hi);
+	  if (int_fits_type_p (result, itype))
+	    return fold_convert (itype, result);
+	}
+    }
+
+  return fold_fixed_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin ffs, clz, ctz, popcount and parity
+   and their long and long long variants (i.e. ffsl and ffsll).
+   Return NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_bitop (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize for constant argument.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == INTEGER_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      HOST_WIDE_INT hi, width, result;
+      unsigned HOST_WIDE_INT lo;
+      tree type;
+
+      type = TREE_TYPE (arg);
+      width = TYPE_PRECISION (type);
+      lo = TREE_INT_CST_LOW (arg);
+
+      /* Clear all the bits that are beyond the type's precision.  */
+      if (width > HOST_BITS_PER_WIDE_INT)
+	{
+	  hi = TREE_INT_CST_HIGH (arg);
+	  if (width < 2 * HOST_BITS_PER_WIDE_INT)
+	    hi &= ~((HOST_WIDE_INT) (-1) >> (width - HOST_BITS_PER_WIDE_INT));
+	}
+      else
+	{
+	  hi = 0;
+	  if (width < HOST_BITS_PER_WIDE_INT)
+	    lo &= ~((unsigned HOST_WIDE_INT) (-1) << width);
+	}
+
+      switch (DECL_FUNCTION_CODE (fndecl))
+	{
+	case BUILT_IN_FFS:
+	case BUILT_IN_FFSL:
+	case BUILT_IN_FFSLL:
+	  if (lo != 0)
+	    result = exact_log2 (lo & -lo) + 1;
+	  else if (hi != 0)
+	    result = HOST_BITS_PER_WIDE_INT + exact_log2 (hi & -hi) + 1;
+	  else
+	    result = 0;
+	  break;
+
+	case BUILT_IN_CLZ:
+	case BUILT_IN_CLZL:
+	case BUILT_IN_CLZLL:
+	  if (hi != 0)
+	    result = width - floor_log2 (hi) - 1 - HOST_BITS_PER_WIDE_INT;
+	  else if (lo != 0)
+	    result = width - floor_log2 (lo) - 1;
+	  else if (! CLZ_DEFINED_VALUE_AT_ZERO (TYPE_MODE (type), result))
+	    result = width;
+	  break;
+
+	case BUILT_IN_CTZ:
+	case BUILT_IN_CTZL:
+	case BUILT_IN_CTZLL:
+	  if (lo != 0)
+	    result = exact_log2 (lo & -lo);
+	  else if (hi != 0)
+	    result = HOST_BITS_PER_WIDE_INT + exact_log2 (hi & -hi);
+	  else if (! CTZ_DEFINED_VALUE_AT_ZERO (TYPE_MODE (type), result))
+	    result = width;
+	  break;
+
+	case BUILT_IN_POPCOUNT:
+	case BUILT_IN_POPCOUNTL:
+	case BUILT_IN_POPCOUNTLL:
+	  result = 0;
+	  while (lo)
+	    result++, lo &= lo - 1;
+	  while (hi)
+	    result++, hi &= hi - 1;
+	  break;
+
+	case BUILT_IN_PARITY:
+	case BUILT_IN_PARITYL:
+	case BUILT_IN_PARITYLL:
+	  result = 0;
+	  while (lo)
+	    result++, lo &= lo - 1;
+	  while (hi)
+	    result++, hi &= hi - 1;
+	  result &= 1;
+	  break;
+
+	default:
+	  gcc_unreachable ();
+	}
+
+      return build_int_cst (TREE_TYPE (TREE_TYPE (fndecl)), result);
+    }
+
+  return NULL_TREE;
+}
+
+/* Return true if EXPR is the real constant contained in VALUE.  */
+
+static bool
+real_dconstp (tree expr, const REAL_VALUE_TYPE *value)
+{
+  STRIP_NOPS (expr);
+
+  return ((TREE_CODE (expr) == REAL_CST
+           && ! TREE_CONSTANT_OVERFLOW (expr)
+           && REAL_VALUES_EQUAL (TREE_REAL_CST (expr), *value))
+          || (TREE_CODE (expr) == COMPLEX_CST
+              && real_dconstp (TREE_REALPART (expr), value)
+              && real_zerop (TREE_IMAGPART (expr))));
+}
+
+/* A subroutine of fold_builtin to fold the various logarithmic
+   functions.  EXP is the CALL_EXPR of a call to a builtin logN
+   function.  VALUE is the base of the logN function.  */
+
+static tree
+fold_builtin_logarithm (tree fndecl, tree arglist,
+			const REAL_VALUE_TYPE *value)
+{
+  if (validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    {
+      tree type = TREE_TYPE (TREE_TYPE (fndecl));
+      tree arg = TREE_VALUE (arglist);
+      const enum built_in_function fcode = builtin_mathfn_code (arg);
+
+      /* Optimize logN(1.0) = 0.0.  */
+      if (real_onep (arg))
+	return build_real (type, dconst0);
+
+      /* Optimize logN(N) = 1.0.  If N can't be truncated to MODE
+         exactly, then only do this if flag_unsafe_math_optimizations.  */
+      if (exact_real_truncate (TYPE_MODE (type), value)
+	  || flag_unsafe_math_optimizations)
+        {
+	  const REAL_VALUE_TYPE value_truncate =
+	    real_value_truncate (TYPE_MODE (type), *value);
+	  if (real_dconstp (arg, &value_truncate))
+	    return build_real (type, dconst1);
+	}
+
+      /* Special case, optimize logN(expN(x)) = x.  */
+      if (flag_unsafe_math_optimizations
+	  && ((value == &dconste
+	       && (fcode == BUILT_IN_EXP
+		   || fcode == BUILT_IN_EXPF
+		   || fcode == BUILT_IN_EXPL))
+	      || (value == &dconst2
+		  && (fcode == BUILT_IN_EXP2
+		      || fcode == BUILT_IN_EXP2F
+		      || fcode == BUILT_IN_EXP2L))
+	      || (value == &dconst10 && (BUILTIN_EXP10_P (fcode)))))
+	return fold_convert (type, TREE_VALUE (TREE_OPERAND (arg, 1)));
+
+      /* Optimize logN(func()) for various exponential functions.  We
+         want to determine the value "x" and the power "exponent" in
+         order to transform logN(x**exponent) into exponent*logN(x).  */
+      if (flag_unsafe_math_optimizations)
+        {
+	  tree exponent = 0, x = 0;
+
+	  switch (fcode)
+	  {
+	  case BUILT_IN_EXP:
+	  case BUILT_IN_EXPF:
+	  case BUILT_IN_EXPL:
+	    /* Prepare to do logN(exp(exponent) -> exponent*logN(e).  */
+	    x = build_real (type,
+			    real_value_truncate (TYPE_MODE (type), dconste));
+	    exponent = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    break;
+	  case BUILT_IN_EXP2:
+	  case BUILT_IN_EXP2F:
+	  case BUILT_IN_EXP2L:
+	    /* Prepare to do logN(exp2(exponent) -> exponent*logN(2).  */
+	    x = build_real (type, dconst2);
+	    exponent = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    break;
+	  case BUILT_IN_EXP10:
+	  case BUILT_IN_EXP10F:
+	  case BUILT_IN_EXP10L:
+	  case BUILT_IN_POW10:
+	  case BUILT_IN_POW10F:
+	  case BUILT_IN_POW10L:
+	    /* Prepare to do logN(exp10(exponent) -> exponent*logN(10).  */
+	    x = build_real (type, dconst10);
+	    exponent = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    break;
+	  case BUILT_IN_SQRT:
+	  case BUILT_IN_SQRTF:
+	  case BUILT_IN_SQRTL:
+	    /* Prepare to do logN(sqrt(x) -> 0.5*logN(x).  */
+	    x = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    exponent = build_real (type, dconsthalf);
+	    break;
+	  case BUILT_IN_CBRT:
+	  case BUILT_IN_CBRTF:
+	  case BUILT_IN_CBRTL:
+	    /* Prepare to do logN(cbrt(x) -> (1/3)*logN(x).  */
+	    x = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    exponent = build_real (type, real_value_truncate (TYPE_MODE (type),
+							      dconstthird));
+	    break;
+	  case BUILT_IN_POW:
+	  case BUILT_IN_POWF:
+	  case BUILT_IN_POWL:
+	    /* Prepare to do logN(pow(x,exponent) -> exponent*logN(x).  */
+	    x = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    exponent = TREE_VALUE (TREE_CHAIN (TREE_OPERAND (arg, 1)));
+	    break;
+	  default:
+	    break;
+	  }
+
+	  /* Now perform the optimization.  */
+	  if (x && exponent)
+	    {
+	      tree logfn;
+	      arglist = build_tree_list (NULL_TREE, x);
+	      logfn = build_function_call_expr (fndecl, arglist);
+	      return fold_build2 (MULT_EXPR, type, exponent, logfn);
+	    }
+	}
+    }
+
+  return 0;
+}
+
+/* Fold a builtin function call to pow, powf, or powl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_pow (tree fndecl, tree arglist, tree type)
+{
+  tree arg0 = TREE_VALUE (arglist);
+  tree arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  if (!validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize pow(1.0,y) = 1.0.  */
+  if (real_onep (arg0))
+    return omit_one_operand (type, build_real (type, dconst1), arg1);
+
+  if (TREE_CODE (arg1) == REAL_CST
+      && ! TREE_CONSTANT_OVERFLOW (arg1))
+    {
+      REAL_VALUE_TYPE cint;
+      REAL_VALUE_TYPE c;
+      HOST_WIDE_INT n;
+
+      c = TREE_REAL_CST (arg1);
+
+      /* Optimize pow(x,0.0) = 1.0.  */
+      if (REAL_VALUES_EQUAL (c, dconst0))
+	return omit_one_operand (type, build_real (type, dconst1),
+				 arg0);
+
+      /* Optimize pow(x,1.0) = x.  */
+      if (REAL_VALUES_EQUAL (c, dconst1))
+	return arg0;
+
+      /* Optimize pow(x,-1.0) = 1.0/x.  */
+      if (REAL_VALUES_EQUAL (c, dconstm1))
+	return fold_build2 (RDIV_EXPR, type,
+			    build_real (type, dconst1), arg0);
+
+      /* Optimize pow(x,0.5) = sqrt(x).  */
+      if (flag_unsafe_math_optimizations
+	  && REAL_VALUES_EQUAL (c, dconsthalf))
+	{
+	  tree sqrtfn = mathfn_built_in (type, BUILT_IN_SQRT);
+
+	  if (sqrtfn != NULL_TREE)
+	    {
+	      tree arglist = build_tree_list (NULL_TREE, arg0);
+	      return build_function_call_expr (sqrtfn, arglist);
+	    }
+	}
+
+      /* Check for an integer exponent.  */
+      n = real_to_integer (&c);
+      real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);
+      if (real_identical (&c, &cint))
+	{
+	  /* Attempt to evaluate pow at compile-time.  */
+	  if (TREE_CODE (arg0) == REAL_CST
+	      && ! TREE_CONSTANT_OVERFLOW (arg0))
+	    {
+	      REAL_VALUE_TYPE x;
+	      bool inexact;
+
+	      x = TREE_REAL_CST (arg0);
+	      inexact = real_powi (&x, TYPE_MODE (type), &x, n);
+	      if (flag_unsafe_math_optimizations || !inexact)
+		return build_real (type, x);
+	    }
+
+	  /* Strip sign ops from even integer powers.  */
+	  if ((n & 1) == 0 && flag_unsafe_math_optimizations)
+	    {
+	      tree narg0 = fold_strip_sign_ops (arg0);
+	      if (narg0)
+		{
+		  arglist = build_tree_list (NULL_TREE, arg1);
+		  arglist = tree_cons (NULL_TREE, narg0, arglist);
+		  return build_function_call_expr (fndecl, arglist);
+		}
+	    }
+	}
+    }
+
+  if (flag_unsafe_math_optimizations)
+    {
+      const enum built_in_function fcode = builtin_mathfn_code (arg0);
+
+      /* Optimize pow(expN(x),y) = expN(x*y).  */
+      if (BUILTIN_EXPONENT_P (fcode))
+        {
+	  tree expfn = TREE_OPERAND (TREE_OPERAND (arg0, 0), 0);
+	  tree arg = TREE_VALUE (TREE_OPERAND (arg0, 1));
+	  arg = fold_build2 (MULT_EXPR, type, arg, arg1);
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  return build_function_call_expr (expfn, arglist);
+	}
+
+      /* Optimize pow(sqrt(x),y) = pow(x,y*0.5).  */
+      if (BUILTIN_SQRT_P (fcode))
+        {
+	  tree narg0 = TREE_VALUE (TREE_OPERAND (arg0, 1));
+	  tree narg1 = fold_build2 (MULT_EXPR, type, arg1,
+				    build_real (type, dconsthalf));
+
+	  arglist = tree_cons (NULL_TREE, narg0,
+			       build_tree_list (NULL_TREE, narg1));
+	  return build_function_call_expr (fndecl, arglist);
+	}
+
+      /* Optimize pow(cbrt(x),y) = pow(x,y/3) iff x is nonnegative.  */
+      if (BUILTIN_CBRT_P (fcode))
+        {
+	  tree arg = TREE_VALUE (TREE_OPERAND (arg0, 1));
+	  if (tree_expr_nonnegative_p (arg))
+	    {
+	      const REAL_VALUE_TYPE dconstroot
+		= real_value_truncate (TYPE_MODE (type), dconstthird);
+	      tree narg1 = fold_build2 (MULT_EXPR, type, arg1,
+					build_real (type, dconstroot));
+	      arglist = tree_cons (NULL_TREE, arg,
+				   build_tree_list (NULL_TREE, narg1));
+	      return build_function_call_expr (fndecl, arglist);
+	    }
+	}
+      
+      /* Optimize pow(pow(x,y),z) = pow(x,y*z).  */
+      if (fcode == BUILT_IN_POW || fcode == BUILT_IN_POWF
+	   || fcode == BUILT_IN_POWL)
+        {
+	  tree arg00 = TREE_VALUE (TREE_OPERAND (arg0, 1));
+	  tree arg01 = TREE_VALUE (TREE_CHAIN (TREE_OPERAND (arg0, 1)));
+	  tree narg1 = fold_build2 (MULT_EXPR, type, arg01, arg1);
+	  arglist = tree_cons (NULL_TREE, arg00,
+			       build_tree_list (NULL_TREE, narg1));
+	  return build_function_call_expr (fndecl, arglist);
+	}
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold a builtin function call to powi, powif, or powil.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_powi (tree fndecl ATTRIBUTE_UNUSED, tree arglist, tree type)
+{
+  tree arg0 = TREE_VALUE (arglist);
+  tree arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  if (!validate_arglist (arglist, REAL_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize pow(1.0,y) = 1.0.  */
+  if (real_onep (arg0))
+    return omit_one_operand (type, build_real (type, dconst1), arg1);
+
+  if (host_integerp (arg1, 0))
+    {
+      HOST_WIDE_INT c = TREE_INT_CST_LOW (arg1);
+
+      /* Evaluate powi at compile-time.  */
+      if (TREE_CODE (arg0) == REAL_CST
+	  && ! TREE_CONSTANT_OVERFLOW (arg0))
+	{
+	  REAL_VALUE_TYPE x;
+	  x = TREE_REAL_CST (arg0);
+	  real_powi (&x, TYPE_MODE (type), &x, c);
+	  return build_real (type, x);
+	}
+
+      /* Optimize pow(x,0) = 1.0.  */
+      if (c == 0)
+	return omit_one_operand (type, build_real (type, dconst1),
+				 arg0);
+
+      /* Optimize pow(x,1) = x.  */
+      if (c == 1)
+	return arg0;
+
+      /* Optimize pow(x,-1) = 1.0/x.  */
+      if (c == -1)
+	return fold_build2 (RDIV_EXPR, type,
+			   build_real (type, dconst1), arg0);
+    }
+
+  return NULL_TREE;
+}
+
+/* A subroutine of fold_builtin to fold the various exponent
+   functions.  EXP is the CALL_EXPR of a call to a builtin function.
+   VALUE is the value which will be raised to a power.  */
+
+static tree
+fold_builtin_exponent (tree fndecl, tree arglist,
+		       const REAL_VALUE_TYPE *value)
+{
+  if (validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    {
+      tree type = TREE_TYPE (TREE_TYPE (fndecl));
+      tree arg = TREE_VALUE (arglist);
+
+      /* Optimize exp*(0.0) = 1.0.  */
+      if (real_zerop (arg))
+	return build_real (type, dconst1);
+
+      /* Optimize expN(1.0) = N.  */
+      if (real_onep (arg))
+        {
+	  REAL_VALUE_TYPE cst;
+
+	  real_convert (&cst, TYPE_MODE (type), value);
+	  return build_real (type, cst);
+	}
+
+      /* Attempt to evaluate expN(integer) at compile-time.  */
+      if (flag_unsafe_math_optimizations
+	  && TREE_CODE (arg) == REAL_CST
+	  && ! TREE_CONSTANT_OVERFLOW (arg))
+        {
+	  REAL_VALUE_TYPE cint;
+	  REAL_VALUE_TYPE c;
+	  HOST_WIDE_INT n;
+
+	  c = TREE_REAL_CST (arg);
+	  n = real_to_integer (&c);
+	  real_from_integer (&cint, VOIDmode, n,
+			     n < 0 ? -1 : 0, 0);
+	  if (real_identical (&c, &cint))
+	    {
+	      REAL_VALUE_TYPE x;
+
+	      real_powi (&x, TYPE_MODE (type), value, n);
+	      return build_real (type, x);
+	    }
+	}
+
+      /* Optimize expN(logN(x)) = x.  */
+      if (flag_unsafe_math_optimizations)
+        {
+	  const enum built_in_function fcode = builtin_mathfn_code (arg);
+
+	  if ((value == &dconste
+	       && (fcode == BUILT_IN_LOG
+		   || fcode == BUILT_IN_LOGF
+		   || fcode == BUILT_IN_LOGL))
+	      || (value == &dconst2
+		  && (fcode == BUILT_IN_LOG2
+		      || fcode == BUILT_IN_LOG2F
+		      || fcode == BUILT_IN_LOG2L))
+	      || (value == &dconst10
+		  && (fcode == BUILT_IN_LOG10
+		      || fcode == BUILT_IN_LOG10F
+		      || fcode == BUILT_IN_LOG10L)))
+	    return fold_convert (type, TREE_VALUE (TREE_OPERAND (arg, 1)));
+	}
+    }
+
+  return 0;
+}
+
+/* Fold function call to builtin memcpy.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_memcpy (tree fndecl, tree arglist)
+{
+  tree dest, src, len;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return DEST.  */
+  if (integer_zerop (len))
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, src);
+
+  /* If SRC and DEST are the same (and not volatile), return DEST.  */
+  if (operand_equal_p (src, dest, 0))
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, len);
+
+  return 0;
+}
+
+/* Fold function call to builtin mempcpy.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_mempcpy (tree arglist, tree type, int endp)
+{
+  if (validate_arglist (arglist,
+			POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+      /* If the LEN parameter is zero, return DEST.  */
+      if (integer_zerop (len))
+	return omit_one_operand (type, dest, src);
+
+      /* If SRC and DEST are the same (and not volatile), return DEST+LEN.  */
+      if (operand_equal_p (src, dest, 0))
+        {
+	  if (endp == 0)
+	    return omit_one_operand (type, dest, len);
+
+	  if (endp == 2)
+	    len = fold_build2 (MINUS_EXPR, TREE_TYPE (len), len,
+			       ssize_int (1));
+      
+	  len = fold_convert (TREE_TYPE (dest), len);
+	  len = fold_build2 (PLUS_EXPR, TREE_TYPE (dest), dest, len);
+	  return fold_convert (type, len);
+	}
+    }
+  return 0;
+}
+
+/* Fold function call to builtin memmove.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_memmove (tree arglist, tree type)
+{
+  tree dest, src, len;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return DEST.  */
+  if (integer_zerop (len))
+    return omit_one_operand (type, dest, src);
+
+  /* If SRC and DEST are the same (and not volatile), return DEST.  */
+  if (operand_equal_p (src, dest, 0))
+    return omit_one_operand (type, dest, len);
+
+  return 0;
+}
+
+/* Fold function call to builtin strcpy.  If LEN is not NULL, it represents
+   the length of the string to be copied.  Return NULL_TREE if no
+   simplification can be made.  */
+
+tree
+fold_builtin_strcpy (tree fndecl, tree arglist, tree len)
+{
+  tree dest, src, fn;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* If SRC and DEST are the same (and not volatile), return DEST.  */
+  if (operand_equal_p (src, dest, 0))
+    return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), dest);
+
+  if (optimize_size)
+    return 0;
+
+  fn = implicit_built_in_decls[BUILT_IN_MEMCPY];
+  if (!fn)
+    return 0;
+
+  if (!len)
+    {
+      len = c_strlen (src, 1);
+      if (! len || TREE_SIDE_EFFECTS (len))
+	return 0;
+    }
+
+  len = size_binop (PLUS_EXPR, len, ssize_int (1));
+  arglist = build_tree_list (NULL_TREE, len);
+  arglist = tree_cons (NULL_TREE, src, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)),
+		       build_function_call_expr (fn, arglist));
+}
+
+/* Fold function call to builtin strncpy.  If SLEN is not NULL, it represents
+   the length of the source string.  Return NULL_TREE if no simplification
+   can be made.  */
+
+tree
+fold_builtin_strncpy (tree fndecl, tree arglist, tree slen)
+{
+  tree dest, src, len, fn;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return DEST.  */
+  if (integer_zerop (len))
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, src);
+
+  /* We can't compare slen with len as constants below if len is not a
+     constant.  */
+  if (len == 0 || TREE_CODE (len) != INTEGER_CST)
+    return 0;
+
+  if (!slen)
+    slen = c_strlen (src, 1);
+
+  /* Now, we must be passed a constant src ptr parameter.  */
+  if (slen == 0 || TREE_CODE (slen) != INTEGER_CST)
+    return 0;
+
+  slen = size_binop (PLUS_EXPR, slen, ssize_int (1));
+
+  /* We do not support simplification of this case, though we do
+     support it when expanding trees into RTL.  */
+  /* FIXME: generate a call to __builtin_memset.  */
+  if (tree_int_cst_lt (slen, len))
+    return 0;
+
+  /* OK transform into builtin memcpy.  */
+  fn = implicit_built_in_decls[BUILT_IN_MEMCPY];
+  if (!fn)
+    return 0;
+  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)),
+		       build_function_call_expr (fn, arglist));
+}
+
+/* Fold function call to builtin memcmp.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_memcmp (tree arglist)
+{
+  tree arg1, arg2, len;
+  const char *p1, *p2;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg1 = TREE_VALUE (arglist);
+  arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return zero.  */
+  if (integer_zerop (len))
+    return omit_two_operands (integer_type_node, integer_zero_node,
+			      arg1, arg2);
+
+  /* If ARG1 and ARG2 are the same (and not volatile), return zero.  */
+  if (operand_equal_p (arg1, arg2, 0))
+    return omit_one_operand (integer_type_node, integer_zero_node, len);
+
+  p1 = c_getstr (arg1);
+  p2 = c_getstr (arg2);
+
+  /* If all arguments are constant, and the value of len is not greater
+     than the lengths of arg1 and arg2, evaluate at compile-time.  */
+  if (host_integerp (len, 1) && p1 && p2
+      && compare_tree_int (len, strlen (p1) + 1) <= 0
+      && compare_tree_int (len, strlen (p2) + 1) <= 0)
+    {
+      const int r = memcmp (p1, p2, tree_low_cst (len, 1));
+
+      if (r > 0)
+	return integer_one_node;
+      else if (r < 0)
+	return integer_minus_one_node;
+      else
+	return integer_zero_node;
+    }
+
+  /* If len parameter is one, return an expression corresponding to
+     (*(const unsigned char*)arg1 - (const unsigned char*)arg2).  */
+  if (host_integerp (len, 1) && tree_low_cst (len, 1) == 1)
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      tree ind1 = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg1)));
+      tree ind2 = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg2)));
+      return fold_build2 (MINUS_EXPR, integer_type_node, ind1, ind2);
+    }
+
+  return 0;
+}
+
+/* Fold function call to builtin strcmp.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_strcmp (tree arglist)
+{
+  tree arg1, arg2;
+  const char *p1, *p2;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg1 = TREE_VALUE (arglist);
+  arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* If ARG1 and ARG2 are the same (and not volatile), return zero.  */
+  if (operand_equal_p (arg1, arg2, 0))
+    return integer_zero_node;
+
+  p1 = c_getstr (arg1);
+  p2 = c_getstr (arg2);
+
+  if (p1 && p2)
+    {
+      const int i = strcmp (p1, p2);
+      if (i < 0)
+	return integer_minus_one_node;
+      else if (i > 0)
+	return integer_one_node;
+      else
+	return integer_zero_node;
+    }
+
+  /* If the second arg is "", return *(const unsigned char*)arg1.  */
+  if (p2 && *p2 == '\0')
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      return fold_convert (integer_type_node,
+			   build1 (INDIRECT_REF, cst_uchar_node,
+				   fold_convert (cst_uchar_ptr_node,
+						 arg1)));
+    }
+
+  /* If the first arg is "", return -*(const unsigned char*)arg2.  */
+  if (p1 && *p1 == '\0')
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      tree temp = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg2)));
+      return fold_build1 (NEGATE_EXPR, integer_type_node, temp);
+    }
+
+  return 0;
+}
+
+/* Fold function call to builtin strncmp.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_strncmp (tree arglist)
+{
+  tree arg1, arg2, len;
+  const char *p1, *p2;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg1 = TREE_VALUE (arglist);
+  arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return zero.  */
+  if (integer_zerop (len))
+    return omit_two_operands (integer_type_node, integer_zero_node,
+			      arg1, arg2);
+
+  /* If ARG1 and ARG2 are the same (and not volatile), return zero.  */
+  if (operand_equal_p (arg1, arg2, 0))
+    return omit_one_operand (integer_type_node, integer_zero_node, len);
+
+  p1 = c_getstr (arg1);
+  p2 = c_getstr (arg2);
+
+  if (host_integerp (len, 1) && p1 && p2)
+    {
+      const int i = strncmp (p1, p2, tree_low_cst (len, 1));
+      if (i > 0)
+	return integer_one_node;
+      else if (i < 0)
+	return integer_minus_one_node;
+      else
+	return integer_zero_node;
+    }
+
+  /* If the second arg is "", and the length is greater than zero,
+     return *(const unsigned char*)arg1.  */
+  if (p2 && *p2 == '\0'
+      && TREE_CODE (len) == INTEGER_CST
+      && tree_int_cst_sgn (len) == 1)
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      return fold_convert (integer_type_node,
+			   build1 (INDIRECT_REF, cst_uchar_node,
+				   fold_convert (cst_uchar_ptr_node,
+						 arg1)));
+    }
+
+  /* If the first arg is "", and the length is greater than zero,
+     return -*(const unsigned char*)arg2.  */
+  if (p1 && *p1 == '\0'
+      && TREE_CODE (len) == INTEGER_CST
+      && tree_int_cst_sgn (len) == 1)
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      tree temp = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg2)));
+      return fold_build1 (NEGATE_EXPR, integer_type_node, temp);
+    }
+
+  /* If len parameter is one, return an expression corresponding to
+     (*(const unsigned char*)arg1 - (const unsigned char*)arg2).  */
+  if (host_integerp (len, 1) && tree_low_cst (len, 1) == 1)
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      tree ind1 = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg1)));
+      tree ind2 = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg2)));
+      return fold_build2 (MINUS_EXPR, integer_type_node, ind1, ind2);
+    }
+
+  return 0;
+}
+
+/* Fold function call to builtin signbit, signbitf or signbitl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_signbit (tree fndecl, tree arglist)
+{
+  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+  tree arg, temp;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  arg = TREE_VALUE (arglist);
+
+  /* If ARG is a compile-time constant, determine the result.  */
+  if (TREE_CODE (arg) == REAL_CST
+      && !TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE c;
+
+      c = TREE_REAL_CST (arg);
+      temp = REAL_VALUE_NEGATIVE (c) ? integer_one_node : integer_zero_node;
+      return fold_convert (type, temp);
+    }
+
+  /* If ARG is non-negative, the result is always zero.  */
+  if (tree_expr_nonnegative_p (arg))
+    return omit_one_operand (type, integer_zero_node, arg);
+
+  /* If ARG's format doesn't have signed zeros, return "arg < 0.0".  */
+  if (!HONOR_SIGNED_ZEROS (TYPE_MODE (TREE_TYPE (arg))))
+    return fold_build2 (LT_EXPR, type, arg,
+			build_real (TREE_TYPE (arg), dconst0));
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin copysign, copysignf or copysignl.
+   Return NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_copysign (tree fndecl, tree arglist, tree type)
+{
+  tree arg1, arg2, tem;
+
+  if (!validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  arg1 = TREE_VALUE (arglist);
+  arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* copysign(X,X) is X.  */
+  if (operand_equal_p (arg1, arg2, 0))
+    return fold_convert (type, arg1);
+
+  /* If ARG1 and ARG2 are compile-time constants, determine the result.  */
+  if (TREE_CODE (arg1) == REAL_CST
+      && TREE_CODE (arg2) == REAL_CST
+      && !TREE_CONSTANT_OVERFLOW (arg1)
+      && !TREE_CONSTANT_OVERFLOW (arg2))
+    {
+      REAL_VALUE_TYPE c1, c2;
+
+      c1 = TREE_REAL_CST (arg1);
+      c2 = TREE_REAL_CST (arg2);
+      real_copysign (&c1, &c2);
+      return build_real (type, c1);
+      c1.sign = c2.sign;
+    }
+
+  /* copysign(X, Y) is fabs(X) when Y is always non-negative.
+     Remember to evaluate Y for side-effects.  */
+  if (tree_expr_nonnegative_p (arg2))
+    return omit_one_operand (type,
+			     fold_build1 (ABS_EXPR, type, arg1),
+			     arg2);
+
+  /* Strip sign changing operations for the first argument.  */
+  tem = fold_strip_sign_ops (arg1);
+  if (tem)
+    {
+      arglist = tree_cons (NULL_TREE, tem, TREE_CHAIN (arglist));
+      return build_function_call_expr (fndecl, arglist);
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold a call to builtin isascii.  */
+
+static tree
+fold_builtin_isascii (tree arglist)
+{
+  if (! validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      /* Transform isascii(c) -> ((c & ~0x7f) == 0).  */
+      tree arg = TREE_VALUE (arglist);
+
+      arg = build2 (BIT_AND_EXPR, integer_type_node, arg,
+		    build_int_cst (NULL_TREE,
+				   ~ (unsigned HOST_WIDE_INT) 0x7f));
+      arg = fold_build2 (EQ_EXPR, integer_type_node,
+			 arg, integer_zero_node);
+
+      if (in_gimple_form && !TREE_CONSTANT (arg))
+        return NULL_TREE;
+      else
+        return arg;
+    }
+}
+
+/* Fold a call to builtin toascii.  */
+
+static tree
+fold_builtin_toascii (tree arglist)
+{
+  if (! validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      /* Transform toascii(c) -> (c & 0x7f).  */
+      tree arg = TREE_VALUE (arglist);
+
+      return fold_build2 (BIT_AND_EXPR, integer_type_node, arg,
+			  build_int_cst (NULL_TREE, 0x7f));
+    }
+}
+
+/* Fold a call to builtin isdigit.  */
+
+static tree
+fold_builtin_isdigit (tree arglist)
+{
+  if (! validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      /* Transform isdigit(c) -> (unsigned)(c) - '0' <= 9.  */
+      /* According to the C standard, isdigit is unaffected by locale.
+	 However, it definitely is affected by the target character set.  */
+      tree arg;
+      unsigned HOST_WIDE_INT target_digit0
+	= lang_hooks.to_target_charset ('0');
+
+      if (target_digit0 == 0)
+	return NULL_TREE;
+
+      arg = fold_convert (unsigned_type_node, TREE_VALUE (arglist));
+      arg = build2 (MINUS_EXPR, unsigned_type_node, arg,
+		    build_int_cst (unsigned_type_node, target_digit0));
+      arg = fold_build2 (LE_EXPR, integer_type_node, arg,
+			 build_int_cst (unsigned_type_node, 9));
+      if (in_gimple_form && !TREE_CONSTANT (arg))
+        return NULL_TREE;
+      else
+        return arg;
+    }
+}
+
+/* Fold a call to fabs, fabsf or fabsl.  */
+
+static tree
+fold_builtin_fabs (tree arglist, tree type)
+{
+  tree arg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  arg = fold_convert (type, arg);
+  if (TREE_CODE (arg) == REAL_CST)
+    return fold_abs_const (arg, type);
+  return fold_build1 (ABS_EXPR, type, arg);
+}
+
+/* Fold a call to abs, labs, llabs or imaxabs.  */
+
+static tree
+fold_builtin_abs (tree arglist, tree type)
+{
+  tree arg;
+
+  if (!validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  arg = fold_convert (type, arg);
+  if (TREE_CODE (arg) == INTEGER_CST)
+    return fold_abs_const (arg, type);
+  return fold_build1 (ABS_EXPR, type, arg);
+}
+
+/* Fold a call to __builtin_isnan(), __builtin_isinf, __builtin_finite.
+   EXP is the CALL_EXPR for the call.  */
+
+static tree
+fold_builtin_classify (tree fndecl, tree arglist, int builtin_index)
+{
+  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+  tree arg;
+  REAL_VALUE_TYPE r;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    {
+      /* Check that we have exactly one argument.  */
+      if (arglist == 0)
+	{
+	  error ("too few arguments to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+      else if (TREE_CHAIN (arglist) != 0)
+	{
+	  error ("too many arguments to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+      else
+	{
+	  error ("non-floating-point argument to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+    }
+
+  arg = TREE_VALUE (arglist);
+  switch (builtin_index)
+    {
+    case BUILT_IN_ISINF:
+      if (!MODE_HAS_INFINITIES (TYPE_MODE (TREE_TYPE (arg))))
+        return omit_one_operand (type, integer_zero_node, arg);
+
+      if (TREE_CODE (arg) == REAL_CST)
+	{
+	  r = TREE_REAL_CST (arg);
+	  if (real_isinf (&r))
+	    return real_compare (GT_EXPR, &r, &dconst0)
+		   ? integer_one_node : integer_minus_one_node;
+	  else
+	    return integer_zero_node;
+	}
+
+      return NULL_TREE;
+
+    case BUILT_IN_FINITE:
+      if (!MODE_HAS_NANS (TYPE_MODE (TREE_TYPE (arg)))
+          && !MODE_HAS_INFINITIES (TYPE_MODE (TREE_TYPE (arg))))
+        return omit_one_operand (type, integer_zero_node, arg);
+
+      if (TREE_CODE (arg) == REAL_CST)
+	{
+	  r = TREE_REAL_CST (arg);
+	  return real_isinf (&r) || real_isnan (&r)
+		 ? integer_zero_node : integer_one_node;
+	}
+
+      return NULL_TREE;
+
+    case BUILT_IN_ISNAN:
+      if (!MODE_HAS_NANS (TYPE_MODE (TREE_TYPE (arg))))
+        return omit_one_operand (type, integer_zero_node, arg);
+
+      if (TREE_CODE (arg) == REAL_CST)
+	{
+	  r = TREE_REAL_CST (arg);
+	  return real_isnan (&r) ? integer_one_node : integer_zero_node;
+	}
+
+      arg = builtin_save_expr (arg);
+      return fold_build2 (UNORDERED_EXPR, type, arg, arg);
+
+    default:
+      gcc_unreachable ();
+    }
+}
+
+/* Fold a call to an unordered comparison function such as
+   __builtin_isgreater().  FNDECL is the FUNCTION_DECL for the function
+   being called and ARGLIST is the argument list for the call.
+   UNORDERED_CODE and ORDERED_CODE are comparison codes that give
+   the opposite of the desired result.  UNORDERED_CODE is used
+   for modes that can hold NaNs and ORDERED_CODE is used for
+   the rest.  */
+
+static tree
+fold_builtin_unordered_cmp (tree fndecl, tree arglist,
+			    enum tree_code unordered_code,
+			    enum tree_code ordered_code)
+{
+  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+  enum tree_code code;
+  tree arg0, arg1;
+  tree type0, type1;
+  enum tree_code code0, code1;
+  tree cmp_type = NULL_TREE;
+
+  if (!validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    {
+      /* Check that we have exactly two arguments.  */
+      if (arglist == 0 || TREE_CHAIN (arglist) == 0)
+	{
+	  error ("too few arguments to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+      else if (TREE_CHAIN (TREE_CHAIN (arglist)) != 0)
+	{
+	  error ("too many arguments to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+    }
+
+  arg0 = TREE_VALUE (arglist);
+  arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+  
+  type0 = TREE_TYPE (arg0);
+  type1 = TREE_TYPE (arg1);
+  
+  code0 = TREE_CODE (type0);
+  code1 = TREE_CODE (type1);
+  
+  if (code0 == REAL_TYPE && code1 == REAL_TYPE)
+    /* Choose the wider of two real types.  */
+    cmp_type = TYPE_PRECISION (type0) >= TYPE_PRECISION (type1)
+      ? type0 : type1;
+  else if (code0 == REAL_TYPE && code1 == INTEGER_TYPE)
+    cmp_type = type0;
+  else if (code0 == INTEGER_TYPE && code1 == REAL_TYPE)
+    cmp_type = type1;
+  else
+    {
+      error ("non-floating-point argument to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+      return error_mark_node;
+    }
+  
+  arg0 = fold_convert (cmp_type, arg0);
+  arg1 = fold_convert (cmp_type, arg1);
+
+  if (unordered_code == UNORDERED_EXPR)
+    {
+      if (!MODE_HAS_NANS (TYPE_MODE (TREE_TYPE (arg0))))
+	return omit_two_operands (type, integer_zero_node, arg0, arg1);
+      return fold_build2 (UNORDERED_EXPR, type, arg0, arg1);
+    }
+
+  code = MODE_HAS_NANS (TYPE_MODE (TREE_TYPE (arg0))) ? unordered_code
+						      : ordered_code;
+  return fold_build1 (TRUTH_NOT_EXPR, type,
+		      fold_build2 (code, type, arg0, arg1));
+}
+
+/* Used by constant folding to simplify calls to builtin functions.  EXP is
+   the CALL_EXPR of a call to a builtin function.  IGNORE is true if the
+   result of the function call is ignored.  This function returns NULL_TREE
+   if no simplification was possible.  */
+
+static tree
+fold_builtin_1 (tree fndecl, tree arglist, bool ignore)
+{
+  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+  enum built_in_function fcode;
+
+  if (DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_MD)
+    return targetm.fold_builtin (fndecl, arglist, ignore);
+
+  fcode = DECL_FUNCTION_CODE (fndecl);
+  switch (fcode)
+    {
+    case BUILT_IN_FPUTS:
+      return fold_builtin_fputs (arglist, ignore, false, NULL_TREE);
+
+    case BUILT_IN_FPUTS_UNLOCKED:
+      return fold_builtin_fputs (arglist, ignore, true, NULL_TREE);
+
+    case BUILT_IN_STRSTR:
+      return fold_builtin_strstr (arglist, type);
+
+    case BUILT_IN_STRCAT:
+      return fold_builtin_strcat (arglist);
+
+    case BUILT_IN_STRNCAT:
+      return fold_builtin_strncat (arglist);
+
+    case BUILT_IN_STRSPN:
+      return fold_builtin_strspn (arglist);
+
+    case BUILT_IN_STRCSPN:
+      return fold_builtin_strcspn (arglist);
+
+    case BUILT_IN_STRCHR:
+    case BUILT_IN_INDEX:
+      return fold_builtin_strchr (arglist, type);
+
+    case BUILT_IN_STRRCHR:
+    case BUILT_IN_RINDEX:
+      return fold_builtin_strrchr (arglist, type);
+
+    case BUILT_IN_STRCPY:
+      return fold_builtin_strcpy (fndecl, arglist, NULL_TREE);
+
+    case BUILT_IN_STRNCPY:
+      return fold_builtin_strncpy (fndecl, arglist, NULL_TREE);
+
+    case BUILT_IN_STRCMP:
+      return fold_builtin_strcmp (arglist);
+
+    case BUILT_IN_STRNCMP:
+      return fold_builtin_strncmp (arglist);
+
+    case BUILT_IN_STRPBRK:
+      return fold_builtin_strpbrk (arglist, type);
+
+    case BUILT_IN_BCMP:
+    case BUILT_IN_MEMCMP:
+      return fold_builtin_memcmp (arglist);
+
+    case BUILT_IN_SPRINTF:
+      return fold_builtin_sprintf (arglist, ignore);
+
+    case BUILT_IN_CONSTANT_P:
+      {
+	tree val;
+
+	val = fold_builtin_constant_p (arglist);
+	/* Gimplification will pull the CALL_EXPR for the builtin out of
+	   an if condition.  When not optimizing, we'll not CSE it back.
+	   To avoid link error types of regressions, return false now.  */
+	if (!val && !optimize)
+	  val = integer_zero_node;
+
+	return val;
+      }
+
+    case BUILT_IN_EXPECT:
+      return fold_builtin_expect (arglist);
+
+    case BUILT_IN_CLASSIFY_TYPE:
+      return fold_builtin_classify_type (arglist);
+
+    case BUILT_IN_STRLEN:
+      return fold_builtin_strlen (arglist);
+
+    case BUILT_IN_FABS:
+    case BUILT_IN_FABSF:
+    case BUILT_IN_FABSL:
+      return fold_builtin_fabs (arglist, type);
+
+    case BUILT_IN_ABS:
+    case BUILT_IN_LABS:
+    case BUILT_IN_LLABS:
+    case BUILT_IN_IMAXABS:
+      return fold_builtin_abs (arglist, type);
+
+    case BUILT_IN_CONJ:
+    case BUILT_IN_CONJF:
+    case BUILT_IN_CONJL:
+      if (validate_arglist (arglist, COMPLEX_TYPE, VOID_TYPE))
+	return fold_build1 (CONJ_EXPR, type, TREE_VALUE (arglist));
+      break;
+
+    case BUILT_IN_CREAL:
+    case BUILT_IN_CREALF:
+    case BUILT_IN_CREALL:
+      if (validate_arglist (arglist, COMPLEX_TYPE, VOID_TYPE))
+        return non_lvalue (fold_build1 (REALPART_EXPR, type,
+					TREE_VALUE (arglist)));
+      break;
+
+    case BUILT_IN_CIMAG:
+    case BUILT_IN_CIMAGF:
+    case BUILT_IN_CIMAGL:
+      if (validate_arglist (arglist, COMPLEX_TYPE, VOID_TYPE))
+        return non_lvalue (fold_build1 (IMAGPART_EXPR, type,
+					TREE_VALUE (arglist)));
+      break;
+
+    case BUILT_IN_CABS:
+    case BUILT_IN_CABSF:
+    case BUILT_IN_CABSL:
+      return fold_builtin_cabs (arglist, type);
+
+    case BUILT_IN_SQRT:
+    case BUILT_IN_SQRTF:
+    case BUILT_IN_SQRTL:
+      return fold_builtin_sqrt (arglist, type);
+
+    case BUILT_IN_CBRT:
+    case BUILT_IN_CBRTF:
+    case BUILT_IN_CBRTL:
+      return fold_builtin_cbrt (arglist, type);
+
+    case BUILT_IN_SIN:
+    case BUILT_IN_SINF:
+    case BUILT_IN_SINL:
+      return fold_builtin_sin (arglist);
+
+    case BUILT_IN_COS:
+    case BUILT_IN_COSF:
+    case BUILT_IN_COSL:
+      return fold_builtin_cos (arglist, type, fndecl);
+
+    case BUILT_IN_EXP:
+    case BUILT_IN_EXPF:
+    case BUILT_IN_EXPL:
+      return fold_builtin_exponent (fndecl, arglist, &dconste);
+
+    case BUILT_IN_EXP2:
+    case BUILT_IN_EXP2F:
+    case BUILT_IN_EXP2L:
+      return fold_builtin_exponent (fndecl, arglist, &dconst2);
+
+    case BUILT_IN_EXP10:
+    case BUILT_IN_EXP10F:
+    case BUILT_IN_EXP10L:
+    case BUILT_IN_POW10:
+    case BUILT_IN_POW10F:
+    case BUILT_IN_POW10L:
+      return fold_builtin_exponent (fndecl, arglist, &dconst10);
+
+    case BUILT_IN_LOG:
+    case BUILT_IN_LOGF:
+    case BUILT_IN_LOGL:
+      return fold_builtin_logarithm (fndecl, arglist, &dconste);
+
+    case BUILT_IN_LOG2:
+    case BUILT_IN_LOG2F:
+    case BUILT_IN_LOG2L:
+      return fold_builtin_logarithm (fndecl, arglist, &dconst2);
+
+    case BUILT_IN_LOG10:
+    case BUILT_IN_LOG10F:
+    case BUILT_IN_LOG10L:
+      return fold_builtin_logarithm (fndecl, arglist, &dconst10);
+
+    case BUILT_IN_TAN:
+    case BUILT_IN_TANF:
+    case BUILT_IN_TANL:
+      return fold_builtin_tan (arglist);
+
+    case BUILT_IN_ATAN:
+    case BUILT_IN_ATANF:
+    case BUILT_IN_ATANL:
+      return fold_builtin_atan (arglist, type);
+
+    case BUILT_IN_POW:
+    case BUILT_IN_POWF:
+    case BUILT_IN_POWL:
+      return fold_builtin_pow (fndecl, arglist, type);
+
+    case BUILT_IN_POWI:
+    case BUILT_IN_POWIF:
+    case BUILT_IN_POWIL:
+      return fold_builtin_powi (fndecl, arglist, type);
+
+    case BUILT_IN_INF:
+    case BUILT_IN_INFF:
+    case BUILT_IN_INFL:
+      return fold_builtin_inf (type, true);
+
+    case BUILT_IN_HUGE_VAL:
+    case BUILT_IN_HUGE_VALF:
+    case BUILT_IN_HUGE_VALL:
+      return fold_builtin_inf (type, false);
+
+    case BUILT_IN_NAN:
+    case BUILT_IN_NANF:
+    case BUILT_IN_NANL:
+      return fold_builtin_nan (arglist, type, true);
+
+    case BUILT_IN_NANS:
+    case BUILT_IN_NANSF:
+    case BUILT_IN_NANSL:
+      return fold_builtin_nan (arglist, type, false);
+
+    case BUILT_IN_FLOOR:
+    case BUILT_IN_FLOORF:
+    case BUILT_IN_FLOORL:
+      return fold_builtin_floor (fndecl, arglist);
+
+    case BUILT_IN_CEIL:
+    case BUILT_IN_CEILF:
+    case BUILT_IN_CEILL:
+      return fold_builtin_ceil (fndecl, arglist);
+
+    case BUILT_IN_TRUNC:
+    case BUILT_IN_TRUNCF:
+    case BUILT_IN_TRUNCL:
+      return fold_builtin_trunc (fndecl, arglist);
+
+    case BUILT_IN_ROUND:
+    case BUILT_IN_ROUNDF:
+    case BUILT_IN_ROUNDL:
+      return fold_builtin_round (fndecl, arglist);
+
+    case BUILT_IN_NEARBYINT:
+    case BUILT_IN_NEARBYINTF:
+    case BUILT_IN_NEARBYINTL:
+    case BUILT_IN_RINT:
+    case BUILT_IN_RINTF:
+    case BUILT_IN_RINTL:
+      return fold_trunc_transparent_mathfn (fndecl, arglist);
+
+    case BUILT_IN_LCEIL:
+    case BUILT_IN_LCEILF:
+    case BUILT_IN_LCEILL:
+    case BUILT_IN_LLCEIL:
+    case BUILT_IN_LLCEILF:
+    case BUILT_IN_LLCEILL:
+    case BUILT_IN_LFLOOR:
+    case BUILT_IN_LFLOORF:
+    case BUILT_IN_LFLOORL:
+    case BUILT_IN_LLFLOOR:
+    case BUILT_IN_LLFLOORF:
+    case BUILT_IN_LLFLOORL:
+    case BUILT_IN_LROUND:
+    case BUILT_IN_LROUNDF:
+    case BUILT_IN_LROUNDL:
+    case BUILT_IN_LLROUND:
+    case BUILT_IN_LLROUNDF:
+    case BUILT_IN_LLROUNDL:
+      return fold_builtin_int_roundingfn (fndecl, arglist);
+
+    case BUILT_IN_LRINT:
+    case BUILT_IN_LRINTF:
+    case BUILT_IN_LRINTL:
+    case BUILT_IN_LLRINT:
+    case BUILT_IN_LLRINTF:
+    case BUILT_IN_LLRINTL:
+      return fold_fixed_mathfn (fndecl, arglist);
+
+    case BUILT_IN_FFS:
+    case BUILT_IN_FFSL:
+    case BUILT_IN_FFSLL:
+    case BUILT_IN_CLZ:
+    case BUILT_IN_CLZL:
+    case BUILT_IN_CLZLL:
+    case BUILT_IN_CTZ:
+    case BUILT_IN_CTZL:
+    case BUILT_IN_CTZLL:
+    case BUILT_IN_POPCOUNT:
+    case BUILT_IN_POPCOUNTL:
+    case BUILT_IN_POPCOUNTLL:
+    case BUILT_IN_PARITY:
+    case BUILT_IN_PARITYL:
+    case BUILT_IN_PARITYLL:
+      return fold_builtin_bitop (fndecl, arglist);
+
+    case BUILT_IN_MEMCPY:
+      return fold_builtin_memcpy (fndecl, arglist);
+
+    case BUILT_IN_MEMPCPY:
+      return fold_builtin_mempcpy (arglist, type, /*endp=*/1);
+
+    case BUILT_IN_MEMMOVE:
+      return fold_builtin_memmove (arglist, type);
+
+    case BUILT_IN_SIGNBIT:
+    case BUILT_IN_SIGNBITF:
+    case BUILT_IN_SIGNBITL:
+      return fold_builtin_signbit (fndecl, arglist);
+
+    case BUILT_IN_ISASCII:
+      return fold_builtin_isascii (arglist);
+
+    case BUILT_IN_TOASCII:
+      return fold_builtin_toascii (arglist);
+
+    case BUILT_IN_ISDIGIT:
+      return fold_builtin_isdigit (arglist);
+
+    case BUILT_IN_COPYSIGN:
+    case BUILT_IN_COPYSIGNF:
+    case BUILT_IN_COPYSIGNL:
+      return fold_builtin_copysign (fndecl, arglist, type);
+
+    case BUILT_IN_FINITE:
+    case BUILT_IN_FINITEF:
+    case BUILT_IN_FINITEL:
+      return fold_builtin_classify (fndecl, arglist, BUILT_IN_FINITE);
+
+    case BUILT_IN_ISINF:
+    case BUILT_IN_ISINFF:
+    case BUILT_IN_ISINFL:
+      return fold_builtin_classify (fndecl, arglist, BUILT_IN_ISINF);
+
+    case BUILT_IN_ISNAN:
+    case BUILT_IN_ISNANF:
+    case BUILT_IN_ISNANL:
+      return fold_builtin_classify (fndecl, arglist, BUILT_IN_ISNAN);
+
+    case BUILT_IN_ISGREATER:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNLE_EXPR, LE_EXPR);
+    case BUILT_IN_ISGREATEREQUAL:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNLT_EXPR, LT_EXPR);
+    case BUILT_IN_ISLESS:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNGE_EXPR, GE_EXPR);
+    case BUILT_IN_ISLESSEQUAL:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNGT_EXPR, GT_EXPR);
+    case BUILT_IN_ISLESSGREATER:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNEQ_EXPR, EQ_EXPR);
+    case BUILT_IN_ISUNORDERED:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNORDERED_EXPR,
+					 NOP_EXPR);
+
+      /* We do the folding for va_start in the expander.  */
+    case BUILT_IN_VA_START:
+      break;
+
+    case BUILT_IN_OBJECT_SIZE:
+      return fold_builtin_object_size (arglist);
+    case BUILT_IN_MEMCPY_CHK:
+    case BUILT_IN_MEMPCPY_CHK:
+    case BUILT_IN_MEMMOVE_CHK:
+    case BUILT_IN_MEMSET_CHK:
+      return fold_builtin_memory_chk (fndecl, arglist, NULL_TREE, ignore,
+				      DECL_FUNCTION_CODE (fndecl));
+    case BUILT_IN_STRCPY_CHK:
+    case BUILT_IN_STPCPY_CHK:
+      return fold_builtin_stxcpy_chk (fndecl, arglist, NULL_TREE, ignore,
+				      DECL_FUNCTION_CODE (fndecl));
+    case BUILT_IN_STRNCPY_CHK:
+      return fold_builtin_strncpy_chk (arglist, NULL_TREE);
+    case BUILT_IN_STRCAT_CHK:
+      return fold_builtin_strcat_chk (fndecl, arglist);
+    case BUILT_IN_STRNCAT_CHK:
+      return fold_builtin_strncat_chk (fndecl, arglist);
+    case BUILT_IN_SPRINTF_CHK:
+    case BUILT_IN_VSPRINTF_CHK:
+      return fold_builtin_sprintf_chk (arglist, DECL_FUNCTION_CODE (fndecl));
+    case BUILT_IN_SNPRINTF_CHK:
+    case BUILT_IN_VSNPRINTF_CHK:
+      return fold_builtin_snprintf_chk (arglist, NULL_TREE,
+					DECL_FUNCTION_CODE (fndecl));
+
+    case BUILT_IN_PRINTF:
+    case BUILT_IN_PRINTF_UNLOCKED:
+    case BUILT_IN_VPRINTF:
+    case BUILT_IN_PRINTF_CHK:
+    case BUILT_IN_VPRINTF_CHK:
+      return fold_builtin_printf (fndecl, arglist, ignore,
+				  DECL_FUNCTION_CODE (fndecl));
+
+    case BUILT_IN_FPRINTF:
+    case BUILT_IN_FPRINTF_UNLOCKED:
+    case BUILT_IN_VFPRINTF:
+    case BUILT_IN_FPRINTF_CHK:
+    case BUILT_IN_VFPRINTF_CHK:
+      return fold_builtin_fprintf (fndecl, arglist, ignore,
+				   DECL_FUNCTION_CODE (fndecl));
+
+    default:
+      break;
+    }
+
+  return 0;
+}
+
+/* A wrapper function for builtin folding that prevents warnings for
+   "statement without effect" and the like, caused by removing the
+   call node earlier than the warning is generated.  */
+
+tree
+fold_builtin (tree fndecl, tree arglist, bool ignore)
+{
+  tree exp = fold_builtin_1 (fndecl, arglist, ignore);
+  if (exp)
+    {
+      exp = build1 (NOP_EXPR, TREE_TYPE (exp), exp);
+      TREE_NO_WARNING (exp) = 1;
+    }
+
+  return exp;
+}
+
+/* Conveniently construct a function call expression.  */
+
+tree
+build_function_call_expr (tree fn, tree arglist)
+{
+  tree call_expr;
+
+  call_expr = build1 (ADDR_EXPR, build_pointer_type (TREE_TYPE (fn)), fn);
+  return fold_build3 (CALL_EXPR, TREE_TYPE (TREE_TYPE (fn)),
+		      call_expr, arglist, NULL_TREE);
+}
+
+/* This function validates the types of a function call argument list
+   represented as a tree chain of parameters against a specified list
+   of tree_codes.  If the last specifier is a 0, that represents an
+   ellipses, otherwise the last specifier must be a VOID_TYPE.  */
+
+static int
+validate_arglist (tree arglist, ...)
+{
+  enum tree_code code;
+  int res = 0;
+  va_list ap;
+
+  va_start (ap, arglist);
+
+  do
+    {
+      code = va_arg (ap, enum tree_code);
+      switch (code)
+	{
+	case 0:
+	  /* This signifies an ellipses, any further arguments are all ok.  */
+	  res = 1;
+	  goto end;
+	case VOID_TYPE:
+	  /* This signifies an endlink, if no arguments remain, return
+	     true, otherwise return false.  */
+	  res = arglist == 0;
+	  goto end;
+	default:
+	  /* If no parameters remain or the parameter's code does not
+	     match the specified code, return false.  Otherwise continue
+	     checking any remaining arguments.  */
+	  if (arglist == 0)
+	    goto end;
+	  if (code == POINTER_TYPE)
+	    {
+	      if (! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist))))
+		goto end;
+	    }
+	  else if (code != TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))))
+	    goto end;
+	  break;
+	}
+      arglist = TREE_CHAIN (arglist);
+    }
+  while (1);
+
+  /* We need gotos here since we can only have one VA_CLOSE in a
+     function.  */
+ end: ;
+  va_end (ap);
+
+  return res;
+}
+
+/* Default target-specific builtin expander that does nothing.  */
+
+rtx
+default_expand_builtin (tree exp ATTRIBUTE_UNUSED,
+			rtx target ATTRIBUTE_UNUSED,
+			rtx subtarget ATTRIBUTE_UNUSED,
+			enum machine_mode mode ATTRIBUTE_UNUSED,
+			int ignore ATTRIBUTE_UNUSED)
+{
+  return NULL_RTX;
+}
+
+/* Returns true is EXP represents data that would potentially reside
+   in a readonly section.  */
+
+static bool
+readonly_data_expr (tree exp)
+{
+  STRIP_NOPS (exp);
+
+  if (TREE_CODE (exp) != ADDR_EXPR)
+    return false;
+
+  exp = get_base_address (TREE_OPERAND (exp, 0));
+  if (!exp)
+    return false;
+
+  /* Make sure we call decl_readonly_section only for trees it
+     can handle (since it returns true for everything it doesn't
+     understand).  */
+  if (TREE_CODE (exp) == STRING_CST
+      || TREE_CODE (exp) == CONSTRUCTOR
+      || (TREE_CODE (exp) == VAR_DECL && TREE_STATIC (exp)))
+    return decl_readonly_section (exp, 0);
+  else
+    return false;
+}
+
+/* Simplify a call to the strstr builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strstr (tree arglist, tree type)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      tree fn;
+      const char *p1, *p2;
+
+      p2 = c_getstr (s2);
+      if (p2 == NULL)
+	return 0;
+
+      p1 = c_getstr (s1);
+      if (p1 != NULL)
+	{
+	  const char *r = strstr (p1, p2);
+	  tree tem;
+
+	  if (r == NULL)
+	    return build_int_cst (TREE_TYPE (s1), 0);
+
+	  /* Return an offset into the constant string argument.  */
+	  tem = fold_build2 (PLUS_EXPR, TREE_TYPE (s1),
+			     s1, build_int_cst (TREE_TYPE (s1), r - p1));
+	  return fold_convert (type, tem);
+	}
+
+      /* The argument is const char *, and the result is char *, so we need
+	 a type conversion here to avoid a warning.  */
+      if (p2[0] == '\0')
+	return fold_convert (type, s1);
+
+      if (p2[1] != '\0')
+	return 0;
+
+      fn = implicit_built_in_decls[BUILT_IN_STRCHR];
+      if (!fn)
+	return 0;
+
+      /* New argument list transforming strstr(s1, s2) to
+	 strchr(s1, s2[0]).  */
+      arglist = build_tree_list (NULL_TREE,
+				 build_int_cst (NULL_TREE, p2[0]));
+      arglist = tree_cons (NULL_TREE, s1, arglist);
+      return build_function_call_expr (fn, arglist);
+    }
+}
+
+/* Simplify a call to the strchr builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strchr (tree arglist, tree type)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p1;
+
+      if (TREE_CODE (s2) != INTEGER_CST)
+	return 0;
+
+      p1 = c_getstr (s1);
+      if (p1 != NULL)
+	{
+	  char c;
+	  const char *r;
+	  tree tem;
+
+	  if (target_char_cast (s2, &c))
+	    return 0;
+
+	  r = strchr (p1, c);
+
+	  if (r == NULL)
+	    return build_int_cst (TREE_TYPE (s1), 0);
+
+	  /* Return an offset into the constant string argument.  */
+	  tem = fold_build2 (PLUS_EXPR, TREE_TYPE (s1),
+			     s1, build_int_cst (TREE_TYPE (s1), r - p1));
+	  return fold_convert (type, tem);
+	}
+      return 0;
+    }
+}
+
+/* Simplify a call to the strrchr builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strrchr (tree arglist, tree type)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      tree fn;
+      const char *p1;
+
+      if (TREE_CODE (s2) != INTEGER_CST)
+	return 0;
+
+      p1 = c_getstr (s1);
+      if (p1 != NULL)
+	{
+	  char c;
+	  const char *r;
+	  tree tem;
+
+	  if (target_char_cast (s2, &c))
+	    return 0;
+
+	  r = strrchr (p1, c);
+
+	  if (r == NULL)
+	    return build_int_cst (TREE_TYPE (s1), 0);
+
+	  /* Return an offset into the constant string argument.  */
+	  tem = fold_build2 (PLUS_EXPR, TREE_TYPE (s1),
+			     s1, build_int_cst (TREE_TYPE (s1), r - p1));
+	  return fold_convert (type, tem);
+	}
+
+      if (! integer_zerop (s2))
+	return 0;
+
+      fn = implicit_built_in_decls[BUILT_IN_STRCHR];
+      if (!fn)
+	return 0;
+
+      /* Transform strrchr(s1, '\0') to strchr(s1, '\0').  */
+      return build_function_call_expr (fn, arglist);
+    }
+}
+
+/* Simplify a call to the strpbrk builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strpbrk (tree arglist, tree type)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      tree fn;
+      const char *p1, *p2;
+
+      p2 = c_getstr (s2);
+      if (p2 == NULL)
+	return 0;
+
+      p1 = c_getstr (s1);
+      if (p1 != NULL)
+	{
+	  const char *r = strpbrk (p1, p2);
+	  tree tem;
+
+	  if (r == NULL)
+	    return build_int_cst (TREE_TYPE (s1), 0);
+
+	  /* Return an offset into the constant string argument.  */
+	  tem = fold_build2 (PLUS_EXPR, TREE_TYPE (s1),
+			     s1, build_int_cst (TREE_TYPE (s1), r - p1));
+	  return fold_convert (type, tem);
+	}
+
+      if (p2[0] == '\0')
+	/* strpbrk(x, "") == NULL.
+	   Evaluate and ignore s1 in case it had side-effects.  */
+	return omit_one_operand (TREE_TYPE (s1), integer_zero_node, s1);
+
+      if (p2[1] != '\0')
+	return 0;  /* Really call strpbrk.  */
+
+      fn = implicit_built_in_decls[BUILT_IN_STRCHR];
+      if (!fn)
+	return 0;
+
+      /* New argument list transforming strpbrk(s1, s2) to
+	 strchr(s1, s2[0]).  */
+      arglist = build_tree_list (NULL_TREE,
+				 build_int_cst (NULL_TREE, p2[0]));
+      arglist = tree_cons (NULL_TREE, s1, arglist);
+      return build_function_call_expr (fn, arglist);
+    }
+}
+
+/* Simplify a call to the strcat builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strcat (tree arglist)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dst = TREE_VALUE (arglist),
+	src = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p = c_getstr (src);
+
+      /* If the string length is zero, return the dst parameter.  */
+      if (p && *p == '\0')
+	return dst;
+
+      return 0;
+    }
+}
+
+/* Simplify a call to the strncat builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strncat (tree arglist)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dst = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      const char *p = c_getstr (src);
+
+      /* If the requested length is zero, or the src parameter string
+	 length is zero, return the dst parameter.  */
+      if (integer_zerop (len) || (p && *p == '\0'))
+        return omit_two_operands (TREE_TYPE (dst), dst, src, len);
+
+      /* If the requested len is greater than or equal to the string
+         length, call strcat.  */
+      if (TREE_CODE (len) == INTEGER_CST && p
+	  && compare_tree_int (len, strlen (p)) >= 0)
+	{
+	  tree newarglist
+	    = tree_cons (NULL_TREE, dst, build_tree_list (NULL_TREE, src));
+	  tree fn = implicit_built_in_decls[BUILT_IN_STRCAT];
+
+	  /* If the replacement _DECL isn't initialized, don't do the
+	     transformation.  */
+	  if (!fn)
+	    return 0;
+
+	  return build_function_call_expr (fn, newarglist);
+	}
+      return 0;
+    }
+}
+
+/* Simplify a call to the strspn builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strspn (tree arglist)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p1 = c_getstr (s1), *p2 = c_getstr (s2);
+
+      /* If both arguments are constants, evaluate at compile-time.  */
+      if (p1 && p2)
+	{
+	  const size_t r = strspn (p1, p2);
+	  return size_int (r);
+	}
+
+      /* If either argument is "", return 0.  */
+      if ((p1 && *p1 == '\0') || (p2 && *p2 == '\0'))
+	/* Evaluate and ignore both arguments in case either one has
+	   side-effects.  */
+	return omit_two_operands (integer_type_node, integer_zero_node,
+				  s1, s2);
+      return 0;
+    }
+}
+
+/* Simplify a call to the strcspn builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strcspn (tree arglist)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p1 = c_getstr (s1), *p2 = c_getstr (s2);
+
+      /* If both arguments are constants, evaluate at compile-time.  */
+      if (p1 && p2)
+	{
+	  const size_t r = strcspn (p1, p2);
+	  return size_int (r);
+	}
+
+      /* If the first argument is "", return 0.  */
+      if (p1 && *p1 == '\0')
+	{
+	  /* Evaluate and ignore argument s2 in case it has
+	     side-effects.  */
+	  return omit_one_operand (integer_type_node,
+				   integer_zero_node, s2);
+	}
+
+      /* If the second argument is "", return __builtin_strlen(s1).  */
+      if (p2 && *p2 == '\0')
+	{
+	  tree newarglist = build_tree_list (NULL_TREE, s1),
+	    fn = implicit_built_in_decls[BUILT_IN_STRLEN];
+
+	  /* If the replacement _DECL isn't initialized, don't do the
+	     transformation.  */
+	  if (!fn)
+	    return 0;
+
+	  return build_function_call_expr (fn, newarglist);
+	}
+      return 0;
+    }
+}
+
+/* Fold a call to the fputs builtin.  IGNORE is true if the value returned
+   by the builtin will be ignored.  UNLOCKED is true is true if this
+   actually a call to fputs_unlocked.  If LEN in non-NULL, it represents
+   the known length of the string.  Return NULL_TREE if no simplification
+   was possible.  */
+
+tree
+fold_builtin_fputs (tree arglist, bool ignore, bool unlocked, tree len)
+{
+  tree fn;
+  /* If we're using an unlocked function, assume the other unlocked
+     functions exist explicitly.  */
+  tree const fn_fputc = unlocked ? built_in_decls[BUILT_IN_FPUTC_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_FPUTC];
+  tree const fn_fwrite = unlocked ? built_in_decls[BUILT_IN_FWRITE_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_FWRITE];
+
+  /* If the return value is used, don't do the transformation.  */
+  if (!ignore)
+    return 0;
+
+  /* Verify the arguments in the original call.  */
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+
+  if (! len)
+    len = c_strlen (TREE_VALUE (arglist), 0);
+
+  /* Get the length of the string passed to fputs.  If the length
+     can't be determined, punt.  */
+  if (!len
+      || TREE_CODE (len) != INTEGER_CST)
+    return 0;
+
+  switch (compare_tree_int (len, 1))
+    {
+    case -1: /* length is 0, delete the call entirely .  */
+      return omit_one_operand (integer_type_node, integer_zero_node,
+			       TREE_VALUE (TREE_CHAIN (arglist)));
+
+    case 0: /* length is 1, call fputc.  */
+      {
+	const char *p = c_getstr (TREE_VALUE (arglist));
+
+	if (p != NULL)
+	  {
+	    /* New argument list transforming fputs(string, stream) to
+	       fputc(string[0], stream).  */
+	    arglist = build_tree_list (NULL_TREE,
+				       TREE_VALUE (TREE_CHAIN (arglist)));
+	    arglist = tree_cons (NULL_TREE,
+				 build_int_cst (NULL_TREE, p[0]),
+				 arglist);
+	    fn = fn_fputc;
+	    break;
+	  }
+      }
+      /* FALLTHROUGH */
+    case 1: /* length is greater than 1, call fwrite.  */
+      {
+	tree string_arg;
+
+	/* If optimizing for size keep fputs.  */
+	if (optimize_size)
+	  return 0;
+	string_arg = TREE_VALUE (arglist);
+	/* New argument list transforming fputs(string, stream) to
+	   fwrite(string, 1, len, stream).  */
+	arglist = build_tree_list (NULL_TREE,
+				   TREE_VALUE (TREE_CHAIN (arglist)));
+	arglist = tree_cons (NULL_TREE, len, arglist);
+	arglist = tree_cons (NULL_TREE, size_one_node, arglist);
+	arglist = tree_cons (NULL_TREE, string_arg, arglist);
+	fn = fn_fwrite;
+	break;
+      }
+    default:
+      gcc_unreachable ();
+    }
+
+  /* If the replacement _DECL isn't initialized, don't do the
+     transformation.  */
+  if (!fn)
+    return 0;
+
+  /* These optimizations are only performed when the result is ignored,
+     hence there's no need to cast the result to integer_type_node.  */
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold the new_arg's arguments (ARGLIST). Returns true if there was an error
+   produced.  False otherwise.  This is done so that we don't output the error
+   or warning twice or three times.  */
+bool
+fold_builtin_next_arg (tree arglist)
+{
+  tree fntype = TREE_TYPE (current_function_decl);
+
+  if (TYPE_ARG_TYPES (fntype) == 0
+      || (TREE_VALUE (tree_last (TYPE_ARG_TYPES (fntype)))
+	  == void_type_node))
+    {
+      error ("%<va_start%> used in function with fixed args");
+      return true;
+    }
+  else if (!arglist)
+    {
+      /* Evidently an out of date version of <stdarg.h>; can't validate
+	 va_start's second argument, but can still work as intended.  */
+      warning (0, "%<__builtin_next_arg%> called without an argument");
+      return true;
+    }
+  /* We use __builtin_va_start (ap, 0, 0) or __builtin_next_arg (0, 0)
+     when we checked the arguments and if needed issued a warning.  */
+  else if (!TREE_CHAIN (arglist)
+           || !integer_zerop (TREE_VALUE (arglist))
+           || !integer_zerop (TREE_VALUE (TREE_CHAIN (arglist)))
+           || TREE_CHAIN (TREE_CHAIN (arglist)))
+    {
+      tree last_parm = tree_last (DECL_ARGUMENTS (current_function_decl));
+      tree arg = TREE_VALUE (arglist);
+
+      if (TREE_CHAIN (arglist))
+        {
+          error ("%<va_start%> used with too many arguments");
+          return true;
+        }
+
+      /* Strip off all nops for the sake of the comparison.  This
+	 is not quite the same as STRIP_NOPS.  It does more.
+	 We must also strip off INDIRECT_EXPR for C++ reference
+	 parameters.  */
+      while (TREE_CODE (arg) == NOP_EXPR
+	     || TREE_CODE (arg) == CONVERT_EXPR
+	     || TREE_CODE (arg) == NON_LVALUE_EXPR
+	     || TREE_CODE (arg) == INDIRECT_REF)
+	arg = TREE_OPERAND (arg, 0);
+      if (arg != last_parm)
+        {
+	  /* FIXME: Sometimes with the tree optimizers we can get the
+	     not the last argument even though the user used the last
+	     argument.  We just warn and set the arg to be the last
+	     argument so that we will get wrong-code because of
+	     it.  */
+	  warning (0, "second parameter of %<va_start%> not last named argument");
+	}
+      /* We want to verify the second parameter just once before the tree
+         optimizers are run and then avoid keeping it in the tree,
+         as otherwise we could warn even for correct code like:
+         void foo (int i, ...)
+         { va_list ap; i++; va_start (ap, i); va_end (ap); }  */
+      TREE_VALUE (arglist) = integer_zero_node;
+      TREE_CHAIN (arglist) = build_tree_list (NULL, integer_zero_node);
+    }
+  return false;
+}
+
+
+/* Simplify a call to the sprintf builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.  If IGNORED is true, it means that
+   the caller does not use the returned value of the function.  */
+
+static tree
+fold_builtin_sprintf (tree arglist, int ignored)
+{
+  tree call, retval, dest, fmt;
+  const char *fmt_str = NULL;
+
+  /* Verify the required arguments in the original call.  We deal with two
+     types of sprintf() calls: 'sprintf (str, fmt)' and
+     'sprintf (dest, "%s", orig)'.  */
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE)
+      && !validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, POINTER_TYPE,
+			    VOID_TYPE))
+    return NULL_TREE;
+
+  /* Get the destination string and the format specifier.  */
+  dest = TREE_VALUE (arglist);
+  fmt = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return NULL_TREE;
+
+  call = NULL_TREE;
+  retval = NULL_TREE;
+
+  if (!init_target_chars())
+    return 0;
+
+  /* If the format doesn't contain % args or %%, use strcpy.  */
+  if (strchr (fmt_str, target_percent) == NULL)
+    {
+      tree fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+
+      if (!fn)
+	return NULL_TREE;
+
+      /* Convert sprintf (str, fmt) into strcpy (str, fmt) when
+	 'format' is known to contain no % formats.  */
+      arglist = build_tree_list (NULL_TREE, fmt);
+      arglist = tree_cons (NULL_TREE, dest, arglist);
+      call = build_function_call_expr (fn, arglist);
+      if (!ignored)
+	retval = build_int_cst (NULL_TREE, strlen (fmt_str));
+    }
+
+  /* If the format is "%s", use strcpy if the result isn't used.  */
+  else if (fmt_str && strcmp (fmt_str, target_percent_s) == 0)
+    {
+      tree fn, orig;
+      fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+
+      if (!fn)
+	return NULL_TREE;
+
+      /* Convert sprintf (str1, "%s", str2) into strcpy (str1, str2).  */
+      orig = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      arglist = build_tree_list (NULL_TREE, orig);
+      arglist = tree_cons (NULL_TREE, dest, arglist);
+      if (!ignored)
+	{
+	  retval = c_strlen (orig, 1);
+	  if (!retval || TREE_CODE (retval) != INTEGER_CST)
+	    return NULL_TREE;
+	}
+      call = build_function_call_expr (fn, arglist);
+    }
+
+  if (call && retval)
+    {
+      retval = convert
+	(TREE_TYPE (TREE_TYPE (implicit_built_in_decls[BUILT_IN_SPRINTF])),
+	 retval);
+      return build2 (COMPOUND_EXPR, TREE_TYPE (retval), call, retval);
+    }
+  else
+    return call;
+}
+
+/* Expand a call to __builtin_object_size.  */
+
+rtx
+expand_builtin_object_size (tree exp)
+{
+  tree ost;
+  int object_size_type;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  location_t locus = EXPR_LOCATION (exp);
+
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      error ("%Hfirst argument of %D must be a pointer, second integer constant",
+	     &locus, fndecl);
+      expand_builtin_trap ();
+      return const0_rtx;
+    }
+
+  ost = TREE_VALUE (TREE_CHAIN (arglist));
+  STRIP_NOPS (ost);
+
+  if (TREE_CODE (ost) != INTEGER_CST
+      || tree_int_cst_sgn (ost) < 0
+      || compare_tree_int (ost, 3) > 0)
+    {
+      error ("%Hlast argument of %D is not integer constant between 0 and 3",
+	     &locus, fndecl);
+      expand_builtin_trap ();
+      return const0_rtx;
+    }
+
+  object_size_type = tree_low_cst (ost, 0);
+
+  return object_size_type < 2 ? constm1_rtx : const0_rtx;
+}
+
+/* Expand EXP, a call to the __mem{cpy,pcpy,move,set}_chk builtin.
+   FCODE is the BUILT_IN_* to use.
+   Return 0 if we failed; the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient (and in
+   mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_memory_chk (tree exp, rtx target, enum machine_mode mode,
+			   enum built_in_function fcode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree dest, src, len, size;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE,
+			 fcode == BUILT_IN_MEMSET_CHK
+			 ? INTEGER_TYPE : POINTER_TYPE,
+			 INTEGER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (host_integerp (len, 1) || integer_all_onesp (size))
+    {
+      tree fn;
+
+      if (! integer_all_onesp (size) && tree_int_cst_lt (size, len))
+	{
+	  location_t locus = EXPR_LOCATION (exp);
+	  warning (0, "%Hcall to %D will always overflow destination buffer",
+		   &locus, get_callee_fndecl (exp));
+	  return 0;
+	}
+
+      arglist = build_tree_list (NULL_TREE, len);
+      arglist = tree_cons (NULL_TREE, src, arglist);
+      arglist = tree_cons (NULL_TREE, dest, arglist);
+
+      fn = NULL_TREE;
+      /* If __builtin_mem{cpy,pcpy,move,set}_chk is used, assume
+	 mem{cpy,pcpy,move,set} is available.  */
+      switch (fcode)
+	{
+	case BUILT_IN_MEMCPY_CHK:
+	  fn = built_in_decls[BUILT_IN_MEMCPY];
+	  break;
+	case BUILT_IN_MEMPCPY_CHK:
+	  fn = built_in_decls[BUILT_IN_MEMPCPY];
+	  break;
+	case BUILT_IN_MEMMOVE_CHK:
+	  fn = built_in_decls[BUILT_IN_MEMMOVE];
+	  break;
+	case BUILT_IN_MEMSET_CHK:
+	  fn = built_in_decls[BUILT_IN_MEMSET];
+	  break;
+	default:
+	  break;
+	}
+
+      if (! fn)
+	return 0;
+
+      fn = build_function_call_expr (fn, arglist);
+      if (TREE_CODE (fn) == CALL_EXPR)
+	CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+      return expand_expr (fn, target, mode, EXPAND_NORMAL);
+    }
+  else if (fcode == BUILT_IN_MEMSET_CHK)
+    return 0;
+  else
+    {
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+
+      /* If DEST is not a pointer type, call the normal function.  */
+      if (dest_align == 0)
+	return 0;
+
+      /* If SRC and DEST are the same (and not volatile), do nothing.  */
+      if (operand_equal_p (src, dest, 0))
+	{
+	  tree expr;
+
+	  if (fcode != BUILT_IN_MEMPCPY_CHK)
+	    {
+	      /* Evaluate and ignore LEN in case it has side-effects.  */
+	      expand_expr (len, const0_rtx, VOIDmode, EXPAND_NORMAL);
+	      return expand_expr (dest, target, mode, EXPAND_NORMAL);
+	    }
+
+	  len = fold_convert (TREE_TYPE (dest), len);
+	  expr = fold_build2 (PLUS_EXPR, TREE_TYPE (dest), dest, len);
+	  return expand_expr (expr, target, mode, EXPAND_NORMAL);
+	}
+
+      /* __memmove_chk special case.  */
+      if (fcode == BUILT_IN_MEMMOVE_CHK)
+	{
+	  unsigned int src_align
+	    = get_pointer_alignment (src, BIGGEST_ALIGNMENT);
+
+	  if (src_align == 0)
+	    return 0;
+
+	  /* If src is categorized for a readonly section we can use
+	     normal __memcpy_chk.  */
+	  if (readonly_data_expr (src))
+	    {
+	      tree fn = built_in_decls[BUILT_IN_MEMCPY_CHK];
+	      if (!fn)
+		return 0;
+	      fn = build_function_call_expr (fn, arglist);
+	      if (TREE_CODE (fn) == CALL_EXPR)
+		CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+	      return expand_expr (fn, target, mode, EXPAND_NORMAL);
+	    }
+	}
+      return 0;
+    }
+}
+
+/* Emit warning if a buffer overflow is detected at compile time.  */
+
+static void
+maybe_emit_chk_warning (tree exp, enum built_in_function fcode)
+{
+  int arg_mask, is_strlen = 0;
+  tree arglist = TREE_OPERAND (exp, 1), a;
+  tree len, size;
+  location_t locus;
+
+  switch (fcode)
+    {
+    case BUILT_IN_STRCPY_CHK:
+    case BUILT_IN_STPCPY_CHK:
+    /* For __strcat_chk the warning will be emitted only if overflowing
+       by at least strlen (dest) + 1 bytes.  */
+    case BUILT_IN_STRCAT_CHK:
+      arg_mask = 6;
+      is_strlen = 1;
+      break;
+    case BUILT_IN_STRNCPY_CHK:
+      arg_mask = 12;
+      break;
+    case BUILT_IN_SNPRINTF_CHK:
+    case BUILT_IN_VSNPRINTF_CHK:
+      arg_mask = 10;
+      break;
+    default:
+      gcc_unreachable ();
+    }
+
+  len = NULL_TREE;
+  size = NULL_TREE;
+  for (a = arglist; a && arg_mask; a = TREE_CHAIN (a), arg_mask >>= 1)
+    if (arg_mask & 1)
+      {
+	if (len)
+	  size = a;
+	else
+	  len = a;
+      }
+
+  if (!len || !size)
+    return;
+
+  len = TREE_VALUE (len);
+  size = TREE_VALUE (size);
+
+  if (! host_integerp (size, 1) || integer_all_onesp (size))
+    return;
+
+  if (is_strlen)
+    {
+      len = c_strlen (len, 1);
+      if (! len || ! host_integerp (len, 1) || tree_int_cst_lt (len, size))
+	return;
+    }
+  else if (! host_integerp (len, 1) || ! tree_int_cst_lt (size, len))
+    return;
+
+  locus = EXPR_LOCATION (exp);
+  warning (0, "%Hcall to %D will always overflow destination buffer",
+	   &locus, get_callee_fndecl (exp));
+}
+
+/* Emit warning if a buffer overflow is detected at compile time
+   in __sprintf_chk/__vsprintf_chk calls.  */
+
+static void
+maybe_emit_sprintf_chk_warning (tree exp, enum built_in_function fcode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree dest, size, len, fmt, flag;
+  const char *fmt_str;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return;
+  dest = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return;
+  flag = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return;
+  size = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return;
+  fmt = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+
+  if (! host_integerp (size, 1) || integer_all_onesp (size))
+    return;
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return;
+
+  if (!init_target_chars())
+    return;
+
+  /* If the format doesn't contain % args or %%, we know its size.  */
+  if (strchr (fmt_str, target_percent) == 0)
+    len = build_int_cstu (size_type_node, strlen (fmt_str));
+  /* If the format is "%s" and first ... argument is a string literal,
+     we know it too.  */
+  else if (fcode == BUILT_IN_SPRINTF_CHK && strcmp (fmt_str, target_percent_s) == 0)
+    {
+      tree arg;
+
+      if (! arglist)
+	return;
+      arg = TREE_VALUE (arglist);
+      if (! POINTER_TYPE_P (TREE_TYPE (arg)))
+	return;
+
+      len = c_strlen (arg, 1);
+      if (!len || ! host_integerp (len, 1))
+	return;
+    }
+  else
+    return;
+
+  if (! tree_int_cst_lt (len, size))
+    {
+      location_t locus = EXPR_LOCATION (exp);
+      warning (0, "%Hcall to %D will always overflow destination buffer",
+	       &locus, get_callee_fndecl (exp));
+    }
+}
+
+/* Fold a call to __builtin_object_size, if possible.  */
+
+tree
+fold_builtin_object_size (tree arglist)
+{
+  tree ptr, ost, ret = 0;
+  int object_size_type;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  ptr = TREE_VALUE (arglist);
+  ost = TREE_VALUE (TREE_CHAIN (arglist));
+  STRIP_NOPS (ost);
+
+  if (TREE_CODE (ost) != INTEGER_CST
+      || tree_int_cst_sgn (ost) < 0
+      || compare_tree_int (ost, 3) > 0)
+    return 0;
+
+  object_size_type = tree_low_cst (ost, 0);
+
+  /* __builtin_object_size doesn't evaluate side-effects in its arguments;
+     if there are any side-effects, it returns (size_t) -1 for types 0 and 1
+     and (size_t) 0 for types 2 and 3.  */
+  if (TREE_SIDE_EFFECTS (ptr))
+    return fold_convert (size_type_node,
+			 object_size_type < 2
+			 ? integer_minus_one_node : integer_zero_node);
+
+  if (TREE_CODE (ptr) == ADDR_EXPR)
+    ret = build_int_cstu (size_type_node,
+			compute_builtin_object_size (ptr, object_size_type));
+
+  else if (TREE_CODE (ptr) == SSA_NAME)
+    {
+      unsigned HOST_WIDE_INT bytes;
+
+      /* If object size is not known yet, delay folding until
+       later.  Maybe subsequent passes will help determining
+       it.  */
+      bytes = compute_builtin_object_size (ptr, object_size_type);
+      if (bytes != (unsigned HOST_WIDE_INT) (object_size_type < 2
+					     ? -1 : 0))
+	ret = build_int_cstu (size_type_node, bytes);
+    }
+
+  if (ret)
+    {
+      ret = force_fit_type (ret, -1, false, false);
+      if (TREE_CONSTANT_OVERFLOW (ret))
+	ret = 0;
+    }
+
+  return ret;
+}
+
+/* Fold a call to the __mem{cpy,pcpy,move,set}_chk builtin.
+   IGNORE is true, if return value can be ignored.  FCODE is the BUILT_IN_*
+   code of the builtin.  If MAXLEN is not NULL, it is maximum length
+   passed as third argument.  */
+
+tree
+fold_builtin_memory_chk (tree fndecl, tree arglist, tree maxlen, bool ignore,
+			 enum built_in_function fcode)
+{
+  tree dest, src, len, size, fn;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE,
+			 fcode == BUILT_IN_MEMSET_CHK
+			 ? INTEGER_TYPE : POINTER_TYPE,
+			 INTEGER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  /* Actually val for __memset_chk, but it doesn't matter.  */
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));
+
+  /* If SRC and DEST are the same (and not volatile), return DEST
+     (resp. DEST+LEN for __mempcpy_chk).  */
+  if (fcode != BUILT_IN_MEMSET_CHK && operand_equal_p (src, dest, 0))
+    {
+      if (fcode != BUILT_IN_MEMPCPY_CHK)
+	return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, len);
+      else
+	{
+	  tree temp = fold_convert (TREE_TYPE (dest), len);
+	  temp = fold_build2 (PLUS_EXPR, TREE_TYPE (dest), dest, temp);
+	  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), temp);
+	}
+    }
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      if (! host_integerp (len, 1))
+	{
+	  /* If LEN is not constant, try MAXLEN too.
+	     For MAXLEN only allow optimizing into non-_ocs function
+	     if SIZE is >= MAXLEN, never convert to __ocs_fail ().  */
+	  if (maxlen == NULL_TREE || ! host_integerp (maxlen, 1))
+	    {
+	      if (fcode == BUILT_IN_MEMPCPY_CHK && ignore)
+		{
+		  /* (void) __mempcpy_chk () can be optimized into
+		     (void) __memcpy_chk ().  */
+		  fn = built_in_decls[BUILT_IN_MEMCPY_CHK];
+		  if (!fn)
+		    return 0;
+
+		  return build_function_call_expr (fn, arglist);
+		}
+	      return 0;
+	    }
+	}
+      else
+	maxlen = len;
+
+      if (tree_int_cst_lt (size, maxlen))
+	return 0;
+    }
+
+  arglist = build_tree_list (NULL_TREE, len);
+  arglist = tree_cons (NULL_TREE, src, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  fn = NULL_TREE;
+  /* If __builtin_mem{cpy,pcpy,move,set}_chk is used, assume
+     mem{cpy,pcpy,move,set} is available.  */
+  switch (fcode)
+    {
+    case BUILT_IN_MEMCPY_CHK:
+      fn = built_in_decls[BUILT_IN_MEMCPY];
+      break;
+    case BUILT_IN_MEMPCPY_CHK:
+      fn = built_in_decls[BUILT_IN_MEMPCPY];
+      break;
+    case BUILT_IN_MEMMOVE_CHK:
+      fn = built_in_decls[BUILT_IN_MEMMOVE];
+      break;
+    case BUILT_IN_MEMSET_CHK:
+      fn = built_in_decls[BUILT_IN_MEMSET];
+      break;
+    default:
+      break;
+    }
+
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the __st[rp]cpy_chk builtin.
+   IGNORE is true, if return value can be ignored.  FCODE is the BUILT_IN_*
+   code of the builtin.  If MAXLEN is not NULL, it is maximum length of
+   strings passed as second argument.  */
+
+tree
+fold_builtin_stxcpy_chk (tree fndecl, tree arglist, tree maxlen, bool ignore,
+			 enum built_in_function fcode)
+{
+  tree dest, src, size, len, fn;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE,
+			 VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If SRC and DEST are the same (and not volatile), return DEST.  */
+  if (fcode == BUILT_IN_STRCPY_CHK && operand_equal_p (src, dest, 0))
+    return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), dest);
+ 
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      len = c_strlen (src, 1);
+      if (! len || ! host_integerp (len, 1))
+	{
+	  /* If LEN is not constant, try MAXLEN too.
+	     For MAXLEN only allow optimizing into non-_ocs function
+	     if SIZE is >= MAXLEN, never convert to __ocs_fail ().  */
+	  if (maxlen == NULL_TREE || ! host_integerp (maxlen, 1))
+	    {
+	      if (fcode == BUILT_IN_STPCPY_CHK)
+		{
+		  if (! ignore)
+		    return 0;
+
+		  /* If return value of __stpcpy_chk is ignored,
+		     optimize into __strcpy_chk.  */
+		  fn = built_in_decls[BUILT_IN_STRCPY_CHK];
+		  if (!fn)
+		    return 0;
+
+		  return build_function_call_expr (fn, arglist);
+		}
+
+	      if (! len || TREE_SIDE_EFFECTS (len))
+		return 0;
+
+	      /* If c_strlen returned something, but not a constant,
+		 transform __strcpy_chk into __memcpy_chk.  */
+	      fn = built_in_decls[BUILT_IN_MEMCPY_CHK];
+	      if (!fn)
+		return 0;
+
+	      len = size_binop (PLUS_EXPR, len, ssize_int (1));
+	      arglist = build_tree_list (NULL_TREE, size);
+	      arglist = tree_cons (NULL_TREE, len, arglist);
+	      arglist = tree_cons (NULL_TREE, src, arglist);
+	      arglist = tree_cons (NULL_TREE, dest, arglist);
+	      return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)),
+				   build_function_call_expr (fn, arglist));
+	    }
+	}
+      else
+	maxlen = len;
+
+      if (! tree_int_cst_lt (maxlen, size))
+	return 0;
+    }
+
+  arglist = build_tree_list (NULL_TREE, src);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_st{r,p}cpy_chk is used, assume st{r,p}cpy is available.  */
+  fn = built_in_decls[fcode == BUILT_IN_STPCPY_CHK
+		      ? BUILT_IN_STPCPY : BUILT_IN_STRCPY];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the __strncpy_chk builtin.
+   If MAXLEN is not NULL, it is maximum length passed as third argument.  */
+
+tree
+fold_builtin_strncpy_chk (tree arglist, tree maxlen)
+{
+  tree dest, src, size, len, fn;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE,
+			 INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      if (! host_integerp (len, 1))
+	{
+	  /* If LEN is not constant, try MAXLEN too.
+	     For MAXLEN only allow optimizing into non-_ocs function
+	     if SIZE is >= MAXLEN, never convert to __ocs_fail ().  */
+	  if (maxlen == NULL_TREE || ! host_integerp (maxlen, 1))
+	    return 0;
+	}
+      else
+	maxlen = len;
+
+      if (tree_int_cst_lt (size, maxlen))
+	return 0;
+    }
+
+  arglist = build_tree_list (NULL_TREE, len);
+  arglist = tree_cons (NULL_TREE, src, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_strncpy_chk is used, assume strncpy is available.  */
+  fn = built_in_decls[BUILT_IN_STRNCPY];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the __strcat_chk builtin FNDECL with ARGLIST.  */
+
+static tree
+fold_builtin_strcat_chk (tree fndecl, tree arglist)
+{
+  tree dest, src, size, fn;
+  const char *p;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE,
+			 VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  p = c_getstr (src);
+  /* If the SRC parameter is "", return DEST.  */
+  if (p && *p == '\0')
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, src);
+
+  if (! host_integerp (size, 1) || ! integer_all_onesp (size))
+    return 0;
+
+  arglist = build_tree_list (NULL_TREE, src);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_strcat_chk is used, assume strcat is available.  */
+  fn = built_in_decls[BUILT_IN_STRCAT];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the __strncat_chk builtin EXP.  */
+
+static tree
+fold_builtin_strncat_chk (tree fndecl, tree arglist)
+{
+  tree dest, src, size, len, fn;
+  const char *p;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE,
+			 INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));
+
+  p = c_getstr (src);
+  /* If the SRC parameter is "" or if LEN is 0, return DEST.  */
+  if (p && *p == '\0')
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, len);
+  else if (integer_zerop (len))
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, src);
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      tree src_len = c_strlen (src, 1);
+      if (src_len
+	  && host_integerp (src_len, 1)
+	  && host_integerp (len, 1)
+	  && ! tree_int_cst_lt (len, src_len))
+	{
+	  /* If LEN >= strlen (SRC), optimize into __strcat_chk.  */
+	  fn = built_in_decls[BUILT_IN_STRCAT_CHK];
+	  if (!fn)
+	    return 0;
+
+	  arglist = build_tree_list (NULL_TREE, size);
+	  arglist = tree_cons (NULL_TREE, src, arglist);
+	  arglist = tree_cons (NULL_TREE, dest, arglist);
+	  return build_function_call_expr (fn, arglist);
+	}
+      return 0;
+    }
+
+  arglist = build_tree_list (NULL_TREE, len);
+  arglist = tree_cons (NULL_TREE, src, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_strncat_chk is used, assume strncat is available.  */
+  fn = built_in_decls[BUILT_IN_STRNCAT];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to __{,v}sprintf_chk with argument list ARGLIST.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   inline.  FCODE is either BUILT_IN_SPRINTF_CHK or BUILT_IN_VSPRINTF_CHK.  */
+
+static tree
+fold_builtin_sprintf_chk (tree arglist, enum built_in_function fcode)
+{
+  tree dest, size, len, fn, fmt, flag;
+  const char *fmt_str;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  dest = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (dest)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  flag = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (flag)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  size = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (size)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  len = NULL_TREE;
+
+  if (!init_target_chars())
+    return 0;
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str != NULL)
+    {
+      /* If the format doesn't contain % args or %%, we know the size.  */
+      if (strchr (fmt_str, target_percent) == 0)
+	{
+	  if (fcode != BUILT_IN_SPRINTF_CHK || arglist == NULL_TREE)
+	    len = build_int_cstu (size_type_node, strlen (fmt_str));
+	}
+      /* If the format is "%s" and first ... argument is a string literal,
+	 we know the size too.  */
+      else if (fcode == BUILT_IN_SPRINTF_CHK && strcmp (fmt_str, target_percent_s) == 0)
+	{
+	  tree arg;
+
+	  if (arglist && !TREE_CHAIN (arglist))
+	    {
+	      arg = TREE_VALUE (arglist);
+	      if (POINTER_TYPE_P (TREE_TYPE (arg)))
+		{
+		  len = c_strlen (arg, 1);
+		  if (! len || ! host_integerp (len, 1))
+		    len = NULL_TREE;
+		}
+	    }
+	}
+    }
+
+  if (! integer_all_onesp (size))
+    {
+      if (! len || ! tree_int_cst_lt (len, size))
+	return 0;
+    }
+
+  /* Only convert __{,v}sprintf_chk to {,v}sprintf if flag is 0
+     or if format doesn't contain % chars or is "%s".  */
+  if (! integer_zerop (flag))
+    {
+      if (fmt_str == NULL)
+	return 0;
+      if (strchr (fmt_str, target_percent) != NULL && strcmp (fmt_str, target_percent_s))
+	return 0;
+    }
+
+  arglist = tree_cons (NULL_TREE, fmt, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_{,v}sprintf_chk is used, assume {,v}sprintf is available.  */
+  fn = built_in_decls[fcode == BUILT_IN_VSPRINTF_CHK
+		      ? BUILT_IN_VSPRINTF : BUILT_IN_SPRINTF];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to {,v}snprintf with argument list ARGLIST.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   inline.  FCODE is either BUILT_IN_SNPRINTF_CHK or
+   BUILT_IN_VSNPRINTF_CHK.  If MAXLEN is not NULL, it is maximum length
+   passed as second argument.  */
+
+tree
+fold_builtin_snprintf_chk (tree arglist, tree maxlen,
+			   enum built_in_function fcode)
+{
+  tree dest, size, len, fn, fmt, flag;
+  const char *fmt_str;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  dest = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (dest)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  len = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (len)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  flag = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (len)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  size = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (size)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      if (! host_integerp (len, 1))
+	{
+	  /* If LEN is not constant, try MAXLEN too.
+	     For MAXLEN only allow optimizing into non-_ocs function
+	     if SIZE is >= MAXLEN, never convert to __ocs_fail ().  */
+	  if (maxlen == NULL_TREE || ! host_integerp (maxlen, 1))
+	    return 0;
+	}
+      else
+	maxlen = len;
+
+      if (tree_int_cst_lt (size, maxlen))
+	return 0;
+    }
+
+  if (!init_target_chars())
+    return 0;
+
+  /* Only convert __{,v}snprintf_chk to {,v}snprintf if flag is 0
+     or if format doesn't contain % chars or is "%s".  */
+  if (! integer_zerop (flag))
+    {
+      fmt_str = c_getstr (fmt);
+      if (fmt_str == NULL)
+	return 0;
+      if (strchr (fmt_str, target_percent) != NULL && strcmp (fmt_str, target_percent_s))
+	return 0;
+    }
+
+  arglist = tree_cons (NULL_TREE, fmt, arglist);
+  arglist = tree_cons (NULL_TREE, len, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_{,v}snprintf_chk is used, assume {,v}snprintf is
+     available.  */
+  fn = built_in_decls[fcode == BUILT_IN_VSNPRINTF_CHK
+		      ? BUILT_IN_VSNPRINTF : BUILT_IN_SNPRINTF];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the {,v}printf{,_unlocked} and __{,v}printf_chk builtins.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.  FCODE is the BUILT_IN_*
+   code of the function to be simplified.  */
+
+static tree
+fold_builtin_printf (tree fndecl, tree arglist, bool ignore,
+		     enum built_in_function fcode)
+{
+  tree fmt, fn = NULL_TREE, fn_putchar, fn_puts, arg, call;
+  const char *fmt_str = NULL;
+
+  /* If the return value is used, don't do the transformation.  */
+  if (! ignore)
+    return 0;
+
+  /* Verify the required arguments in the original call.  */
+  if (fcode == BUILT_IN_PRINTF_CHK || fcode == BUILT_IN_VPRINTF_CHK)
+    {
+      tree flag;
+
+      if (! arglist)
+	return 0;
+      flag = TREE_VALUE (arglist);
+      if (TREE_CODE (TREE_TYPE (flag)) != INTEGER_TYPE
+	  || TREE_SIDE_EFFECTS (flag))
+	return 0;
+      arglist = TREE_CHAIN (arglist);
+    }
+
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return NULL_TREE;
+
+  if (fcode == BUILT_IN_PRINTF_UNLOCKED)
+    {
+      /* If we're using an unlocked function, assume the other
+	 unlocked functions exist explicitly.  */
+      fn_putchar = built_in_decls[BUILT_IN_PUTCHAR_UNLOCKED];
+      fn_puts = built_in_decls[BUILT_IN_PUTS_UNLOCKED];
+    }
+  else
+    {
+      fn_putchar = implicit_built_in_decls[BUILT_IN_PUTCHAR];
+      fn_puts = implicit_built_in_decls[BUILT_IN_PUTS];
+    }
+
+  if (!init_target_chars())
+    return 0;
+  
+  if (strcmp (fmt_str, target_percent_s) == 0 || strchr (fmt_str, target_percent) == NULL)
+    {
+      const char *str;
+
+      if (strcmp (fmt_str, target_percent_s) == 0)
+	{
+	  if (fcode == BUILT_IN_VPRINTF || fcode == BUILT_IN_VPRINTF_CHK)
+	    return 0;
+
+	  if (! arglist
+	      || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	      || TREE_CHAIN (arglist))
+	    return 0;
+
+	  str = c_getstr (TREE_VALUE (arglist));
+	  if (str == NULL)
+	    return 0;
+	}
+      else
+	{
+	  /* The format specifier doesn't contain any '%' characters.  */
+	  if (fcode != BUILT_IN_VPRINTF && fcode != BUILT_IN_VPRINTF_CHK
+	      && arglist)
+	    return 0;
+	  str = fmt_str;
+	}
+
+      /* If the string was "", printf does nothing.  */
+      if (str[0] == '\0')
+	return build_int_cst (TREE_TYPE (TREE_TYPE (fndecl)), 0);
+
+      /* If the string has length of 1, call putchar.  */
+      if (str[1] == '\0')
+	{
+	  /* Given printf("c"), (where c is any one character,)
+	     convert "c"[0] to an int and pass that to the replacement
+	     function.  */
+	  arg = build_int_cst (NULL_TREE, str[0]);
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  fn = fn_putchar;
+	}
+      else
+	{
+	  /* If the string was "string\n", call puts("string").  */
+	  size_t len = strlen (str);
+	  if ((unsigned char)str[len - 1] == target_newline)
+	    {
+	      /* Create a NUL-terminated string that's one char shorter
+		 than the original, stripping off the trailing '\n'.  */
+	      char *newstr = alloca (len);
+	      memcpy (newstr, str, len - 1);
+	      newstr[len - 1] = 0;
+
+	      arg = build_string_literal (len, newstr);
+	      arglist = build_tree_list (NULL_TREE, arg);
+	      fn = fn_puts;
+	    }
+	  else
+	    /* We'd like to arrange to call fputs(string,stdout) here,
+	       but we need stdout and don't have a way to get it yet.  */
+	    return 0;
+	}
+    }
+
+  /* The other optimizations can be done only on the non-va_list variants.  */
+  else if (fcode == BUILT_IN_VPRINTF || fcode == BUILT_IN_VPRINTF_CHK)
+    return 0;
+
+  /* If the format specifier was "%s\n", call __builtin_puts(arg).  */
+  else if (strcmp (fmt_str, target_percent_s_newline) == 0)
+    {
+      if (! arglist
+	  || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	  || TREE_CHAIN (arglist))
+	return 0;
+      fn = fn_puts;
+    }
+
+  /* If the format specifier was "%c", call __builtin_putchar(arg).  */
+  else if (strcmp (fmt_str, target_percent_c) == 0)
+    {
+      if (! arglist
+	  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != INTEGER_TYPE
+	  || TREE_CHAIN (arglist))
+	return 0;
+      fn = fn_putchar;
+    }
+
+  if (!fn)
+    return 0;
+
+  call = build_function_call_expr (fn, arglist);
+  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), call);
+}
+
+/* Fold a call to the {,v}fprintf{,_unlocked} and __{,v}printf_chk builtins.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.  FCODE is the BUILT_IN_*
+   code of the function to be simplified.  */
+
+static tree
+fold_builtin_fprintf (tree fndecl, tree arglist, bool ignore,
+		      enum built_in_function fcode)
+{
+  tree fp, fmt, fn = NULL_TREE, fn_fputc, fn_fputs, arg, call;
+  const char *fmt_str = NULL;
+
+  /* If the return value is used, don't do the transformation.  */
+  if (! ignore)
+    return 0;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  fp = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fp)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  if (fcode == BUILT_IN_FPRINTF_CHK || fcode == BUILT_IN_VFPRINTF_CHK)
+    {
+      tree flag;
+
+      if (! arglist)
+	return 0;
+      flag = TREE_VALUE (arglist);
+      if (TREE_CODE (TREE_TYPE (flag)) != INTEGER_TYPE
+	  || TREE_SIDE_EFFECTS (flag))
+	return 0;
+      arglist = TREE_CHAIN (arglist);
+    }
+
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return NULL_TREE;
+
+  if (fcode == BUILT_IN_FPRINTF_UNLOCKED)
+    {
+      /* If we're using an unlocked function, assume the other
+	 unlocked functions exist explicitly.  */
+      fn_fputc = built_in_decls[BUILT_IN_FPUTC_UNLOCKED];
+      fn_fputs = built_in_decls[BUILT_IN_FPUTS_UNLOCKED];
+    }
+  else
+    {
+      fn_fputc = implicit_built_in_decls[BUILT_IN_FPUTC];
+      fn_fputs = implicit_built_in_decls[BUILT_IN_FPUTS];
+    }
+
+  if (!init_target_chars())
+    return 0;
+  
+  /* If the format doesn't contain % args or %%, use strcpy.  */
+  if (strchr (fmt_str, target_percent) == NULL)
+    {
+      if (fcode != BUILT_IN_VFPRINTF && fcode != BUILT_IN_VFPRINTF_CHK
+	  && arglist)
+	return 0;
+
+      /* If the format specifier was "", fprintf does nothing.  */
+      if (fmt_str[0] == '\0')
+	{
+	  /* If FP has side-effects, just wait until gimplification is
+	     done.  */
+	  if (TREE_SIDE_EFFECTS (fp))
+	    return 0;
+
+	  return build_int_cst (TREE_TYPE (TREE_TYPE (fndecl)), 0);
+	}
+
+      /* When "string" doesn't contain %, replace all cases of
+	 fprintf (fp, string) with fputs (string, fp).  The fputs
+	 builtin will take care of special cases like length == 1.  */
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, fmt, arglist);
+      fn = fn_fputs;
+    }
+
+  /* The other optimizations can be done only on the non-va_list variants.  */
+  else if (fcode == BUILT_IN_VFPRINTF || fcode == BUILT_IN_VFPRINTF_CHK)
+    return 0;
+
+  /* If the format specifier was "%s", call __builtin_fputs (arg, fp).  */
+  else if (strcmp (fmt_str, target_percent_s) == 0)
+    {
+      if (! arglist
+	  || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	  || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, arg, arglist);
+      fn = fn_fputs;
+    }
+
+  /* If the format specifier was "%c", call __builtin_fputc (arg, fp).  */
+  else if (strcmp (fmt_str, target_percent_c) == 0)
+    {
+      if (! arglist
+	  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != INTEGER_TYPE
+	  || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, arg, arglist);
+      fn = fn_fputc;
+    }
+
+  if (!fn)
+    return 0;
+
+  call = build_function_call_expr (fn, arglist);
+  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), call);
+}
+
+/* Initialize format string characters in the target charset.  */
+
+static bool
+init_target_chars (void)
+{
+  static bool init;
+  if (!init)
+    {
+      target_newline = lang_hooks.to_target_charset ('\n');
+      target_percent = lang_hooks.to_target_charset ('%');
+      target_c = lang_hooks.to_target_charset ('c');
+      target_s = lang_hooks.to_target_charset ('s');
+      if (target_newline == 0 || target_percent == 0 || target_c == 0
+	  || target_s == 0)
+	return false;
+
+      target_percent_c[0] = target_percent;
+      target_percent_c[1] = target_c;
+      target_percent_c[2] = '\0';
+
+      target_percent_s[0] = target_percent;
+      target_percent_s[1] = target_s;
+      target_percent_s[2] = '\0';
+
+      target_percent_s_newline[0] = target_percent;
+      target_percent_s_newline[1] = target_s;
+      target_percent_s_newline[2] = target_newline;
+      target_percent_s_newline[3] = '\0';
+      
+      init = true;
+    }
+  return true;
+}
diff -Naur gcc-4.1-20051216.orig/gcc/builtins.c.rej gcc-4.1-20051216-src/gcc/builtins.c.rej
--- gcc-4.1-20051216.orig/gcc/builtins.c.rej	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/builtins.c.rej	2005-12-18 22:24:28.000000000 +0100
@@ -0,0 +1,249 @@
+***************
+*** 91,114 ****
+  static void expand_builtin_return (rtx);
+  static enum type_class type_to_class (tree);
+  static rtx expand_builtin_classify_type (tree);
+  static void expand_errno_check (tree, rtx);
+  static rtx expand_builtin_mathfn (tree, rtx, rtx);
+  static rtx expand_builtin_mathfn_2 (tree, rtx, rtx);
+  static rtx expand_builtin_mathfn_3 (tree, rtx, rtx);
+  static rtx expand_builtin_args_info (tree);
+  static rtx expand_builtin_next_arg (void);
+  static rtx expand_builtin_va_start (tree);
+  static rtx expand_builtin_va_end (tree);
+  static rtx expand_builtin_va_copy (tree);
+  static rtx expand_builtin_memcmp (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strcmp (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strncmp (tree, rtx, enum machine_mode);
+  static rtx builtin_memcpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_strcat (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strncat (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strspn (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strcspn (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_memcpy (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_mempcpy (tree, tree, rtx, enum machine_mode, int);
+  static rtx expand_builtin_memmove (tree, tree, rtx, enum machine_mode, tree);
+  static rtx expand_builtin_bcopy (tree);
+--- 94,124 ----
+  static void expand_builtin_return (rtx);
+  static enum type_class type_to_class (tree);
+  static rtx expand_builtin_classify_type (tree);
++ #if 0
+  static void expand_errno_check (tree, rtx);
+  static rtx expand_builtin_mathfn (tree, rtx, rtx);
+  static rtx expand_builtin_mathfn_2 (tree, rtx, rtx);
+  static rtx expand_builtin_mathfn_3 (tree, rtx, rtx);
++ #endif /* 0 */
+  static rtx expand_builtin_args_info (tree);
+  static rtx expand_builtin_next_arg (void);
+  static rtx expand_builtin_va_start (tree);
+  static rtx expand_builtin_va_end (tree);
+  static rtx expand_builtin_va_copy (tree);
++ #if 0
+  static rtx expand_builtin_memcmp (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strcmp (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strncmp (tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static rtx builtin_memcpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
++ #if 0
+  static rtx expand_builtin_strcat (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strncat (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strspn (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strcspn (tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static rtx expand_builtin_memcpy (tree, rtx, enum machine_mode);
++ #if 0
+  static rtx expand_builtin_mempcpy (tree, tree, rtx, enum machine_mode, int);
+  static rtx expand_builtin_memmove (tree, tree, rtx, enum machine_mode, tree);
+  static rtx expand_builtin_bcopy (tree);
+***************
+*** 116,148 ****
+  static rtx expand_builtin_stpcpy (tree, rtx, enum machine_mode);
+  static rtx builtin_strncpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_strncpy (tree, rtx, enum machine_mode);
+  static rtx builtin_memset_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx builtin_memset_gen_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_memset (tree, rtx, enum machine_mode, tree);
+  static rtx expand_builtin_bzero (tree);
+  static rtx expand_builtin_strlen (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strstr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strpbrk (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strchr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strrchr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_alloca (tree, rtx);
+  static rtx expand_builtin_unop (enum machine_mode, tree, rtx, rtx, optab);
+  static rtx expand_builtin_frame_address (tree, tree);
+  static rtx expand_builtin_fputs (tree, rtx, bool);
+  static rtx expand_builtin_printf (tree, rtx, enum machine_mode, bool);
+  static rtx expand_builtin_fprintf (tree, rtx, enum machine_mode, bool);
+  static rtx expand_builtin_sprintf (tree, rtx, enum machine_mode);
+  static tree stabilize_va_list (tree, int);
+  static rtx expand_builtin_expect (tree, rtx);
+  static tree fold_builtin_constant_p (tree);
+  static tree fold_builtin_classify_type (tree);
+  static tree fold_builtin_strlen (tree);
+  static tree fold_builtin_inf (tree, int);
+  static tree fold_builtin_nan (tree, tree, int);
+  static int validate_arglist (tree, ...);
+  static bool integer_valued_real_p (tree);
+  static tree fold_trunc_transparent_mathfn (tree);
+  static bool readonly_data_expr (tree);
+  static rtx expand_builtin_fabs (tree, rtx, rtx);
+  static rtx expand_builtin_signbit (tree, rtx);
+  static tree fold_builtin_cabs (tree, tree);
+--- 126,168 ----
+  static rtx expand_builtin_stpcpy (tree, rtx, enum machine_mode);
+  static rtx builtin_strncpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_strncpy (tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static rtx builtin_memset_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx builtin_memset_gen_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_memset (tree, rtx, enum machine_mode, tree);
++ #if 0
+  static rtx expand_builtin_bzero (tree);
+  static rtx expand_builtin_strlen (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strstr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strpbrk (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strchr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strrchr (tree, tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static rtx expand_builtin_alloca (tree, rtx);
+  static rtx expand_builtin_unop (enum machine_mode, tree, rtx, rtx, optab);
+  static rtx expand_builtin_frame_address (tree, tree);
++ #if 0
+  static rtx expand_builtin_fputs (tree, rtx, bool);
+  static rtx expand_builtin_printf (tree, rtx, enum machine_mode, bool);
+  static rtx expand_builtin_fprintf (tree, rtx, enum machine_mode, bool);
+  static rtx expand_builtin_sprintf (tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static tree stabilize_va_list (tree, int);
+  static rtx expand_builtin_expect (tree, rtx);
+  static tree fold_builtin_constant_p (tree);
+  static tree fold_builtin_classify_type (tree);
++ #if 0
+  static tree fold_builtin_strlen (tree);
+  static tree fold_builtin_inf (tree, int);
+  static tree fold_builtin_nan (tree, tree, int);
++ #endif /* 0 */
+  static int validate_arglist (tree, ...);
++ #if 0
+  static bool integer_valued_real_p (tree);
+  static tree fold_trunc_transparent_mathfn (tree);
++ #endif /* 0 */
+  static bool readonly_data_expr (tree);
++ #if 0
+  static rtx expand_builtin_fabs (tree, rtx, rtx);
+  static rtx expand_builtin_signbit (tree, rtx);
+  static tree fold_builtin_cabs (tree, tree);
+***************
+*** 159,165 ****
+  static tree fold_builtin_ceil (tree);
+  static tree fold_builtin_round (tree);
+  static tree fold_builtin_bitop (tree);
+  static tree fold_builtin_memcpy (tree);
+  static tree fold_builtin_mempcpy (tree, tree, int);
+  static tree fold_builtin_memmove (tree, tree);
+  static tree fold_builtin_strchr (tree, tree);
+--- 179,187 ----
+  static tree fold_builtin_ceil (tree);
+  static tree fold_builtin_round (tree);
+  static tree fold_builtin_bitop (tree);
++ #endif /* 0 */
+  static tree fold_builtin_memcpy (tree);
++ #if 0
+  static tree fold_builtin_mempcpy (tree, tree, int);
+  static tree fold_builtin_memmove (tree, tree);
+  static tree fold_builtin_strchr (tree, tree);
+***************
+*** 174,181 ****
+  static tree fold_builtin_fabs (tree, tree);
+  static tree fold_builtin_abs (tree, tree);
+  static tree fold_builtin_unordered_cmp (tree, enum tree_code, enum tree_code);
+  static tree fold_builtin_1 (tree, bool);
+  
+  static tree fold_builtin_strpbrk (tree, tree);
+  static tree fold_builtin_strstr (tree, tree);
+  static tree fold_builtin_strrchr (tree, tree);
+--- 196,205 ----
+  static tree fold_builtin_fabs (tree, tree);
+  static tree fold_builtin_abs (tree, tree);
+  static tree fold_builtin_unordered_cmp (tree, enum tree_code, enum tree_code);
++ #endif /* 0 */
+  static tree fold_builtin_1 (tree, bool);
+  
++ #if 0
+  static tree fold_builtin_strpbrk (tree, tree);
+  static tree fold_builtin_strstr (tree, tree);
+  static tree fold_builtin_strrchr (tree, tree);
+***************
+*** 184,190 ****
+  static tree fold_builtin_strspn (tree);
+  static tree fold_builtin_strcspn (tree);
+  static tree fold_builtin_sprintf (tree, int);
+  
+  
+  /* Return the alignment in bits of EXP, a pointer valued expression.
+     But don't return more than MAX_ALIGN no matter what.
+--- 208,217 ----
+  static tree fold_builtin_strspn (tree);
+  static tree fold_builtin_strcspn (tree);
+  static tree fold_builtin_sprintf (tree, int);
++ #endif /* 0 */
+  
++ /* (TIGCC 20050206) Implement ER_throw. */
++ static void expand_builtin_ER_throw (tree);
+  
+  /* Return the alignment in bits of EXP, a pointer valued expression.
+     But don't return more than MAX_ALIGN no matter what.
+***************
+*** 5831,5836 ****
+        if (target)
+  	return target;
+        break;
+  
+      default:	/* just do library call, if unknown builtin */
+        break;
+--- 5917,5927 ----
+        if (target)
+  	return target;
+        break;
++ #endif /* 0 */
++ 
++     case BUILT_IN_ER_THROW:
++       expand_builtin_ER_throw (arglist);
++       return const0_rtx;
+  
+      default:	/* just do library call, if unknown builtin */
+        break;
+***************
+*** 8882,8887 ****
+      case BUILT_IN_LLRINTF:
+      case BUILT_IN_LLRINTL:
+        return fold_fixed_mathfn (exp);
+  
+      case BUILT_IN_FFS:
+      case BUILT_IN_FFSL:
+--- 8986,8992 ----
+      case BUILT_IN_LLRINTF:
+      case BUILT_IN_LLRINTL:
+        return fold_fixed_mathfn (exp);
++ #endif /* 0 */
+  
+      case BUILT_IN_FFS:
+      case BUILT_IN_FFSL:
+***************
+*** 8362,8367 ****
+        return fold_builtin_unordered_cmp (exp, UNEQ_EXPR, EQ_EXPR);
+      case BUILT_IN_ISUNORDERED:
+        return fold_builtin_unordered_cmp (exp, UNORDERED_EXPR, NOP_EXPR);
+  
+        /* We do the folding for va_start in the expander.  */
+      case BUILT_IN_VA_START:
+--- 8468,8474 ----
+        return fold_builtin_unordered_cmp (exp, UNEQ_EXPR, EQ_EXPR);
+      case BUILT_IN_ISUNORDERED:
+        return fold_builtin_unordered_cmp (exp, UNORDERED_EXPR, NOP_EXPR);
++ #endif /* 0 */
+  
+        /* We do the folding for va_start in the expander.  */
+      case BUILT_IN_VA_START:
diff -Naur gcc-4.1-20051216.orig/gcc/builtins.def gcc-4.1-20051216-src/gcc/builtins.def
--- gcc-4.1-20051216.orig/gcc/builtins.def	2005-07-24 10:36:33.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/builtins.def	2005-12-18 22:24:28.000000000 +0100
@@ -507,6 +507,7 @@
 DEF_LIB_BUILTIN        (BUILT_IN_STRSPN, "strspn", BT_FN_SIZE_CONST_STRING_CONST_STRING, ATTR_PURE_NOTHROW_NONNULL)
 DEF_LIB_BUILTIN        (BUILT_IN_STRSTR, "strstr", BT_FN_STRING_CONST_STRING_CONST_STRING, ATTR_PURE_NOTHROW_NONNULL)
 
+#if 0
 /* Category: stdio builtins.  */
 DEF_LIB_BUILTIN        (BUILT_IN_FPRINTF, "fprintf", BT_FN_INT_FILEPTR_CONST_STRING_VAR, ATTR_FORMAT_PRINTF_2_3)
 DEF_EXT_LIB_BUILTIN    (BUILT_IN_FPRINTF_UNLOCKED, "fprintf_unlocked", BT_FN_INT_FILEPTR_CONST_STRING_VAR, ATTR_FORMAT_PRINTF_2_3)
@@ -568,6 +569,7 @@
 DEF_C94_BUILTIN        (BUILT_IN_ISWXDIGIT, "iswxdigit", BT_FN_INT_WINT, ATTR_PURE_NOTHROW_LIST)
 DEF_C94_BUILTIN        (BUILT_IN_TOWLOWER, "towlower", BT_FN_WINT_WINT, ATTR_PURE_NOTHROW_LIST)
 DEF_C94_BUILTIN        (BUILT_IN_TOWUPPER, "towupper", BT_FN_WINT_WINT, ATTR_PURE_NOTHROW_LIST)
+#endif /* 0 */
 
 /* Category: miscellaneous builtins.  */
 DEF_LIB_BUILTIN        (BUILT_IN_ABORT, "abort", BT_FN_VOID, ATTR_NORETURN_NOTHROW_LIST)
@@ -577,7 +579,9 @@
 DEF_GCC_BUILTIN        (BUILT_IN_APPLY, "apply", BT_FN_PTR_PTR_FN_VOID_VAR_PTR_SIZE, ATTR_NULL)
 DEF_GCC_BUILTIN        (BUILT_IN_APPLY_ARGS, "apply_args", BT_FN_PTR_VAR, ATTR_NULL)
 DEF_GCC_BUILTIN        (BUILT_IN_ARGS_INFO, "args_info", BT_FN_INT_INT, ATTR_NULL)
+#if 0
 DEF_LIB_BUILTIN        (BUILT_IN_CALLOC, "calloc", BT_FN_PTR_SIZE_SIZE, ATTR_MALLOC_NOTHROW_LIST)
+#endif /* 0 */
 DEF_GCC_BUILTIN        (BUILT_IN_CLASSIFY_TYPE, "classify_type", BT_FN_INT_VAR, ATTR_NULL)
 DEF_GCC_BUILTIN        (BUILT_IN_CLZ, "clz", BT_FN_INT_UINT, ATTR_CONST_NOTHROW_LIST)
 DEF_GCC_BUILTIN        (BUILT_IN_CLZIMAX, "clzimax", BT_FN_INT_UINTMAX, ATTR_CONST_NOTHROW_LIST)
@@ -659,6 +663,9 @@
 DEF_EXT_LIB_BUILTIN    (BUILT_IN__EXIT, "_exit", BT_FN_VOID_INT, ATTR_NORETURN_NOTHROW_LIST)
 DEF_C99_BUILTIN        (BUILT_IN__EXIT2, "_Exit", BT_FN_VOID_INT, ATTR_NORETURN_NOTHROW_LIST)
 
+/* (TIGCC 20050206) Implement ER_throw. */
+DEF_GCC_BUILTIN        (BUILT_IN_ER_THROW, "ER_throw", BT_FN_VOID_INT, ATTR_NORETURN_NOTHROW_LIST)
+
 /* Implementing nested functions.  */
 DEF_BUILTIN_STUB (BUILT_IN_INIT_TRAMPOLINE, "__builtin_init_trampoline")
 DEF_BUILTIN_STUB (BUILT_IN_ADJUST_TRAMPOLINE, "__builtin_adjust_trampoline")
diff -Naur gcc-4.1-20051216.orig/gcc/c-common.c gcc-4.1-20051216-src/gcc/c-common.c
--- gcc-4.1-20051216.orig/gcc/c-common.c	2005-12-08 12:24:07.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-common.c	2005-12-18 22:24:28.000000000 +0100
@@ -2934,16 +2934,20 @@
 #define DEF_ATTR_INT(ENUM, VALUE) ENUM,
 #define DEF_ATTR_IDENT(ENUM, STRING) ENUM,
 #define DEF_ATTR_TREE_LIST(ENUM, PURPOSE, VALUE, CHAIN) ENUM,
+#define DEF_FN_ATTR(NAME, ATTRS, PREDICATE) /* No entry needed in enum.  */
 #include "builtin-attrs.def"
 #undef DEF_ATTR_NULL_TREE
 #undef DEF_ATTR_INT
 #undef DEF_ATTR_IDENT
 #undef DEF_ATTR_TREE_LIST
+#undef DEF_FN_ATTR
   ATTR_LAST
 };
 
 static GTY(()) tree built_in_attributes[(int) ATTR_LAST];
 
+static bool c_attrs_initialized = false;
+
 static void c_init_attributes (void);
 
 /* Build tree nodes and builtin functions common to both C and C++ language
@@ -3354,7 +3358,8 @@
 #undef DEF_POINTER_TYPE
   builtin_types[(int) BT_LAST] = NULL_TREE;
 
-  c_init_attributes ();
+  if (!c_attrs_initialized)
+    c_init_attributes ();
 
 #define DEF_BUILTIN(ENUM, NAME, CLASS, TYPE, LIBTYPE, BOTH_P, FALLBACK_P, \
 		    NONANSI_P, ATTRS, IMPLICIT, COND)			\
@@ -4037,11 +4042,40 @@
     = tree_cons (built_in_attributes[(int) PURPOSE],	\
 		 built_in_attributes[(int) VALUE],	\
 		 built_in_attributes[(int) CHAIN]);
+#define DEF_FN_ATTR(NAME, ATTRS, PREDICATE) /* No initialization needed.  */
+#include "builtin-attrs.def"
+#undef DEF_ATTR_NULL_TREE
+#undef DEF_ATTR_INT
+#undef DEF_ATTR_IDENT
+#undef DEF_ATTR_TREE_LIST
+#undef DEF_FN_ATTR
+  c_attrs_initialized = true;
+}
+
+/* Depending on the name of DECL, apply default attributes to it.  */
+
+void
+c_common_insert_default_attributes (tree decl)
+{
+  tree name = DECL_NAME (decl);
+
+  if (!c_attrs_initialized)
+    c_init_attributes ();
+
+#define DEF_ATTR_NULL_TREE(ENUM) /* Nothing needed after initialization.  */
+#define DEF_ATTR_INT(ENUM, VALUE)
+#define DEF_ATTR_IDENT(ENUM, STRING)
+#define DEF_ATTR_TREE_LIST(ENUM, PURPOSE, VALUE, CHAIN)
+#define DEF_FN_ATTR(NAME, ATTRS, PREDICATE)			\
+  if ((PREDICATE) && name == built_in_attributes[(int) NAME])	\
+    decl_attributes (&decl, built_in_attributes[(int) ATTRS],	\
+		     ATTR_FLAG_BUILT_IN);
 #include "builtin-attrs.def"
 #undef DEF_ATTR_NULL_TREE
 #undef DEF_ATTR_INT
 #undef DEF_ATTR_IDENT
 #undef DEF_ATTR_TREE_LIST
+#undef DEF_FN_ATTR
 }
 
 /* Attribute handlers common to C front ends.  */
diff -Naur gcc-4.1-20051216.orig/gcc/c-common.h gcc-4.1-20051216-src/gcc/c-common.h
--- gcc-4.1-20051216.orig/gcc/c-common.h	2005-12-08 12:24:07.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-common.h	2005-12-18 22:24:28.000000000 +0100
@@ -632,6 +632,7 @@
 extern void set_Wformat (int);
 extern tree handle_format_attribute (tree *, tree, tree, int, bool *);
 extern tree handle_format_arg_attribute (tree *, tree, tree, int, bool *);
+extern void c_common_insert_default_attributes (tree);
 extern int c_common_handle_option (size_t code, const char *arg, int value);
 extern bool c_common_missing_argument (const char *opt, size_t code);
 extern tree c_common_type_for_mode (enum machine_mode, int);
diff -Naur gcc-4.1-20051216.orig/gcc/c-cppbuiltin.c gcc-4.1-20051216-src/gcc/c-cppbuiltin.c
--- gcc-4.1-20051216.orig/gcc/c-cppbuiltin.c	2005-08-13 22:58:02.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-cppbuiltin.c	2005-12-18 22:24:28.000000000 +0100
@@ -51,9 +51,11 @@
 static void builtin_define_with_value_n (const char *, const char *,
 					 size_t);
 static void builtin_define_with_int_value (const char *, HOST_WIDE_INT);
+#if 0
 static void builtin_define_with_hex_fp_value (const char *, tree,
 					      int, const char *,
 					      const char *);
+#endif /* 0 */
 static void builtin_define_stdint_macros (void);
 static void builtin_define_type_max (const char *, tree, int);
 static void builtin_define_type_precision (const char *, tree);
@@ -72,6 +74,7 @@
 static void
 builtin_define_float_constants (const char *name_prefix, const char *fp_suffix, tree type)
 {
+#if 0 /* (TIGCC) Do nothing. We have our own float.h! */
   /* Used to convert radix-based values to base 10 values in several cases.
 
      In the max_exp -> max_10_exp conversion for 128-bit IEEE, we need at
@@ -254,6 +257,7 @@
      NaN has quiet NaNs.  */
   sprintf (name, "__%s_HAS_QUIET_NAN__", name_prefix);
   builtin_define_with_int_value (name, MODE_HAS_NANS (TYPE_MODE (type)));
+#endif /* 0 */
 }
 
 /* Define __GNUC__, __GNUC_MINOR__ and __GNUC_PATCHLEVEL__.  */
@@ -571,6 +575,7 @@
   cpp_define (parse_in, buf);
 }
 
+#if 0
 /* Pass an object-like macro a hexadecimal floating-point value.  */
 static void
 builtin_define_with_hex_fp_value (const char *macro,
@@ -596,6 +601,7 @@
   sprintf (buf, "%s=%s%s", macro, dec_str, fp_suffix);
   cpp_define (parse_in, buf);
 }
+#endif /* 0 */
 
 /* Define MAX for TYPE based on the precision of the type.  IS_LONG is
    1 for type "long" and 2 for "long long".  We have to handle
diff -Naur gcc-4.1-20051216.orig/gcc/c-decl.c gcc-4.1-20051216-src/gcc/c-decl.c
--- gcc-4.1-20051216.orig/gcc/c-decl.c	2005-11-30 11:29:09.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-decl.c	2005-12-19 00:27:27.000000000 +0100
@@ -2418,7 +2418,6 @@
 void
 undeclared_variable (tree id, location_t loc)
 {
-  static bool already = false;
   struct c_scope *scope;
 
   if (current_function_decl == 0)
@@ -2430,13 +2429,6 @@
     {
       error ("%H%qE undeclared (first use in this function)", &loc, id);
 
-      if (!already)
-	{
-	  error ("%H(Each undeclared identifier is reported only once", &loc);
-	  error ("%Hfor each function it appears in.)", &loc);
-	  already = true;
-	}
-
       /* If we are parsing old-style parameter decls, current_function_decl
          will be nonnull but current_function_scope will be null.  */
       scope = current_function_scope ? current_function_scope : current_scope;
@@ -2730,7 +2722,7 @@
 
   input_location = save_loc;
 
-  pedantic_lvalues = true;
+  pedantic_lvalues = pedantic;
 
   make_fname_decl = c_make_fname_decl;
   start_fname_decls ();
@@ -2825,6 +2817,18 @@
 
   return decl;
 }
+
+/* Apply default attributes to a function, if a system function with default
+   attributes.  */
+
+void
+c_insert_default_attributes (decl)
+     tree decl;
+{
+  if (!TREE_PUBLIC (decl))
+    return;
+  c_common_insert_default_attributes (decl);
+}
 
 /* Called when a declaration is seen that contains no names to declare.
    If its type is a reference to a structure, union or enum inherited
@@ -3573,10 +3577,86 @@
 push_parm_decl (const struct c_parm *parm)
 {
   tree decl;
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+  tree asmspec;
 
+  asmspec = parm->asmspec;
+/* end-TIGCC-local (regparms) */
   decl = grokdeclarator (parm->declarator, parm->specs, PARM, false, NULL);
   decl_attributes (&decl, parm->attrs, 0);
 
+  /* begin-TIGCC-local (regparms): explicit register specification for parameters */
+  if (asmspec)
+#ifdef EXPLICIT_REGPARM
+    {
+      const char *regname=TREE_STRING_POINTER(asmspec);
+      int regnum;
+      if ((regnum=decode_reg_name(regname))>=0)
+	{
+	  tree type=TREE_TYPE(decl);
+	  if (HARD_REGNO_MODE_OK(regnum, TYPE_MODE(type)))
+	    {
+	      tree t, attrs;
+/*	      push_obstacks_nochange();
+	      end_temporary_allocation(); */
+	      /* Build tree for __attribute__ ((asm(regnum))). */
+#if 0
+	      /* This doesn't work well because of a bug in
+		 attribute_list_contained(), which passes list of arguments to
+		 simple_cst_equal() instead of passing every argument
+		 separately. */
+	      attrs=tree_cons(get_identifier("asm"), tree_cons(NULL_TREE,
+		    build_int_cstu(NULL_TREE, regnum), NULL_TREE), NULL_TREE);
+#else
+	      attrs=tree_cons(get_identifier("asm"),
+			      build_int_cstu(NULL_TREE, regnum), NULL_TREE);
+#endif
+#if 0
+	      /* build_type_attribute_variant() would seem to be more
+		 appropriate here. However, that function does not support
+		 attributes for parameters properly. It modifies
+		 TYPE_MAIN_VARIANT of a new type. As a result, comptypes()
+		 thinks that types of parameters in prototype and definition
+		 are different and issues error messages. See also comment
+		 below. */
+	      type=build_type_attribute_variant(type, attrs);
+#else
+	      /* First check whether such a type already exists - if yes, use
+		 that one. This is very important, since otherwise
+		 common_type() would think that it sees two different
+		 types and would try to merge them - this could result in
+		 warning messages. */
+	      for (t=TYPE_MAIN_VARIANT(type); t; t=TYPE_NEXT_VARIANT(t))
+		if (comptypes(t, type)==1
+		    && attribute_list_equal(TYPE_ATTRIBUTES(t), attrs))
+		      break;
+	      if (t)
+		type=t;
+	      else
+		{
+		  /* Create a new variant, with differing attributes.
+		     (Hack! Type with differing attributes should no longer be
+		     a variant of its main type. See comment above for
+		     explanation why this was necessary). */
+		  type=build_variant_type_copy(type);
+		  TYPE_ATTRIBUTES(type)=attrs;
+		}
+#endif
+	      TREE_TYPE(decl)=type;
+/*	      pop_obstacks(); */
+	    }
+	  else
+	    error("%Jregister number for `%s' isn't suitable for the data type",
+	          decl);
+	}
+      else
+	error("invalid register name `%s'", regname);
+    }
+#else /* !EXPLICIT_REGPARM */
+    error("explicit register specification for parameters is not supported for this target");
+#endif
+  /* end-TIGCC-local (regparms) */
+
   decl = pushdecl (decl);
 
   finish_decl (decl, NULL_TREE, NULL_TREE);
@@ -3628,7 +3708,11 @@
   DECL_CONTEXT (decl) = current_function_decl;
   TREE_USED (decl) = 1;
   TREE_TYPE (decl) = type;
-  TREE_READONLY (decl) = TYPE_READONLY (type);
+  /* (TIGCC 20050206) If -fglobal-compound-literals (on by default) is given,
+     for constant constructors, the compound literal is written out as if it was
+     const, which gets GCC to output it as a global, avoiding the copy.  */
+  TREE_READONLY (decl) = TYPE_READONLY (type)
+                         || (flag_global_compound_literals && TREE_CONSTANT (init));
   store_init_value (decl, init);
 
   if (TREE_CODE (type) == ARRAY_TYPE && !COMPLETE_TYPE_P (type))
@@ -6854,12 +6938,13 @@
 
 struct c_parm *
 build_c_parm (struct c_declspecs *specs, tree attrs,
-	      struct c_declarator *declarator)
+	      struct c_declarator *declarator, tree asmspec)
 {
   struct c_parm *ret = XOBNEW (&parser_obstack, struct c_parm);
   ret->specs = specs;
   ret->attrs = attrs;
   ret->declarator = declarator;
+  ret->asmspec = asmspec; /* (TIGCC 20050203) */
   return ret;
 }
 
diff -Naur gcc-4.1-20051216.orig/gcc/cfgexpand.c gcc-4.1-20051216-src/gcc/cfgexpand.c
--- gcc-4.1-20051216.orig/gcc/cfgexpand.c	2005-10-19 18:27:10.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/cfgexpand.c	2005-12-18 22:24:35.000000000 +0100
@@ -1322,6 +1322,23 @@
 	    }
 	  else
 	    {
+	      /* (TIGCC 20050206) If -fno-function-cse, restore function call
+	                          sequences to their expected form. */
+	      if (flag_no_function_cse && TREE_CODE (stmt) == MODIFY_EXPR)
+	        {
+	          block_stmt_iterator bsi2 = bsi;
+	          bsi_next (&bsi2);
+	          if (!bsi_end_p (bsi2))
+	            {
+	              tree call = get_call_expr_in (bsi_stmt (bsi2));
+	              if (call && TREE_OPERAND (stmt, 0) == TREE_OPERAND (call, 0)
+	                  && !TREE_SIDE_EFFECTS (TREE_OPERAND (stmt, 0))
+	                  && !TREE_SIDE_EFFECTS (TREE_OPERAND (stmt, 1)))
+	              {
+	                TREE_OPERAND (call, 0) = TREE_OPERAND (stmt, 1);
+	              }
+	            }
+	        }
 	      last = get_last_insn ();
 	      expand_expr_stmt (stmt);
 	      maybe_dump_rtl_for_tree_stmt (stmt, last);
diff -Naur gcc-4.1-20051216.orig/gcc/c-format.c gcc-4.1-20051216-src/gcc/c-format.c
--- gcc-4.1-20051216.orig/gcc/c-format.c	2005-10-26 04:15:02.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-format.c	2005-12-18 22:24:28.000000000 +0100
@@ -281,16 +281,12 @@
 } format_wanted_type;
 
 
+/* (TIGCC 20040219) AMS doesn't support any C99 or extended modifiers.
+    -- Kevin Kofler */
 static const format_length_info printf_length_specs[] =
 {
-  { "h", FMT_LEN_h, STD_C89, "hh", FMT_LEN_hh, STD_C99 },
-  { "l", FMT_LEN_l, STD_C89, "ll", FMT_LEN_ll, STD_C9L },
-  { "q", FMT_LEN_ll, STD_EXT, NULL, 0, 0 },
-  { "L", FMT_LEN_L, STD_C89, NULL, 0, 0 },
-  { "z", FMT_LEN_z, STD_C99, NULL, 0, 0 },
-  { "Z", FMT_LEN_z, STD_EXT, NULL, 0, 0 },
-  { "t", FMT_LEN_t, STD_C99, NULL, 0, 0 },
-  { "j", FMT_LEN_j, STD_C99, NULL, 0, 0 },
+  { "h", FMT_LEN_h, STD_C89, NULL, 0, 0 },
+  { "l", FMT_LEN_l, STD_C89, NULL, 0, 0 },
   { NULL, 0, 0, NULL, 0, 0 }
 };
 
@@ -315,16 +311,12 @@
 #define gcc_cdiag_length_specs gcc_diag_length_specs
 #define gcc_cxxdiag_length_specs gcc_diag_length_specs
 
-/* This differs from printf_length_specs only in that "Z" is not accepted.  */
+/* (TIGCC 20040219) My *scanf doesn't support any C99 or extended modifiers.
+    -- Kevin Kofler */
 static const format_length_info scanf_length_specs[] =
 {
-  { "h", FMT_LEN_h, STD_C89, "hh", FMT_LEN_hh, STD_C99 },
-  { "l", FMT_LEN_l, STD_C89, "ll", FMT_LEN_ll, STD_C9L },
-  { "q", FMT_LEN_ll, STD_EXT, NULL, 0, 0 },
-  { "L", FMT_LEN_L, STD_C89, NULL, 0, 0 },
-  { "z", FMT_LEN_z, STD_C99, NULL, 0, 0 },
-  { "t", FMT_LEN_t, STD_C99, NULL, 0, 0 },
-  { "j", FMT_LEN_j, STD_C99, NULL, 0, 0 },
+  { "h", FMT_LEN_h, STD_C89, NULL, 0, 0 },
+  { "l", FMT_LEN_l, STD_C89, NULL, 0, 0 },
   { NULL, 0, 0, NULL, 0, 0 }
 };
 
@@ -338,6 +330,9 @@
   { NULL, 0, 0, NULL, 0, 0 }
 };
 
+/* (TIGCC 20040219) AMS doesn't support any of the GNU extended modifiers.
+                    However, it supports some of its own.
+    -- Kevin Kofler */
 static const format_flag_spec printf_flag_specs[] =
 {
   { ' ',  0, 0, N_("' ' flag"),        N_("the ' ' printf flag"),              STD_C89 },
@@ -345,8 +340,9 @@
   { '#',  0, 0, N_("'#' flag"),        N_("the '#' printf flag"),              STD_C89 },
   { '0',  0, 0, N_("'0' flag"),        N_("the '0' printf flag"),              STD_C89 },
   { '-',  0, 0, N_("'-' flag"),        N_("the '-' printf flag"),              STD_C89 },
-  { '\'', 0, 0, N_("''' flag"),        N_("the ''' printf flag"),              STD_EXT },
-  { 'I',  0, 0, N_("'I' flag"),        N_("the 'I' printf flag"),              STD_EXT },
+  { 'z',  0, 0, N_("'z' flag"),        N_("the 'z' printf flag"),              STD_EXT },
+  { '^',  0, 0, N_("'^' flag"),        N_("the '^' printf flag"),              STD_EXT },
+  { '|',  0, 0, N_("'|' flag"),        N_("the '|' printf flag"),              STD_EXT },
   { 'w',  0, 0, N_("field width"),     N_("field width in printf format"),     STD_C89 },
   { 'p',  0, 0, N_("precision"),       N_("precision in printf format"),       STD_C89 },
   { 'L',  0, 0, N_("length modifier"), N_("length modifier in printf format"), STD_C89 },
@@ -419,14 +415,13 @@
   { 0, 0, 0, NULL, NULL, 0 }
 };
 
+/* (TIGCC 20040219) My *scanf doesn't support any extended modifiers.
+    -- Kevin Kofler */
 static const format_flag_spec scanf_flag_specs[] =
 {
   { '*',  0, 0, N_("assignment suppression"), N_("the assignment suppression scanf feature"), STD_C89 },
-  { 'a',  0, 0, N_("'a' flag"),               N_("the 'a' scanf flag"),                       STD_EXT },
   { 'w',  0, 0, N_("field width"),            N_("field width in scanf format"),              STD_C89 },
   { 'L',  0, 0, N_("length modifier"),        N_("length modifier in scanf format"),          STD_C89 },
-  { '\'', 0, 0, N_("''' flag"),               N_("the ''' scanf flag"),                       STD_EXT },
-  { 'I',  0, 0, N_("'I' flag"),               N_("the 'I' scanf flag"),                       STD_EXT },
   { 0, 0, 0, NULL, NULL, 0 }
 };
 
@@ -486,26 +481,22 @@
 };
 
 
+/* (TIGCC 20040219) AMS doesn't support any of the C99 or GNU extended
+                    modifiers. However, it supports some of its own.
+    -- Kevin Kofler */
 static const format_char_info print_char_table[] =
 {
   /* C89 conversion specifiers.  */
-  { "di",  0, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  TEX_LL,  T99_SST, T99_PD,  T99_IM  }, "-wp0 +'I",  "i",  NULL },
-  { "oxX", 0, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "-wp0#",     "i",  NULL },
-  { "u",   0, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "-wp0'I",    "i",  NULL },
-  { "fgG", 0, STD_C89, { T89_D,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T89_LD,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#'I", "",   NULL },
-  { "eE",  0, STD_C89, { T89_D,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T89_LD,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#I",  "",   NULL },
-  { "c",   0, STD_C89, { T89_I,   BADLEN,  BADLEN,  T94_WI,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w",        "",   NULL },
-  { "s",   1, STD_C89, { T89_C,   BADLEN,  BADLEN,  T94_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp",       "cR", NULL },
-  { "p",   1, STD_C89, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w",        "c",  NULL },
-  { "n",   1, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  BADLEN,  T99_SST, T99_PD,  T99_IM  }, "",          "W",  NULL },
-  /* C99 conversion specifiers.  */
-  { "F",   0, STD_C99, { T99_D,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T99_LD,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#'I", "",   NULL },
-  { "aA",  0, STD_C99, { T99_D,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T99_LD,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#",   "",   NULL },
-  /* X/Open conversion specifiers.  */
-  { "C",   0, STD_EXT, { TEX_WI,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w",        "",   NULL },
-  { "S",   1, STD_EXT, { TEX_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp",       "R",  NULL },
-  /* GNU conversion specifiers.  */
-  { "m",   0, STD_EXT, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp",       "",   NULL },
+  { "di",  0, STD_C89, { T89_S,   BADLEN,  T89_S,   T89_L,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +|z",  "i", NULL  },
+  { "xX", 0, STD_C89, { T89_US,  BADLEN,  T89_US,  T89_UL,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0#|z",     "i", NULL  },
+  { "u",   0, STD_C89, { T89_US,  BADLEN,  T89_US,  T89_UL,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0|z",    "i", NULL  },
+  { "fgG", 0, STD_C89, { T89_D,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#^|z", "", NULL   },
+  { "eE",  0, STD_C89, { T89_D,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#^|z",  "", NULL   },
+  { "rR",  0, STD_EXT, { T89_D,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#^|z",  "", NULL   },
+  { "yY",  0, STD_EXT, { T89_D,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#^|z",  "", NULL   },
+  { "c",   0, STD_C89, { T89_S,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w|z",        "", NULL   },
+  { "s",   1, STD_C89, { T89_C,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp|z",       "cR", NULL },
+  { "p",   1, STD_C89, { BADLEN,  BADLEN,  BADLEN,  T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w|z",        "c", NULL  },
   { NULL,  0, 0, NOLENGTHS, NULL, NULL, NULL }
 };
 
@@ -641,23 +632,18 @@
   { NULL,  0, 0, NOLENGTHS, NULL, NULL, NULL }
 };
 
+/* (TIGCC 20040219) My *scanf doesn't support any extended modifiers. -- Kevin Kofler */
 static const format_char_info scan_char_table[] =
 {
   /* C89 conversion specifiers.  */
-  { "di",    1, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  TEX_LL,  T99_SST, T99_PD,  T99_IM  }, "*w'I", "W",   NULL },
-  { "u",     1, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "*w'I", "W",   NULL },
-  { "oxX",   1, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "*w",   "W",   NULL },
-  { "efgEG", 1, STD_C89, { T89_F,   BADLEN,  BADLEN,  T89_D,   BADLEN,  T89_LD,  BADLEN,  BADLEN,  BADLEN  }, "*w'",  "W",   NULL },
+  { "di",    1, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  TEX_LL,  T99_SST, T99_PD,  T99_IM  }, "*w", "W", NULL   },
+  { "u",     1, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "*w", "W", NULL   },
+  { "oxX",   1, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "*w",   "W", NULL   },
+  { "efgEG", 1, STD_C89, { T89_F,   BADLEN,  BADLEN,  T89_D,   BADLEN,  T89_LD,  BADLEN,  BADLEN,  BADLEN  }, "*w",  "W", NULL   },
   { "c",     1, STD_C89, { T89_C,   BADLEN,  BADLEN,  T94_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*w",   "cW",  NULL },
   { "s",     1, STD_C89, { T89_C,   BADLEN,  BADLEN,  T94_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*aw",  "cW",  NULL },
   { "[",     1, STD_C89, { T89_C,   BADLEN,  BADLEN,  T94_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*aw",  "cW[", NULL },
   { "p",     2, STD_C89, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*w",   "W",   NULL },
-  { "n",     1, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  BADLEN,  T99_SST, T99_PD,  T99_IM  }, "",     "W",   NULL },
-  /* C99 conversion specifiers.  */
-  { "FaA",   1, STD_C99, { T99_F,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T99_LD,  BADLEN,  BADLEN,  BADLEN  }, "*w'",  "W",   NULL },
-  /* X/Open conversion specifiers.  */
-  { "C",     1, STD_EXT, { TEX_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*w",   "W",   NULL },
-  { "S",     1, STD_EXT, { TEX_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*aw",  "W",   NULL },
   { NULL, 0, 0, NOLENGTHS, NULL, NULL, NULL }
 };
 
@@ -695,9 +681,10 @@
 };
 
 /* This must be in the same order as enum format_type.  */
+/* (TIGCC 20040219) Changed the flag chars. See the *f_flag_specs comments. */
 static const format_kind_info format_types_orig[] =
 {
-  { "printf",   printf_length_specs,  print_char_table, " +#0-'I", NULL, 
+  { "printf",   printf_length_specs,  print_char_table, " +#0-z^|", NULL, 
     printf_flag_specs, printf_flag_pairs,
     FMT_FLAG_ARG_CONVERT|FMT_FLAG_DOLLAR_MULTIPLE|FMT_FLAG_USE_DOLLAR|FMT_FLAG_EMPTY_PREC_OK,
     'w', 0, 'p', 0, 'L',
@@ -739,7 +726,7 @@
     0, 0, 0, 0, 0,
     NULL, NULL
   },
-  { "scanf",    scanf_length_specs,   scan_char_table,  "*'I", NULL, 
+  { "scanf",    scanf_length_specs,   scan_char_table,  "*", NULL, 
     scanf_flag_specs, scanf_flag_pairs,
     FMT_FLAG_ARG_CONVERT|FMT_FLAG_SCANF_A_KLUDGE|FMT_FLAG_USE_DOLLAR|FMT_FLAG_ZERO_WIDTH_BAD|FMT_FLAG_DOLLAR_GAP_POINTER_OK,
     'w', 0, 0, '*', 'L',
@@ -2215,6 +2202,17 @@
 			  || cur_type == signed_char_type_node
 			  || cur_type == unsigned_char_type_node);
 
+      /* (TIGCC) Account for *printf and *scanf not actually supporting -mlong.  */
+      if (!TARGET_SHORT) {
+        if (cur_type == short_integer_type_node
+            || cur_type == integer_type_node)
+          orig_cur_type = cur_type = long_integer_type_node;
+
+        if (cur_type == short_unsigned_type_node
+            || cur_type == unsigned_type_node)
+          orig_cur_type = cur_type = long_unsigned_type_node;
+      }
+
       /* Check the type of the "real" argument, if there's a type we want.  */
       if (lang_hooks.types_compatible_p (wanted_type, cur_type))
 	continue;
@@ -2229,12 +2227,18 @@
 	 -pedantic.  With -pedantic, warn if the type is a pointer
 	 target and not a character type, and for character types at
 	 a second level of indirection.  */
-      if (TREE_CODE (wanted_type) == INTEGER_TYPE
+      /* TIGCC Patch: Don't warn about differences in floating point
+         format; they're all the same.
+         (TIGCC 20040728) But do warn if someone passes an integer where a float
+                          is expected! -- Kevin Kofler  */
+      if ((TREE_CODE (wanted_type) == REAL_TYPE
+           && TREE_CODE (cur_type) == REAL_TYPE)
+	  || (TREE_CODE (wanted_type) == INTEGER_TYPE
 	  && TREE_CODE (cur_type) == INTEGER_TYPE
 	  && (!pedantic || i == 0 || (i == 1 && char_type_flag))
 	  && (TYPE_UNSIGNED (wanted_type)
 	      ? wanted_type == c_common_unsigned_type (cur_type)
-	      : wanted_type == c_common_signed_type (cur_type)))
+	      : wanted_type == c_common_signed_type (cur_type))))
 	continue;
       /* Likewise, "signed char", "unsigned char" and "char" are
 	 equivalent but the above test won't consider them equivalent.  */
diff -Naur gcc-4.1-20051216.orig/gcc/c-incpath.c gcc-4.1-20051216-src/gcc/c-incpath.c
--- gcc-4.1-20051216.orig/gcc/c-incpath.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-incpath.c	2005-12-18 22:24:28.000000000 +0100
@@ -335,9 +335,13 @@
      function does not recognize a directory that ends in a backslash
      (unless it is a drive root dir, such "c:\").  Forward slashes,
      trailing or otherwise, cause no problems for stat().  */
+  /* (TIGCC 20050206) This is entirely backwards! We need backslashes.
+                      Forward-slashes are no good. But we need to get rid of
+                      trailing backslashes. -- Kevin Kofler  */
   char* c;
   for (c = path; *c; c++)
-    if (*c == '\\') *c = '/';
+    if (*c == '/') *c = '\\';
+  if (c[strlen(c)-1] == '\\') c[strlen(c)-1] = '\0';
 #endif
 
   p = xmalloc (sizeof (cpp_dir));
@@ -360,6 +364,7 @@
 			 const char *iprefix, int stdinc, int cxx_stdinc,
 			 int verbose)
 {
+#if 0 /* (TIGCC 20050205) Don't use environment variables. */
   static const char *const lang_env_vars[] =
     { "C_INCLUDE_PATH", "CPLUS_INCLUDE_PATH",
       "OBJC_INCLUDE_PATH", "OBJCPLUS_INCLUDE_PATH" };
@@ -375,11 +380,14 @@
      include chain.  */
   add_env_var_paths ("CPATH", BRACKET);
   add_env_var_paths (lang_env_vars[idx], SYSTEM);
+#endif /* 0 */
   
   target_c_incpath.extra_pre_includes (sysroot, iprefix, stdinc);
 
   /* Finally chain on the standard directories.  */
-  if (stdinc)
+  /* (TIGCC 20031007) We don't want any "standard" include directories.
+                      -- Kevin Kofler  */
+  if (0 /*stdinc*/)
     add_standard_paths (sysroot, iprefix, cxx_stdinc);
 
   target_c_incpath.extra_includes (sysroot, iprefix, stdinc);
diff -Naur gcc-4.1-20051216.orig/gcc/c-lang.c gcc-4.1-20051216-src/gcc/c-lang.c
--- gcc-4.1-20051216.orig/gcc/c-lang.c	2005-07-01 01:09:06.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-lang.c	2005-12-18 22:24:28.000000000 +0100
@@ -44,6 +44,8 @@
 #define LANG_HOOKS_NAME "GNU C"
 #undef LANG_HOOKS_INIT
 #define LANG_HOOKS_INIT c_objc_common_init
+#undef LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES
+#define LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES c_insert_default_attributes
 
 /* Each front end provides its own lang hook initializer.  */
 const struct lang_hooks lang_hooks = LANG_HOOKS_INITIALIZER;
diff -Naur gcc-4.1-20051216.orig/gcc/c-lex.c gcc-4.1-20051216-src/gcc/c-lex.c
--- gcc-4.1-20051216.orig/gcc/c-lex.c	2005-07-19 22:19:16.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-lex.c	2005-12-18 22:24:28.000000000 +0100
@@ -433,7 +433,7 @@
 	cppchar_t c = tok->val.str.text[0];
 
 	if (c == '"' || c == '\'')
-	  error ("missing terminating %c character", (int) c);
+	  cpp_unterminated (parse_in, c);
 	else if (ISGRAPH (c))
 	  error ("stray %qc in program", (int) c);
 	else
diff -Naur gcc-4.1-20051216.orig/gcc/combine.c gcc-4.1-20051216-src/gcc/combine.c
--- gcc-4.1-20051216.orig/gcc/combine.c	2005-12-01 04:24:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/combine.c	2005-12-18 22:24:35.000000000 +0100
@@ -4396,8 +4396,10 @@
       /* x - 0 is the same as x unless x's mode has signed zeros and
 	 allows rounding towards -infinity.  Under those conditions,
 	 0 - 0 is -0.  */
+      /* (TIGCC 20050210) This is invalid independently of the rounding mode
+                          for 3-sign-zeros. */
       if (!(HONOR_SIGNED_ZEROS (GET_MODE (XEXP (x, 0)))
-	    && HONOR_SIGN_DEPENDENT_ROUNDING (GET_MODE (XEXP (x, 0))))
+	    /*&& HONOR_SIGN_DEPENDENT_ROUNDING (GET_MODE (XEXP (x, 0)))*/)
 	  && XEXP (x, 1) == CONST0_RTX (GET_MODE (XEXP (x, 0))))
 	return XEXP (x, 0);
       break;
diff -Naur gcc-4.1-20051216.orig/gcc/common.opt gcc-4.1-20051216-src/gcc/common.opt
--- gcc-4.1-20051216.orig/gcc/common.opt	2005-11-11 18:59:54.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/common.opt	2005-12-18 22:24:35.000000000 +0100
@@ -447,6 +447,14 @@
 Perform global common subexpression elimination after register allocation
 has finished
 
+fglobal-cast-constructors
+Common Report Var(flag_global_compound_literals) Init(1)
+Make compound literals (cast constructors) global for backwards compatibility
+
+fglobal-compound-literals
+Common Report Var(flag_global_compound_literals) VarExists
+Make compound literals (cast constructors) global for backwards compatibility
+
 fguess-branch-probability
 Common Report Var(flag_guess_branch_prob)
 Enable guessing of branch probabilities
@@ -562,6 +570,10 @@
 Common Report Var(flag_merge_constants,2) Init(1)
 Attempt to merge identical constants and constant variables
 
+fmerge-constant-pools
+Common Report Var(flag_merge_constant_pools) Init(1)
+When merging constants, also merge constant pools
+
 fmerge-constants
 Common Report Var(flag_merge_constants,1) VarExists
 Attempt to merge identical constants across compilation units
@@ -590,6 +602,10 @@
 Common RejectNegative Report Var(flag_mudflap_ignore_reads)
 Ignore read operations when inserting mudflap instrumentation
 
+freg-relative-
+Common Joined RejectNegative
+-freg-relative-<register>	Emit code relative to the base register <register>
+
 freschedule-modulo-scheduled-loops
 Common Report Var(flag_resched_modulo_sched)
 Enable/Disable the traditional scheduling in loops that already passed modulo scheduling
@@ -1042,7 +1058,7 @@
 Assume signed arithmetic overflow wraps around
 
 fzero-initialized-in-bss
-Common Report Var(flag_zero_initialized_in_bss) Init(1)
+Common Report Var(flag_zero_initialized_in_bss) Init(0)
 Put zero initialized data in the bss section
 
 g
diff -Naur gcc-4.1-20051216.orig/gcc/config/dbxcoff.h gcc-4.1-20051216-src/gcc/config/dbxcoff.h
--- gcc-4.1-20051216.orig/gcc/config/dbxcoff.h	2005-06-25 03:22:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/dbxcoff.h	2005-12-18 22:24:35.000000000 +0100
@@ -48,8 +48,13 @@
 
 /* Like block addresses, stabs line numbers are relative to the
    current function.  */
+/* TIGCC Patch: We don't want COFF line numbers to be function-relative.
+   That's why we write '.ln LINE'. This will break support for existing
+   debuggers, but there are none for TIGCC. The line numbers can be
+   extracted from the .s file, plus they are passed on to the object file
+   symbol table. */
 
-#define DBX_LINES_FUNCTION_RELATIVE 1
+#define DBX_LINES_FUNCTION_RELATIVE (!TARGET_COFFABSLINES)
 
 /* When generating stabs debugging, use N_BINCL entries.  */
 
diff -Naur gcc-4.1-20051216.orig/gcc/config/i386/xm-mingw32.h gcc-4.1-20051216-src/gcc/config/i386/xm-mingw32.h
--- gcc-4.1-20051216.orig/gcc/config/i386/xm-mingw32.h	2005-06-25 03:22:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/i386/xm-mingw32.h	2005-12-18 22:24:35.000000000 +0100
@@ -20,6 +20,10 @@
 Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA
 02110-1301, USA.  */
 
+/* Mingw32 does not try to hide the underlying DOS-based file system
+   like Cygwin does.  */
+#define HAVE_DOS_BASED_FILE_SYSTEM
+
 #define HOST_EXECUTABLE_SUFFIX ".exe"
 
 #undef PATH_SEPARATOR
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k.c gcc-4.1-20051216-src/gcc/config/m68k/m68k.c
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k.c	2005-07-12 01:32:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k.c	2005-12-19 02:00:46.000000000 +0100
@@ -43,6 +43,11 @@
 #include "target-def.h"
 #include "debug.h"
 #include "flags.h"
+#include "c-pragma.h"
+#include "cgraph.h"
+
+/* TIGCC register for reg-relative code.  */
+char TARGET_RELATION_REG[10] = "a4";
 
 enum reg_class regno_reg_class[] =
 {
@@ -122,10 +127,20 @@
 static bool m68k_save_reg (unsigned int regno, bool interrupt_handler);
 static int const_int_cost (rtx);
 static bool m68k_rtx_costs (rtx, int, int, int *);
+static bool m68k_cannot_force_const_mem (rtx); /* (TIGCC 20050424) */
+
+static int comp_m68k_type_attributes (tree, tree);
+static int comp_amigaos_type_attributes (tree, tree);
+static tree m68k_handle_stkparm_attribute (tree *, tree, tree, int, bool *);
+static tree m68k_handle_regparm_attribute (tree *, tree, tree, int, bool *);
 
 
 /* Specify the identification number of the library being built */
 const char *m68k_library_id_string = "_current_shared_library_a5_offset_";
+/* Specify number of registers for integer, pointer and float arguments.  */
+const char *m68k_regparm_string;
+/* Specify number of registers for integer, pointer and float arguments.  */
+int m68k_regparm;
 
 /* Nonzero if the last compare/test insn had FP operands.  The
    sCC expanders peek at this to determine what to do for the
@@ -133,6 +148,8 @@
 int m68k_last_compare_had_fp_operands;
 
 /* Initialize the GCC target structure.  */
+#undef TARGET_COMP_TYPE_ATTRIBUTES
+#define TARGET_COMP_TYPE_ATTRIBUTES comp_amigaos_type_attributes
 
 #if INT_OP_GROUP == INT_OP_DOT_WORD
 #undef TARGET_ASM_ALIGNED_HI_OP
@@ -186,15 +203,35 @@
 #undef TARGET_ATTRIBUTE_TABLE
 #define TARGET_ATTRIBUTE_TABLE m68k_attribute_table
 
+/* Pass the right values to functions whose prototypes contain "char"
+   or "short". */
+#if 0
 #undef TARGET_PROMOTE_PROTOTYPES
 #define TARGET_PROMOTE_PROTOTYPES hook_bool_tree_true
+#endif /* 0 */
 
 #undef TARGET_STRUCT_VALUE_RTX
 #define TARGET_STRUCT_VALUE_RTX m68k_struct_value_rtx
 
+#undef TARGET_ASM_FILE_START
+#define TARGET_ASM_FILE_START m68k_asm_file_start
+
+/* (TIGCC 20050424) Everything which is not a CONST_DOUBLE has no business of
+                    being in the constant pool. This is especially valid for
+                    expressions containing relocations. -- Kevin Kofler */
+#undef TARGET_CANNOT_FORCE_CONST_MEM
+#define TARGET_CANNOT_FORCE_CONST_MEM m68k_cannot_force_const_mem
+
 static const struct attribute_spec m68k_attribute_table[] =
 {
   /* { name, min_len, max_len, decl_req, type_req, fn_type_req, handler } */
+  /* The stkparm attribute means a function takes its parameters on the stack
+     (AMS calling convention). */
+  { "stkparm",   0, 0, false, true,  true,  m68k_handle_stkparm_attribute },
+  /* The regparm attribute means a function takes its parameters in registers.
+     Its optional argument specifies the maximum number of arguments to be
+     passed in each category of registers (data registers, address registers). */
+  { "regparm",   0, 1, false, true,  true,  m68k_handle_regparm_attribute },
   { "interrupt_handler", 0, 0, true,  false, false, m68k_handle_fndecl_attribute },
   { NULL,                0, 0, false, false, false, NULL }
 };
@@ -314,6 +351,19 @@
 void
 override_options (void)
 {
+   /* Validate -mregparm and -mregparm= value.  */
+   if (m68k_regparm_string)
+     {
+       m68k_regparm = atoi (m68k_regparm_string);
+       if (m68k_regparm < 1 || m68k_regparm > M68K_MAX_REGPARM)
+ 	error ("-mregparm=%d is not between 1 and %d",
+ 	       m68k_regparm, M68K_MAX_REGPARM);
+       target_flags |= MASK_REGPARM;
+     }
+   else
+     if (TARGET_REGPARM)
+       m68k_regparm = M68K_DEFAULT_REGPARM;
+
   /* Sanity check to ensure that msep-data and mid-sahred-library are not
    * both specified together.  Doing so simply doesn't make sense.
    */
@@ -349,6 +399,116 @@
   SUBTARGET_OVERRIDE_OPTIONS;
 }
 
+/* Handle a "stkparm" attribute;
+   arguments as in struct attribute_spec.handler. */
+static tree
+m68k_handle_stkparm_attribute (tree *node, tree name, tree args ATTRIBUTE_UNUSED,
+                               int flags ATTRIBUTE_UNUSED, bool *no_add_attrs)
+{
+  if (lookup_attribute ("regparm", TYPE_ATTRIBUTES (*node)))
+  {
+    error ("`regparm' and `stkparm' are mutually exclusive");
+    *no_add_attrs = true;
+  }
+
+  if (TREE_CODE (*node) != FUNCTION_TYPE
+      && TREE_CODE (*node) != METHOD_TYPE
+      && TREE_CODE (*node) != FIELD_DECL
+      && TREE_CODE (*node) != TYPE_DECL)
+    {
+      warning ("`%s' attribute only applies to functions",
+	       IDENTIFIER_POINTER (name));
+      *no_add_attrs = true;
+    }
+
+  return NULL_TREE;
+}
+
+/* Handle a "regparm" attribute;
+   arguments as in struct attribute_spec.handler. */
+static tree
+m68k_handle_regparm_attribute (tree *node, tree name, tree args,
+                               int flags ATTRIBUTE_UNUSED, bool *no_add_attrs)
+{
+  if (lookup_attribute ("stkparm", TYPE_ATTRIBUTES (*node)))
+  {
+    error ("`regparm' and `stkparm' are mutually exclusive");
+    *no_add_attrs = true;
+  }
+
+  if (TREE_CODE (*node) != FUNCTION_TYPE
+      && TREE_CODE (*node) != METHOD_TYPE
+      && TREE_CODE (*node) != FIELD_DECL
+      && TREE_CODE (*node) != TYPE_DECL)
+    {
+      warning ("`%s' attribute only applies to functions",
+	       IDENTIFIER_POINTER (name));
+      *no_add_attrs = true;
+    }
+  else
+    {
+      /* 'regparm' accepts one optional argument - number of registers per
+         single class (data, address) that should be used to pass arguments. */
+      if (args && TREE_CODE (args) == TREE_LIST)
+      {
+        tree numofregs = TREE_VALUE (args);
+        if (numofregs)
+          if (TREE_CODE (numofregs) != INTEGER_CST
+              || TREE_INT_CST_HIGH (numofregs)
+              || TREE_INT_CST_LOW (numofregs) < 1
+              || TREE_INT_CST_LOW (numofregs) > M68K_MAX_REGPARM)
+          {
+            error ("invalid argument to `regparm' attribute");
+       	    *no_add_attrs = true;
+          }
+      }
+    }
+
+  return NULL_TREE;
+}
+
+/* Return zero if the attributes on TYPE1 and TYPE2 are incompatible,
+   one if they are compatible, and two if they are nearly compatible
+   (which causes a warning to be generated). */
+
+int
+comp_m68k_type_attributes (tree type1, tree type2)
+{
+  /* Functions or methods are incompatible if they specify mutually
+     exclusive ways of passing arguments.  */
+  if (TREE_CODE (type1) == FUNCTION_TYPE || TREE_CODE (type1) == METHOD_TYPE)
+    {
+      tree arg1, arg2;
+      if (!! lookup_attribute ("stkparm", TYPE_ATTRIBUTES (type1)) !=
+	     !! lookup_attribute ("stkparm", TYPE_ATTRIBUTES (type2))
+	  || !! lookup_attribute ("regparm", TYPE_ATTRIBUTES (type1)) !=
+	     !! lookup_attribute ("regparm", TYPE_ATTRIBUTES (type2)))
+	return 0; /* 'regparm' and 'stkparm' are mutually exclusive.  */
+
+      arg1 = lookup_attribute ("regparm", TYPE_ATTRIBUTES (type1));
+      arg2 = lookup_attribute ("regparm", TYPE_ATTRIBUTES (type2));
+      if (arg1 && arg2)
+	{
+	  int num1 = 0, num2 = 0;
+	  if (TREE_VALUE (arg1) && TREE_CODE (TREE_VALUE (arg1)) == TREE_LIST)
+	    {
+	      tree numofregs = TREE_VALUE (TREE_VALUE (arg1));
+	      if (numofregs)
+		num1 = TREE_INT_CST_LOW (numofregs);
+	    }
+	  if (TREE_VALUE (arg2) && TREE_CODE (TREE_VALUE (arg2)) == TREE_LIST)
+	    {
+	      tree numofregs = TREE_VALUE (TREE_VALUE (arg2));
+	      if (numofregs)
+		num2 = TREE_INT_CST_LOW (numofregs);
+	    }
+	  if (num1 != num2)
+	    return 0; /* Different numbers, or no number in one type.  */
+	}
+    }
+  return 1;
+}
+
 /* Return nonzero if FUNC is an interrupt function as specified by the
    "interrupt_handler" attribute.  */
 static bool
@@ -464,6 +624,11 @@
 static bool
 m68k_save_reg (unsigned int regno, bool interrupt_handler)
 {
+  /* (TIGCC 20050208) Handle OPTIMIZE_ROM_CALLS. Register #13 is %a5. */
+  if (interrupt_handler && regno == 13 && global_regs[13]
+      && cpp_defined (parse_in, "OPTIMIZE_ROM_CALLS", 18))
+    return true;
+
   if (flag_pic && regno == PIC_OFFSET_TABLE_REGNUM)
     {
       if (current_function_uses_pic_offset_table)
@@ -603,7 +768,8 @@
 
       if (dwarf2out_do_frame ())
 	{
-	  cfa_offset += current_frame.size + 4;
+	  /* (TIGCC 20050407) This +4 seems wrong from my tests. */
+	  cfa_offset += current_frame.size /*+ 4*/;
 	  dwarf2out_def_cfa ("", STACK_POINTER_REGNUM, cfa_offset);
 	}
     } /* !frame_pointer_needed */
@@ -724,6 +890,11 @@
 	    }
 	}
     }
+
+  /* (TIGCC 20050208) Handle OPTIMIZE_ROM_CALLS. Register #13 is %a5. */
+  if (global_regs[13] && m68k_interrupt_function_p (current_function_decl)
+      && cpp_defined (parse_in, "OPTIMIZE_ROM_CALLS", 18))
+    asm_fprintf (stream, "\tmove.l 200.w,%%a5\n");
 }
 
 /* Return true if this function's epilogue can be output as RTL.  */
@@ -763,9 +934,11 @@
     insn = prev_nonnote_insn (insn);
   if (insn && GET_CODE (insn) == BARRIER)
     {
+#if 0 /* (TIGCC 20050206) */
       /* Output just a no-op so that debuggers don't get confused
 	 about which function the pc is in at this address.  */
       fprintf (stream, "\tnop\n");
+#endif /* 0 */
       return;
     }
 
@@ -1054,8 +1227,17 @@
        * We'll use the -Os command-line flag to decide which to generate.
        * Both sequences take the same time to execute on the ColdFire.
        */
+/* (TIGCC 20040222, 20050204) No long branches please... */
+/* (TIGCC 20050209) FIXME: This should really be handled fully in one place.
+                           Currently, part of this logic is in the patching code
+                           and part is in GCC. It should be all in GCC IMHO. */
+  else if (TARGET_PCREL && GET_CODE (dest) == MEM
+           && GET_CODE (XEXP (dest, 0)) == SYMBOL_REF
+           && (!strncmp(XSTR (XEXP (dest, 0), 0),"_ROM_CALL_",10)
+               || !strncmp(XSTR (XEXP (dest, 0), 0),"_RAM_CALL_",10)))
+    out = "jbsr %o0";
   else if (TARGET_PCREL)
-    out = "bsr.l %o0";
+    out = "bsr %o0";
   else if ((flag_pic == 1) || TARGET_68020)
 #if defined(USE_GAS)
     out = "bsr.l %0@PLTPC";
@@ -1457,11 +1639,11 @@
 
 typedef enum { MOVL, SWAP, NEGW, NOTW, NOTB, MOVQ, MVS, MVZ } CONST_METHOD;
 
-static CONST_METHOD const_method (rtx);
+CONST_METHOD const_method (rtx);
 
 #define USE_MOVQ(i)	((unsigned)((i) + 128) <= 255)
 
-static CONST_METHOD
+CONST_METHOD
 const_method (rtx constant)
 {
   int i;
@@ -1563,10 +1745,15 @@
        for add and the time for shift, taking away a little more because
        sometimes move insns are needed.  */
     /* div?.w is relatively cheaper on 68000 counted in COSTS_N_INSNS terms.  */
+    /* (TIGCC 20030705) Decrease multiplication/division cost under -Os, so that
+                        muls/divs/divu gets preferred over large expansions of
+                        shifts & adds.
+                        -- Kevin Kofler */
 #define MULL_COST (TARGET_68060 ? 2 : TARGET_68040 ? 5 : (TARGET_COLDFIRE && !TARGET_5200) ? 3 : TARGET_COLDFIRE ? 10 : 13)
-#define MULW_COST (TARGET_68060 ? 2 : TARGET_68040 ? 3 : TARGET_68020 ? 8 : \
-			(TARGET_COLDFIRE && !TARGET_5200) ? 2 : 5)
-#define DIVW_COST (TARGET_68020 ? 27 : TARGET_CF_HWDIV ? 11 : 12)
+#define MULW_COST (optimize_size ? 3 : (TARGET_68060 ? 2 : TARGET_68040 ? 3 : TARGET_68020 ? 8 : \
+			(TARGET_COLDFIRE && !TARGET_5200) ? 2 : 5))
+#define DIVW_COST (optimize_size ? 3 : (TARGET_68020 ? 27 : TARGET_CF_HWDIV ? 11 : 12))
+#define UDIVW_COST (optimize_size ? 6 : (TARGET_68020 ? 27 : TARGET_CF_HWDIV ? 11 : 12))
 
     case PLUS:
       /* An lea costs about three times as much as a simple add.  */
@@ -1597,11 +1784,15 @@
         {
 	  if (GET_CODE (XEXP (x, 1)) == CONST_INT)
 	    {
+/* (TIGCC 20030705) shifts costs under -Os are instruction counts, not cycle counts -- Kevin Kofler */ \
+/* (TIGCC 20050210) lsl #2 is cheaper than 2 adds even when optimizing for speed.
+                    This ugly hack (making long shifts "cost less" than word
+                    shifts) accounts for that. */ \
 	      if (INTVAL (XEXP (x, 1)) < 16)
-	        *total = COSTS_N_INSNS (2) + INTVAL (XEXP (x, 1)) / 2;
+	        *total = COSTS_N_INSNS (2) + INTVAL (XEXP (x, 1)) / (optimize_size ? 9 : GET_MODE (x) == SImode ? 3 : 2);
 	      else
 	        /* We're using clrw + swap for these cases.  */
-	        *total = COSTS_N_INSNS (4) + (INTVAL (XEXP (x, 1)) - 16) / 2;
+	        *total = COSTS_N_INSNS (4) + (INTVAL (XEXP (x, 1)) - 16) / (optimize_size ? 9 : GET_MODE (x) == SImode ? 3 : 2);
 	    }
 	  else
 	    *total = COSTS_N_INSNS (10); /* worst case */
@@ -1634,10 +1825,10 @@
         *total = COSTS_N_INSNS (MULL_COST);
       return true;
 
+/* (TIGCC 20030705) distinguish signed vs. unsigned division */ \
+/* - ext is cheaper than the unsigned equivalent -- Kevin Kofler */ \
     case DIV:
-    case UDIV:
     case MOD:
-    case UMOD:
       if (GET_MODE (x) == QImode || GET_MODE (x) == HImode)
         *total = COSTS_N_INSNS (DIVW_COST);	/* div.w */
       else if (TARGET_CF_HWDIV)
@@ -1646,6 +1837,16 @@
 	*total = COSTS_N_INSNS (43);		/* div.l */
       return true;
 
+    case UDIV:							\
+    case UMOD:							\
+      if (GET_MODE (x) == QImode || GET_MODE (x) == HImode)
+        *total = COSTS_N_INSNS (UDIVW_COST);	/* div.w */
+      else if (TARGET_CF_HWDIV)
+        *total = COSTS_N_INSNS (18);
+      else
+	*total = COSTS_N_INSNS (43);		/* div.l */
+      return true;
+
     default:
       return false;
     }
@@ -1862,6 +2063,24 @@
   return "move%.b %1,%0";
 }
 
+static const char *
+output_move_himode_const (rtx *operands)
+{
+  if (operands[1] == const0_rtx
+      && (DATA_REG_P (operands[0])
+	  || GET_CODE (operands[0]) == MEM)
+      /* clr insns on 68000 read before writing.
+	 This isn't so on the 68010, but we have no TARGET_68010.  */
+      && ((TARGET_68020 || TARGET_5200)
+	  || !(GET_CODE (operands[0]) == MEM
+	       && MEM_VOLATILE_P (operands[0]))))
+    return "clr%.w %0";
+  else if (operands[1] == const0_rtx
+	   && ADDRESS_REG_P (operands[0]))
+    return "sub%.w %0,%0";
+  return "move%.w %1,%0";
+}
+
 const char *
 output_move_stricthi (rtx *operands)
 {
@@ -1886,6 +2105,17 @@
   return "move%.b %1,%0";
 }
 
+/* (TIGCC) Return the best assembler insn template
+   for moving operands[1] into operands[0] as a halfword.  */
+
+static const char *
+halfsinglemove_string (rtx *operands)
+{
+  if (GET_CODE (operands[1]) == CONST_INT)
+    return output_move_himode_const (operands);
+  return "move%.w %1,%0";
+}
+
 /* Return the best assembler insn template
    for moving operands[1] into operands[0] as a fullword.  */
 
@@ -1962,10 +2192,14 @@
       operands[0] = XEXP (XEXP (operands[0], 0), 0);
       if (size == 12)
         output_asm_insn ("sub%.l #12,%0", operands);
+      else if (size == 10)
+        output_asm_insn ("sub%.l #10,%0", operands);
       else
         output_asm_insn ("subq%.l #8,%0", operands);
-      if (GET_MODE (operands[1]) == XFmode)
+      if (GET_MODE (operands[0]) == XFmode)
 	operands[0] = gen_rtx_MEM (XFmode, operands[0]);
+      else if (GET_MODE (operands[0]) == BFmode)
+	operands[0] = gen_rtx_MEM (BFmode, operands[0]);
       else if (GET_MODE (operands[0]) == DFmode)
 	operands[0] = gen_rtx_MEM (DFmode, operands[0]);
       else
@@ -1977,10 +2211,14 @@
       operands[1] = XEXP (XEXP (operands[1], 0), 0);
       if (size == 12)
         output_asm_insn ("sub%.l #12,%1", operands);
+      else if (size == 10)
+        output_asm_insn ("sub%.l #10,%1", operands);
       else
         output_asm_insn ("subq%.l #8,%1", operands);
       if (GET_MODE (operands[1]) == XFmode)
 	operands[1] = gen_rtx_MEM (XFmode, operands[1]);
+      else if (GET_MODE (operands[1]) == BFmode)
+	operands[1] = gen_rtx_MEM (BFmode, operands[1]);
       else if (GET_MODE (operands[1]) == DFmode)
 	operands[1] = gen_rtx_MEM (DFmode, operands[1]);
       else
@@ -2016,7 +2254,7 @@
       else if (optype0 == OFFSOP)
 	{
 	  middlehalf[0] = adjust_address (operands[0], SImode, 4);
-	  latehalf[0] = adjust_address (operands[0], SImode, size - 4);
+	  latehalf[0] = adjust_address (operands[0], SImode, 8);
 	}
       else
 	{
@@ -2032,7 +2270,7 @@
       else if (optype1 == OFFSOP)
 	{
 	  middlehalf[1] = adjust_address (operands[1], SImode, 4);
-	  latehalf[1] = adjust_address (operands[1], SImode, size - 4);
+	  latehalf[1] = adjust_address (operands[1], SImode, 8);
 	}
       else if (optype1 == CNSTOP)
 	{
@@ -2060,8 +2298,66 @@
 	  latehalf[1] = operands[1];
 	}
     }
-  else
-    /* size is not 12: */
+  else if (size == 10)
+    {
+      if (optype0 == REGOP)
+	{
+	  latehalf[0] = gen_rtx_REG (HImode, REGNO (operands[0]) + 2);
+	  middlehalf[0] = gen_rtx_REG (SImode, REGNO (operands[0]) + 1);
+	}
+      else if (optype0 == OFFSOP)
+	{
+	  middlehalf[0] = adjust_address (operands[0], SImode, 4);
+	  latehalf[0] = adjust_address (operands[0], SImode, 8);
+	}
+      else
+	{
+	  middlehalf[0] = operands[0];
+	  latehalf[0] = operands[0];
+	}
+
+      if (optype1 == REGOP)
+	{
+	  latehalf[1] = gen_rtx_REG (HImode, REGNO (operands[1]) + 2);
+	  middlehalf[1] = gen_rtx_REG (SImode, REGNO (operands[1]) + 1);
+	}
+      else if (optype1 == OFFSOP)
+	{
+	  middlehalf[1] = adjust_address (operands[1], SImode, 4);
+	  latehalf[1] = adjust_address (operands[1], SImode, 8);
+	}
+      else if (optype1 == CNSTOP)
+	{
+	  if (GET_CODE (operands[1]) == CONST_DOUBLE)
+	    {
+	      REAL_VALUE_TYPE r;
+	      long l[3];
+
+	      abort ();
+	      REAL_VALUE_FROM_CONST_DOUBLE (r, operands[1]);
+	      REAL_VALUE_TO_TARGET_LONG_DOUBLE (r, l);
+	      operands[1] = GEN_INT (l[0]);
+	      middlehalf[1] = GEN_INT (l[1]);
+	      latehalf[1] = GEN_INT (l[2]);
+	    }
+	  else if (CONSTANT_P (operands[1]))
+	    {
+	      /* actually, no non-CONST_DOUBLE constant should ever
+		 appear here.  */
+	      abort ();
+	      if (GET_CODE (operands[1]) == CONST_INT && INTVAL (operands[1]) < 0)
+		latehalf[1] = constm1_rtx;
+	      else
+		latehalf[1] = const0_rtx;
+	    }
+	}
+      else
+	{
+	  middlehalf[1] = operands[1];
+	  latehalf[1] = operands[1];
+	}
+    }
+  else    /* size is neither 12 or 10: */
     {
       if (optype0 == REGOP)
 	latehalf[0] = gen_rtx_REG (SImode, REGNO (operands[0]) + 1);
@@ -2086,7 +2382,16 @@
   if (optype0 == PUSHOP
       && REGNO (XEXP (XEXP (operands[0], 0), 0)) == STACK_POINTER_REGNUM
       && reg_overlap_mentioned_p (stack_pointer_rtx, operands[1]))
+  {
+    if (size==10) {
+      /* (TIGCC 20040219) The above is not quite right for size==10. What we
+         have to do here is: (1) move.w operands[1]+8,-(%sp);
+         (2) move.l operands[1]+6,-(%sp); (3) move.l operands[1]+6,-(%sp).
+         -- Kevin Kofler */
+      operands[1] = middlehalf[1] = adjust_address (operands[1], SImode, 6);
+    } else
     operands[1] = middlehalf[1] = latehalf[1];
+  }
 
   /* For (set (reg:DI N) (mem:DI ... (reg:SI N) ...)),
      if the upper part of reg N does not appear in the MEM, arrange to
@@ -2114,6 +2419,12 @@
 	      middlehalf[1] = adjust_address (operands[1], DImode, size - 8);
 	      latehalf[1] = adjust_address (operands[1], DImode, size - 4);
 	    }
+	  else if( GET_MODE (operands[1]) == BFmode )
+	    {
+	      operands[1] = gen_rtx_MEM (BFmode, latehalf[0]);
+	      middlehalf[1] = adjust_address (operands[1], DImode, 4);
+	      latehalf[1] = adjust_address (operands[1], DImode, 8);
+	    }
 	  else
 	    {
 	      operands[1] = gen_rtx_MEM (DImode, latehalf[0]);
@@ -2143,6 +2454,30 @@
 	  output_asm_insn (singlemove_string (middlehalf), middlehalf);
 	  return "";
 	}
+      else if (size == 10
+	       && reg_overlap_mentioned_p (middlehalf[0],
+					   XEXP (operands[1], 0)))
+	{
+	  /* Check for two regs used by both source and dest.
+	     Note that this can't happen if the dest is all data regs.
+	     It can happen if the dest is d6, d7, a0.
+	     But in that case, latehalf is an addr reg, so
+	     the code at compadr does ok.  */
+
+	  if (reg_overlap_mentioned_p (testlow, XEXP (operands[1], 0))
+	      || reg_overlap_mentioned_p (latehalf[0], XEXP (operands[1], 0)))
+	    goto compadr;
+
+	  /* JRV says this can't happen: */
+	  if (addreg0 || addreg1)
+	    abort ();
+
+	  /* Only the middle reg conflicts; simply put it last. */
+	  output_asm_insn (singlemove_string (operands), operands);
+	  output_asm_insn (halfsinglemove_string (latehalf), latehalf);
+	  output_asm_insn (singlemove_string (middlehalf), middlehalf);
+	  return "";
+	}
       else if (reg_overlap_mentioned_p (testlow, XEXP (operands[1], 0)))
 	/* If the low half of dest is mentioned in the source memory
 	   address, the arrange to emit the move late half first.  */
@@ -2166,21 +2501,24 @@
       /* Make any unoffsettable addresses point at high-numbered word.  */
       if (addreg0)
 	{
-	  if (size == 12)
+	  if (size == 12 || size == 10)
 	    output_asm_insn ("addq%.l #8,%0", &addreg0);
 	  else
 	    output_asm_insn ("addq%.l #4,%0", &addreg0);
 	}
       if (addreg1)
 	{
-	  if (size == 12)
+	  if (size == 12 || size == 10)
 	    output_asm_insn ("addq%.l #8,%0", &addreg1);
 	  else
 	    output_asm_insn ("addq%.l #4,%0", &addreg1);
 	}
 
       /* Do that word.  */
-      output_asm_insn (singlemove_string (latehalf), latehalf);
+      if (size == 10)
+        output_asm_insn (halfsinglemove_string (latehalf), latehalf);
+      else
+        output_asm_insn (singlemove_string (latehalf), latehalf);
 
       /* Undo the adds we just did.  */
       if (addreg0)
@@ -2188,7 +2526,7 @@
       if (addreg1)
 	output_asm_insn ("subq%.l #4,%0", &addreg1);
 
-      if (size == 12)
+      if (size == 12 || size == 10)
 	{
 	  output_asm_insn (singlemove_string (middlehalf), middlehalf);
 	  if (addreg0)
@@ -2206,7 +2544,7 @@
   output_asm_insn (singlemove_string (operands), operands);
 
   /* Do the middle one of the three words for long double */
-  if (size == 12)
+  if (size == 12 || size == 10)
     {
       if (addreg0)
 	output_asm_insn ("addq%.l #4,%0", &addreg0);
@@ -2223,19 +2561,22 @@
     output_asm_insn ("addq%.l #4,%0", &addreg1);
 
   /* Do that word.  */
-  output_asm_insn (singlemove_string (latehalf), latehalf);
+  if (size == 10)
+    output_asm_insn (halfsinglemove_string (latehalf), latehalf);
+  else
+    output_asm_insn (singlemove_string (latehalf), latehalf);
 
   /* Undo the adds we just did.  */
   if (addreg0)
     {
-      if (size == 12)
+      if (size == 12 || size == 10)
         output_asm_insn ("subq%.l #8,%0", &addreg0);
       else
         output_asm_insn ("subq%.l #4,%0", &addreg0);
     }
   if (addreg1)
     {
-      if (size == 12)
+      if (size == 12 || size == 10)
         output_asm_insn ("subq%.l #8,%0", &addreg1);
       else
         output_asm_insn ("subq%.l #4,%0", &addreg1);
@@ -2565,6 +2906,8 @@
 int
 floating_exact_log2 (rtx x)
 {
+abort();
+#if 0
   REAL_VALUE_TYPE r, r1;
   int exp;
 
@@ -2579,6 +2922,7 @@
     return exp;
 
   return 0;
+#endif /* 0 */
 }
 
 /* A C compound statement to output to stdio stream STREAM the
@@ -2625,6 +2969,8 @@
    'x' for float insn (print a CONST_DOUBLE as a float rather than in hex),
        or print pair of registers as rx:ry.
 
+(TIGCC 20040222) 'A' like 'o', but for addresses.
+
    */
 
 void
@@ -2665,6 +3011,14 @@
 		  && TARGET_PCREL);
       output_addr_const (file, XEXP (op, 0));
     }
+  else if (letter == 'A') /* (TIGCC 20040222) */
+    {
+      if (TARGET_PCREL) {
+        target_flags&=~MASK_PCREL; /* ugly hack, but works */
+        print_operand_address(file,op);
+        target_flags|=MASK_PCREL;
+      } else print_operand_address(file,op);
+    }
   else if (GET_CODE (op) == REG)
     {
       if (letter == 'R')
@@ -2677,13 +3031,24 @@
   else if (GET_CODE (op) == MEM)
     {
       output_address (XEXP (op, 0));
+      /* TIGCC Patch: This is a very bad try to implement addresses relative to a register.
+         Julien Muchembled says this should work.
+         At least it should if only one file is used.
+         (TIGCC 20040808) Added CONST. A MEM(CONST) is used for sym+const addressing. This
+                          needs to be made reg-relative too. -- Kevin Kofler  */
+      if (TARGET_REG_RELATIVE && (GET_CODE (XEXP (op, 0)) == SYMBOL_REF || GET_CODE (XEXP (op, 0)) == LABEL_REF || GET_CODE (XEXP (op, 0)) == CODE_LABEL || GET_CODE (XEXP (op, 0)) == CONST))
+        fprintf (file, "-__relation(%%%s)", TARGET_RELATION_REG);
+      else
+	{
       if (letter == 'd' && ! TARGET_68020
 	  && CONSTANT_ADDRESS_P (XEXP (op, 0))
 	  && !(GET_CODE (XEXP (op, 0)) == CONST_INT
 	       && INTVAL (XEXP (op, 0)) < 0x8000
 	       && INTVAL (XEXP (op, 0)) >= -0x8000))
 	fprintf (file, MOTOROLA ? ".l" : ":l");
+	}
     }
+#if 0
   else if (GET_CODE (op) == CONST_DOUBLE && GET_MODE (op) == SFmode)
     {
       REAL_VALUE_TYPE r;
@@ -2702,6 +3067,7 @@
       REAL_VALUE_FROM_CONST_DOUBLE (r, op);
       ASM_OUTPUT_DOUBLE_OPERAND (file, r);
     }
+#endif /* 0 */
   else
     {
       /* Use `print_operand_address' instead of `output_addr_const'
@@ -3199,6 +3565,166 @@
   return "or%.l %2,%0";
 }
 
+/* Argument-passing support functions.  */
+
+/* Initialize a variable CUM of type CUMULATIVE_ARGS
+   for a call to a function whose data type is FNTYPE.
+   For a library call, FNTYPE is 0.  */
+
+static void
+m68k_init_cumulative_args (CUMULATIVE_ARGS *cum, tree fntype, tree fndecl)
+{
+  cum->last_arg_reg = -1;
+  cum->regs_already_used = 0;
+  if (fntype)
+    {
+      if (lookup_attribute ("stkparm", TYPE_ATTRIBUTES (fntype)))
+	cum->num_of_regs = 0;
+      else
+	{
+	  tree ratree = lookup_attribute ("regparm", TYPE_ATTRIBUTES (fntype));
+	  if (ratree)
+	    {
+	      cum->num_of_regs = m68k_regparm ? m68k_regparm
+					      : M68K_DEFAULT_REGPARM;
+	      if (TREE_VALUE (ratree)
+		  && TREE_CODE (TREE_VALUE (ratree)) == TREE_LIST)
+		{
+		  tree num_of_regs = TREE_VALUE (TREE_VALUE (ratree));
+		  cum->num_of_regs =
+		    num_of_regs ? TREE_INT_CST_LOW (num_of_regs) :
+		      (m68k_regparm ? m68k_regparm : M68K_DEFAULT_REGPARM);
+		}
+	    }
+/* (TIGCC 20050208) Use register calling convention for local functions when
+                    possible. Partially copied from i386.c. */
+	  else if (fndecl && flag_unit_at_a_time)
+	    {
+	      struct cgraph_local_info *i = cgraph_local_info (fndecl);
+	      if (i && i->local)
+	        {
+	          cum->num_of_regs = m68k_regparm ? m68k_regparm
+	                             : M68K_DEFAULT_REGPARM;
+	        }
+	      else
+	        cum->num_of_regs = m68k_regparm;
+	    }
+	  else
+	    cum->num_of_regs = m68k_regparm;
+	}
+    }
+  else /* Libcall.  */
+    cum->num_of_regs = 0;
+
+  if (cum->num_of_regs)
+    {
+      /* If this is a vararg call, put all arguments on stack.  */
+      tree param, next_param;
+      for (param = TYPE_ARG_TYPES (fntype); param; param = next_param)
+	{
+	  next_param = TREE_CHAIN (param);
+	  if (!next_param && TREE_VALUE (param) != void_type_node)
+	    cum->num_of_regs = 0;
+	}
+    }
+
+#if ! defined (PCC_STATIC_STRUCT_RETURN) && defined (M68K_STRUCT_VALUE_REGNUM)
+  /* If return value is a structure, and we pass the buffer address in a
+     register, we can't use this register for our own purposes.
+     FIXME: Something similar would be useful for static chain.  */
+  if (fntype && aggregate_value_p (TREE_TYPE (fntype), fntype))
+    cum->regs_already_used |= (1 << M68K_STRUCT_VALUE_REGNUM);
+#endif
+}
+
+/* Update the data in CUM to advance over an argument.  */
+
+static void
+m68k_function_arg_advance (CUMULATIVE_ARGS *cum)
+{
+  if (cum->last_arg_reg != -1)
+    {
+      int count;
+      for (count = 0; count < cum->last_arg_len; count++)
+	cum->regs_already_used |= (1 << (cum->last_arg_reg + count));
+      cum->last_arg_reg = -1;
+    }
+}
+
+/* Define where to put the arguments to a function.
+   Value is zero to push the argument on the stack,
+   or a hard register in which to store the argument.
+
+   MODE is the argument's machine mode.
+   TYPE is the data type of the argument (as a tree).
+   This is null for libcalls where that information may
+    not be available.
+   CUM is a variable of type CUMULATIVE_ARGS which gives info about
+    the preceding args and about the function being called.  */
+
+static struct rtx_def *
+m68k_function_arg (CUMULATIVE_ARGS *cum, enum machine_mode mode, tree type)
+{
+  if (cum->num_of_regs)
+    {
+      int regbegin = -1, altregbegin = -1, len;
+
+      /* FIXME: The last condition below is a workaround for a bug.  */
+      if (TARGET_68881 && FLOAT_MODE_P (mode) &&
+	  GET_MODE_UNIT_SIZE (mode) <= 12 &&
+	  (GET_MODE_CLASS (mode) != MODE_COMPLEX_FLOAT || mode == SCmode))
+	{
+	  regbegin = 16; /* FPx */
+	  len = GET_MODE_NUNITS (mode);
+	}
+      /* FIXME: Two last conditions below are workarounds for bugs.  */
+      else if (INTEGRAL_MODE_P (mode) && mode !=CQImode && mode != CHImode)
+	{
+	  if (POINTER_TYPE_P (type))
+	    regbegin = 8; /* Ax */
+	  else
+	    regbegin = 0; /* Dx */
+	  altregbegin = 8 - regbegin;
+	  len = (GET_MODE_SIZE (mode) + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD;
+	}
+
+      if (regbegin != -1)
+	{
+	  int reg;
+	  long mask;
+
+look_for_reg:
+	  mask = 1 << regbegin;
+	  for (reg = 0; reg < cum->num_of_regs; reg++, mask <<= 1)
+	    if (!(cum->regs_already_used & mask))
+	      {
+		int end;
+		for (end = reg; end < cum->num_of_regs && end < reg + len;
+		     end++, mask <<= 1)
+		  if (cum->regs_already_used & mask)
+		    break;
+		if (end == reg + len)
+		  {
+		    cum->last_arg_reg = reg + regbegin;
+		    cum->last_arg_len = len;
+		    break;
+		  }
+	      }
+
+	  if (reg == cum->num_of_regs && altregbegin != -1)
+	    {
+	      regbegin = altregbegin;
+	      altregbegin = -1;
+	      goto look_for_reg;
+	    }
+	}
+
+      if (cum->last_arg_reg != -1)
+	return gen_rtx_REG (mode, cum->last_arg_reg);
+    }
+  return 0;
+}
+
 const char *
 output_xorsi3 (rtx *operands)
 {
@@ -3243,13 +3769,28 @@
 			     tree decl ATTRIBUTE_UNUSED)
 {
   char flagchar;
-
-  if (flags & SECTION_WRITE)
+  /* (TIGCC 20040725) Constant/string merging flags for TIGCC-extended COFF.
+                      SECTION_STRINGS is abused for the unaligned flag. */
+  const char *xflags = "";
+
+  /* (TIGCC 20040619) Handle BSS sections properly with -fdata-sections.
+                      -- Kevin Kofler*/
+  if ((flags & SECTION_BSS) && !TARGET_NO_BSS)
+    flagchar = 'b';
+  /* (TIGCC 20040620) Handle rodata sections properly with -fdata-sections.
+                      -- Kevin Kofler*/
+  else if ((flags & SECTION_WRITE)
+           || (!TARGET_RODATA_TO_TEXT && !(flags & SECTION_CODE)))
     flagchar = 'd';
   else
     flagchar = 'x';
 
-  fprintf (asm_out_file, "\t.section\t%s,\"%c\"\n", name, flagchar);
+  if (flags & SECTION_MERGE)
+    xflags = (flags & SECTION_STRINGS)?"mu":"m";
+  else if (flags & SECTION_STRINGS)
+    xflags = "u";
+
+  fprintf (asm_out_file, "\t.section\t%s,\"%c%s\"\n", name, flagchar, xflags);
 }
 
 #endif /* M68K_TARGET_COFF */
@@ -3302,7 +3843,7 @@
   if (flag_pic)
     {
       if (TARGET_PCREL)
-	fmt = "bra.l %o0";
+	fmt = "bra %o0"; /* (TIGCC 20040222, 20050204) No long branches please... */
       else if ((flag_pic == 1) || TARGET_68020)
 	{
 	  if (MOTOROLA)
@@ -3377,7 +3918,10 @@
     {
 	/* Address Registers, can't hold bytes, can hold aggregate if
 	   fits in.  */
-	if (GET_MODE_SIZE (mode) == 1)
+	/* (TIGCC 20050924) We can put bytes in address registers on non-Coldfire.
+	   GCC just uses word moves where appropriate. This always worked for us.
+	   -- Kevin Kofler */
+	if (TARGET_COLDFIRE && GET_MODE_SIZE (mode) == 1)
 	  return false;
 	if (regno + GET_MODE_SIZE (mode) / 4 <= 16)
 	  return true;
@@ -3393,3 +3937,127 @@
     }
   return false;
 }
+
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+
+/* Initialize a variable CUM of type CUMULATIVE_ARGS
+   for a call to a function whose data type is FNTYPE.
+   For a library call, FNTYPE is 0.  */
+
+void
+amigaos_init_cumulative_args(CUMULATIVE_ARGS *cum, tree fntype, tree fndecl)
+{
+  m68k_init_cumulative_args(cum, fntype, fndecl);
+
+  if (fntype)
+    cum->formal_type=TYPE_ARG_TYPES(fntype);
+  else /* Call to compiler-support function. */
+    cum->formal_type=0;
+}
+
+/* Update the data in CUM to advance over an argument.  */
+
+void
+amigaos_function_arg_advance(CUMULATIVE_ARGS *cum)
+{
+  m68k_function_arg_advance(cum);
+
+  if (cum->formal_type)
+    cum->formal_type=TREE_CHAIN((tree)cum->formal_type);
+}
+
+/* A C expression that controls whether a function argument is passed
+   in a register, and which register. */
+
+struct rtx_def *
+amigaos_function_arg(CUMULATIVE_ARGS *cum, enum machine_mode mode,
+  tree type)
+{
+  tree asmtree;
+  if (cum->formal_type && TREE_VALUE((tree)cum->formal_type)
+      && (asmtree=lookup_attribute("asm",
+			TYPE_ATTRIBUTES(TREE_VALUE((tree)cum->formal_type)))))
+    {
+      int i;
+#if 0
+      /* See c-decl.c/push_parm_decl for an explanation why this doesn't work.
+       */
+      cum->last_arg_reg=TREE_INT_CST_LOW(TREE_VALUE(TREE_VALUE(asmtree)));
+#else
+      cum->last_arg_reg=TREE_INT_CST_LOW(TREE_VALUE(asmtree));
+#endif
+      cum->last_arg_len=HARD_REGNO_NREGS(cum->last_arg_reg, mode);
+
+      for (i=0; i<cum->last_arg_len; i++)
+	if (cum->regs_already_used & (1 << (cum->last_arg_reg+i)))
+	  {
+	    error("two parameters allocated for one register");
+	    break;
+	  }
+      return gen_rtx_REG (mode, cum->last_arg_reg);
+    }
+  else
+    return (struct rtx_def *)m68k_function_arg(cum, mode, type);
+}
+
+/* Return zero if the attributes on TYPE1 and TYPE2 are incompatible,
+   one if they are compatible, and two if they are nearly compatible
+   (which causes a warning to be generated). */
+
+int
+comp_amigaos_type_attributes(tree type1, tree type2)
+{
+  int ret;
+  if ((ret=comp_m68k_type_attributes(type1, type2))!=1)
+    return ret;
+
+  /* Functions or methods are incompatible if they specify mutually exclusive
+     ways of passing arguments. */
+  if (TREE_CODE(type1)==FUNCTION_TYPE || TREE_CODE(type1)==METHOD_TYPE)
+    {
+      tree arg1, arg2;
+      arg1=TYPE_ARG_TYPES(type1);
+      arg2=TYPE_ARG_TYPES(type2);
+      for (; arg1 && arg2; arg1=TREE_CHAIN(arg1), arg2=TREE_CHAIN(arg2))
+	if (TREE_VALUE(arg1) && TREE_VALUE(arg2))
+	  {
+	    tree asm1, asm2;
+	    asm1=lookup_attribute("asm", TYPE_ATTRIBUTES(TREE_VALUE(arg1)));
+	    asm2=lookup_attribute("asm", TYPE_ATTRIBUTES(TREE_VALUE(arg2)));
+	    if (asm1 && asm2)
+	      {
+		if (TREE_INT_CST_LOW(TREE_VALUE(asm1))!=
+		    TREE_INT_CST_LOW(TREE_VALUE(asm2)))
+		  return 0; /* Two different registers specified. */
+	      }
+	    else
+	      if (asm1 || asm2)
+		return 0; /* "asm" used in only one type. */
+	  }
+    }
+  return 1;
+}
+
+/* end-TIGCC-local (regparms) */
+
+/* (TIGCC) If TARGET_MERGE_SECTIONS is set (on by default), we need an explicit
+   '.text' or '.data' (depending on TARGET_MERGE_TO_DATA) statement at the
+   beginning of the file. */
+
+void m68k_asm_file_start(void)
+{
+	output_file_directive (asm_out_file, main_input_filename);
+	fprintf (asm_out_file, "#NO_APP\n");
+	if (TARGET_REG_RELATIVE)
+		fprintf (asm_out_file, "\t.set __relation,__ld_entry_point_plus_0x8000\n\t.xdef __ref_all___reg_relative_%s\n", TARGET_RELATION_REG);
+	fprintf (asm_out_file, (TARGET_MERGE_SECTIONS?(TARGET_MERGE_TO_DATA?"\t.data\ntigcc_compiled.:\n":"\t.text\ntigcc_compiled.:\n"):"tigcc_compiled.:\n"));
+}
+
+/* (TIGCC 20050424) Everything which is not a CONST_DOUBLE has no business of
+                    being in the constant pool. This is especially valid for
+                    expressions containing relocations. -- Kevin Kofler */
+static bool m68k_cannot_force_const_mem (rtx r)
+{
+  return (GET_CODE (r) != CONST_DOUBLE);
+}
+
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k.h gcc-4.1-20051216-src/gcc/config/m68k/m68k.h
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k.h	2005-07-12 01:32:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k.h	2005-12-19 02:42:39.000000000 +0100
@@ -113,6 +113,10 @@
 /* Set the default.  */
 #define INT_OP_GROUP INT_OP_DOT_WORD
 
+/* Access everything in relation to a specific register */
+#define MASK_REG_RELATIVE	(1<<30)
+#define TARGET_REG_RELATIVE	(target_flags & MASK_REG_RELATIVE)
+
 /* Compile for a CPU32.  A 68020 without bitfields is a good
    heuristic for a CPU32.  */
 #define TARGET_CPU32	(TARGET_68020 && !TARGET_BITFIELD)
@@ -126,6 +130,8 @@
 /* These are meant to be redefined in the host dependent files */
 #define SUBTARGET_OVERRIDE_OPTIONS
 
+extern char TARGET_RELATION_REG[];
+
 /* target machine storage layout */
 
 #define LONG_DOUBLE_TYPE_SIZE 80
@@ -141,7 +147,7 @@
 
 #define UNITS_PER_WORD 4
 
-#define PARM_BOUNDARY (TARGET_SHORT ? 16 : 32)
+#define PARM_BOUNDARY 16
 #define STACK_BOUNDARY 16
 #define FUNCTION_BOUNDARY 16
 #define EMPTY_FIELD_BOUNDARY 16
@@ -175,7 +181,9 @@
 #define FIRST_PSEUDO_REGISTER 25
 
 /* All m68k targets (except AmigaOS) use %a5 as the PIC register  */
-#define PIC_OFFSET_TABLE_REGNUM (flag_pic ? 13 : INVALID_REGNUM)
+/* (TIGCC 20050209) TIGCC doesn't use a PIC register, and besides this was
+                    forgetting the -mpcrel case.  */
+#define PIC_OFFSET_TABLE_REGNUM (INVALID_REGNUM)
 
 /* 1 for registers that have pervasive standard uses
    and are not available for the register allocator.
@@ -375,6 +383,9 @@
    `S' is for operands that satisfy 'm' when -mpcrel is in effect.
    `T' is for operands that satisfy 's' when -mpcrel is not in effect.
    `U' is for register offset addressing.  */
+/* (TIGCC 20040808) Under -freg-relative-an, the same restrictions on 's'/'T' as
+                    for -mpcrel apply. We can't use immediates as labels if
+                    we need to output reg-relative code. -- Kevin Kofler  */
 #define EXTRA_CONSTRAINT(OP,CODE)			\
   (((CODE) == 'S')					\
    ? (TARGET_PCREL					\
@@ -384,7 +395,7 @@
 	  || GET_CODE (XEXP (OP, 0)) == CONST))		\
    : 							\
   (((CODE) == 'T')					\
-   ? ( !TARGET_PCREL 					\
+   ? ( (!TARGET_PCREL && !TARGET_REG_RELATIVE) 					\
       && (GET_CODE (OP) == SYMBOL_REF			\
 	  || GET_CODE (OP) == LABEL_REF			\
 	  || GET_CODE (OP) == CONST))			\
@@ -486,24 +497,59 @@
 
 #define PCC_STATIC_STRUCT_RETURN
 
-/* On the m68k, all arguments are usually pushed on the stack.  */
-#define FUNCTION_ARG_REGNO_P(N) 0
-
-/* On the m68k, this is a single integer, which is a number of bytes
-   of arguments scanned so far.  */
-#define CUMULATIVE_ARGS int
-
-/* On the m68k, the offset starts at 0.  */
-#define INIT_CUMULATIVE_ARGS(CUM, FNTYPE, LIBNAME, INDIRECT, N_NAMED_ARGS) \
- ((CUM) = 0)
+/* Define this if explicit register specification for parameters
+   is supported.  */
+
+#define EXPLICIT_REGPARM
+
+#define FUNCTION_ARG_REGNO_P(N)			\
+  (((N) >= 0 && (N) < M68K_MAX_REGPARM)		\
+   || ((N) >= 8 && (N) < 8 + M68K_MAX_REGPARM)	\
+   || (TARGET_68881 && (N) >= 16 && (N) < 16 + M68K_MAX_REGPARM))
+
+/* On the m68k, this is a structure:
+   num_of_regs: number of data, address and float registers to use for
+     arguments passing (if it's 2, than pass arguments in d0, d1, a0, a1,
+     fp0 and fp1). 0 - pass everything on stack. vararg calls are
+     always passed entirely on stack.
+   regs_already_used: bitmask of the already used registers.
+   last_arg_reg: register number of the most recently passed argument.
+     -1 if passed on stack.
+   last_arg_len: number of registers used by the most recently passed
+     argument.
+   formal_type: formal type of the current argument.
+*/
+
+struct m68k_args
+{
+  int num_of_regs;
+  long regs_already_used;
+  int last_arg_reg;
+  int last_arg_len;
+  void *formal_type;
+};
+
+#define CUMULATIVE_ARGS struct m68k_args
+
+/* Max. number of data, address and float registers to be used for passing
+   integer, pointer and float arguments when TARGET_REGPARM.
+   It's 6, so d0-d5, a0-a5 and fp0-fp5 can be used.  */
+
+#define M68K_MAX_REGPARM 6  /* was 4 in the original patch */
+
+/* The default number of data, address and float registers to use when
+   user specified '-mregparm' switch, not '-mregparm=<value>' option.  */
+
+#define M68K_DEFAULT_REGPARM 2  /* was 2 in the orginial patch */
+
+#define INIT_CUMULATIVE_ARGS(CUM, FNTYPE, LIBNAME, FNDECL, N_NAMED_ARGS) \
+  (amigaos_init_cumulative_args (&(CUM), (FNTYPE), (FNDECL)))
 
 #define FUNCTION_ARG_ADVANCE(CUM, MODE, TYPE, NAMED)	\
- ((CUM) += ((MODE) != BLKmode			\
-	    ? (GET_MODE_SIZE (MODE) + 3) & ~3	\
-	    : (int_size_in_bytes (TYPE) + 3) & ~3))
+  (amigaos_function_arg_advance (&(CUM)))
 
-/* On the m68k all args are always pushed.  */
-#define FUNCTION_ARG(CUM, MODE, TYPE, NAMED) 0
+#define FUNCTION_ARG(CUM, MODE, TYPE, NAMED) \
+  ((struct rtx_def *)amigaos_function_arg (&(CUM), (MODE), (TYPE)))
 
 #define FUNCTION_PROFILER(FILE, LABELNO)  \
   asm_fprintf (FILE, "\tlea %LLP%d,%Ra0\n\tjsr mcount\n", (LABELNO))
@@ -639,7 +685,11 @@
 
 /* Nonzero if the constant value X is a legitimate general operand.
    It is given that X satisfies CONSTANT_P or is a CONST_DOUBLE.  */
-#define LEGITIMATE_CONSTANT_P(X) (GET_MODE (X) != XFmode)
+/* (TIGCC 20040808) If reg-relative, we need to reject "constants" of the #label
+                    or #label+const form. -- Kevin Kofler  */
+
+#define LEGITIMATE_CONSTANT_P(X) (!TARGET_REG_RELATIVE \
+                                  || !pcrel_address (X, VOIDmode))
 
 #ifndef REG_OK_STRICT
 #define PCREL_GENERAL_OPERAND_OK 0
@@ -950,15 +1000,19 @@
 #define ASM_OUTPUT_SKIP(FILE,SIZE)  \
   fprintf (FILE, "\t.skip %u\n", (int)(SIZE))
 
+#ifndef ASM_OUTPUT_COMMON
 #define ASM_OUTPUT_COMMON(FILE, NAME, SIZE, ROUNDED)  \
 ( fputs (".comm ", (FILE)),			\
   assemble_name ((FILE), (NAME)),		\
   fprintf ((FILE), ",%u\n", (int)(ROUNDED)))
+#endif
 
+#ifndef ASM_OUTPUT_LOCAL
 #define ASM_OUTPUT_LOCAL(FILE, NAME, SIZE, ROUNDED)  \
 ( fputs (".lcomm ", (FILE)),			\
   assemble_name ((FILE), (NAME)),		\
   fprintf ((FILE), ",%u\n", (int)(ROUNDED)))
+#endif
 
 /* Output a float value (represented as a C double) as an immediate operand.
    This macro is m68k-specific.  */
@@ -1030,4 +1084,6 @@
 
 /* Variables in m68k.c */
 extern const char *m68k_library_id_string;
+extern const char *m68k_regparm_string;
+extern int m68k_regparm;
 extern int m68k_last_compare_had_fp_operands;
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k.md gcc-4.1-20051216-src/gcc/config/m68k/m68k.md
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k.md	2005-11-22 21:53:08.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k.md	2005-12-18 22:24:36.000000000 +0100
@@ -329,20 +329,22 @@
                  (match_operand:SI 1 "general_src_operand" "mSr,mSa,KTr,Ksr,>")))]
   "!TARGET_COLDFIRE"
 {
+/* (TIGCC 20040222) This used %d0 and %d1 to force absolute addressing, which
+                    doesn't make sense and breaks -mpcrel. -- Kevin Kofler */
   if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)
     return "cmpm%.l %1,%0";
   if (REG_P (operands[1])
       || (!REG_P (operands[0]) && GET_CODE (operands[0]) != MEM))
     {
       cc_status.flags |= CC_REVERSED;
-      return "cmp%.l %d0,%d1";
+      return "cmp%.l %0,%1";
     }
   if (ADDRESS_REG_P (operands[0])
       && GET_CODE (operands[1]) == CONST_INT
       && INTVAL (operands[1]) < 0x8000
       && INTVAL (operands[1]) >= -0x8000)
     return "cmp%.w %1,%0";
-  return "cmp%.l %d1,%d0";
+  return "cmp%.l %1,%0";
 })
 
 (define_insn ""
@@ -360,52 +362,62 @@
   return "cmp%.l %d1,%d0";
 })
 
+;; (TIGCC 20040808) Don't allow source-only operands as the destination in the
+;;                  compare. We need to use nonimmediate_operand, not
+;;                  nonimmediate_src_operand. Otherwise, -mpcrel outputs invalid
+;;                  assembly code. The SImode patterns already got this right.
+;; -- Kevin Kofler
+
 (define_expand "cmphi"
   [(set (cc0)
-        (compare (match_operand:HI 0 "nonimmediate_src_operand" "")
+        (compare (match_operand:HI 0 "nonimmediate_operand" "")
                  (match_operand:HI 1 "general_src_operand" "")))]
   "!TARGET_COLDFIRE"
   "m68k_last_compare_had_fp_operands = 0;")
 
 (define_insn ""
   [(set (cc0)
-        (compare (match_operand:HI 0 "nonimmediate_src_operand" "rnmS,d,n,mS,>")
+        (compare (match_operand:HI 0 "nonimmediate_operand" "rnmS,d,n,mS,>")
                  (match_operand:HI 1 "general_src_operand" "d,rnmS,mS,n,>")))]
   "!TARGET_COLDFIRE"
 {
+/* (TIGCC 20040222) This used %d0 and %d1 to force absolute addressing, which
+                    doesn't make sense and breaks -mpcrel. -- Kevin Kofler */
   if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)
     return "cmpm%.w %1,%0";
   if ((REG_P (operands[1]) && !ADDRESS_REG_P (operands[1]))
       || (!REG_P (operands[0]) && GET_CODE (operands[0]) != MEM))
     {
       cc_status.flags |= CC_REVERSED;
-      return "cmp%.w %d0,%d1";
+      return "cmp%.w %0,%1";
     }
-  return "cmp%.w %d1,%d0";
+  return "cmp%.w %1,%0";
 })
 
 (define_expand "cmpqi"
   [(set (cc0)
-        (compare (match_operand:QI 0 "nonimmediate_src_operand" "")
+        (compare (match_operand:QI 0 "nonimmediate_operand" "")
                  (match_operand:QI 1 "general_src_operand" "")))]
   "!TARGET_COLDFIRE"
   "m68k_last_compare_had_fp_operands = 0;")
 
 (define_insn ""
   [(set (cc0)
-        (compare (match_operand:QI 0 "nonimmediate_src_operand" "dn,dmS,>")
+        (compare (match_operand:QI 0 "nonimmediate_operand" "dn,dmS,>")
                  (match_operand:QI 1 "general_src_operand" "dmS,nd,>")))]
   "!TARGET_COLDFIRE"
 {
+/* (TIGCC 20040222) This used %d0 and %d1 to force absolute addressing, which
+                    doesn't make sense and breaks -mpcrel. -- Kevin Kofler */
   if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)
     return "cmpm%.b %1,%0";
   if (REG_P (operands[1])
       || (!REG_P (operands[0]) && GET_CODE (operands[0]) != MEM))
     {
       cc_status.flags |= CC_REVERSED;
-      return "cmp%.b %d0,%d1";
+      return "cmp%.b %0,%1";
     }
-  return "cmp%.b %d1,%d0";
+  return "cmp%.b %1,%0";
 })
 
 (define_expand "cmpdf"
@@ -693,10 +705,11 @@
 
 ;; Special case of fullword move, where we need to get a non-GOT PIC
 ;; reference into an address register.
+;; (TIGCC 20040808) This is also needed for -freg-relative-an. -- Kevin Kofler
 (define_insn ""
   [(set (match_operand:SI 0 "nonimmediate_operand" "=a<")
         (match_operand:SI 1 "pcrel_address" ""))]
-  "TARGET_PCREL"
+  "TARGET_PCREL || TARGET_REG_RELATIVE"
 {
   if (push_operand (operands[0], SImode))
     return "pea %a1";
@@ -775,13 +788,49 @@
   "TARGET_COLDFIRE"
   "* return output_move_strictqi (operands);")
 
+;; (TIGCC 20050210) Distinguish nonmemory_operand vs. memory_operand here, and
+;;                  optimize pushes from nonmemory_operand to word pushes. We
+;;                  can't do that for memory operands because of odd addresses.
+;;                  The distinction between register_operand and
+;;                  const_int_operand is because of paradoxical subreg
+;;                  technicalities.
+
 (define_expand "pushqi1"
+  [(match_operand:QI 0 "general_operand" "")]
+  "!TARGET_COLDFIRE"
+"{
+  if (const_int_operand (operands[0], QImode))
+    emit_insn (gen_pushqi1_imm (operands[0]));
+  else if (register_operand (operands[0], QImode)) {
+    if (GET_CODE (operands[0]) == SUBREG)
+      emit_insn (gen_pushqi1_reg (SUBREG_REG (operands[0])));
+    else
+      emit_insn (gen_pushqi1_reg (operands[0]));
+  } else
+    emit_insn (gen_pushqi1_mem (operands[0]));
+  DONE;
+}")
+
+(define_expand "pushqi1_mem"
   [(set (reg:SI SP_REG) (plus:SI (reg:SI SP_REG) (const_int -2)))
    (set (mem:QI (plus:SI (reg:SI SP_REG) (const_int 1)))
 	(match_operand:QI 0 "general_operand" ""))]
   "!TARGET_COLDFIRE"
   "")
 
+(define_expand "pushqi1_imm"
+  [(set (mem:HI (pre_dec:SI (reg:SI SP_REG)))
+	(match_operand:HI 0 "const_int_operand" ""))]
+  "!TARGET_COLDFIRE"
+  "")
+
+;; Yes, this is a paradoxical subreg.
+(define_expand "pushqi1_reg"
+  [(set (mem:HI (pre_dec:SI (reg:SI SP_REG)))
+	(subreg:HI (match_operand:QI 0 "register_operand" "") 0))]
+  "!TARGET_COLDFIRE"
+  "")
+
 (define_expand "movsf"
   [(set (match_operand:SF 0 "nonimmediate_operand" "")
 	(match_operand:SF 1 "general_operand" ""))]
@@ -897,6 +946,34 @@
 ;; constants.  Most but not all have output templates that handle constants.
 ;; See also LEGITIMATE_CONSTANT_P.
 
+(define_expand "movbf"
+  ;; SMAP BCD
+  [(set (match_operand:BF 0 "nonimmediate_operand" "")
+	(match_operand:BF 1 "general_operand" ""))]
+  ""
+  "
+{
+  /* We can't rewrite operands during reload.  */
+  if (! reload_in_progress)
+    {
+      if (CONSTANT_P (operands[1]))
+        {
+          operands[1] = force_const_mem (BFmode, operands[1]);
+          if (! memory_address_p (BFmode, XEXP (operands[1], 0)))
+              operands[1] = adjust_address (operands[1], BFmode, 0);
+        }
+      if (flag_pic && TARGET_PCREL)
+        {
+          /* Don't allow writes to memory except via a register; the
+             m68k doesn't consider PC-relative addresses to be writable.  */
+          if (GET_CODE (operands[0]) == MEM
+              && symbolic_operand (XEXP (operands[0], 0), SImode))
+              operands[0] = gen_rtx_MEM (BFmode,
+                                         force_reg (SImode, XEXP (operands[0], 0)));
+        }
+    }
+}")
+ 
 (define_expand "movxf"
   [(set (match_operand:XF 0 "nonimmediate_operand" "")
 	(match_operand:XF 1 "general_operand" ""))]
@@ -963,6 +1040,46 @@
 })
 
 (define_insn ""
+  ;; SMAP BCD
+  [(set (match_operand:BF 0 "nonimmediate_operand" "=rm,rf,&rof<>")
+	(match_operand:BF 1 "nonimmediate_operand" "rf,m,rof<>"))]
+  "! TARGET_68881 && ! TARGET_COLDFIRE"
+{
+  if (FP_REG_P (operands[0]))
+    {
+      if (FP_REG_P (operands[1]))
+	return "fmove%.x %1,%0";
+      if (REG_P (operands[1]))
+	{
+	  rtx xoperands[2];
+	  xoperands[1] = gen_rtx_REG (HImode, REGNO (operands[1]) + 2);
+	  output_asm_insn ("move%.w %1,%-", xoperands);
+	  xoperands[1] = gen_rtx_REG (SImode, REGNO (operands[1]) + 1);
+	  output_asm_insn ("move%.l %1,%-", xoperands);
+	  output_asm_insn ("move%.l %1,%-", operands);
+	  return "fmove%.x %+,%0";
+	}
+      if (GET_CODE (operands[1]) == CONST_DOUBLE)
+        return "fmove%.x %1,%0";
+      return "fmove%.x %f1,%0";
+    }
+  if (FP_REG_P (operands[1]))
+    {
+      if (REG_P (operands[0]))
+        {
+          output_asm_insn ("fmove%.x %f1,%-\;move%.l %+,%0", operands);
+          operands[0] = gen_rtx_REG (SImode, REGNO (operands[0]) + 1);
+          output_asm_insn ("move%.l %+,%0", operands);
+          operands[0] = gen_rtx_REG (HImode, REGNO (operands[0]) + 1);
+          return "move%.w %+,%0";
+        }
+      else
+        return "fmove%.x %f1,%0";
+    }
+  return output_move_double (operands);
+})
+
+(define_insn ""
   [(set (match_operand:XF 0 "nonimmediate_operand" "=rm,rf,&rof<>")
 	(match_operand:XF 1 "nonimmediate_operand" "rf,m,rof<>"))]
   "! TARGET_68881 && ! TARGET_COLDFIRE"
@@ -1233,9 +1350,12 @@
   "TARGET_CFV4"
   "mvz%.w %1,%0")
 
+;; (TIGCC 20050210) We need to mark the register operand as earlyclobber in the
+;;                  case of memory operands to avoid having to split (see
+;;                  reg_mentioned_p below) things.
 (define_insn "zero_extendhisi2"
-  [(set (match_operand:SI 0 "register_operand" "=d")
-	(zero_extend:SI (match_operand:HI 1 "nonimmediate_src_operand" "rmS")))]
+  [(set (match_operand:SI 0 "register_operand" "=d,&d")
+	(zero_extend:SI (match_operand:HI 1 "nonimmediate_src_operand" "r,mS")))]
   ""
   "#")
 
@@ -1258,8 +1378,8 @@
   "mvz%.b %1,%0")
 
 (define_insn "zero_extendqisi2"
-  [(set (match_operand:SI 0 "register_operand" "=d")
-	(zero_extend:SI (match_operand:QI 1 "nonimmediate_src_operand" "dmS")))]
+  [(set (match_operand:SI 0 "register_operand" "=d,&d")
+	(zero_extend:SI (match_operand:QI 1 "nonimmediate_src_operand" "d,mS")))]
   ""
   "#")
 
@@ -4135,7 +4255,11 @@
       output_asm_insn (INTVAL (operands[2]) <= 8 ? "asr%.l %2,%0" :
 			"moveq %2,%1\;asr%.l %1,%0", operands);
       output_asm_insn ("mov%.l %0,%1\;smi %0", operands);
-      return INTVAL (operands[2]) >= 15 ? "ext%.w %d0" :
+/* (TIGCC 20040222) The %d0 here was a typo or thinko. It means 'force absolute
+                    addressing' in this context, not 'data register'. This
+                    doesn't make sense in a context where only data registers
+                    are allowed, so I removed it. -- Kevin Kofler */
+      return INTVAL (operands[2]) >= 15 ? "ext%.w %0" :
 	     TARGET_68020 ? "extb%.l %0" : "ext%.w %0\;ext%.l %0";
     }
 })
@@ -6320,10 +6444,19 @@
   return "rtd %0";
 })
 
+;; (TIGCC 20040222) Use jra instead of jmp here. Also don't add (%pc) under
+;;                  -mpcrel. Moreover, we need to handle extended address
+;;                  operands here. -- Kevin Kofler
+;; (TIGCC 20050204) Use plain bra for labels under -mpcrel to guarantee PC-rel
+;;                  code.
 (define_insn "indirect_jump"
-  [(set (pc) (match_operand:SI 0 "address_operand" "p"))]
+  [(set (pc) (match_operand:SI 0 "extended_address_operand" "p"))]
   ""
-  "jmp %a0")
+{
+  return (TARGET_PCREL && GET_CODE (operands[0]) == MEM
+          && GET_CODE (XEXP (operands[0], 0)) == SYMBOL_REF)?
+         "bra %A0":"jra %A0";
+})
 
 ;; This should not be used unless the add/sub insns can't be.
 
@@ -6417,6 +6550,9 @@
 })
 
 ;; Speed up stack adjust followed by a fullword fixedpoint push.
+;; (TIGCC 20050211) Don't do this if pushing an immediate operand in range for
+;;                  a pea, and a stack adjust is needed anyway. That would
+;;                  generate bigger (or same size) and slower code.
 
 (define_peephole
   [(set (reg:SI SP_REG) (plus:SI (reg:SI SP_REG)
@@ -6424,7 +6560,8 @@
    (set (match_operand:SI 1 "push_operand" "=m")
 	(match_operand:SI 2 "general_operand" "g"))]
   "INTVAL (operands[0]) >= 4
-   && ! reg_mentioned_p (stack_pointer_rtx, operands[2])"
+   && ! reg_mentioned_p (stack_pointer_rtx, operands[2])
+   && !(INTVAL (operands[0]) > 4 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) && INTVAL (operands[2]) >= -0x8000 && INTVAL (operands[2]) < 0x8000)"
 {
   if (INTVAL (operands[0]) > 4)
     {
@@ -6460,6 +6597,77 @@
   return "move%.l %2,%@";
 })
 
+;; (TIGCC 20050207) Bundle 2 immediate word pushes to the stack into 1 immediate
+;;                  longword push.
+
+(define_peephole
+  [(set (match_operand:HI 0 "push_operand" "=m")
+	(match_operand:HI 1 "const_int_operand" "n"))
+   (set (match_operand:HI 2 "push_operand" "=m")
+	(match_operand:HI 3 "const_int_operand" "n"))]
+  ""
+{
+  rtx xoperands[2];
+  xoperands[0] = operands[0];
+  xoperands[1] = GEN_INT ((INTVAL (operands[1]) & 0xFFFF) + (INTVAL (operands[3]) << 16));
+  output_asm_insn (output_move_simode_const (xoperands), xoperands);
+  CC_STATUS_INIT; /* We clobbered the CC. */
+  return "";
+})
+
+;; (TIGCC 20050210) Same as above, but with a stack adjust.
+
+(define_peephole
+  [(set (reg:SI SP_REG) (plus:SI (reg:SI SP_REG)
+				 (match_operand:SI 0 "const_int_operand" "n")))
+   (set (mem:HI (reg:SI SP_REG))
+	(match_operand:HI 1 "const_int_operand" "n"))
+   (set (match_operand:HI 2 "push_operand" "=m")
+	(match_operand:HI 3 "const_int_operand" "n"))]
+  "INTVAL (operands[0]) >= 2"
+{
+  HOST_WIDE_INT longword = (INTVAL (operands[1]) & 0xFFFF) + (INTVAL (operands[3]) << 16);
+  bool usepea = longword && longword < 0x8000 && longword >= -0x8000
+                && INTVAL (operands[0]) > 2;
+  rtx xoperands[2];
+  if (INTVAL (operands[0]) > 2)
+    {
+      xoperands[0] = stack_pointer_rtx;
+      xoperands[1] = GEN_INT (INTVAL (operands[0]) + (usepea?2:-2));
+      if (INTVAL (xoperands[1]) <= 8)
+	{
+	  if (!TARGET_COLDFIRE)
+	    output_asm_insn ("addq%.w %1,%0", xoperands);
+	  else
+	    output_asm_insn ("addq%.l %1,%0", xoperands);
+	}
+      else if (TARGET_CPU32 && INTVAL (xoperands[1]) <= 16)
+	{
+	  xoperands[1] = GEN_INT (INTVAL (xoperands[1]) - 8);
+	  output_asm_insn ("addq%.w #8,%0\;addq%.w %1,%0", xoperands);
+	}
+      else if (INTVAL (xoperands[1]) <= 0x7FFF)
+        {
+	  if (TARGET_68040)
+	    output_asm_insn ("add%.w %1,%0", xoperands);
+	  else if (MOTOROLA)
+	    output_asm_insn ("lea (%c1,%0),%0", xoperands);
+	  else
+	    output_asm_insn ("lea %0@(%c1),%0", xoperands);
+        }
+      else
+        output_asm_insn ("add%.l %1,%0", xoperands);
+    }
+  if (usepea)
+    xoperands[0] = operands[2];
+  else
+    xoperands[0] = gen_rtx_MEM (SImode, stack_pointer_rtx);
+  xoperands[1] = GEN_INT (longword);
+  output_asm_insn (output_move_simode_const (xoperands), xoperands);
+  CC_STATUS_INIT; /* We clobbered the CC. */
+  return "";
+})
+
 ;; Speed up pushing a single byte but leaving four bytes of space.
 
 (define_peephole
@@ -7092,3 +7300,166 @@
   default: gcc_unreachable ();
   }
 })
+
+;; (TIGCC 20050210) Optimize lea (4,%an),%am; move.l foo,-(%am) into
+;;                  move.l %an,%am; move.l foo,(%an)
+;; (TIGCC 20050211) Don't do this if foo is an immediate operand in range for
+;;                  a moveq (because the movsi insn won't like that).
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (const_int 4)))
+   (set (mem:SI (pre_dec:SI (match_dup 0)))
+        (match_operand:SI 2 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && ! reg_mentioned_p (operands[0], operands[2]) && !(GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) && INTVAL (operands[2]) >= -128 && INTVAL (operands[2]) < 128)"
+  [(set (match_dup 0) (match_dup 1))
+   (set (mem:SI (match_dup 1)) (match_dup 2))]
+  "")
+
+;; (TIGCC 20050211) Optimize lea (4,%an),%am; move.l #foo,-(%am), foo!=0,
+;;                  -128<=foo<128 into moveq.l #foo,%dx; move.l %an,%am;
+;;                  move.l %dx,(%an) if we have a free data register to do that.
+(define_peephole2
+  [(match_scratch:SI 0 "d")
+   (set (match_operand:SI 1 "register_operand" "")
+        (plus:SI (match_operand:SI 2 "register_operand" "")
+            (const_int 4)))
+   (match_dup 0)
+   (set (mem:SI (pre_dec:SI (match_dup 1)))
+        (match_operand:SI 3 "const_int_operand" ""))]
+  "REG_P(operands[2]) && (REGNO (operands[2]) ^ 010) < 8 && INTVAL (operands[3]) && INTVAL (operands[3]) >= -128 && INTVAL (operands[3]) < 128"
+  [(set (match_dup 0) (match_dup 3))
+   (set (match_dup 1) (match_dup 2))
+   (set (mem:SI (match_dup 2)) (match_dup 0))]
+  "")
+
+;; (TIGCC 20050210) Optimize lea (2,%an),%am; move.w foo,-(%am) into
+;;                  move.l %an,%am; move.w foo,(%an)
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (const_int 2)))
+   (set (mem:HI (pre_dec:SI (match_dup 0)))
+        (match_operand:HI 2 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && ! reg_mentioned_p (operands[0], operands[2])"
+  [(set (match_dup 0) (match_dup 1))
+   (set (mem:HI (match_dup 1)) (match_dup 2))]
+  "")
+
+;; (TIGCC 20050210) Optimize lea (1,%an),%am; move.w foo,-(%am), m!=7 into
+;;                  move.l %an,%am; move.b foo,(%an)
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (const_int 1)))
+   (set (mem:QI (pre_dec:SI (match_dup 0)))
+        (match_operand:QI 2 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && !(REG_P(operands[0]) && REGNO (operands[0]) == STACK_POINTER_REGNUM) && ! reg_mentioned_p (operands[0], operands[2])"
+  [(set (match_dup 0) (match_dup 1))
+   (set (mem:QI (match_dup 1)) (match_dup 2))]
+  "")
+
+;; (TIGCC 20050210) Optimize lea (x,%an),%am; move.l foo,-(%am), x!=4,
+;;                  x>=-0x7ffc into lea (x-4,%an),%am; move.l foo,(%am)
+;; (TIGCC 20050211) Don't do this if foo is an immediate operand in range for
+;;                  a pea (especially not if in range for a moveq, because the
+;;                  movsi insn won't like that).
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (match_operand:SI 2 "const_int_operand" "")))
+   (set (mem:SI (pre_dec:SI (match_dup 0)))
+        (match_operand:SI 3 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && ! reg_mentioned_p (operands[0], operands[3]) && INTVAL (operands[2]) != 4 && INTVAL (operands[2]) >= -0x7ffc && !(GET_CODE (operands[3]) == CONST_INT && INTVAL (operands[3]) && INTVAL (operands[3]) >= -0x8000 && INTVAL (operands[3]) < 0x8000)"
+  [(set (match_dup 0) (plus:SI (match_dup 1) (match_dup 2)))
+   (set (mem:SI (match_dup 0)) (match_dup 3))]
+  "operands[2] = GEN_INT (INTVAL (operands[2]) - 4);")
+
+;; (TIGCC 20050210) Optimize lea (x,%an),%am; move.w foo,-(%am), m!=7, x!=2,
+;;                  x>=-0x7ffe into lea (x-2,%an),%am; move.w foo,(%am)
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (match_operand:SI 2 "const_int_operand" "")))
+   (set (mem:HI (pre_dec:SI (match_dup 0)))
+        (match_operand:HI 3 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && ! reg_mentioned_p (operands[0], operands[3]) && INTVAL (operands[2]) != 2 && INTVAL (operands[2]) >= -0x7ffe"
+  [(set (match_dup 0) (plus:SI (match_dup 1) (match_dup 2)))
+   (set (mem:HI (match_dup 0)) (match_dup 3))]
+  "operands[2] = GEN_INT (INTVAL (operands[2]) - 2);")
+
+;; (TIGCC 20050210) Optimize lea (x,%an),%am; move.b foo,-(%am), m!=7, x!=1,
+;;                  x>=-0x7fff into lea (x-1,%an),%am; move.b foo,(%am)
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (match_operand:SI 2 "const_int_operand" "")))
+   (set (mem:QI (pre_dec:SI (match_dup 0)))
+        (match_operand:QI 3 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && !(REG_P(operands[0]) && REGNO (operands[0]) == STACK_POINTER_REGNUM) && ! reg_mentioned_p (operands[0], operands[3]) && INTVAL (operands[2]) != 1 && INTVAL (operands[2]) >= -0x7fff"
+  [(set (match_dup 0) (plus:SI (match_dup 1) (match_dup 2)))
+   (set (mem:QI (match_dup 0)) (match_dup 3))]
+  "operands[2] = GEN_INT (INTVAL (operands[2]) - 1);")
+
+;; (TIGCC 20050213) Optimize and #const1,%dn; and #const2,%dn (generated by
+;;                  zero_extend) into and #const1&const2,%dn
+
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (and:SI (match_dup 0)
+            (match_operand:SI 1 "const_int_operand" "")))
+   (set (match_dup 0)
+        (and:SI (match_dup 0)
+            (match_operand:SI 2 "const_int_operand" "")))]
+  ""
+  [(set (match_dup 0) (and:SI (match_dup 0) (match_dup 1)))]
+  "operands[1] = GEN_INT (INTVAL (operands[1]) & INTVAL (operands[2]));")
+
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "")
+        (and:HI (match_dup 0)
+            (match_operand:HI 1 "const_int_operand" "")))
+   (set (match_dup 0)
+        (and:HI (match_dup 0)
+            (match_operand:HI 2 "const_int_operand" "")))]
+  ""
+  [(set (match_dup 0) (and:HI (match_dup 0) (match_dup 1)))]
+  "operands[1] = GEN_INT (INTVAL (operands[1]) & INTVAL (operands[2]));")
+
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "")
+        (and:QI (match_dup 0)
+            (match_operand:QI 1 "const_int_operand" "")))
+   (set (match_dup 0)
+        (and:QI (match_dup 0)
+            (match_operand:QI 2 "const_int_operand" "")))]
+  ""
+  [(set (match_dup 0) (and:QI (match_dup 0) (match_dup 1)))]
+  "operands[1] = GEN_INT (INTVAL (operands[1]) & INTVAL (operands[2]));")
+
+;; (TIGCC 20050213) Optimize and.l #65535,%dn; clr.w %dn (generated by
+;;                  zero_extend) into moveq #0,%dn
+
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (and:SI (match_dup 0)
+            (const_int 65535)))
+   (set (strict_low_part (match_operand:HI 1 "register_operand" ""))
+        (const_int 0))]
+  "REG_P(operands[0]) && REG_P(operands[1]) && REGNO(operands[0]) == REGNO(operands[1])"
+  [(set (match_dup 0) (const_int 0))]
+  "")
+
+;; (TIGCC 20050213) Optimize and.w #255,%dn; clr.b %dn (generated by
+;;                  zero_extend) into clr.w %dn
+
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "")
+        (and:HI (match_dup 0)
+            (const_int 255)))
+   (set (strict_low_part (match_operand:QI 1 "register_operand" ""))
+        (const_int 0))]
+  "REG_P(operands[0]) && REG_P(operands[1]) && REGNO(operands[0]) == REGNO(operands[1])"
+  [(set (strict_low_part (match_dup 0)) (const_int 0))]
+  "")
+
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k-modes.def gcc-4.1-20051216-src/gcc/config/m68k/m68k-modes.def
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k-modes.def	2005-06-25 03:22:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k-modes.def	2005-12-18 22:24:35.000000000 +0100
@@ -18,5 +18,6 @@
 the Free Software Foundation, 51 Franklin Street, Fifth Floor,
 Boston, MA 02110-1301, USA.  */
 
-/* 80-bit floating point (IEEE extended, in a 96-bit field) */
-FRACTIONAL_FLOAT_MODE (XF, 80, 12, ieee_extended_motorola_format);
+FLOAT_MODE (BF, 10, 0);
+FLOAT_MODE (XF, 12, 0);
+
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k-none.h gcc-4.1-20051216-src/gcc/config/m68k/m68k-none.h
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k-none.h	2005-06-25 03:22:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k-none.h	2005-12-18 22:24:35.000000000 +0100
@@ -18,10 +18,12 @@
 the Free Software Foundation, 51 Franklin Street, Fifth Floor,
 Boston, MA 02110-1301, USA.  */
 
-/* Default to m68k (m68020).  */
-#ifndef TARGET_CPU_DEFAULT
-#define TARGET_CPU_DEFAULT M68K_CPU_m68k
-#endif
+/* Define the appropriate flags for the TI's architecture */
+#undef TARGET_CPU_DEFAULT
+#define TARGET_CPU_DEFAULT M68K_CPU_m68000
+
+#undef TARGET_DEFAULT
+#define TARGET_DEFAULT ((TARGET_CPU_DEFAULT >> 4) | MASK_SHORT | MASK_TIOS | MASK_MERGE_SECTIONS)
 
 /* These are values set by the configure script in TARGET_CPU_DEFAULT.
    They are (sequential integer + (desired value for TARGET_DEFAULT) << 4).  */
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k.opt gcc-4.1-20051216-src/gcc/config/m68k/m68k.opt
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k.opt	2005-12-19 02:06:37.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k.opt	2005-12-19 02:42:18.000000000 +0100
@@ -92,6 +92,10 @@
 Target Report RejectNegative Mask(BITFIELD)
 Use the bit-field instructions
 
+mbss
+Target Report InverseMask(BSS)
+Output common/lcomm (BSS) symbols for uninitialized data
+
 mc68000
 Target RejectNegative
 Generate code for a 68000
@@ -100,6 +104,10 @@
 Target RejectNegative
 Generate code for a 68020
 
+mcoff-abslines
+Target Report Mask(COFFABSLINES)
+Use absolute line numbers for COFF debugging
+
 mcpu32
 Target RejectNegative
 Generate code for a cpu32
@@ -108,10 +116,26 @@
 Target Report Mask(ID_SHARED_LIBRARY)
 Enable ID based shared library
 
+mlong
+Target InverseMask(SHORT)
+Consider type 'int' to be 32 bits wide
+
+mmerge-sections
+Target Report Mask(MERGE_SECTIONS)
+Merge the .text and .data sections
+
+mmerge-to-data
+Target Report Mask(MERGE_TO_DATA)
+When merging sections, merge to .data rather than to .text
+
 mnobitfield
 Target RejectNegative InverseMask(BITFIELD)
 Do not use the bit-field instructions
 
+mnolong
+Target Report RejectNegative Mask(SHORT)
+Consider type 'int' to be 16 bits wide
+
 mnortd
 Target RejectNegative InverseMask(RTD)
 Use normal calling convention
@@ -124,6 +148,18 @@
 Target Report Mask(PCREL)
 Generate pc-relative code
 
+mregparm
+Target Report Mask(REGPARM)
+Allow passing by registers
+
+mregparm=
+Target Report Joined Var(m68k_regparm_string)
+Number of register parameters of each register type
+
+mrodata-to-text
+Target Report Mask(RODATA_TO_TEXT)
+When not merging sections, put read-only data into .text rather than .data
+
 mrtd
 Target Report RejectNegative Mask(RTD)
 Use different calling convention using 'rtd'
@@ -137,7 +173,7 @@
 ID of shared library to build
 
 mshort
-Target Report RejectNegative Mask(SHORT)
+Target Report Mask(SHORT)
 Consider type 'int' to be 16 bits wide
 
 msoft-float
@@ -147,3 +183,7 @@
 mstrict-align
 Target Report Mask(STRICT_ALIGNMENT)
 Do not use unaligned memory references
+
+mtios
+Target Report Mask(TIOS)
+Enable TIOS interoperability
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k-protos.h gcc-4.1-20051216-src/gcc/config/m68k/m68k-protos.h
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k-protos.h	2005-07-12 01:32:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k-protos.h	2005-12-18 22:24:35.000000000 +0100
@@ -44,6 +44,13 @@
 extern int floating_exact_log2 (rtx);
 extern bool strict_low_part_peephole_ok (enum machine_mode mode, rtx first_insn, rtx target);
 
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+void amigaos_init_cumulative_args(struct m68k_args *, tree, tree);
+void amigaos_function_arg_advance(struct m68k_args *);
+struct rtx_def *amigaos_function_arg(struct m68k_args *, enum machine_mode, tree);
+/* end-TIGCC-local (regparms) */
+void m68k_asm_file_start(void);
+
 /* Functions from m68k.c used in macros.  */
 extern int standard_68881_constant_p (rtx);
 extern void print_operand_address (FILE *, rtx);
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k-ti.h gcc-4.1-20051216-src/gcc/config/m68k/m68k-ti.h
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k-ti.h	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k-ti.h	2005-12-18 22:24:35.000000000 +0100
@@ -0,0 +1,215 @@
+/* Definitions of target machine for GNU compiler.
+   TI-68k architecture (68000),
+   COFF object files and debugging version.
+   Derived in part from m68kemb.h and other files.
+   Copyright (C) 1994 Free Software Foundation, Inc.
+   Copyright (C) 2000 mmu_man (Franois Revol)
+   (Modified by Sebastian Reichelt for the Windows release of TIGCC)
+ 
+This file is part of TIGCC.
+
+GNU CC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 2, or (at your option)
+any later version.
+
+GNU CC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GNU CC; see the file COPYING. If not, write to
+the Free Software Foundation, 59 Temple Place - Suite 330,
+Boston, MA 02111-1307, USA. */
+
+/* Define the output of the target version */
+
+#undef TARGET_VERSION
+#define TARGET_VERSION fprintf (stderr, " (MC68000 TI with COFF output)");
+
+/* Even if we compile with -mlong, we want only 16-bit alignment. */
+
+#undef PARM_BOUNDARY
+#define PARM_BOUNDARY 16
+
+/* Don't default to pcc-struct-return, so that we can return small
+   structures and unions in registers, which is slightly more
+   efficient. There are probably no TIOS routines returning structs;
+   if there are, the appropriate program will have to be compiled
+   with the "-fpcc-struct-return" option. But that option will cause
+   problems with ROM_CALLs returning a HSym, which is defined as a
+   structure in TIGCC.  */
+
+#undef DEFAULT_PCC_STRUCT_RETURN
+#define DEFAULT_PCC_STRUCT_RETURN 0
+
+/* In order for bitfields to work on a 68000, or with -mnobitfield, we must
+   define either PCC_BITFIELD_TYPE_MATTERS or STRUCTURE_SIZE_BOUNDARY.
+   Defining STRUCTURE_SIZE_BOUNDARY results in structure packing problems,
+   so we define PCC_BITFIELD_TYPE_MATTERS.  */
+
+#define PCC_BITFIELD_TYPE_MATTERS 1
+
+/* Undefine PCC_STATIC_STRUCT_RETURN so that we get a re-entrant
+   calling convention (whatever that means).  */
+
+#undef PCC_STATIC_STRUCT_RETURN
+
+/* Define how to generate (in the callee) the output value of a
+   function and how to find (in the caller) the value returned by a
+   function. VALTYPE is the data type of the value (as a tree). If
+   the precise function being called is known, FUNC is its
+   FUNCTION_DECL; otherwise, FUNC is 0. When calling TIOS functions,
+   find the result in d0 or a0 as appropriate. */
+ 
+#undef FUNCTION_VALUE
+#define FUNCTION_VALUE(VALTYPE, FUNC) \
+	(((TARGET_TIOS) && (POINTER_TYPE_P (VALTYPE))) \
+	? gen_rtx_REG (TYPE_MODE (VALTYPE), 8) \
+	: LIBCALL_VALUE (TYPE_MODE (VALTYPE)))
+
+/* Define how to find a library call return value. Usually the value will be
+   in d0 (thru d1 or d2), but floats should be assumed to be returned in a
+   stack frame. This happens automatically if the specified register (d1 in
+   this case) is not a possible register for returning the value, because
+   floats take up 3 registers. Never use direct floats if d3 is clobbered
+   by function calls. */
+
+#undef LIBCALL_VALUE
+#define LIBCALL_VALUE(MODE) \
+	(((TARGET_DIRECTFLOAT) && ((MODE) == BFmode)) \
+	? gen_rtx_REG (MODE, 1) \
+	: gen_rtx_REG (MODE, 0))
+
+/* 1 if N is a possible register number for a function value. For
+   calling TIOS functions, allow a0 in addition to d0 (see above). */
+
+#undef FUNCTION_VALUE_REGNO_P
+#define FUNCTION_VALUE_REGNO_P(N) \
+	(((N) == 0) || (TARGET_TIOS && ((N) == 8)) || (TARGET_DIRECTFLOAT && ((N) == 1)))
+
+/* Define this to be true when FUNCTION_VALUE_REGNO_P is true for
+   more than one register (see above). */
+
+#undef NEEDS_UNTYPED_CALL
+#define NEEDS_UNTYPED_CALL (TARGET_TIOS || TARGET_DIRECTFLOAT)
+
+/* This says how to output an assembler line
+   to define a global common symbol. */
+
+#undef ASM_OUTPUT_COMMON
+#define ASM_OUTPUT_COMMON(FILE,NAME,SIZE,ROUNDED) \
+do { \
+	if (TARGET_NO_BSS && ((NAME) [0] != '_')) \
+	{ \
+		long i; \
+		data_section (); \
+		fputs (".globl ", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fputs ("\n\t.even\n", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fputs (":\n", (FILE)); \
+		fprintf ((FILE), "\t.space %u\n", (unsigned)(ROUNDED)); \
+		fputs ("\t.even\n", (FILE)); \
+	} \
+	else \
+	{ \
+		fputs (".comm ", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fprintf ((FILE), ",%u\n", (unsigned)(ROUNDED)); \
+	} \
+} while (0)
+
+/* This says how to output an assembler line
+   to define a local common symbol. */
+
+#undef ASM_OUTPUT_LOCAL
+#define ASM_OUTPUT_LOCAL(FILE,NAME,SIZE,ROUNDED) \
+do { \
+	if (TARGET_NO_BSS) \
+	{ \
+		long i; \
+		data_section (); \
+		fputs ("\t.even\n", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fputs (":\n", (FILE)); \
+		fprintf ((FILE), "\t.space %u\n", (unsigned)(ROUNDED)); \
+		fputs ("\t.even\n", (FILE)); \
+	} \
+	else \
+	{ \
+		fputs (".lcomm ", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fprintf ((FILE), ",%u\n", (unsigned)(ROUNDED)); \
+	} \
+} while (0)
+
+/* If TARGET_MERGE_SECTIONS is set (on by default): if TARGET_MERGE_TO_DATA is
+   set, only use data sections, otherwise only use text sections. Both code and
+   data in RAM programs on a TI-89/92+/V200 are always writable; that's why it
+   does not make sense to have different data and text sections.
+   Those cannot be set to an empty string, since a number may follow, etc.
+   Anyway, better more than less. */
+
+#undef TEXT_SECTION_ASM_OP
+#define TEXT_SECTION_ASM_OP ((TARGET_MERGE_SECTIONS && TARGET_MERGE_TO_DATA)? \
+                             "\t.data":"\t.text")
+
+#undef DATA_SECTION_ASM_OP
+#define DATA_SECTION_ASM_OP ((TARGET_MERGE_SECTIONS && !TARGET_MERGE_TO_DATA)? \
+                             "\t.text":"\t.data")
+
+/* If TARGET_NO_BSS is set (off by default), use the data section here.
+   Otherwise use the BSS section. */
+
+#undef BSS_SECTION_ASM_OP
+#define BSS_SECTION_ASM_OP (TARGET_NO_BSS?DATA_SECTION_ASM_OP:"\t.section .bss")
+
+/* When not merging sections, put read-only data into .data unless
+   TARGET_RODATA_TO_TEXT is set. But jump tables do NOT qualify for going into
+   the data section! */
+#define READONLY_DATA_SECTION() (TARGET_RODATA_TO_TEXT ? text_section() \
+                                                       : data_section())
+#define JUMP_TABLES_IN_TEXT_SECTION 1
+
+/* Define "__INT_SHORT__" if short ints are set, e.g. if the "-mlong" switch
+   is not used. This is necessary for the TIGCC Library, since INT_MAX and
+   others need to be constants. */
+
+#undef CPP_SUBTARGET_SPEC
+#if (defined(__CYGWIN__) || defined(__WIN32__))
+#define CPP_SUBTARGET_SPEC "-D__TIGCC_ENV__ -D__TIGCC_WIN_ENV__ %{!mlong:%{!mnoshort:%{!mno-short:-D__INT_SHORT__ }}}"
+#else
+#define CPP_SUBTARGET_SPEC "-D__TIGCC_ENV__ %{!mlong:%{!mnoshort:%{!mno-short:-D__INT_SHORT__ }}}"
+#endif
+#undef CPP_SPEC
+#define CPP_SPEC CPP_SUBTARGET_SPEC
+
+/* Trampolines are code on the stack, so we need to add 0x40000 to their address
+   for it to work on a TI-89/92+/V200 HW2. On HW3, we should NOT add that
+   address. Moreover, EXECUTE_IN_GHOST_SPACE is required for it to work
+   correctly. Therefore, I am emitting a libcall and letting TIGCCLIB worry
+   about the details.
+   (code partially lifted from gcc/config/sh/sh.h) */
+#define TRAMPOLINE_ADJUST_ADDRESS(TRAMP) do \
+{ \
+  (TRAMP) = expand_simple_binop (Pmode, PLUS, (TRAMP), \
+                                 emit_library_call_value (gen_rtx_SYMBOL_REF (\
+                                                           Pmode, \
+                                                           "__trampoline_offset"), \
+                                                          NULL_RTX, LCT_CONST, \
+                                                          Pmode, 0), \
+                                 gen_reg_rtx (Pmode), 0, \
+                                 OPTAB_LIB_WIDEN); \
+} while (0)
+
+/* We want -fomit-frame-pointer by default. */
+#define CAN_DEBUG_WITHOUT_FP
+
+/* We want DWARF2 debugging and unwinding information */
+#define DWARF2_DEBUGGING_INFO 1
+#define DWARF2_ASM_LINE_DEBUG_INFO 1
+#define DWARF2_UNWIND_INFO 1
+
+/* end of m68k-ti.h */
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/predicates.md gcc-4.1-20051216-src/gcc/config/m68k/predicates.md
--- gcc-4.1-20051216.orig/gcc/config/m68k/predicates.md	2005-12-19 01:42:58.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/m68k/predicates.md	2005-12-19 02:04:39.000000000 +0100
@@ -88,7 +88,7 @@
 ;; hosted on 64-bit machines.
 
 (define_predicate "const_uint32_operand"
-  (match_code "const_int,const_double")
+  (match_code "const_int")
 {
   /* It doesn't make sense to ask this question with a mode that is
      not larger than 32 bits.  */
@@ -101,7 +101,7 @@
 	  && (INTVAL (op) >= 0 && INTVAL (op) <= 0xffffffffL));
 #else
   return (GET_CODE (op) == CONST_INT
-	  || (GET_CODE (op) == CONST_DOUBLE && CONST_DOUBLE_HIGH (op) == 0));
+	  && INTVAL (op) >= 0);
 #endif
 })
 
@@ -194,3 +194,13 @@
 {
   return MEM_P (op) && GET_CODE (XEXP (op, 0)) == PRE_DEC;
 })
+
+;; (TIGCC 20040222) This predicate is used to allow straight labels in the
+;;                  indirect_jump pattern. -- Kevin Kofler
+(define_predicate "extended_address_operand"
+  (match_code "const_int,const_double,const,symbol_ref,label_ref,subreg,reg,mem,plus,minus,mult")
+{
+  if (TARGET_PCREL && CONSTANT_ADDRESS_P (op))
+    return 1;
+  return address_operand (op, mode);
+})
diff -Naur gcc-4.1-20051216.orig/gcc/config/smapbcd.h gcc-4.1-20051216-src/gcc/config/smapbcd.h
--- gcc-4.1-20051216.orig/gcc/config/smapbcd.h	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/smapbcd.h	2005-12-18 22:24:36.000000000 +0100
@@ -0,0 +1,369 @@
+/* Definitions for SMAP II BCD support in the GNU C Compiler.
+   These macros implement software BCD floating point support;
+   primary use will be TIGCC.
+   Copyright (C) 1994 Free Software Foundation, Inc.
+   Copyright (C) 2000 Sebastian Reichelt
+   Copyright (C) 2003-2005 Kevin Kofler
+
+This file is part of TIGCC.
+
+GNU CC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 2, or (at your option)
+any later version.
+
+GNU CC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GNU CC; see the file COPYING. If not, write to
+the Free Software Foundation, 59 Temple Place - Suite 330,
+Boston, MA 02111-1307, USA. */
+
+#undef TARGET_FLOAT_FORMAT
+#define	TARGET_FLOAT_FORMAT SMAP_BCD_FLOAT_FORMAT
+
+#ifndef __SMAP_BCD_FLOAT
+#define __SMAP_BCD_FLOAT
+
+typedef struct real_value smap_bcd_float;
+
+#endif
+
+#undef REAL_VALUE_TYPE
+#define REAL_VALUE_TYPE smap_bcd_float
+
+#undef FLOAT_TYPE_SIZE
+#undef DOUBLE_TYPE_SIZE
+#undef LONG_DOUBLE_TYPE_SIZE
+
+/* We have to define a special mode for this; one that handles 10 byte
+   floats. There have to be a lot of changes to other files; due to the
+   fact that they are so countless, it would be too hard to make them
+   compatible with a general-purpose GCC. */
+#define FLOAT_TYPE_SIZE 80
+#define DOUBLE_TYPE_SIZE 80
+#define LONG_DOUBLE_TYPE_SIZE 80
+
+#ifndef REAL_IS_NOT_DOUBLE
+#define REAL_IS_NOT_DOUBLE
+#endif
+
+#define ZERO (__extension__(smap_bcd_float){0x4000,0})
+#define UNSIGNED_ZERO (__extension__(smap_bcd_float){0x4000,0})
+#define POSITIVE_ZERO (__extension__(smap_bcd_float){0,0})
+#define NEGATIVE_ZERO (__extension__(smap_bcd_float){0x8000,0})
+
+#define UNSIGNED_INF (__extension__(smap_bcd_float){0x7FFF,0xAA00CC0000000000})
+#define POSITIVE_INF (__extension__(smap_bcd_float){0x7FFF,0xAA00BB0000000000})
+#define NEGATIVE_INF (__extension__(smap_bcd_float){0xFFFF,0xAA00BB0000000000})
+
+#define NAN (__extension__(smap_bcd_float){0x7FFF,0xAA00000000000000})
+
+#ifndef REAL_INFINITY
+#define REAL_INFINITY
+#endif
+
+#undef REAL_VALUE_ISNAN
+#define REAL_VALUE_ISNAN(x) \
+	(REAL_VALUES_IDENTICAL (x, NAN))
+
+#undef REAL_VALUE_ISINF
+#define REAL_VALUE_ISINF(x) \
+	((REAL_VALUES_IDENTICAL (x, POSITIVE_INF)) \
+	|| (REAL_VALUES_IDENTICAL (x, NEGATIVE_INF)) \
+	|| (REAL_VALUES_IDENTICAL (x, UNSIGNED_INF)))
+
+#define REAL_VALUE_ISNANUINF(x) \
+	((REAL_VALUE_ISNAN (x)) \
+	|| (REAL_VALUES_IDENTICAL (x, UNSIGNED_INF)))
+
+#define REAL_VALUE_ISFINITE(x) \
+	(!(REAL_VALUE_ISNAN (x)) \
+	&& !(REAL_VALUE_ISINF (x)))
+
+#define REAL_VALUE_ISZERO(x) \
+	(!((x).mantissa))
+
+#undef REAL_VALUE_MINUS_ZERO
+#define REAL_VALUE_MINUS_ZERO(x) \
+	(REAL_VALUES_IDENTICAL (x, NEGATIVE_ZERO))
+
+#define REAL_VALUE_ISPOSITIVE(x) \
+	(!(REAL_VALUE_ISNANUINF (x)) \
+	&& ((x).exponent < 0x8000) \
+	&& !(REAL_VALUE_ISZERO (x)))
+
+#define REAL_VALUE_ISNEGATIVE(x) \
+	(!(REAL_VALUE_ISNANUINF (x)) \
+	&& ((x).exponent >= 0x8000) \
+	&& !(REAL_VALUE_ISZERO (x)))
+
+#undef REAL_VALUE_POSITIVE
+#define REAL_VALUE_POSITIVE(x) \
+	(REAL_VALUE_ISPOSITIVE (x))
+
+#undef REAL_VALUE_NEGATIVE
+#define REAL_VALUE_NEGATIVE(x) \
+	(REAL_VALUE_ISNEGATIVE (x))
+
+#define real_isneg(x) \
+	(REAL_VALUE_ISNEGATIVE (*(x)))
+
+#undef REAL_VALUES_IDENTICAL
+#define REAL_VALUES_IDENTICAL(x, y) \
+	((x).exponent == (y).exponent && (x).mantissa == (y).mantissa)
+
+#undef REAL_VALUES_EQUAL
+#define REAL_VALUES_EQUAL(x,y) \
+	(((REAL_VALUES_IDENTICAL (x, y)) \
+	&& !REAL_VALUE_ISNANUINF (x) \
+	&& !REAL_VALUE_ISNANUINF (y)) \
+	|| (REAL_VALUE_ISZERO (x) \
+	&& REAL_VALUE_ISZERO (y)))
+
+#undef REAL_VALUES_LESS
+#define REAL_VALUES_LESS(x,y) \
+__extension__ ({ \
+	register int result = 0; \
+	if (REAL_VALUE_ISNANUINF (x) \
+		|| REAL_VALUE_ISNANUINF (y) \
+		|| REAL_VALUES_EQUAL (x, y) \
+		|| (REAL_VALUE_ISPOSITIVE (x) && !(REAL_VALUE_ISPOSITIVE (y))) \
+		|| (!(REAL_VALUE_ISNEGATIVE (x)) && REAL_VALUE_ISNEGATIVE (y))) \
+		result = 0; \
+	else if ((REAL_VALUE_ISNEGATIVE (x) && !(REAL_VALUE_ISNEGATIVE (y))) \
+		|| (!(REAL_VALUE_ISPOSITIVE (x)) && REAL_VALUE_ISPOSITIVE (y))) \
+		result = 1; \
+	else \
+	{ \
+		if ((x).exponent == (y).exponent) \
+		{ \
+			if (REAL_VALUE_ISNEGATIVE (x)) \
+				result = ((x).mantissa > (y).mantissa); \
+			else \
+				result = ((x).mantissa < (y).mantissa); \
+		} \
+		else \
+		{ \
+			if (REAL_VALUE_ISNEGATIVE (x)) \
+				result = ((x).exponent > (y).exponent); \
+			else \
+				result = ((x).exponent < (y).exponent); \
+		} \
+	} \
+	result; \
+})
+
+#undef REAL_VALUE_LDEXP
+#define REAL_VALUE_LDEXP(x,tempscale) \
+__extension__ ({ \
+	REAL_VALUE_TYPE __tempx = x; \
+	int scale; \
+	unsigned long long pmul; \
+	signed short carry, help; \
+	if (REAL_VALUE_ISFINITE (__tempx)) \
+	{ \
+		if (tempscale > 0) \
+			for (scale = 0; scale < tempscale; scale++) \
+			{ \
+				if (__tempx.mantissa >= 0x5000000000000000) \
+				{ \
+					__tempx.mantissa /= 0x10; \
+					__tempx.exponent++; \
+				} \
+				carry = 0; \
+				for (pmul = 1; 1; pmul *= 0x10) \
+				{ \
+					help = (__tempx.mantissa / pmul) & 0xF; \
+					__tempx.mantissa -= ((unsigned long long) help) * pmul; \
+					help *= 2; \
+					help += carry; \
+					carry = help / 10; \
+					__tempx.mantissa += ((unsigned long long) (help % 10)) * pmul; \
+					if (pmul >= 0x1000000000000000) \
+						break; \
+				} \
+			} \
+		else if (tempscale < 0) \
+			for (scale = 0; scale > tempscale; scale--) \
+			{ \
+				carry = 0; \
+				for (pmul = 0x1000000000000000; pmul > 0; pmul /= 0x10) \
+				{ \
+					help = (__tempx.mantissa / pmul) & 0xF; \
+					__tempx.mantissa -= ((unsigned long long) help) * pmul; \
+					help += carry; \
+					__tempx.mantissa += ((unsigned long long) (help / 2)) * pmul; \
+					carry = (help % 2) * 10; \
+				} \
+				if (__tempx.mantissa < 0x1000000000000000) \
+				{ \
+					__tempx.mantissa *= 0x10; \
+					__tempx.mantissa += carry / 2; \
+					__tempx.exponent--; \
+				} \
+			} \
+	} \
+	__tempx; \
+})
+
+#undef REAL_VALUE_FIX
+#define REAL_VALUE_FIX(x) \
+	((REAL_VALUE_ISNEGATIVE (x)) \
+	? (-(REAL_VALUE_UNSIGNED_FIX (REAL_VALUE_NEGATE (x)))) \
+	: (REAL_VALUE_UNSIGNED_FIX (x)))
+
+#undef REAL_VALUE_UNSIGNED_FIX
+#define REAL_VALUE_UNSIGNED_FIX(x) \
+__extension__ ({ \
+	register unsigned int r = 0; \
+	signed char i; \
+	unsigned long long mpmul = 0x1000000000000000; \
+	if (((x.exponent & 0x7FFF) >= 0x4000) && ((x.exponent & 0x7FFF) < 0x4016)) \
+	{ \
+		for (i = 0; i <= (x.exponent & 0x7FFF) - 0x4000; i++) \
+			if (mpmul) \
+			{ \
+				r *= 10; \
+				r += (x.mantissa / mpmul) & 0xF; \
+				mpmul /= 0x10; \
+			} \
+	} \
+	r; \
+})
+
+#undef REAL_VALUE_RNDZINT
+#define REAL_VALUE_RNDZINT(x) \
+__extension__ ({ \
+	REAL_VALUE_TYPE r = ZERO; \
+	signed char i; \
+	unsigned long long mpmul = 0x1000000000000000; \
+	r.exponent = (x).exponent; \
+	if (((r.exponent & 0x7FFF) >= 0x4000) && ((r.exponent & 0x7FFF) < 0x4016)) \
+	{ \
+		for (i = 0; i <= (r.exponent & 0x7FFF) - 0x4000; i++) \
+			if (mpmul) \
+			{ \
+				r.mantissa += x.mantissa & (0xF * mpmul); \
+				mpmul /= 0x10; \
+			} \
+	} \
+	r; \
+})
+
+#undef REAL_VALUE_UNSIGNED_RNDZINT
+#define REAL_VALUE_UNSIGNED_RNDZINT(x) \
+	((REAL_VALUE_ISPOSITIVE (x)) \
+	? (REAL_VALUE_RNDZINT (x)) \
+	: (ZERO))
+
+#undef REAL_VALUE_ATOF
+#define REAL_VALUE_ATOF(string,mode) \
+	real_from_string2((string), (mode))
+
+#undef REAL_ARITHMETIC
+#define REAL_ARITHMETIC(value, code, d1, d2) \
+	real_arithmetic (&(value), (code), &(d1), &(d2))
+
+#undef REAL_VALUE_NEGATE
+#define REAL_VALUE_NEGATE(x) \
+__extension__ ({ \
+	REAL_VALUE_TYPE __tempx = x; \
+	if ((!(REAL_VALUE_ISNANUINF (__tempx))) && ((__tempx.mantissa) || (__tempx.exponent != 0x4000))) \
+		__tempx.exponent ^= 0x8000; \
+	__tempx; \
+})
+
+#undef REAL_VALUE_TRUNCATE
+#define REAL_VALUE_TRUNCATE(mode,x) \
+	(x)
+
+#define real_convert(r,mode,x) \
+	(*(r)=*(x))
+
+#define REAL_VALUE_TO_INT(lo, hi, r) real_to_integer2 ((lo), (hi), &(r))
+
+#define REAL_VALUE_FROM_INT(d, lo, hi, mode) \
+	real_from_integer (&(d), (mode), (lo), (hi), 0)
+
+#define REAL_VALUE_FROM_UNSIGNED_INT(d, lo, hi, mode) \
+	real_from_integer (&(d), (mode), (lo), (hi), 1)
+
+#undef REAL_VALUE_TO_TARGET_SINGLE
+#define REAL_VALUE_TO_TARGET_SINGLE(IN, OUT) \
+	abort();
+
+#undef REAL_VALUE_TO_TARGET_DOUBLE
+#define REAL_VALUE_TO_TARGET_DOUBLE(IN, OUT) \
+	abort();
+
+#undef REAL_VALUE_TO_TARGET_LONG_DOUBLE
+#define REAL_VALUE_TO_TARGET_LONG_DOUBLE(IN, OUT) \
+do { \
+	REAL_VALUE_TYPE f = (IN); \
+	(OUT)[0] = f.exponent * 0x10000 + ((unsigned short) (f.mantissa / 0x1000000000000)), (OUT)[1] = (unsigned long) (f.mantissa / 0x10000), (OUT)[2] = ((unsigned short) (f.mantissa)) * 0x10000; \
+} while (0)
+
+#undef REAL_VALUE_TO_TARGET_SMAP_BCD
+#define REAL_VALUE_TO_TARGET_SMAP_BCD(IN, OUT) \
+do { \
+	REAL_VALUE_TYPE f = (IN); \
+	(OUT)[0] = f.exponent, (OUT)[1] = (unsigned long) (f.mantissa / 0x100000000), (OUT)[2] = (unsigned long) (f.mantissa); \
+} while (0)
+
+#define REAL_VALUE_TO_STRING(IN, OUT) \
+do { \
+	REAL_VALUE_TYPE f = (IN); \
+	if (REAL_VALUE_ISNAN (f)) \
+		sprintf ((OUT), "NaN"); \
+	else if (REAL_VALUES_IDENTICAL (f, UNSIGNED_INF)) \
+		sprintf ((OUT), "Inf"); \
+	else if (REAL_VALUES_IDENTICAL (f, POSITIVE_INF)) \
+		sprintf ((OUT), "+Inf"); \
+	else if (REAL_VALUES_IDENTICAL (f, NEGATIVE_INF)) \
+		sprintf ((OUT), "-Inf"); \
+	else if (REAL_VALUES_IDENTICAL (f, UNSIGNED_ZERO)) \
+		sprintf ((OUT), "0.0"); \
+	else if (REAL_VALUES_IDENTICAL (f, POSITIVE_ZERO)) \
+		sprintf ((OUT), "+0.0"); \
+	else if (REAL_VALUES_IDENTICAL (f, NEGATIVE_ZERO)) \
+		sprintf ((OUT), "-0.0"); \
+	else \
+	{ \
+		long exp; \
+		int neg = REAL_VALUE_ISNEGATIVE (f); \
+		if (neg) \
+			exp = f.exponent - 0xC000; \
+		else \
+			exp = f.exponent - 0x4000; \
+		sprintf ((OUT), "%s%lx.%07lx%08lxe%d", neg ? "-" : "", (unsigned long) (f.mantissa >> 60), (unsigned long) (f.mantissa >> 32) & 0x0ffffffful, (unsigned long) (f.mantissa), (int) (exp)); \
+	} \
+} while (0)
+
+#define REAL_VALUE_ABS(x) ((REAL_VALUE_ISNEGATIVE((x))\
+                            || REAL_VALUE_MINUS_ZERO((x))\
+                            || REAL_VALUES_IDENTICAL ((x), NEGATIVE_INF))?\
+                           REAL_VALUE_NEGATE((x)):(x))
+
+/* WARNING: This is the number of bits we can represent, not the true size of
+            the mantissa. */
+#define significand_size(dummy) (53)
+
+#undef MODE_HAS_NANS
+#define MODE_HAS_NANS(MODE) ((MODE)==BFmode)
+
+#undef MODE_HAS_INFINITIES
+#define MODE_HAS_INFINITIES(MODE) ((MODE)==BFmode)
+
+/* FIXME: GCC expects this to mean that there is only 0 and -0. We actually have
+          0, +0 and -0. This allows a few optimizations GCC is too cautious to
+          do in the presence of signed zeros. */
+#undef MODE_HAS_SIGNED_ZEROS
+#define MODE_HAS_SIGNED_ZEROS(MODE) ((MODE)==BFmode)
+
+#define REAL_MODE_FORMAT_COMPOSITE_P(dummy) (0)
+
+/* end of smapbcd.h */
diff -Naur gcc-4.1-20051216.orig/gcc/config.gcc gcc-4.1-20051216-src/gcc/config.gcc
--- gcc-4.1-20051216.orig/gcc/config.gcc	2005-12-16 14:51:19.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config.gcc	2005-12-18 22:24:36.000000000 +0100
@@ -1374,7 +1374,7 @@
 m68k-*-coff*)
 	tmake_file=m68k/t-m68kbare
 	tm_defines="MOTOROLA USE_GAS"
-	tm_file="m68k/m68k.h m68k/m68k-none.h m68k/m68kemb.h dbxcoff.h m68k/coff.h dbx.h"
+	tm_file="m68k/m68k.h m68k/m68k-none.h dbxcoff.h m68k/coff.h smapbcd.h m68k/m68k-ti.h dbx.h"
 	use_fixproto=yes
 	;;
 m68020-*-elf* | m68k-*-elf*)
diff -Naur gcc-4.1-20051216.orig/gcc/convert.c gcc-4.1-20051216-src/gcc/convert.c
--- gcc-4.1-20051216.orig/gcc/convert.c	2005-10-11 20:14:57.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/convert.c	2005-12-18 22:24:36.000000000 +0100
@@ -73,6 +73,9 @@
 {
   tree sub, expt, subt;
 
+/* (TIGCC 20050205) We do not implement exact_real_truncate and there is no
+                    narrower float mode anyway. -- Kevin Kofler */
+#if 0
   /*  For floating point constant look up the narrowest type that can hold
       it properly and handle it like (type)(narrowest_type)constant.
       This way we can optimize for instance a=a*2.0 where "a" is float
@@ -93,6 +96,7 @@
       if (type)
 	return build_real (type, real_value_truncate (TYPE_MODE (type), orig));
     }
+#endif /* 0 */
 
   if (TREE_CODE (exp) != NOP_EXPR
       && TREE_CODE (exp) != CONVERT_EXPR)
diff -Naur gcc-4.1-20051216.orig/gcc/c.opt gcc-4.1-20051216-src/gcc/c.opt
--- gcc-4.1-20051216.orig/gcc/c.opt	2005-11-15 20:14:59.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c.opt	2005-12-19 00:46:06.000000000 +0100
@@ -420,7 +420,7 @@
 Give strings the type \"array of char\"
 
 Wpointer-sign
-C ObjC Var(warn_pointer_sign) Init(1)
+C ObjC Var(warn_pointer_sign) Init(0)
 Warn when a pointer differs in signedness in an assignment
 
 ansi
@@ -446,6 +446,10 @@
 C ObjC C++ ObjC++
 Recognize the \"asm\" keyword
 
+fauto-octals
+C ObjC C++ ObjC++
+Numbers starting with zero should be octal (default on).
+
 fbuiltin
 C ObjC C++ ObjC++
 Recognize built-in functions
diff -Naur gcc-4.1-20051216.orig/gcc/c-opts.c gcc-4.1-20051216-src/gcc/c-opts.c
--- gcc-4.1-20051216.orig/gcc/c-opts.c	2005-11-04 09:29:16.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-opts.c	2005-12-18 22:24:28.000000000 +0100
@@ -222,6 +222,9 @@
      before passing on command-line options to cpplib.  */
   cpp_opts->warn_dollars = 0;
 
+  /* (TIGCC 20050217) Enable -fms-extensions by default. */
+  flag_ms_extensions = 1;
+
   flag_const_strings = c_dialect_cxx ();
   flag_exceptions = c_dialect_cxx ();
   warn_pointer_arith = c_dialect_cxx ();
@@ -319,7 +322,9 @@
 	    error ("-I- specified twice");
 	  quote_chain_split = true;
 	  split_quote_chain ();
+#if 0 /* (TIGCC 20050206) */
 	  inform ("obsolete option -I- used, please use -iquote instead");
+#endif /* 0 */
 	}
       break;
 
@@ -874,6 +879,8 @@
     case OPT_pedantic:
       cpp_opts->pedantic = 1;
       cpp_opts->warn_endif_labels = 1;
+      /* (TIGCC 20050217) No Microsoft extensions if -pedantic. */
+      flag_ms_extensions = 0;
       break;
 
     case OPT_print_objc_runtime_info:
@@ -935,6 +942,10 @@
     case OPT_v:
       verbose = true;
       break;
+
+    case OPT_fauto_octals:
+      cpp_opts->no_auto_octals = !value;
+      break;
     }
 
   return result;
@@ -1010,10 +1021,12 @@
 	       "-Wformat-security ignored without -Wformat");
     }
 
+#if 0 /* (TIGCC 20050306) Disable as we don't have these libcalls. */
   /* C99 requires special handling of complex multiplication and division;
      -ffast-math and -fcx-limited-range are handled in process_options.  */
   if (flag_isoc99)
     flag_complex_method = 2;
+#endif /* 0 */
 
   if (flag_preprocess_only)
     {
diff -Naur gcc-4.1-20051216.orig/gcc/cppdefault.c gcc-4.1-20051216-src/gcc/cppdefault.c
--- gcc-4.1-20051216.orig/gcc/cppdefault.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/cppdefault.c	2005-12-18 22:24:36.000000000 +0100
@@ -46,6 +46,7 @@
 = INCLUDE_DEFAULTS;
 #else
 = {
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
 #ifdef GPLUSPLUS_INCLUDE_DIR
     /* Pick up GNU C++ generic include files.  */
     { GPLUSPLUS_INCLUDE_DIR, "G++", 1, 1, 0 },
@@ -85,11 +86,12 @@
     /* /usr/include comes dead last.  */
     { STANDARD_INCLUDE_DIR, STANDARD_INCLUDE_COMPONENT, 0, 0, 1 },
 #endif
+#endif /* 0 */
     { 0, 0, 0, 0, 0 }
   };
 #endif /* no INCLUDE_DEFAULTS */
 
-#ifdef GCC_INCLUDE_DIR
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
 const char cpp_GCC_INCLUDE_DIR[] = GCC_INCLUDE_DIR;
 const size_t cpp_GCC_INCLUDE_DIR_len = sizeof GCC_INCLUDE_DIR - 8;
 #else
diff -Naur gcc-4.1-20051216.orig/gcc/c-ppoutput.c gcc-4.1-20051216-src/gcc/c-ppoutput.c
--- gcc-4.1-20051216.orig/gcc/c-ppoutput.c	2005-10-14 16:56:45.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-ppoutput.c	2005-12-18 22:24:35.000000000 +0100
@@ -174,7 +174,8 @@
       print.prev = token;
       cpp_output_token (token, print.outf);
 
-      if (token->type == CPP_COMMENT)
+      if (token->type == CPP_STRING || token->type == CPP_WSTRING
+	  || token->type == CPP_COMMENT)
 	account_for_newlines (token->val.str.text, token->val.str.len);
     }
 }
diff -Naur gcc-4.1-20051216.orig/gcc/c-pretty-print.c gcc-4.1-20051216-src/gcc/c-pretty-print.c
--- gcc-4.1-20051216.orig/gcc/c-pretty-print.c	2005-11-03 04:30:36.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-pretty-print.c	2005-12-18 22:24:35.000000000 +0100
@@ -904,8 +904,7 @@
 static void
 pp_c_floating_constant (c_pretty_printer *pp, tree r)
 {
-  real_to_decimal (pp_buffer (pp)->digit_buffer, &TREE_REAL_CST (r),
-		   sizeof (pp_buffer (pp)->digit_buffer), 0, 1);
+  REAL_VALUE_TO_STRING (TREE_REAL_CST (r), pp_buffer (pp)->digit_buffer);
   pp_string (pp, pp_buffer(pp)->digit_buffer);
   if (TREE_TYPE (r) == float_type_node)
     pp_character (pp, 'f');
@@ -1948,6 +1947,17 @@
       pp_postfix_expression (pp, TREE_OPERAND (e, 1));
       break;
 
+    /* (TIGCC 20050210) Get pp_c_expression to print statement expressions
+                        correctly. We only print the last statement of a list,
+                        because that's the result of the statement expression. */
+    case BIND_EXPR:
+      pp_c_expression (pp, BIND_EXPR_BODY (e));
+      break;
+
+    case STATEMENT_LIST:
+      pp_c_expression (pp, STATEMENT_LIST_TAIL (e)->stmt);
+      break;
+
     default:
       pp_unsupported_tree (pp, e);
       break;
diff -Naur gcc-4.1-20051216.orig/gcc/c-tree.h gcc-4.1-20051216-src/gcc/c-tree.h
--- gcc-4.1-20051216.orig/gcc/c-tree.h	2005-11-19 00:40:29.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-tree.h	2005-12-18 22:24:35.000000000 +0100
@@ -353,6 +353,8 @@
   tree attrs;
   /* The declarator.  */
   struct c_declarator *declarator;
+  /* (TIGCC 20050203) The asmspec.  */
+  tree asmspec;
 };
 
 /* Save and restore the variables in this file and elsewhere
@@ -431,6 +433,7 @@
 extern tree pushdecl (tree);
 extern void c_expand_body (tree);
 
+extern void c_insert_default_attributes (tree);
 extern void c_init_decl_processing (void);
 extern void c_dup_lang_specific_decl (tree);
 extern void c_print_identifier (FILE *, tree, int);
@@ -478,7 +481,7 @@
 extern struct c_typespec parser_xref_tag (enum tree_code, tree);
 extern int c_expand_decl (tree);
 extern struct c_parm *build_c_parm (struct c_declspecs *, tree,
-				    struct c_declarator *);
+				    struct c_declarator *, tree /* (TIGCC 20050203) */);
 extern struct c_declarator *build_attrs_declarator (tree,
 						    struct c_declarator *);
 extern struct c_declarator *build_function_declarator (struct c_arg_info *,
diff -Naur gcc-4.1-20051216.orig/gcc/c-typeck.c gcc-4.1-20051216-src/gcc/c-typeck.c
--- gcc-4.1-20051216.orig/gcc/c-typeck.c	2005-12-08 12:24:07.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-typeck.c	2005-12-19 00:34:06.000000000 +0100
@@ -83,6 +83,8 @@
 static tree lookup_field (tree, tree);
 static tree convert_arguments (tree, tree, tree, tree);
 static tree pointer_diff (tree, tree);
+static tree unary_complex_lvalue (enum tree_code, tree, int);
+static void pedantic_lvalue_warning (enum tree_code);
 static tree convert_for_assignment (tree, tree, enum impl_conv, tree, tree,
 				    int);
 static tree valid_compound_expr_initializer (tree, tree);
@@ -2162,6 +2164,7 @@
   /* fntype now gets the type of function pointed to.  */
   fntype = TREE_TYPE (fntype);
 
+#if 0
   /* Check that the function is called through a compatible prototype.
      If it is not, replace the call by a trap, wrapped up in a compound
      expression if necessary.  This has the nice side-effect to prevent
@@ -2200,6 +2203,7 @@
 	  return build2 (COMPOUND_EXPR, return_type, trap, rhs);
 	}
     }
+#endif /* 0 */
 
   /* Convert the parameters to the types declared in the
      function prototype, or apply default promotions.  */
@@ -2774,6 +2778,12 @@
     case POSTINCREMENT_EXPR:
     case PREDECREMENT_EXPR:
     case POSTDECREMENT_EXPR:
+      /* Handle complex lvalues (when permitted)
+	 by reduction to simpler cases.  */
+
+      val = unary_complex_lvalue (code, arg, 0);
+      if (val != 0)
+	return val;
 
       /* Increment or decrement the real part of the value,
 	 and don't change the imaginary part.  */
@@ -2842,6 +2852,57 @@
 
 	inc = convert (argtype, inc);
 
+	/* Handle incrementing a cast-expression.  */
+
+	while (1)
+	  switch (TREE_CODE (arg))
+	    {
+	    case NOP_EXPR:
+	    case CONVERT_EXPR:
+	    case FLOAT_EXPR:
+	    case FIX_TRUNC_EXPR:
+	    case FIX_FLOOR_EXPR:
+	    case FIX_ROUND_EXPR:
+	    case FIX_CEIL_EXPR:
+	      pedantic_lvalue_warning (CONVERT_EXPR);
+	      /* If the real type has the same machine representation
+		 as the type it is cast to, we can make better output
+		 by adding directly to the inside of the cast.  */
+	      if ((TREE_CODE (TREE_TYPE (arg))
+		   == TREE_CODE (TREE_TYPE (TREE_OPERAND (arg, 0))))
+		  && (TYPE_MODE (TREE_TYPE (arg))
+		      == TYPE_MODE (TREE_TYPE (TREE_OPERAND (arg, 0)))))
+		arg = TREE_OPERAND (arg, 0);
+	      else
+		{
+		  tree incremented, modify, value;
+		  if (TREE_CODE (TREE_TYPE (arg)) == BOOLEAN_TYPE)
+		    value = boolean_increment (code, arg);
+		  else
+		    {
+		      arg = stabilize_reference (arg);
+		      if (code == PREINCREMENT_EXPR || code == PREDECREMENT_EXPR)
+			value = arg;
+		      else
+			value = save_expr (arg);
+		      incremented = build (((code == PREINCREMENT_EXPR
+					     || code == POSTINCREMENT_EXPR)
+					    ? PLUS_EXPR : MINUS_EXPR),
+					   argtype, value, inc);
+		      TREE_SIDE_EFFECTS (incremented) = 1;
+		      modify = build_modify_expr (arg, NOP_EXPR, incremented);
+		      value = build (COMPOUND_EXPR, TREE_TYPE (arg), modify, value);
+		    }
+		  TREE_USED (value) = 1;
+		  return value;
+		}
+	      break;
+
+	    default:
+	      goto give_up;
+	    }
+      give_up:
+
 	/* Complain about anything else that is not a true lvalue.  */
 	if (!lvalue_or_else (arg, ((code == PREINCREMENT_EXPR
 				    || code == POSTINCREMENT_EXPR)
@@ -2892,6 +2953,12 @@
 				  TREE_OPERAND (arg, 1), 1);
 	}
 
+      /* Handle complex lvalues (when permitted)
+	 by reduction to simpler cases.  */
+      val = unary_complex_lvalue (code, arg, flag);
+      if (val != 0)
+	return val;
+
       /* Anything not already handled and not a true memory reference
 	 or a non-lvalue array is an error.  */
       else if (typecode != FUNCTION_TYPE && !flag
@@ -2977,6 +3044,69 @@
     }
 }
 
+/* Apply unary lvalue-demanding operator CODE to the expression ARG
+   for certain kinds of expressions which are not really lvalues
+   but which we can accept as lvalues.  If FLAG is nonzero, then
+   non-lvalues are OK since we may be converting a non-lvalue array to
+   a pointer in C99.
+
+   If ARG is not a kind of expression we can handle, return zero.  */
+
+static tree
+unary_complex_lvalue (enum tree_code code, tree arg, int flag)
+{
+  /* Handle (a, b) used as an "lvalue".  */
+  if (TREE_CODE (arg) == COMPOUND_EXPR)
+    {
+      tree real_result = build_unary_op (code, TREE_OPERAND (arg, 1), 0);
+
+      /* If this returns a function type, it isn't really being used as
+	 an lvalue, so don't issue a warning about it.  */
+      if (TREE_CODE (TREE_TYPE (arg)) != FUNCTION_TYPE && !flag)
+	pedantic_lvalue_warning (COMPOUND_EXPR);
+
+      return build (COMPOUND_EXPR, TREE_TYPE (real_result),
+		    TREE_OPERAND (arg, 0), real_result);
+    }
+
+  /* Handle (a ? b : c) used as an "lvalue".  */
+  if (TREE_CODE (arg) == COND_EXPR)
+    {
+      if (!flag)
+	pedantic_lvalue_warning (COND_EXPR);
+      if (TREE_CODE (TREE_TYPE (arg)) != FUNCTION_TYPE && !flag)
+	pedantic_lvalue_warning (COMPOUND_EXPR);
+
+      return (build_conditional_expr
+	      (TREE_OPERAND (arg, 0),
+	       build_unary_op (code, TREE_OPERAND (arg, 1), flag),
+	       build_unary_op (code, TREE_OPERAND (arg, 2), flag)));
+    }
+
+  return 0;
+}
+
+/* If pedantic, warn about improper lvalue.   CODE is either COND_EXPR
+   COMPOUND_EXPR, or CONVERT_EXPR (for casts).  */
+
+static void
+pedantic_lvalue_warning (enum tree_code code)
+{
+  if (pedantic)
+    switch (code)
+      {
+      case COND_EXPR:
+	pedwarn ("ISO C forbids use of conditional expressions as lvalues");
+	break;
+      case COMPOUND_EXPR:
+	pedwarn ("ISO C forbids use of compound expressions as lvalues");
+	break;
+      default:
+	pedwarn ("ISO C forbids use of cast expressions as lvalues");
+	break;
+      }
+}
+  
 /* Give an error for storing in something that is 'const'.  */
 
 static void
@@ -3490,8 +3620,8 @@
 	}
     }
 
-  /* Don't let a cast be an lvalue.  */
-  if (value == expr)
+  /* If pedantic, don't let a cast be an lvalue.  */
+  if (value == expr && pedantic)
     value = non_lvalue (value);
 
   return value;
@@ -3539,6 +3669,45 @@
 
   newrhs = rhs;
 
+  /* Handle control structure constructs used as "lvalues".  */
+
+  switch (TREE_CODE (lhs))
+    {
+      /* Handle (a, b) used as an "lvalue".  */
+    case COMPOUND_EXPR:
+      pedantic_lvalue_warning (COMPOUND_EXPR);
+      newrhs = build_modify_expr (TREE_OPERAND (lhs, 1), modifycode, rhs);
+      if (TREE_CODE (newrhs) == ERROR_MARK)
+	return error_mark_node;
+      return build (COMPOUND_EXPR, lhstype,
+		    TREE_OPERAND (lhs, 0), newrhs);
+
+      /* Handle (a ? b : c) used as an "lvalue".  */
+    case COND_EXPR:
+      pedantic_lvalue_warning (COND_EXPR);
+      rhs = save_expr (rhs);
+      {
+	/* Produce (a ? (b = rhs) : (c = rhs))
+	   except that the RHS goes through a save-expr
+	   so the code to compute it is only emitted once.  */
+	tree cond
+	  = build_conditional_expr (TREE_OPERAND (lhs, 0),
+				    build_modify_expr (TREE_OPERAND (lhs, 1),
+						       modifycode, rhs),
+				    build_modify_expr (TREE_OPERAND (lhs, 2),
+						       modifycode, rhs));
+	if (TREE_CODE (cond) == ERROR_MARK)
+	  return cond;
+	/* Make sure the code to compute the rhs comes out
+	   before the split.  */
+	return build (COMPOUND_EXPR, TREE_TYPE (lhs),
+		      /* But cast it to void to avoid an "unused" error.  */
+		      convert (void_type_node, rhs), cond);
+      }
+    default:
+      break;
+    }
+
   /* If a binary op has been requested, combine the old LHS value with the RHS
      producing the value we should actually store into the LHS.  */
 
@@ -3548,6 +3717,42 @@
       newrhs = build_binary_op (modifycode, lhs, rhs, 1);
     }
 
+  /* Handle a cast used as an "lvalue".
+     We have already performed any binary operator using the value as cast.
+     Now convert the result to the cast type of the lhs,
+     and then true type of the lhs and store it there;
+     then convert result back to the cast type to be the value
+     of the assignment.  */
+
+  switch (TREE_CODE (lhs))
+    {
+    case NOP_EXPR:
+    case CONVERT_EXPR:
+    case FLOAT_EXPR:
+    case FIX_TRUNC_EXPR:
+    case FIX_FLOOR_EXPR:
+    case FIX_ROUND_EXPR:
+    case FIX_CEIL_EXPR:
+      newrhs = default_function_array_conversion (newrhs);
+      {
+	tree inner_lhs = TREE_OPERAND (lhs, 0);
+	tree result;
+	result = build_modify_expr (inner_lhs, NOP_EXPR,
+				    convert (TREE_TYPE (inner_lhs),
+					     convert (lhstype, newrhs)));
+	if (TREE_CODE (result) == ERROR_MARK)
+	  return result;
+	pedantic_lvalue_warning (CONVERT_EXPR);
+	return convert (TREE_TYPE (lhs), result);
+      }
+
+    default:
+      break;
+    }
+
+  /* Now we have handled acceptable kinds of LHS that are not truly lvalues.
+     Reject anything strange now.  */
+
   if (!lvalue_or_else (lhs, lv_assign))
     return error_mark_node;
 
@@ -4343,10 +4548,11 @@
 {
   char *ofwhat;
 
-  error ("%s", _(msgid));
   ofwhat = print_spelling ((char *) alloca (spelling_length () + 1));
   if (*ofwhat)
-    error ("(near initialization for %qs)", ofwhat);
+    error ("%s (near initialization for %qs)", _(msgid), ofwhat);
+  else
+    error ("%s", _(msgid));
 }
 
 /* Issue a pedantic warning for a bad initializer component.
@@ -4358,10 +4564,11 @@
 {
   char *ofwhat;
 
-  pedwarn ("%s", _(msgid));
   ofwhat = print_spelling ((char *) alloca (spelling_length () + 1));
   if (*ofwhat)
-    pedwarn ("(near initialization for %qs)", ofwhat);
+    pedwarn ("%s (near initialization for %qs)", _(msgid), ofwhat);
+  else
+    pedwarn ("%s", _(msgid));
 }
 
 /* Issue a warning for a bad initializer component.
@@ -4373,10 +4580,11 @@
 {
   char *ofwhat;
 
-  warning (0, "%s", _(msgid));
   ofwhat = print_spelling ((char *) alloca (spelling_length () + 1));
   if (*ofwhat)
-    warning (0, "(near initialization for %qs)", ofwhat);
+    warning (0, "%s (near initialization for %qs)", _(msgid), ofwhat);
+  else
+    warning (0, "%s", _(msgid));
 }
 
 /* If TYPE is an array type and EXPR is a parenthesized string
diff -Naur gcc-4.1-20051216.orig/gcc/diagnostic.c gcc-4.1-20051216-src/gcc/diagnostic.c
--- gcc-4.1-20051216.orig/gcc/diagnostic.c	2005-11-04 00:08:18.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/diagnostic.c	2005-12-18 22:24:36.000000000 +0100
@@ -252,9 +252,8 @@
       if (context->abort_on_error)
 	real_abort ();
 
-      fnotice (stderr, "Please submit a full bug report,\n"
-	       "with preprocessed source if appropriate.\n"
-	       "See %s for instructions.\n", bug_report_url);
+      fnotice (stderr, "Please fill out a bug report form at %s.\n",
+               bug_report_url);
       exit (FATAL_EXIT_CODE);
 
     case DK_FATAL:
diff -Naur gcc-4.1-20051216.orig/gcc/dwarf2.h gcc-4.1-20051216-src/gcc/dwarf2.h
--- gcc-4.1-20051216.orig/gcc/dwarf2.h	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/dwarf2.h	2005-12-18 22:24:36.000000000 +0100
@@ -352,6 +352,7 @@
     DW_AT_body_begin = 0x2105,
     DW_AT_body_end   = 0x2106,
     DW_AT_GNU_vector = 0x2107,
+    DW_AT_regparm_location = 0x2120,
     /* VMS extensions.  */
     DW_AT_VMS_rtnbeg_pd_address = 0x2201,
     /* UPC extension.  */
diff -Naur gcc-4.1-20051216.orig/gcc/dwarf2out.c gcc-4.1-20051216-src/gcc/dwarf2out.c
--- gcc-4.1-20051216.orig/gcc/dwarf2out.c	2005-12-09 00:47:48.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/dwarf2out.c	2005-12-18 22:24:40.000000000 +0100
@@ -758,6 +758,18 @@
 	      || loc1->base_offset == loc2->base_offset));
 }
 
+/* Determine if two dw_cfa_location structures define the same data.  */
+
+static bool
+cfa_equal_p (const dw_cfa_location *loc1, const dw_cfa_location *loc2)
+{
+  return (loc1->reg == loc2->reg
+	  && loc1->offset == loc2->offset
+	  && loc1->indirect == loc2->indirect
+	  && (loc1->indirect == 0
+	      || loc1->base_offset == loc2->base_offset));
+}
+
 /* This routine does the actual work.  The CFA is now calculated from
    the dw_cfa_location structure.  */
 
@@ -2164,8 +2176,11 @@
      emit any EH unwind information.  Note that if exceptions aren't
      enabled, we won't have collected nothrow information, and if we
      asked for asynchronous tables, we always want this info.  */
+  /* (TIGCC 20050507) We want unwinding tables for debugging purposes only,
+     so we don't want an .eh_frame section we didn't ask for. */
   if (for_eh)
     {
+#if 0
       bool any_eh_needed = !flag_exceptions || flag_asynchronous_unwind_tables;
 
       for (i = 0; i < fde_table_in_use; i++)
@@ -2178,6 +2193,7 @@
 	  any_eh_needed = true;
 
       if (! any_eh_needed)
+#endif /* 0 */
 	return;
     }
 
@@ -3918,6 +3934,10 @@
    within the current function.  */
 static HOST_WIDE_INT frame_pointer_cfa_offset;
 
+/* Offset from the "steady-state frame pointer" to the CFA,
+   within the current function.  */
+static HOST_WIDE_INT frame_pointer_cfa_offset;
+
 /* Forward declarations for functions defined in this file.  */
 
 static int is_pseudo_reg (rtx);
@@ -4139,7 +4159,7 @@
 static void decls_for_scope (tree, dw_die_ref, int);
 static int is_redundant_typedef (tree);
 static void gen_namespace_die (tree);
-static void gen_decl_die (tree, dw_die_ref);
+static dw_die_ref gen_decl_die (tree, dw_die_ref);
 static dw_die_ref force_decl_die (tree);
 static dw_die_ref force_type_die (tree);
 static dw_die_ref setup_namespace_context (tree, dw_die_ref);
@@ -4640,6 +4660,8 @@
       return "DW_AT_body_end";
     case DW_AT_GNU_vector:
       return "DW_AT_GNU_vector";
+    case DW_AT_regparm_location:
+      return "DW_AT_regparm_location";
 
     case DW_AT_VMS_rtnbeg_pd_address:
       return "DW_AT_VMS_rtnbeg_pd_address";
@@ -9746,14 +9768,7 @@
   int i;
 
   REAL_VALUE_FROM_CONST_DOUBLE (rv, rtl);
-  real_to_target (val, &rv, GET_MODE (rtl));
-
-  /* real_to_target puts 32-bit pieces in each long.  Pack them.  */
-  for (i = 0; i < GET_MODE_SIZE (GET_MODE (rtl)) / 4; i++)
-    {
-      insert_int (val[i], 4, array);
-      array += 4;
-    }
+  REAL_VALUE_TO_TARGET_SMAP_BCD (rv, array);
 }
 
 /* Attach a DW_AT_const_value attribute for a variable or a parameter which
@@ -9792,7 +9807,7 @@
 	    unsigned char *array = ggc_alloc (length);
 
 	    insert_float (rtl, array);
-	    add_AT_vec (die, DW_AT_const_value, length / 4, 4, array);
+	    add_AT_vec (die, DW_AT_const_value, 1, length, array); /* (TIGCC 20050403) */
 	  }
 	else
 	  {
@@ -10439,6 +10454,98 @@
 }
 #endif
 
+/* Convert the CFI instructions for the current function into a location
+   list.  This is used for DW_AT_frame_base when we targeting a dwarf2
+   consumer that does not support the dwarf3 DW_OP_call_frame_cfa.  */
+
+static dw_loc_list_ref
+convert_cfa_to_loc_list (void)
+{
+  dw_fde_ref fde;
+  dw_loc_list_ref list, *list_tail;
+  dw_cfi_ref cfi;
+  dw_cfa_location last_cfa, next_cfa;
+  const char *start_label, *last_label, *section;
+
+  fde = &fde_table[fde_table_in_use - 1];
+
+  section = secname_for_decl (current_function_decl);
+  list_tail = &list;
+  list = NULL;
+
+  next_cfa.reg = INVALID_REGNUM;
+  next_cfa.offset = 0;
+  next_cfa.indirect = 0;
+  next_cfa.base_offset = 0;
+
+  start_label = fde->dw_fde_begin;
+
+  /* ??? Bald assumption that the CIE opcode list does not contain
+     advance opcodes.  */
+  for (cfi = cie_cfi_head; cfi; cfi = cfi->dw_cfi_next)
+    lookup_cfa_1 (cfi, &next_cfa);
+
+  last_cfa = next_cfa;
+  last_label = start_label;
+
+  for (cfi = fde->dw_fde_cfi; cfi; cfi = cfi->dw_cfi_next)
+    switch (cfi->dw_cfi_opc)
+      {
+      case DW_CFA_advance_loc1:
+      case DW_CFA_advance_loc2:
+      case DW_CFA_advance_loc4:
+	if (!cfa_equal_p (&last_cfa, &next_cfa))
+	  {
+	    *list_tail = new_loc_list (build_cfa_loc (&last_cfa), start_label,
+				       last_label, section, list == NULL);
+
+	    list_tail = &(*list_tail)->dw_loc_next;
+	    last_cfa = next_cfa;
+	    start_label = last_label;
+	  }
+	last_label = cfi->dw_cfi_oprnd1.dw_cfi_addr;
+	break;
+
+      case DW_CFA_advance_loc:
+	/* The encoding is complex enough that we should never emit this.  */
+      case DW_CFA_remember_state:
+      case DW_CFA_restore_state:
+	/* We don't handle these two in this function.  It would be possible
+	   if it were to be required.  */
+	gcc_unreachable ();
+
+      default:
+	lookup_cfa_1 (cfi, &next_cfa);
+	break;
+      }
+
+  if (!cfa_equal_p (&last_cfa, &next_cfa))
+    {
+      *list_tail = new_loc_list (build_cfa_loc (&last_cfa), start_label,
+				 last_label, section, list == NULL);
+      list_tail = &(*list_tail)->dw_loc_next;
+      start_label = last_label;
+    }
+  *list_tail = new_loc_list (build_cfa_loc (&next_cfa), start_label,
+			     fde->dw_fde_end, section, list == NULL);
+
+  return list;
+}
+
+/* Compute a displacement from the "steady-state frame pointer" to
+   the CFA, and store it in frame_pointer_cfa_offset.  */
+
+static void
+compute_frame_pointer_to_cfa_displacement (void)
+{
+  HOST_WIDE_INT offset;
+
+  offset = eliminate_reg_to_offset (arg_pointer_rtx);
+  offset += ARG_POINTER_CFA_OFFSET (current_function_decl);
+
+  frame_pointer_cfa_offset = -offset;
+}
+
 /* Generate a DW_AT_name attribute given some string value to be included as
    the value of the attribute.  */
 
@@ -11338,6 +11445,10 @@
    DW_TAG_unspecified_parameters DIE) to represent the types of the formal
    parameters as specified in some function type specification (except for
    those which appear as part of a function *definition*).  */
+/* (TIGCC 20050409) We also want to generate DW_AT_regparm_location
+   information for register parameters so GDB can call the function
+   correctly. We don't use DW_AT_location in order not to conflict with
+   the location list support. */
 
 static void
 gen_formal_types_die (tree function_or_method_type, dw_die_ref context_die)
@@ -11346,15 +11457,21 @@
   tree formal_type = NULL;
   tree first_parm_type;
   tree arg;
+  tree function_or_method_decl = NULL_TREE;
+  CUMULATIVE_ARGS cum;
 
   if (TREE_CODE (function_or_method_type) == FUNCTION_DECL)
     {
+      function_or_method_decl = function_or_method_type;
       arg = DECL_ARGUMENTS (function_or_method_type);
       function_or_method_type = TREE_TYPE (function_or_method_type);
     }
   else
     arg = NULL_TREE;
 
+  if (function_or_method_decl)
+    INIT_CUMULATIVE_ARGS (cum, function_or_method_type, NULL, function_or_method_decl, 0);
+
   first_parm_type = TYPE_ARG_TYPES (function_or_method_type);
 
   /* Make our first pass over the list of formal parameter types and output a
@@ -11374,6 +11491,17 @@
 	  || (arg && DECL_ARTIFICIAL (arg)))
 	add_AT_flag (parm_die, DW_AT_artificial, 1);
 
+      if (function_or_method_decl)
+        {
+          rtx argrtx = FUNCTION_ARG(cum, TYPE_MODE (formal_type), formal_type, 0);
+          if (argrtx && GET_CODE (argrtx) == REG && REGNO (argrtx) < FIRST_PSEUDO_REGISTER)
+            {
+              add_AT_location_description (parm_die, DW_AT_regparm_location, reg_loc_descriptor (argrtx));
+            }
+
+          FUNCTION_ARG_ADVANCE(cum, 0, 0, 0);
+        }
+
       link = TREE_CHAIN (link);
       if (arg)
 	arg = TREE_CHAIN (arg);
@@ -11477,6 +11605,10 @@
 
 /* Generate a DIE to represent a declared function (either file-scope or
    block-local).  */
+/* (TIGCC 20050409) We also want to generate DW_AT_regparm_location
+   information for register parameters so GDB can call the function
+   correctly. We don't use DW_AT_location in order not to conflict with
+   the location list support. */
 
 static void
 gen_subprogram_die (tree decl, dw_die_ref context_die)
@@ -11739,6 +11871,8 @@
       tree arg_decls = DECL_ARGUMENTS (decl);
       tree parm;
 
+      INIT_CUMULATIVE_ARGS (cum, TREE_TYPE (decl), NULL, decl, 0);
+
       /* When generating DIEs, generate the unspecified_parameters DIE
 	 instead if we come across the arg "__builtin_va_alist" */
       for (parm = arg_decls; parm; parm = TREE_CHAIN (parm))
@@ -11749,7 +11883,16 @@
 			    "__builtin_va_alist"))
 	      gen_unspecified_parameters_die (parm, subr_die);
 	    else
-	      gen_decl_die (parm, subr_die);
+	      {
+	        dw_die_ref parm_die = gen_decl_die (parm, subr_die);
+	        rtx argrtx = FUNCTION_ARG(cum, TYPE_MODE (TREE_TYPE (parm)), TREE_TYPE (parm), 0);
+	        if (parm_die && argrtx && GET_CODE (argrtx) == REG && REGNO (argrtx) < FIRST_PSEUDO_REGISTER)
+	          {
+	            add_AT_location_description (parm_die, DW_AT_regparm_location, reg_loc_descriptor (argrtx));
+	          }
+	      }
+
+	    FUNCTION_ARG_ADVANCE(cum, 0, 0, 0);
 	  }
 
       /* Decide whether we need an unspecified_parameters DIE at the end.
@@ -12977,14 +13120,15 @@
 }
 
 /* Generate Dwarf debug information for a decl described by DECL.  */
+/* (TIGCC 20050409) Return the DIE for the parameter case. */
 
-static void
+static dw_die_ref
 gen_decl_die (tree decl, dw_die_ref context_die)
 {
   tree origin;
 
   if (DECL_P (decl) && DECL_IGNORED_P (decl))
-    return;
+    return NULL;
 
   switch (TREE_CODE (decl))
     {
@@ -13127,8 +13271,7 @@
 
     case PARM_DECL:
       gen_type_die (TREE_TYPE (decl), context_die);
-      gen_formal_parameter_die (decl, context_die);
-      break;
+      return gen_formal_parameter_die (decl, context_die);
 
     case NAMESPACE_DECL:
       gen_namespace_die (decl);
@@ -13139,6 +13282,8 @@
       gcc_assert ((int)TREE_CODE (decl) > NUM_TREE_CODES);
       break;
     }
+
+    return NULL;
 }
 
 /* Add Ada "use" clause information for SGI Workshop debugger.  */
@@ -13474,6 +13619,12 @@
    numbers are different because we prune debug info for unused variables and
    types, which may include filenames.  */
 
+/* If the assembler will construct the file table, then translate the compiler
+   internal file table number into the assembler file table number, and emit
+   a .file directive if we haven't already emitted one yet.  The file table
+   numbers are different because we prune debug info for unused variables and
+   types, which may include filenames.  */
+
 static int
 maybe_emit_file (int fileno)
 {
@@ -13606,10 +13757,10 @@
 	  line_info_table_in_use++;
 
 	  /* Indicate that multiple line number tables exist.  */
-	  if (DECL_SECTION_NAME (current_function_decl))
+	  if (current_function_decl && DECL_SECTION_NAME (current_function_decl))
 	    separate_line_info_table_in_use++;
 	}
-      else if (DECL_SECTION_NAME (current_function_decl))
+      else if (current_function_decl && DECL_SECTION_NAME (current_function_decl))
 	{
 	  dw_separate_line_info_ref line_info;
 	  targetm.asm_out.internal_label (asm_out_file, SEPARATE_LINE_CODE_LABEL,
diff -Naur gcc-4.1-20051216.orig/gcc/dwarf2out.c.orig gcc-4.1-20051216-src/gcc/dwarf2out.c.orig
--- gcc-4.1-20051216.orig/gcc/dwarf2out.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/dwarf2out.c.orig	2005-12-09 00:47:48.000000000 +0100
@@ -0,0 +1,14260 @@
+/* Output Dwarf2 format symbol table information from GCC.
+   Copyright (C) 1992, 1993, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,
+   2003, 2004, 2005 Free Software Foundation, Inc.
+   Contributed by Gary Funck (gary@intrepid.com).
+   Derived from DWARF 1 implementation of Ron Guilmette (rfg@monkeys.com).
+   Extensively modified by Jason Merrill (jason@cygnus.com).
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 2, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING.  If not, write to the Free
+Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA
+02110-1301, USA.  */
+
+/* TODO: Emit .debug_line header even when there are no functions, since
+	   the file numbers are used by .debug_info.  Alternately, leave
+	   out locations for types and decls.
+	 Avoid talking about ctors and op= for PODs.
+	 Factor out common prologue sequences into multiple CIEs.  */
+
+/* The first part of this file deals with the DWARF 2 frame unwind
+   information, which is also used by the GCC efficient exception handling
+   mechanism.  The second part, controlled only by an #ifdef
+   DWARF2_DEBUGGING_INFO, deals with the other DWARF 2 debugging
+   information.  */
+
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "tm.h"
+#include "tree.h"
+#include "version.h"
+#include "flags.h"
+#include "real.h"
+#include "rtl.h"
+#include "hard-reg-set.h"
+#include "regs.h"
+#include "insn-config.h"
+#include "reload.h"
+#include "function.h"
+#include "output.h"
+#include "expr.h"
+#include "libfuncs.h"
+#include "except.h"
+#include "dwarf2.h"
+#include "dwarf2out.h"
+#include "dwarf2asm.h"
+#include "toplev.h"
+#include "varray.h"
+#include "ggc.h"
+#include "md5.h"
+#include "tm_p.h"
+#include "diagnostic.h"
+#include "debug.h"
+#include "target.h"
+#include "langhooks.h"
+#include "hashtab.h"
+#include "cgraph.h"
+#include "input.h"
+
+#ifdef DWARF2_DEBUGGING_INFO
+static void dwarf2out_source_line (unsigned int, const char *);
+#endif
+
+/* DWARF2 Abbreviation Glossary:
+   CFA = Canonical Frame Address
+	   a fixed address on the stack which identifies a call frame.
+	   We define it to be the value of SP just before the call insn.
+	   The CFA register and offset, which may change during the course
+	   of the function, are used to calculate its value at runtime.
+   CFI = Call Frame Instruction
+	   an instruction for the DWARF2 abstract machine
+   CIE = Common Information Entry
+	   information describing information common to one or more FDEs
+   DIE = Debugging Information Entry
+   FDE = Frame Description Entry
+	   information describing the stack call frame, in particular,
+	   how to restore registers
+
+   DW_CFA_... = DWARF2 CFA call frame instruction
+   DW_TAG_... = DWARF2 DIE tag */
+
+/* Decide whether we want to emit frame unwind information for the current
+   translation unit.  */
+
+int
+dwarf2out_do_frame (void)
+{
+  return (write_symbols == DWARF2_DEBUG
+	  || write_symbols == VMS_AND_DWARF2_DEBUG
+#ifdef DWARF2_FRAME_INFO
+	  || DWARF2_FRAME_INFO
+#endif
+#ifdef DWARF2_UNWIND_INFO
+	  || flag_unwind_tables
+	  || (flag_exceptions && ! USING_SJLJ_EXCEPTIONS)
+#endif
+	  );
+}
+
+/* The size of the target's pointer type.  */
+#ifndef PTR_SIZE
+#define PTR_SIZE (POINTER_SIZE / BITS_PER_UNIT)
+#endif
+
+/* Various versions of targetm.eh_frame_section.  Note these must appear
+   outside the DWARF2_DEBUGGING_INFO || DWARF2_UNWIND_INFO macro guards.  */
+
+/* Version of targetm.eh_frame_section for systems with named sections.  */
+void
+named_section_eh_frame_section (void)
+{
+#ifdef EH_FRAME_SECTION_NAME
+  int flags;
+
+  if (EH_TABLES_CAN_BE_READ_ONLY)
+    {
+      int fde_encoding;
+      int per_encoding;
+      int lsda_encoding;
+
+      fde_encoding = ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/1, /*global=*/0);
+      per_encoding = ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/2, /*global=*/1);
+      lsda_encoding = ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/0, /*global=*/0);
+      flags = (! flag_pic
+	       || ((fde_encoding & 0x70) != DW_EH_PE_absptr
+		   && (fde_encoding & 0x70) != DW_EH_PE_aligned
+		   && (per_encoding & 0x70) != DW_EH_PE_absptr
+		   && (per_encoding & 0x70) != DW_EH_PE_aligned
+		   && (lsda_encoding & 0x70) != DW_EH_PE_absptr
+		   && (lsda_encoding & 0x70) != DW_EH_PE_aligned))
+	      ? 0 : SECTION_WRITE;
+    }
+  else
+    flags = SECTION_WRITE;
+  named_section_flags (EH_FRAME_SECTION_NAME, flags);
+#endif
+}
+
+/* Version of targetm.eh_frame_section for systems using collect2.  */
+void
+collect2_eh_frame_section (void)
+{
+  tree label = get_file_function_name ('F');
+
+  data_section ();
+  ASM_OUTPUT_ALIGN (asm_out_file, floor_log2 (PTR_SIZE));
+  targetm.asm_out.globalize_label (asm_out_file, IDENTIFIER_POINTER (label));
+  ASM_OUTPUT_LABEL (asm_out_file, IDENTIFIER_POINTER (label));
+}
+
+/* Default version of targetm.eh_frame_section.  */
+void
+default_eh_frame_section (void)
+{
+#ifdef EH_FRAME_SECTION_NAME
+  named_section_eh_frame_section ();
+#else
+  collect2_eh_frame_section ();
+#endif
+}
+
+DEF_VEC_P(rtx);
+DEF_VEC_ALLOC_P(rtx,gc);
+
+/* Array of RTXes referenced by the debugging information, which therefore
+   must be kept around forever.  */
+static GTY(()) VEC(rtx,gc) *used_rtx_array;
+
+/* A pointer to the base of a list of incomplete types which might be
+   completed at some later time.  incomplete_types_list needs to be a
+   VEC(tree,gc) because we want to tell the garbage collector about
+   it.  */
+static GTY(()) VEC(tree,gc) *incomplete_types;
+
+/* A pointer to the base of a table of references to declaration
+   scopes.  This table is a display which tracks the nesting
+   of declaration scopes at the current scope and containing
+   scopes.  This table is used to find the proper place to
+   define type declaration DIE's.  */
+static GTY(()) VEC(tree,gc) *decl_scope_table;
+
+/* How to start an assembler comment.  */
+#ifndef ASM_COMMENT_START
+#define ASM_COMMENT_START ";#"
+#endif
+
+typedef struct dw_cfi_struct *dw_cfi_ref;
+typedef struct dw_fde_struct *dw_fde_ref;
+typedef union  dw_cfi_oprnd_struct *dw_cfi_oprnd_ref;
+
+/* Call frames are described using a sequence of Call Frame
+   Information instructions.  The register number, offset
+   and address fields are provided as possible operands;
+   their use is selected by the opcode field.  */
+
+enum dw_cfi_oprnd_type {
+  dw_cfi_oprnd_unused,
+  dw_cfi_oprnd_reg_num,
+  dw_cfi_oprnd_offset,
+  dw_cfi_oprnd_addr,
+  dw_cfi_oprnd_loc
+};
+
+typedef union dw_cfi_oprnd_struct GTY(())
+{
+  unsigned int GTY ((tag ("dw_cfi_oprnd_reg_num"))) dw_cfi_reg_num;
+  HOST_WIDE_INT GTY ((tag ("dw_cfi_oprnd_offset"))) dw_cfi_offset;
+  const char * GTY ((tag ("dw_cfi_oprnd_addr"))) dw_cfi_addr;
+  struct dw_loc_descr_struct * GTY ((tag ("dw_cfi_oprnd_loc"))) dw_cfi_loc;
+}
+dw_cfi_oprnd;
+
+typedef struct dw_cfi_struct GTY(())
+{
+  dw_cfi_ref dw_cfi_next;
+  enum dwarf_call_frame_info dw_cfi_opc;
+  dw_cfi_oprnd GTY ((desc ("dw_cfi_oprnd1_desc (%1.dw_cfi_opc)")))
+    dw_cfi_oprnd1;
+  dw_cfi_oprnd GTY ((desc ("dw_cfi_oprnd2_desc (%1.dw_cfi_opc)")))
+    dw_cfi_oprnd2;
+}
+dw_cfi_node;
+
+/* This is how we define the location of the CFA. We use to handle it
+   as REG + OFFSET all the time,  but now it can be more complex.
+   It can now be either REG + CFA_OFFSET or *(REG + BASE_OFFSET) + CFA_OFFSET.
+   Instead of passing around REG and OFFSET, we pass a copy
+   of this structure.  */
+typedef struct cfa_loc GTY(())
+{
+  HOST_WIDE_INT offset;
+  HOST_WIDE_INT base_offset;
+  unsigned int reg;
+  int indirect;            /* 1 if CFA is accessed via a dereference.  */
+} dw_cfa_location;
+
+/* All call frame descriptions (FDE's) in the GCC generated DWARF
+   refer to a single Common Information Entry (CIE), defined at
+   the beginning of the .debug_frame section.  This use of a single
+   CIE obviates the need to keep track of multiple CIE's
+   in the DWARF generation routines below.  */
+
+typedef struct dw_fde_struct GTY(())
+{
+  tree decl;
+  const char *dw_fde_begin;
+  const char *dw_fde_current_label;
+  const char *dw_fde_end;
+  const char *dw_fde_hot_section_label;
+  const char *dw_fde_hot_section_end_label;
+  const char *dw_fde_unlikely_section_label;
+  const char *dw_fde_unlikely_section_end_label;
+  bool dw_fde_switched_sections;
+  dw_cfi_ref dw_fde_cfi;
+  unsigned funcdef_number;
+  unsigned all_throwers_are_sibcalls : 1;
+  unsigned nothrow : 1;
+  unsigned uses_eh_lsda : 1;
+}
+dw_fde_node;
+
+/* Maximum size (in bytes) of an artificially generated label.  */
+#define MAX_ARTIFICIAL_LABEL_BYTES	30
+
+/* The size of addresses as they appear in the Dwarf 2 data.
+   Some architectures use word addresses to refer to code locations,
+   but Dwarf 2 info always uses byte addresses.  On such machines,
+   Dwarf 2 addresses need to be larger than the architecture's
+   pointers.  */
+#ifndef DWARF2_ADDR_SIZE
+#define DWARF2_ADDR_SIZE (POINTER_SIZE / BITS_PER_UNIT)
+#endif
+
+/* The size in bytes of a DWARF field indicating an offset or length
+   relative to a debug info section, specified to be 4 bytes in the
+   DWARF-2 specification.  The SGI/MIPS ABI defines it to be the same
+   as PTR_SIZE.  */
+
+#ifndef DWARF_OFFSET_SIZE
+#define DWARF_OFFSET_SIZE 4
+#endif
+
+/* According to the (draft) DWARF 3 specification, the initial length
+   should either be 4 or 12 bytes.  When it's 12 bytes, the first 4
+   bytes are 0xffffffff, followed by the length stored in the next 8
+   bytes.
+
+   However, the SGI/MIPS ABI uses an initial length which is equal to
+   DWARF_OFFSET_SIZE.  It is defined (elsewhere) accordingly.  */
+
+#ifndef DWARF_INITIAL_LENGTH_SIZE
+#define DWARF_INITIAL_LENGTH_SIZE (DWARF_OFFSET_SIZE == 4 ? 4 : 12)
+#endif
+
+#define DWARF_VERSION 2
+
+/* Round SIZE up to the nearest BOUNDARY.  */
+#define DWARF_ROUND(SIZE,BOUNDARY) \
+  ((((SIZE) + (BOUNDARY) - 1) / (BOUNDARY)) * (BOUNDARY))
+
+/* Offsets recorded in opcodes are a multiple of this alignment factor.  */
+#ifndef DWARF_CIE_DATA_ALIGNMENT
+#ifdef STACK_GROWS_DOWNWARD
+#define DWARF_CIE_DATA_ALIGNMENT (-((int) UNITS_PER_WORD))
+#else
+#define DWARF_CIE_DATA_ALIGNMENT ((int) UNITS_PER_WORD)
+#endif
+#endif
+
+/* A pointer to the base of a table that contains frame description
+   information for each routine.  */
+static GTY((length ("fde_table_allocated"))) dw_fde_ref fde_table;
+
+/* Number of elements currently allocated for fde_table.  */
+static GTY(()) unsigned fde_table_allocated;
+
+/* Number of elements in fde_table currently in use.  */
+static GTY(()) unsigned fde_table_in_use;
+
+/* Size (in elements) of increments by which we may expand the
+   fde_table.  */
+#define FDE_TABLE_INCREMENT 256
+
+/* A list of call frame insns for the CIE.  */
+static GTY(()) dw_cfi_ref cie_cfi_head;
+
+#if defined (DWARF2_DEBUGGING_INFO) || defined (DWARF2_UNWIND_INFO)
+/* Some DWARF extensions (e.g., MIPS/SGI) implement a subprogram
+   attribute that accelerates the lookup of the FDE associated
+   with the subprogram.  This variable holds the table index of the FDE
+   associated with the current function (body) definition.  */
+static unsigned current_funcdef_fde;
+#endif
+
+struct indirect_string_node GTY(())
+{
+  const char *str;
+  unsigned int refcount;
+  unsigned int form;
+  char *label;
+};
+
+static GTY ((param_is (struct indirect_string_node))) htab_t debug_str_hash;
+
+static GTY(()) int dw2_string_counter;
+static GTY(()) unsigned long dwarf2out_cfi_label_num;
+
+#if defined (DWARF2_DEBUGGING_INFO) || defined (DWARF2_UNWIND_INFO)
+
+/* Forward declarations for functions defined in this file.  */
+
+static char *stripattributes (const char *);
+static const char *dwarf_cfi_name (unsigned);
+static dw_cfi_ref new_cfi (void);
+static void add_cfi (dw_cfi_ref *, dw_cfi_ref);
+static void add_fde_cfi (const char *, dw_cfi_ref);
+static void lookup_cfa_1 (dw_cfi_ref, dw_cfa_location *);
+static void lookup_cfa (dw_cfa_location *);
+static void reg_save (const char *, unsigned, unsigned, HOST_WIDE_INT);
+static void initial_return_save (rtx);
+static HOST_WIDE_INT stack_adjust_offset (rtx);
+static void output_cfi (dw_cfi_ref, dw_fde_ref, int);
+static void output_call_frame_info (int);
+static void dwarf2out_stack_adjust (rtx, bool);
+static void flush_queued_reg_saves (void);
+static bool clobbers_queued_reg_save (rtx);
+static void dwarf2out_frame_debug_expr (rtx, const char *);
+
+/* Support for complex CFA locations.  */
+static void output_cfa_loc (dw_cfi_ref);
+static void get_cfa_from_loc_descr (dw_cfa_location *,
+				    struct dw_loc_descr_struct *);
+static struct dw_loc_descr_struct *build_cfa_loc
+ (dw_cfa_location *);
+static void def_cfa_1 (const char *, dw_cfa_location *);
+
+/* How to start an assembler comment.  */
+#ifndef ASM_COMMENT_START
+#define ASM_COMMENT_START ";#"
+#endif
+
+/* Data and reference forms for relocatable data.  */
+#define DW_FORM_data (DWARF_OFFSET_SIZE == 8 ? DW_FORM_data8 : DW_FORM_data4)
+#define DW_FORM_ref (DWARF_OFFSET_SIZE == 8 ? DW_FORM_ref8 : DW_FORM_ref4)
+
+#ifndef DEBUG_FRAME_SECTION
+#define DEBUG_FRAME_SECTION	".debug_frame"
+#endif
+
+#ifndef FUNC_BEGIN_LABEL
+#define FUNC_BEGIN_LABEL	"LFB"
+#endif
+
+#ifndef FUNC_END_LABEL
+#define FUNC_END_LABEL		"LFE"
+#endif
+
+#ifndef FRAME_BEGIN_LABEL
+#define FRAME_BEGIN_LABEL	"Lframe"
+#endif
+#define CIE_AFTER_SIZE_LABEL	"LSCIE"
+#define CIE_END_LABEL		"LECIE"
+#define FDE_LABEL		"LSFDE"
+#define FDE_AFTER_SIZE_LABEL	"LASFDE"
+#define FDE_END_LABEL		"LEFDE"
+#define LINE_NUMBER_BEGIN_LABEL	"LSLT"
+#define LINE_NUMBER_END_LABEL	"LELT"
+#define LN_PROLOG_AS_LABEL	"LASLTP"
+#define LN_PROLOG_END_LABEL	"LELTP"
+#define DIE_LABEL_PREFIX	"DW"
+
+/* The DWARF 2 CFA column which tracks the return address.  Normally this
+   is the column for PC, or the first column after all of the hard
+   registers.  */
+#ifndef DWARF_FRAME_RETURN_COLUMN
+#ifdef PC_REGNUM
+#define DWARF_FRAME_RETURN_COLUMN	DWARF_FRAME_REGNUM (PC_REGNUM)
+#else
+#define DWARF_FRAME_RETURN_COLUMN	DWARF_FRAME_REGISTERS
+#endif
+#endif
+
+/* The mapping from gcc register number to DWARF 2 CFA column number.  By
+   default, we just provide columns for all registers.  */
+#ifndef DWARF_FRAME_REGNUM
+#define DWARF_FRAME_REGNUM(REG) DBX_REGISTER_NUMBER (REG)
+#endif
+
+/* Hook used by __throw.  */
+
+rtx
+expand_builtin_dwarf_sp_column (void)
+{
+  return GEN_INT (DWARF_FRAME_REGNUM (STACK_POINTER_REGNUM));
+}
+
+/* Return a pointer to a copy of the section string name S with all
+   attributes stripped off, and an asterisk prepended (for assemble_name).  */
+
+static inline char *
+stripattributes (const char *s)
+{
+  char *stripped = xmalloc (strlen (s) + 2);
+  char *p = stripped;
+
+  *p++ = '*';
+
+  while (*s && *s != ',')
+    *p++ = *s++;
+
+  *p = '\0';
+  return stripped;
+}
+
+/* Generate code to initialize the register size table.  */
+
+void
+expand_builtin_init_dwarf_reg_sizes (tree address)
+{
+  int i;
+  enum machine_mode mode = TYPE_MODE (char_type_node);
+  rtx addr = expand_expr (address, NULL_RTX, VOIDmode, 0);
+  rtx mem = gen_rtx_MEM (BLKmode, addr);
+  bool wrote_return_column = false;
+
+  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)
+    if (DWARF_FRAME_REGNUM (i) < DWARF_FRAME_REGISTERS)
+      {
+	HOST_WIDE_INT offset = DWARF_FRAME_REGNUM (i) * GET_MODE_SIZE (mode);
+	enum machine_mode save_mode = reg_raw_mode[i];
+	HOST_WIDE_INT size;
+
+	if (HARD_REGNO_CALL_PART_CLOBBERED (i, save_mode))
+	  save_mode = choose_hard_reg_mode (i, 1, true);
+	if (DWARF_FRAME_REGNUM (i) == DWARF_FRAME_RETURN_COLUMN)
+	  {
+	    if (save_mode == VOIDmode)
+	      continue;
+	    wrote_return_column = true;
+	  }
+	size = GET_MODE_SIZE (save_mode);
+	if (offset < 0)
+	  continue;
+
+	emit_move_insn (adjust_address (mem, mode, offset),
+			gen_int_mode (size, mode));
+      }
+
+#ifdef DWARF_ALT_FRAME_RETURN_COLUMN
+  gcc_assert (wrote_return_column);
+  i = DWARF_ALT_FRAME_RETURN_COLUMN;
+  wrote_return_column = false;
+#else
+  i = DWARF_FRAME_RETURN_COLUMN;
+#endif
+
+  if (! wrote_return_column)
+    {
+      enum machine_mode save_mode = Pmode;
+      HOST_WIDE_INT offset = i * GET_MODE_SIZE (mode);
+      HOST_WIDE_INT size = GET_MODE_SIZE (save_mode);
+      emit_move_insn (adjust_address (mem, mode, offset), GEN_INT (size));
+    }
+}
+
+/* Convert a DWARF call frame info. operation to its string name */
+
+static const char *
+dwarf_cfi_name (unsigned int cfi_opc)
+{
+  switch (cfi_opc)
+    {
+    case DW_CFA_advance_loc:
+      return "DW_CFA_advance_loc";
+    case DW_CFA_offset:
+      return "DW_CFA_offset";
+    case DW_CFA_restore:
+      return "DW_CFA_restore";
+    case DW_CFA_nop:
+      return "DW_CFA_nop";
+    case DW_CFA_set_loc:
+      return "DW_CFA_set_loc";
+    case DW_CFA_advance_loc1:
+      return "DW_CFA_advance_loc1";
+    case DW_CFA_advance_loc2:
+      return "DW_CFA_advance_loc2";
+    case DW_CFA_advance_loc4:
+      return "DW_CFA_advance_loc4";
+    case DW_CFA_offset_extended:
+      return "DW_CFA_offset_extended";
+    case DW_CFA_restore_extended:
+      return "DW_CFA_restore_extended";
+    case DW_CFA_undefined:
+      return "DW_CFA_undefined";
+    case DW_CFA_same_value:
+      return "DW_CFA_same_value";
+    case DW_CFA_register:
+      return "DW_CFA_register";
+    case DW_CFA_remember_state:
+      return "DW_CFA_remember_state";
+    case DW_CFA_restore_state:
+      return "DW_CFA_restore_state";
+    case DW_CFA_def_cfa:
+      return "DW_CFA_def_cfa";
+    case DW_CFA_def_cfa_register:
+      return "DW_CFA_def_cfa_register";
+    case DW_CFA_def_cfa_offset:
+      return "DW_CFA_def_cfa_offset";
+
+    /* DWARF 3 */
+    case DW_CFA_def_cfa_expression:
+      return "DW_CFA_def_cfa_expression";
+    case DW_CFA_expression:
+      return "DW_CFA_expression";
+    case DW_CFA_offset_extended_sf:
+      return "DW_CFA_offset_extended_sf";
+    case DW_CFA_def_cfa_sf:
+      return "DW_CFA_def_cfa_sf";
+    case DW_CFA_def_cfa_offset_sf:
+      return "DW_CFA_def_cfa_offset_sf";
+
+    /* SGI/MIPS specific */
+    case DW_CFA_MIPS_advance_loc8:
+      return "DW_CFA_MIPS_advance_loc8";
+
+    /* GNU extensions */
+    case DW_CFA_GNU_window_save:
+      return "DW_CFA_GNU_window_save";
+    case DW_CFA_GNU_args_size:
+      return "DW_CFA_GNU_args_size";
+    case DW_CFA_GNU_negative_offset_extended:
+      return "DW_CFA_GNU_negative_offset_extended";
+
+    default:
+      return "DW_CFA_<unknown>";
+    }
+}
+
+/* Return a pointer to a newly allocated Call Frame Instruction.  */
+
+static inline dw_cfi_ref
+new_cfi (void)
+{
+  dw_cfi_ref cfi = ggc_alloc (sizeof (dw_cfi_node));
+
+  cfi->dw_cfi_next = NULL;
+  cfi->dw_cfi_oprnd1.dw_cfi_reg_num = 0;
+  cfi->dw_cfi_oprnd2.dw_cfi_reg_num = 0;
+
+  return cfi;
+}
+
+/* Add a Call Frame Instruction to list of instructions.  */
+
+static inline void
+add_cfi (dw_cfi_ref *list_head, dw_cfi_ref cfi)
+{
+  dw_cfi_ref *p;
+
+  /* Find the end of the chain.  */
+  for (p = list_head; (*p) != NULL; p = &(*p)->dw_cfi_next)
+    ;
+
+  *p = cfi;
+}
+
+/* Generate a new label for the CFI info to refer to.  */
+
+char *
+dwarf2out_cfi_label (void)
+{
+  static char label[20];
+
+  ASM_GENERATE_INTERNAL_LABEL (label, "LCFI", dwarf2out_cfi_label_num++);
+  ASM_OUTPUT_LABEL (asm_out_file, label);
+  return label;
+}
+
+/* Add CFI to the current fde at the PC value indicated by LABEL if specified,
+   or to the CIE if LABEL is NULL.  */
+
+static void
+add_fde_cfi (const char *label, dw_cfi_ref cfi)
+{
+  if (label)
+    {
+      dw_fde_ref fde = &fde_table[fde_table_in_use - 1];
+
+      if (*label == 0)
+	label = dwarf2out_cfi_label ();
+
+      if (fde->dw_fde_current_label == NULL
+	  || strcmp (label, fde->dw_fde_current_label) != 0)
+	{
+	  dw_cfi_ref xcfi;
+
+	  fde->dw_fde_current_label = label = xstrdup (label);
+
+	  /* Set the location counter to the new label.  */
+	  xcfi = new_cfi ();
+	  xcfi->dw_cfi_opc = DW_CFA_advance_loc4;
+	  xcfi->dw_cfi_oprnd1.dw_cfi_addr = label;
+	  add_cfi (&fde->dw_fde_cfi, xcfi);
+	}
+
+      add_cfi (&fde->dw_fde_cfi, cfi);
+    }
+
+  else
+    add_cfi (&cie_cfi_head, cfi);
+}
+
+/* Subroutine of lookup_cfa.  */
+
+static void
+lookup_cfa_1 (dw_cfi_ref cfi, dw_cfa_location *loc)
+{
+  switch (cfi->dw_cfi_opc)
+    {
+    case DW_CFA_def_cfa_offset:
+      loc->offset = cfi->dw_cfi_oprnd1.dw_cfi_offset;
+      break;
+    case DW_CFA_def_cfa_offset_sf:
+      loc->offset
+	= cfi->dw_cfi_oprnd1.dw_cfi_offset * DWARF_CIE_DATA_ALIGNMENT;
+      break;
+    case DW_CFA_def_cfa_register:
+      loc->reg = cfi->dw_cfi_oprnd1.dw_cfi_reg_num;
+      break;
+    case DW_CFA_def_cfa:
+      loc->reg = cfi->dw_cfi_oprnd1.dw_cfi_reg_num;
+      loc->offset = cfi->dw_cfi_oprnd2.dw_cfi_offset;
+      break;
+    case DW_CFA_def_cfa_sf:
+      loc->reg = cfi->dw_cfi_oprnd1.dw_cfi_reg_num;
+      loc->offset
+	= cfi->dw_cfi_oprnd2.dw_cfi_offset * DWARF_CIE_DATA_ALIGNMENT;
+      break;
+    case DW_CFA_def_cfa_expression:
+      get_cfa_from_loc_descr (loc, cfi->dw_cfi_oprnd1.dw_cfi_loc);
+      break;
+    default:
+      break;
+    }
+}
+
+/* Find the previous value for the CFA.  */
+
+static void
+lookup_cfa (dw_cfa_location *loc)
+{
+  dw_cfi_ref cfi;
+
+  loc->reg = INVALID_REGNUM;
+  loc->offset = 0;
+  loc->indirect = 0;
+  loc->base_offset = 0;
+
+  for (cfi = cie_cfi_head; cfi; cfi = cfi->dw_cfi_next)
+    lookup_cfa_1 (cfi, loc);
+
+  if (fde_table_in_use)
+    {
+      dw_fde_ref fde = &fde_table[fde_table_in_use - 1];
+      for (cfi = fde->dw_fde_cfi; cfi; cfi = cfi->dw_cfi_next)
+	lookup_cfa_1 (cfi, loc);
+    }
+}
+
+/* The current rule for calculating the DWARF2 canonical frame address.  */
+static dw_cfa_location cfa;
+
+/* The register used for saving registers to the stack, and its offset
+   from the CFA.  */
+static dw_cfa_location cfa_store;
+
+/* The running total of the size of arguments pushed onto the stack.  */
+static HOST_WIDE_INT args_size;
+
+/* The last args_size we actually output.  */
+static HOST_WIDE_INT old_args_size;
+
+/* Entry point to update the canonical frame address (CFA).
+   LABEL is passed to add_fde_cfi.  The value of CFA is now to be
+   calculated from REG+OFFSET.  */
+
+void
+dwarf2out_def_cfa (const char *label, unsigned int reg, HOST_WIDE_INT offset)
+{
+  dw_cfa_location loc;
+  loc.indirect = 0;
+  loc.base_offset = 0;
+  loc.reg = reg;
+  loc.offset = offset;
+  def_cfa_1 (label, &loc);
+}
+
+/* Determine if two dw_cfa_location structures define the same data.  */
+
+static bool
+cfa_equal_p (const dw_cfa_location *loc1, const dw_cfa_location *loc2)
+{
+  return (loc1->reg == loc2->reg
+	  && loc1->offset == loc2->offset
+	  && loc1->indirect == loc2->indirect
+	  && (loc1->indirect == 0
+	      || loc1->base_offset == loc2->base_offset));
+}
+
+/* This routine does the actual work.  The CFA is now calculated from
+   the dw_cfa_location structure.  */
+
+static void
+def_cfa_1 (const char *label, dw_cfa_location *loc_p)
+{
+  dw_cfi_ref cfi;
+  dw_cfa_location old_cfa, loc;
+
+  cfa = *loc_p;
+  loc = *loc_p;
+
+  if (cfa_store.reg == loc.reg && loc.indirect == 0)
+    cfa_store.offset = loc.offset;
+
+  loc.reg = DWARF_FRAME_REGNUM (loc.reg);
+  lookup_cfa (&old_cfa);
+
+  /* If nothing changed, no need to issue any call frame instructions.  */
+  if (cfa_equal_p (&loc, &old_cfa))
+    return;
+
+  cfi = new_cfi ();
+
+  if (loc.reg == old_cfa.reg && !loc.indirect)
+    {
+      /* Construct a "DW_CFA_def_cfa_offset <offset>" instruction, indicating
+	 the CFA register did not change but the offset did.  */
+      if (loc.offset < 0)
+	{
+	  HOST_WIDE_INT f_offset = loc.offset / DWARF_CIE_DATA_ALIGNMENT;
+	  gcc_assert (f_offset * DWARF_CIE_DATA_ALIGNMENT == loc.offset);
+
+	  cfi->dw_cfi_opc = DW_CFA_def_cfa_offset_sf;
+	  cfi->dw_cfi_oprnd1.dw_cfi_offset = f_offset;
+	}
+      else
+	{
+	  cfi->dw_cfi_opc = DW_CFA_def_cfa_offset;
+	  cfi->dw_cfi_oprnd1.dw_cfi_offset = loc.offset;
+	}
+    }
+
+#ifndef MIPS_DEBUGGING_INFO  /* SGI dbx thinks this means no offset.  */
+  else if (loc.offset == old_cfa.offset
+	   && old_cfa.reg != INVALID_REGNUM
+	   && !loc.indirect)
+    {
+      /* Construct a "DW_CFA_def_cfa_register <register>" instruction,
+	 indicating the CFA register has changed to <register> but the
+	 offset has not changed.  */
+      cfi->dw_cfi_opc = DW_CFA_def_cfa_register;
+      cfi->dw_cfi_oprnd1.dw_cfi_reg_num = loc.reg;
+    }
+#endif
+
+  else if (loc.indirect == 0)
+    {
+      /* Construct a "DW_CFA_def_cfa <register> <offset>" instruction,
+	 indicating the CFA register has changed to <register> with
+	 the specified offset.  */
+      if (loc.offset < 0)
+	{
+	  HOST_WIDE_INT f_offset = loc.offset / DWARF_CIE_DATA_ALIGNMENT;
+	  gcc_assert (f_offset * DWARF_CIE_DATA_ALIGNMENT == loc.offset);
+
+	  cfi->dw_cfi_opc = DW_CFA_def_cfa_sf;
+	  cfi->dw_cfi_oprnd1.dw_cfi_reg_num = loc.reg;
+	  cfi->dw_cfi_oprnd2.dw_cfi_offset = f_offset;
+	}
+      else
+	{
+	  cfi->dw_cfi_opc = DW_CFA_def_cfa;
+	  cfi->dw_cfi_oprnd1.dw_cfi_reg_num = loc.reg;
+	  cfi->dw_cfi_oprnd2.dw_cfi_offset = loc.offset;
+	}
+    }
+  else
+    {
+      /* Construct a DW_CFA_def_cfa_expression instruction to
+	 calculate the CFA using a full location expression since no
+	 register-offset pair is available.  */
+      struct dw_loc_descr_struct *loc_list;
+
+      cfi->dw_cfi_opc = DW_CFA_def_cfa_expression;
+      loc_list = build_cfa_loc (&loc);
+      cfi->dw_cfi_oprnd1.dw_cfi_loc = loc_list;
+    }
+
+  add_fde_cfi (label, cfi);
+}
+
+/* Add the CFI for saving a register.  REG is the CFA column number.
+   LABEL is passed to add_fde_cfi.
+   If SREG is -1, the register is saved at OFFSET from the CFA;
+   otherwise it is saved in SREG.  */
+
+static void
+reg_save (const char *label, unsigned int reg, unsigned int sreg, HOST_WIDE_INT offset)
+{
+  dw_cfi_ref cfi = new_cfi ();
+
+  cfi->dw_cfi_oprnd1.dw_cfi_reg_num = reg;
+
+  if (sreg == INVALID_REGNUM)
+    {
+      if (reg & ~0x3f)
+	/* The register number won't fit in 6 bits, so we have to use
+	   the long form.  */
+	cfi->dw_cfi_opc = DW_CFA_offset_extended;
+      else
+	cfi->dw_cfi_opc = DW_CFA_offset;
+
+#ifdef ENABLE_CHECKING
+      {
+	/* If we get an offset that is not a multiple of
+	   DWARF_CIE_DATA_ALIGNMENT, there is either a bug in the
+	   definition of DWARF_CIE_DATA_ALIGNMENT, or a bug in the machine
+	   description.  */
+	HOST_WIDE_INT check_offset = offset / DWARF_CIE_DATA_ALIGNMENT;
+
+	gcc_assert (check_offset * DWARF_CIE_DATA_ALIGNMENT == offset);
+      }
+#endif
+      offset /= DWARF_CIE_DATA_ALIGNMENT;
+      if (offset < 0)
+	cfi->dw_cfi_opc = DW_CFA_offset_extended_sf;
+
+      cfi->dw_cfi_oprnd2.dw_cfi_offset = offset;
+    }
+  else if (sreg == reg)
+    cfi->dw_cfi_opc = DW_CFA_same_value;
+  else
+    {
+      cfi->dw_cfi_opc = DW_CFA_register;
+      cfi->dw_cfi_oprnd2.dw_cfi_reg_num = sreg;
+    }
+
+  add_fde_cfi (label, cfi);
+}
+
+/* Add the CFI for saving a register window.  LABEL is passed to reg_save.
+   This CFI tells the unwinder that it needs to restore the window registers
+   from the previous frame's window save area.
+
+   ??? Perhaps we should note in the CIE where windows are saved (instead of
+   assuming 0(cfa)) and what registers are in the window.  */
+
+void
+dwarf2out_window_save (const char *label)
+{
+  dw_cfi_ref cfi = new_cfi ();
+
+  cfi->dw_cfi_opc = DW_CFA_GNU_window_save;
+  add_fde_cfi (label, cfi);
+}
+
+/* Add a CFI to update the running total of the size of arguments
+   pushed onto the stack.  */
+
+void
+dwarf2out_args_size (const char *label, HOST_WIDE_INT size)
+{
+  dw_cfi_ref cfi;
+
+  if (size == old_args_size)
+    return;
+
+  old_args_size = size;
+
+  cfi = new_cfi ();
+  cfi->dw_cfi_opc = DW_CFA_GNU_args_size;
+  cfi->dw_cfi_oprnd1.dw_cfi_offset = size;
+  add_fde_cfi (label, cfi);
+}
+
+/* Entry point for saving a register to the stack.  REG is the GCC register
+   number.  LABEL and OFFSET are passed to reg_save.  */
+
+void
+dwarf2out_reg_save (const char *label, unsigned int reg, HOST_WIDE_INT offset)
+{
+  reg_save (label, DWARF_FRAME_REGNUM (reg), INVALID_REGNUM, offset);
+}
+
+/* Entry point for saving the return address in the stack.
+   LABEL and OFFSET are passed to reg_save.  */
+
+void
+dwarf2out_return_save (const char *label, HOST_WIDE_INT offset)
+{
+  reg_save (label, DWARF_FRAME_RETURN_COLUMN, INVALID_REGNUM, offset);
+}
+
+/* Entry point for saving the return address in a register.
+   LABEL and SREG are passed to reg_save.  */
+
+void
+dwarf2out_return_reg (const char *label, unsigned int sreg)
+{
+  reg_save (label, DWARF_FRAME_RETURN_COLUMN, DWARF_FRAME_REGNUM (sreg), 0);
+}
+
+/* Record the initial position of the return address.  RTL is
+   INCOMING_RETURN_ADDR_RTX.  */
+
+static void
+initial_return_save (rtx rtl)
+{
+  unsigned int reg = INVALID_REGNUM;
+  HOST_WIDE_INT offset = 0;
+
+  switch (GET_CODE (rtl))
+    {
+    case REG:
+      /* RA is in a register.  */
+      reg = DWARF_FRAME_REGNUM (REGNO (rtl));
+      break;
+
+    case MEM:
+      /* RA is on the stack.  */
+      rtl = XEXP (rtl, 0);
+      switch (GET_CODE (rtl))
+	{
+	case REG:
+	  gcc_assert (REGNO (rtl) == STACK_POINTER_REGNUM);
+	  offset = 0;
+	  break;
+
+	case PLUS:
+	  gcc_assert (REGNO (XEXP (rtl, 0)) == STACK_POINTER_REGNUM);
+	  offset = INTVAL (XEXP (rtl, 1));
+	  break;
+
+	case MINUS:
+	  gcc_assert (REGNO (XEXP (rtl, 0)) == STACK_POINTER_REGNUM);
+	  offset = -INTVAL (XEXP (rtl, 1));
+	  break;
+
+	default:
+	  gcc_unreachable ();
+	}
+
+      break;
+
+    case PLUS:
+      /* The return address is at some offset from any value we can
+	 actually load.  For instance, on the SPARC it is in %i7+8. Just
+	 ignore the offset for now; it doesn't matter for unwinding frames.  */
+      gcc_assert (GET_CODE (XEXP (rtl, 1)) == CONST_INT);
+      initial_return_save (XEXP (rtl, 0));
+      return;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  if (reg != DWARF_FRAME_RETURN_COLUMN)
+    reg_save (NULL, DWARF_FRAME_RETURN_COLUMN, reg, offset - cfa.offset);
+}
+
+/* Given a SET, calculate the amount of stack adjustment it
+   contains.  */
+
+static HOST_WIDE_INT
+stack_adjust_offset (rtx pattern)
+{
+  rtx src = SET_SRC (pattern);
+  rtx dest = SET_DEST (pattern);
+  HOST_WIDE_INT offset = 0;
+  enum rtx_code code;
+
+  if (dest == stack_pointer_rtx)
+    {
+      /* (set (reg sp) (plus (reg sp) (const_int))) */
+      code = GET_CODE (src);
+      if (! (code == PLUS || code == MINUS)
+	  || XEXP (src, 0) != stack_pointer_rtx
+	  || GET_CODE (XEXP (src, 1)) != CONST_INT)
+	return 0;
+
+      offset = INTVAL (XEXP (src, 1));
+      if (code == PLUS)
+	offset = -offset;
+    }
+  else if (MEM_P (dest))
+    {
+      /* (set (mem (pre_dec (reg sp))) (foo)) */
+      src = XEXP (dest, 0);
+      code = GET_CODE (src);
+
+      switch (code)
+	{
+	case PRE_MODIFY:
+	case POST_MODIFY:
+	  if (XEXP (src, 0) == stack_pointer_rtx)
+	    {
+	      rtx val = XEXP (XEXP (src, 1), 1);
+	      /* We handle only adjustments by constant amount.  */
+	      gcc_assert (GET_CODE (XEXP (src, 1)) == PLUS
+			  && GET_CODE (val) == CONST_INT);
+	      offset = -INTVAL (val);
+	      break;
+	    }
+	  return 0;
+
+	case PRE_DEC:
+	case POST_DEC:
+	  if (XEXP (src, 0) == stack_pointer_rtx)
+	    {
+	      offset = GET_MODE_SIZE (GET_MODE (dest));
+	      break;
+	    }
+	  return 0;
+
+	case PRE_INC:
+	case POST_INC:
+	  if (XEXP (src, 0) == stack_pointer_rtx)
+	    {
+	      offset = -GET_MODE_SIZE (GET_MODE (dest));
+	      break;
+	    }
+	  return 0;
+
+	default:
+	  return 0;
+	}
+    }
+  else
+    return 0;
+
+  return offset;
+}
+
+/* Check INSN to see if it looks like a push or a stack adjustment, and
+   make a note of it if it does.  EH uses this information to find out how
+   much extra space it needs to pop off the stack.  */
+
+static void
+dwarf2out_stack_adjust (rtx insn, bool after_p)
+{
+  HOST_WIDE_INT offset;
+  const char *label;
+  int i;
+
+  /* Don't handle epilogues at all.  Certainly it would be wrong to do so
+     with this function.  Proper support would require all frame-related
+     insns to be marked, and to be able to handle saving state around
+     epilogues textually in the middle of the function.  */
+  if (prologue_epilogue_contains (insn) || sibcall_epilogue_contains (insn))
+    return;
+
+  /* If only calls can throw, and we have a frame pointer,
+     save up adjustments until we see the CALL_INSN.  */
+  if (!flag_asynchronous_unwind_tables && cfa.reg != STACK_POINTER_REGNUM)
+    {
+      if (CALL_P (insn) && !after_p)
+	{
+	  /* Extract the size of the args from the CALL rtx itself.  */
+	  insn = PATTERN (insn);
+	  if (GET_CODE (insn) == PARALLEL)
+	    insn = XVECEXP (insn, 0, 0);
+	  if (GET_CODE (insn) == SET)
+	    insn = SET_SRC (insn);
+	  gcc_assert (GET_CODE (insn) == CALL);
+	  dwarf2out_args_size ("", INTVAL (XEXP (insn, 1)));
+	}
+      return;
+    }
+
+  if (CALL_P (insn) && !after_p)
+    {
+      if (!flag_asynchronous_unwind_tables)
+	dwarf2out_args_size ("", args_size);
+      return;
+    }
+  else if (BARRIER_P (insn))
+    {
+      /* When we see a BARRIER, we know to reset args_size to 0.  Usually
+	 the compiler will have already emitted a stack adjustment, but
+	 doesn't bother for calls to noreturn functions.  */
+#ifdef STACK_GROWS_DOWNWARD
+      offset = -args_size;
+#else
+      offset = args_size;
+#endif
+    }
+  else if (GET_CODE (PATTERN (insn)) == SET)
+    offset = stack_adjust_offset (PATTERN (insn));
+  else if (GET_CODE (PATTERN (insn)) == PARALLEL
+	   || GET_CODE (PATTERN (insn)) == SEQUENCE)
+    {
+      /* There may be stack adjustments inside compound insns.  Search
+	 for them.  */
+      for (offset = 0, i = XVECLEN (PATTERN (insn), 0) - 1; i >= 0; i--)
+	if (GET_CODE (XVECEXP (PATTERN (insn), 0, i)) == SET)
+	  offset += stack_adjust_offset (XVECEXP (PATTERN (insn), 0, i));
+    }
+  else
+    return;
+
+  if (offset == 0)
+    return;
+
+  if (cfa.reg == STACK_POINTER_REGNUM)
+    cfa.offset += offset;
+
+#ifndef STACK_GROWS_DOWNWARD
+  offset = -offset;
+#endif
+
+  args_size += offset;
+  if (args_size < 0)
+    args_size = 0;
+
+  label = dwarf2out_cfi_label ();
+  def_cfa_1 (label, &cfa);
+  if (flag_asynchronous_unwind_tables)
+    dwarf2out_args_size (label, args_size);
+}
+
+#endif
+
+/* We delay emitting a register save until either (a) we reach the end
+   of the prologue or (b) the register is clobbered.  This clusters
+   register saves so that there are fewer pc advances.  */
+
+struct queued_reg_save GTY(())
+{
+  struct queued_reg_save *next;
+  rtx reg;
+  HOST_WIDE_INT cfa_offset;
+  rtx saved_reg;
+};
+
+static GTY(()) struct queued_reg_save *queued_reg_saves;
+
+/* The caller's ORIG_REG is saved in SAVED_IN_REG.  */
+struct reg_saved_in_data GTY(()) {
+  rtx orig_reg;
+  rtx saved_in_reg;
+};
+
+/* A list of registers saved in other registers.
+   The list intentionally has a small maximum capacity of 4; if your
+   port needs more than that, you might consider implementing a
+   more efficient data structure.  */
+static GTY(()) struct reg_saved_in_data regs_saved_in_regs[4];
+static GTY(()) size_t num_regs_saved_in_regs;
+
+#if defined (DWARF2_DEBUGGING_INFO) || defined (DWARF2_UNWIND_INFO)
+static const char *last_reg_save_label;
+
+/* Add an entry to QUEUED_REG_SAVES saying that REG is now saved at
+   SREG, or if SREG is NULL then it is saved at OFFSET to the CFA.  */
+
+static void
+queue_reg_save (const char *label, rtx reg, rtx sreg, HOST_WIDE_INT offset)
+{
+  struct queued_reg_save *q;
+
+  /* Duplicates waste space, but it's also necessary to remove them
+     for correctness, since the queue gets output in reverse
+     order.  */
+  for (q = queued_reg_saves; q != NULL; q = q->next)
+    if (REGNO (q->reg) == REGNO (reg))
+      break;
+
+  if (q == NULL)
+    {
+      q = ggc_alloc (sizeof (*q));
+      q->next = queued_reg_saves;
+      queued_reg_saves = q;
+    }
+
+  q->reg = reg;
+  q->cfa_offset = offset;
+  q->saved_reg = sreg;
+
+  last_reg_save_label = label;
+}
+
+/* Output all the entries in QUEUED_REG_SAVES.  */
+
+static void
+flush_queued_reg_saves (void)
+{
+  struct queued_reg_save *q;
+
+  for (q = queued_reg_saves; q; q = q->next)
+    {
+      size_t i;
+      unsigned int reg, sreg;
+
+      for (i = 0; i < num_regs_saved_in_regs; i++)
+	if (REGNO (regs_saved_in_regs[i].orig_reg) == REGNO (q->reg))
+	  break;
+      if (q->saved_reg && i == num_regs_saved_in_regs)
+	{
+	  gcc_assert (i != ARRAY_SIZE (regs_saved_in_regs));
+	  num_regs_saved_in_regs++;
+	}
+      if (i != num_regs_saved_in_regs)
+	{
+	  regs_saved_in_regs[i].orig_reg = q->reg;
+	  regs_saved_in_regs[i].saved_in_reg = q->saved_reg;
+	}
+
+      reg = DWARF_FRAME_REGNUM (REGNO (q->reg));
+      if (q->saved_reg)
+	sreg = DWARF_FRAME_REGNUM (REGNO (q->saved_reg));
+      else
+	sreg = INVALID_REGNUM;
+      reg_save (last_reg_save_label, reg, sreg, q->cfa_offset);
+    }
+
+  queued_reg_saves = NULL;
+  last_reg_save_label = NULL;
+}
+
+/* Does INSN clobber any register which QUEUED_REG_SAVES lists a saved
+   location for?  Or, does it clobber a register which we've previously
+   said that some other register is saved in, and for which we now
+   have a new location for?  */
+
+static bool
+clobbers_queued_reg_save (rtx insn)
+{
+  struct queued_reg_save *q;
+
+  for (q = queued_reg_saves; q; q = q->next)
+    {
+      size_t i;
+      if (modified_in_p (q->reg, insn))
+	return true;
+      for (i = 0; i < num_regs_saved_in_regs; i++)
+	if (REGNO (q->reg) == REGNO (regs_saved_in_regs[i].orig_reg)
+	    && modified_in_p (regs_saved_in_regs[i].saved_in_reg, insn))
+	  return true;
+    }
+
+  return false;
+}
+
+/* Entry point for saving the first register into the second.  */
+
+void
+dwarf2out_reg_save_reg (const char *label, rtx reg, rtx sreg)
+{
+  size_t i;
+  unsigned int regno, sregno;
+
+  for (i = 0; i < num_regs_saved_in_regs; i++)
+    if (REGNO (regs_saved_in_regs[i].orig_reg) == REGNO (reg))
+      break;
+  if (i == num_regs_saved_in_regs)
+    {
+      gcc_assert (i != ARRAY_SIZE (regs_saved_in_regs));
+      num_regs_saved_in_regs++;
+    }
+  regs_saved_in_regs[i].orig_reg = reg;
+  regs_saved_in_regs[i].saved_in_reg = sreg;
+
+  regno = DWARF_FRAME_REGNUM (REGNO (reg));
+  sregno = DWARF_FRAME_REGNUM (REGNO (sreg));
+  reg_save (label, regno, sregno, 0);
+}
+
+/* What register, if any, is currently saved in REG?  */
+
+static rtx
+reg_saved_in (rtx reg)
+{
+  unsigned int regn = REGNO (reg);
+  size_t i;
+  struct queued_reg_save *q;
+
+  for (q = queued_reg_saves; q; q = q->next)
+    if (q->saved_reg && regn == REGNO (q->saved_reg))
+      return q->reg;
+
+  for (i = 0; i < num_regs_saved_in_regs; i++)
+    if (regs_saved_in_regs[i].saved_in_reg
+	&& regn == REGNO (regs_saved_in_regs[i].saved_in_reg))
+      return regs_saved_in_regs[i].orig_reg;
+
+  return NULL_RTX;
+}
+
+
+/* A temporary register holding an integral value used in adjusting SP
+   or setting up the store_reg.  The "offset" field holds the integer
+   value, not an offset.  */
+static dw_cfa_location cfa_temp;
+
+/* Record call frame debugging information for an expression EXPR,
+   which either sets SP or FP (adjusting how we calculate the frame
+   address) or saves a register to the stack or another register.
+   LABEL indicates the address of EXPR.
+
+   This function encodes a state machine mapping rtxes to actions on
+   cfa, cfa_store, and cfa_temp.reg.  We describe these rules so
+   users need not read the source code.
+
+  The High-Level Picture
+
+  Changes in the register we use to calculate the CFA: Currently we
+  assume that if you copy the CFA register into another register, we
+  should take the other one as the new CFA register; this seems to
+  work pretty well.  If it's wrong for some target, it's simple
+  enough not to set RTX_FRAME_RELATED_P on the insn in question.
+
+  Changes in the register we use for saving registers to the stack:
+  This is usually SP, but not always.  Again, we deduce that if you
+  copy SP into another register (and SP is not the CFA register),
+  then the new register is the one we will be using for register
+  saves.  This also seems to work.
+
+  Register saves: There's not much guesswork about this one; if
+  RTX_FRAME_RELATED_P is set on an insn which modifies memory, it's a
+  register save, and the register used to calculate the destination
+  had better be the one we think we're using for this purpose.
+  It's also assumed that a copy from a call-saved register to another
+  register is saving that register if RTX_FRAME_RELATED_P is set on
+  that instruction.  If the copy is from a call-saved register to
+  the *same* register, that means that the register is now the same
+  value as in the caller.
+
+  Except: If the register being saved is the CFA register, and the
+  offset is nonzero, we are saving the CFA, so we assume we have to
+  use DW_CFA_def_cfa_expression.  If the offset is 0, we assume that
+  the intent is to save the value of SP from the previous frame.
+
+  In addition, if a register has previously been saved to a different
+  register,
+
+  Invariants / Summaries of Rules
+
+  cfa	       current rule for calculating the CFA.  It usually
+	       consists of a register and an offset.
+  cfa_store    register used by prologue code to save things to the stack
+	       cfa_store.offset is the offset from the value of
+	       cfa_store.reg to the actual CFA
+  cfa_temp     register holding an integral value.  cfa_temp.offset
+	       stores the value, which will be used to adjust the
+	       stack pointer.  cfa_temp is also used like cfa_store,
+	       to track stores to the stack via fp or a temp reg.
+
+  Rules  1- 4: Setting a register's value to cfa.reg or an expression
+	       with cfa.reg as the first operand changes the cfa.reg and its
+	       cfa.offset.  Rule 1 and 4 also set cfa_temp.reg and
+	       cfa_temp.offset.
+
+  Rules  6- 9: Set a non-cfa.reg register value to a constant or an
+	       expression yielding a constant.  This sets cfa_temp.reg
+	       and cfa_temp.offset.
+
+  Rule 5:      Create a new register cfa_store used to save items to the
+	       stack.
+
+  Rules 10-14: Save a register to the stack.  Define offset as the
+	       difference of the original location and cfa_store's
+	       location (or cfa_temp's location if cfa_temp is used).
+
+  The Rules
+
+  "{a,b}" indicates a choice of a xor b.
+  "<reg>:cfa.reg" indicates that <reg> must equal cfa.reg.
+
+  Rule 1:
+  (set <reg1> <reg2>:cfa.reg)
+  effects: cfa.reg = <reg1>
+	   cfa.offset unchanged
+	   cfa_temp.reg = <reg1>
+	   cfa_temp.offset = cfa.offset
+
+  Rule 2:
+  (set sp ({minus,plus,losum} {sp,fp}:cfa.reg
+			      {<const_int>,<reg>:cfa_temp.reg}))
+  effects: cfa.reg = sp if fp used
+	   cfa.offset += {+/- <const_int>, cfa_temp.offset} if cfa.reg==sp
+	   cfa_store.offset += {+/- <const_int>, cfa_temp.offset}
+	     if cfa_store.reg==sp
+
+  Rule 3:
+  (set fp ({minus,plus,losum} <reg>:cfa.reg <const_int>))
+  effects: cfa.reg = fp
+	   cfa_offset += +/- <const_int>
+
+  Rule 4:
+  (set <reg1> ({plus,losum} <reg2>:cfa.reg <const_int>))
+  constraints: <reg1> != fp
+	       <reg1> != sp
+  effects: cfa.reg = <reg1>
+	   cfa_temp.reg = <reg1>
+	   cfa_temp.offset = cfa.offset
+
+  Rule 5:
+  (set <reg1> (plus <reg2>:cfa_temp.reg sp:cfa.reg))
+  constraints: <reg1> != fp
+	       <reg1> != sp
+  effects: cfa_store.reg = <reg1>
+	   cfa_store.offset = cfa.offset - cfa_temp.offset
+
+  Rule 6:
+  (set <reg> <const_int>)
+  effects: cfa_temp.reg = <reg>
+	   cfa_temp.offset = <const_int>
+
+  Rule 7:
+  (set <reg1>:cfa_temp.reg (ior <reg2>:cfa_temp.reg <const_int>))
+  effects: cfa_temp.reg = <reg1>
+	   cfa_temp.offset |= <const_int>
+
+  Rule 8:
+  (set <reg> (high <exp>))
+  effects: none
+
+  Rule 9:
+  (set <reg> (lo_sum <exp> <const_int>))
+  effects: cfa_temp.reg = <reg>
+	   cfa_temp.offset = <const_int>
+
+  Rule 10:
+  (set (mem (pre_modify sp:cfa_store (???? <reg1> <const_int>))) <reg2>)
+  effects: cfa_store.offset -= <const_int>
+	   cfa.offset = cfa_store.offset if cfa.reg == sp
+	   cfa.reg = sp
+	   cfa.base_offset = -cfa_store.offset
+
+  Rule 11:
+  (set (mem ({pre_inc,pre_dec} sp:cfa_store.reg)) <reg>)
+  effects: cfa_store.offset += -/+ mode_size(mem)
+	   cfa.offset = cfa_store.offset if cfa.reg == sp
+	   cfa.reg = sp
+	   cfa.base_offset = -cfa_store.offset
+
+  Rule 12:
+  (set (mem ({minus,plus,losum} <reg1>:{cfa_store,cfa_temp} <const_int>))
+
+       <reg2>)
+  effects: cfa.reg = <reg1>
+	   cfa.base_offset = -/+ <const_int> - {cfa_store,cfa_temp}.offset
+
+  Rule 13:
+  (set (mem <reg1>:{cfa_store,cfa_temp}) <reg2>)
+  effects: cfa.reg = <reg1>
+	   cfa.base_offset = -{cfa_store,cfa_temp}.offset
+
+  Rule 14:
+  (set (mem (postinc <reg1>:cfa_temp <const_int>)) <reg2>)
+  effects: cfa.reg = <reg1>
+	   cfa.base_offset = -cfa_temp.offset
+	   cfa_temp.offset -= mode_size(mem)
+
+ Rule 15:
+ (set <reg> {unspec, unspec_volatile})
+ effects: target-dependent  */
+
+static void
+dwarf2out_frame_debug_expr (rtx expr, const char *label)
+{
+  rtx src, dest;
+  HOST_WIDE_INT offset;
+
+  /* If RTX_FRAME_RELATED_P is set on a PARALLEL, process each member of
+     the PARALLEL independently. The first element is always processed if
+     it is a SET. This is for backward compatibility.   Other elements
+     are processed only if they are SETs and the RTX_FRAME_RELATED_P
+     flag is set in them.  */
+  if (GET_CODE (expr) == PARALLEL || GET_CODE (expr) == SEQUENCE)
+    {
+      int par_index;
+      int limit = XVECLEN (expr, 0);
+
+      for (par_index = 0; par_index < limit; par_index++)
+	if (GET_CODE (XVECEXP (expr, 0, par_index)) == SET
+	    && (RTX_FRAME_RELATED_P (XVECEXP (expr, 0, par_index))
+		|| par_index == 0))
+	  dwarf2out_frame_debug_expr (XVECEXP (expr, 0, par_index), label);
+
+      return;
+    }
+
+  gcc_assert (GET_CODE (expr) == SET);
+
+  src = SET_SRC (expr);
+  dest = SET_DEST (expr);
+
+  if (REG_P (src))
+    {
+      rtx rsi = reg_saved_in (src);
+      if (rsi)
+	src = rsi;
+    }
+
+  switch (GET_CODE (dest))
+    {
+    case REG:
+      switch (GET_CODE (src))
+	{
+	  /* Setting FP from SP.  */
+	case REG:
+	  if (cfa.reg == (unsigned) REGNO (src))
+	    {
+	      /* Rule 1 */
+	      /* Update the CFA rule wrt SP or FP.  Make sure src is
+		 relative to the current CFA register.
+
+		 We used to require that dest be either SP or FP, but the
+		 ARM copies SP to a temporary register, and from there to
+		 FP.  So we just rely on the backends to only set
+		 RTX_FRAME_RELATED_P on appropriate insns.  */
+	      cfa.reg = REGNO (dest);
+	      cfa_temp.reg = cfa.reg;
+	      cfa_temp.offset = cfa.offset;
+	    }
+	  else
+	    {
+	      /* Saving a register in a register.  */
+	      gcc_assert (!fixed_regs [REGNO (dest)]
+			  /* For the SPARC and its register window.  */
+			  || (DWARF_FRAME_REGNUM (REGNO (src))
+			      == DWARF_FRAME_RETURN_COLUMN));
+	      queue_reg_save (label, src, dest, 0);
+	    }
+	  break;
+
+	case PLUS:
+	case MINUS:
+	case LO_SUM:
+	  if (dest == stack_pointer_rtx)
+	    {
+	      /* Rule 2 */
+	      /* Adjusting SP.  */
+	      switch (GET_CODE (XEXP (src, 1)))
+		{
+		case CONST_INT:
+		  offset = INTVAL (XEXP (src, 1));
+		  break;
+		case REG:
+		  gcc_assert ((unsigned) REGNO (XEXP (src, 1))
+			      == cfa_temp.reg);
+		  offset = cfa_temp.offset;
+		  break;
+		default:
+		  gcc_unreachable ();
+		}
+
+	      if (XEXP (src, 0) == hard_frame_pointer_rtx)
+		{
+		  /* Restoring SP from FP in the epilogue.  */
+		  gcc_assert (cfa.reg == (unsigned) HARD_FRAME_POINTER_REGNUM);
+		  cfa.reg = STACK_POINTER_REGNUM;
+		}
+	      else if (GET_CODE (src) == LO_SUM)
+		/* Assume we've set the source reg of the LO_SUM from sp.  */
+		;
+	      else
+		gcc_assert (XEXP (src, 0) == stack_pointer_rtx);
+
+	      if (GET_CODE (src) != MINUS)
+		offset = -offset;
+	      if (cfa.reg == STACK_POINTER_REGNUM)
+		cfa.offset += offset;
+	      if (cfa_store.reg == STACK_POINTER_REGNUM)
+		cfa_store.offset += offset;
+	    }
+	  else if (dest == hard_frame_pointer_rtx)
+	    {
+	      /* Rule 3 */
+	      /* Either setting the FP from an offset of the SP,
+		 or adjusting the FP */
+	      gcc_assert (frame_pointer_needed);
+
+	      gcc_assert (REG_P (XEXP (src, 0))
+			  && (unsigned) REGNO (XEXP (src, 0)) == cfa.reg
+			  && GET_CODE (XEXP (src, 1)) == CONST_INT);
+	      offset = INTVAL (XEXP (src, 1));
+	      if (GET_CODE (src) != MINUS)
+		offset = -offset;
+	      cfa.offset += offset;
+	      cfa.reg = HARD_FRAME_POINTER_REGNUM;
+	    }
+	  else
+	    {
+	      gcc_assert (GET_CODE (src) != MINUS);
+
+	      /* Rule 4 */
+	      if (REG_P (XEXP (src, 0))
+		  && REGNO (XEXP (src, 0)) == cfa.reg
+		  && GET_CODE (XEXP (src, 1)) == CONST_INT)
+		{
+		  /* Setting a temporary CFA register that will be copied
+		     into the FP later on.  */
+		  offset = - INTVAL (XEXP (src, 1));
+		  cfa.offset += offset;
+		  cfa.reg = REGNO (dest);
+		  /* Or used to save regs to the stack.  */
+		  cfa_temp.reg = cfa.reg;
+		  cfa_temp.offset = cfa.offset;
+		}
+
+	      /* Rule 5 */
+	      else if (REG_P (XEXP (src, 0))
+		       && REGNO (XEXP (src, 0)) == cfa_temp.reg
+		       && XEXP (src, 1) == stack_pointer_rtx)
+		{
+		  /* Setting a scratch register that we will use instead
+		     of SP for saving registers to the stack.  */
+		  gcc_assert (cfa.reg == STACK_POINTER_REGNUM);
+		  cfa_store.reg = REGNO (dest);
+		  cfa_store.offset = cfa.offset - cfa_temp.offset;
+		}
+
+	      /* Rule 9 */
+	      else if (GET_CODE (src) == LO_SUM
+		       && GET_CODE (XEXP (src, 1)) == CONST_INT)
+		{
+		  cfa_temp.reg = REGNO (dest);
+		  cfa_temp.offset = INTVAL (XEXP (src, 1));
+		}
+	      else
+		gcc_unreachable ();
+	    }
+	  break;
+
+	  /* Rule 6 */
+	case CONST_INT:
+	  cfa_temp.reg = REGNO (dest);
+	  cfa_temp.offset = INTVAL (src);
+	  break;
+
+	  /* Rule 7 */
+	case IOR:
+	  gcc_assert (REG_P (XEXP (src, 0))
+		      && (unsigned) REGNO (XEXP (src, 0)) == cfa_temp.reg
+		      && GET_CODE (XEXP (src, 1)) == CONST_INT);
+
+	  if ((unsigned) REGNO (dest) != cfa_temp.reg)
+	    cfa_temp.reg = REGNO (dest);
+	  cfa_temp.offset |= INTVAL (XEXP (src, 1));
+	  break;
+
+	  /* Skip over HIGH, assuming it will be followed by a LO_SUM,
+	     which will fill in all of the bits.  */
+	  /* Rule 8 */
+	case HIGH:
+	  break;
+
+	  /* Rule 15 */
+	case UNSPEC:
+	case UNSPEC_VOLATILE:
+	  gcc_assert (targetm.dwarf_handle_frame_unspec);
+	  targetm.dwarf_handle_frame_unspec (label, expr, XINT (src, 1));
+	  return;
+
+	default:
+	  gcc_unreachable ();
+	}
+
+      def_cfa_1 (label, &cfa);
+      break;
+
+    case MEM:
+      gcc_assert (REG_P (src));
+
+      /* Saving a register to the stack.  Make sure dest is relative to the
+	 CFA register.  */
+      switch (GET_CODE (XEXP (dest, 0)))
+	{
+	  /* Rule 10 */
+	  /* With a push.  */
+	case PRE_MODIFY:
+	  /* We can't handle variable size modifications.  */
+	  gcc_assert (GET_CODE (XEXP (XEXP (XEXP (dest, 0), 1), 1))
+		      == CONST_INT);
+	  offset = -INTVAL (XEXP (XEXP (XEXP (dest, 0), 1), 1));
+
+	  gcc_assert (REGNO (XEXP (XEXP (dest, 0), 0)) == STACK_POINTER_REGNUM
+		      && cfa_store.reg == STACK_POINTER_REGNUM);
+
+	  cfa_store.offset += offset;
+	  if (cfa.reg == STACK_POINTER_REGNUM)
+	    cfa.offset = cfa_store.offset;
+
+	  offset = -cfa_store.offset;
+	  break;
+
+	  /* Rule 11 */
+	case PRE_INC:
+	case PRE_DEC:
+	  offset = GET_MODE_SIZE (GET_MODE (dest));
+	  if (GET_CODE (XEXP (dest, 0)) == PRE_INC)
+	    offset = -offset;
+
+	  gcc_assert (REGNO (XEXP (XEXP (dest, 0), 0)) == STACK_POINTER_REGNUM
+		      && cfa_store.reg == STACK_POINTER_REGNUM);
+
+	  cfa_store.offset += offset;
+	  if (cfa.reg == STACK_POINTER_REGNUM)
+	    cfa.offset = cfa_store.offset;
+
+	  offset = -cfa_store.offset;
+	  break;
+
+	  /* Rule 12 */
+	  /* With an offset.  */
+	case PLUS:
+	case MINUS:
+	case LO_SUM:
+	  {
+	    int regno;
+
+	    gcc_assert (GET_CODE (XEXP (XEXP (dest, 0), 1)) == CONST_INT);
+	    offset = INTVAL (XEXP (XEXP (dest, 0), 1));
+	    if (GET_CODE (XEXP (dest, 0)) == MINUS)
+	      offset = -offset;
+
+	    regno = REGNO (XEXP (XEXP (dest, 0), 0));
+
+	    if (cfa_store.reg == (unsigned) regno)
+	      offset -= cfa_store.offset;
+	    else
+	      {
+		gcc_assert (cfa_temp.reg == (unsigned) regno);
+		offset -= cfa_temp.offset;
+	      }
+	  }
+	  break;
+
+	  /* Rule 13 */
+	  /* Without an offset.  */
+	case REG:
+	  {
+	    int regno = REGNO (XEXP (dest, 0));
+
+	    if (cfa_store.reg == (unsigned) regno)
+	      offset = -cfa_store.offset;
+	    else
+	      {
+		gcc_assert (cfa_temp.reg == (unsigned) regno);
+		offset = -cfa_temp.offset;
+	      }
+	  }
+	  break;
+
+	  /* Rule 14 */
+	case POST_INC:
+	  gcc_assert (cfa_temp.reg
+		      == (unsigned) REGNO (XEXP (XEXP (dest, 0), 0)));
+	  offset = -cfa_temp.offset;
+	  cfa_temp.offset -= GET_MODE_SIZE (GET_MODE (dest));
+	  break;
+
+	default:
+	  gcc_unreachable ();
+	}
+
+      if (REGNO (src) != STACK_POINTER_REGNUM
+	  && REGNO (src) != HARD_FRAME_POINTER_REGNUM
+	  && (unsigned) REGNO (src) == cfa.reg)
+	{
+	  /* We're storing the current CFA reg into the stack.  */
+
+	  if (cfa.offset == 0)
+	    {
+	      /* If the source register is exactly the CFA, assume
+		 we're saving SP like any other register; this happens
+		 on the ARM.  */
+	      def_cfa_1 (label, &cfa);
+	      queue_reg_save (label, stack_pointer_rtx, NULL_RTX, offset);
+	      break;
+	    }
+	  else
+	    {
+	      /* Otherwise, we'll need to look in the stack to
+		 calculate the CFA.  */
+	      rtx x = XEXP (dest, 0);
+
+	      if (!REG_P (x))
+		x = XEXP (x, 0);
+	      gcc_assert (REG_P (x));
+
+	      cfa.reg = REGNO (x);
+	      cfa.base_offset = offset;
+	      cfa.indirect = 1;
+	      def_cfa_1 (label, &cfa);
+	      break;
+	    }
+	}
+
+      def_cfa_1 (label, &cfa);
+      queue_reg_save (label, src, NULL_RTX, offset);
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+}
+
+/* Record call frame debugging information for INSN, which either
+   sets SP or FP (adjusting how we calculate the frame address) or saves a
+   register to the stack.  If INSN is NULL_RTX, initialize our state.
+
+   If AFTER_P is false, we're being called before the insn is emitted,
+   otherwise after.  Call instructions get invoked twice.  */
+
+void
+dwarf2out_frame_debug (rtx insn, bool after_p)
+{
+  const char *label;
+  rtx src;
+
+  if (insn == NULL_RTX)
+    {
+      size_t i;
+
+      /* Flush any queued register saves.  */
+      flush_queued_reg_saves ();
+
+      /* Set up state for generating call frame debug info.  */
+      lookup_cfa (&cfa);
+      gcc_assert (cfa.reg
+		  == (unsigned long)DWARF_FRAME_REGNUM (STACK_POINTER_REGNUM));
+
+      cfa.reg = STACK_POINTER_REGNUM;
+      cfa_store = cfa;
+      cfa_temp.reg = -1;
+      cfa_temp.offset = 0;
+
+      for (i = 0; i < num_regs_saved_in_regs; i++)
+	{
+	  regs_saved_in_regs[i].orig_reg = NULL_RTX;
+	  regs_saved_in_regs[i].saved_in_reg = NULL_RTX;
+	}
+      num_regs_saved_in_regs = 0;
+      return;
+    }
+
+  if (!NONJUMP_INSN_P (insn) || clobbers_queued_reg_save (insn))
+    flush_queued_reg_saves ();
+
+  if (! RTX_FRAME_RELATED_P (insn))
+    {
+      if (!ACCUMULATE_OUTGOING_ARGS)
+	dwarf2out_stack_adjust (insn, after_p);
+      return;
+    }
+
+  label = dwarf2out_cfi_label ();
+  src = find_reg_note (insn, REG_FRAME_RELATED_EXPR, NULL_RTX);
+  if (src)
+    insn = XEXP (src, 0);
+  else
+    insn = PATTERN (insn);
+
+  dwarf2out_frame_debug_expr (insn, label);
+}
+
+#endif
+
+/* Describe for the GTY machinery what parts of dw_cfi_oprnd1 are used.  */
+static enum dw_cfi_oprnd_type dw_cfi_oprnd1_desc
+ (enum dwarf_call_frame_info cfi);
+
+static enum dw_cfi_oprnd_type
+dw_cfi_oprnd1_desc (enum dwarf_call_frame_info cfi)
+{
+  switch (cfi)
+    {
+    case DW_CFA_nop:
+    case DW_CFA_GNU_window_save:
+      return dw_cfi_oprnd_unused;
+
+    case DW_CFA_set_loc:
+    case DW_CFA_advance_loc1:
+    case DW_CFA_advance_loc2:
+    case DW_CFA_advance_loc4:
+    case DW_CFA_MIPS_advance_loc8:
+      return dw_cfi_oprnd_addr;
+
+    case DW_CFA_offset:
+    case DW_CFA_offset_extended:
+    case DW_CFA_def_cfa:
+    case DW_CFA_offset_extended_sf:
+    case DW_CFA_def_cfa_sf:
+    case DW_CFA_restore_extended:
+    case DW_CFA_undefined:
+    case DW_CFA_same_value:
+    case DW_CFA_def_cfa_register:
+    case DW_CFA_register:
+      return dw_cfi_oprnd_reg_num;
+
+    case DW_CFA_def_cfa_offset:
+    case DW_CFA_GNU_args_size:
+    case DW_CFA_def_cfa_offset_sf:
+      return dw_cfi_oprnd_offset;
+
+    case DW_CFA_def_cfa_expression:
+    case DW_CFA_expression:
+      return dw_cfi_oprnd_loc;
+
+    default:
+      gcc_unreachable ();
+    }
+}
+
+/* Describe for the GTY machinery what parts of dw_cfi_oprnd2 are used.  */
+static enum dw_cfi_oprnd_type dw_cfi_oprnd2_desc
+ (enum dwarf_call_frame_info cfi);
+
+static enum dw_cfi_oprnd_type
+dw_cfi_oprnd2_desc (enum dwarf_call_frame_info cfi)
+{
+  switch (cfi)
+    {
+    case DW_CFA_def_cfa:
+    case DW_CFA_def_cfa_sf:
+    case DW_CFA_offset:
+    case DW_CFA_offset_extended_sf:
+    case DW_CFA_offset_extended:
+      return dw_cfi_oprnd_offset;
+
+    case DW_CFA_register:
+      return dw_cfi_oprnd_reg_num;
+
+    default:
+      return dw_cfi_oprnd_unused;
+    }
+}
+
+#if defined (DWARF2_DEBUGGING_INFO) || defined (DWARF2_UNWIND_INFO)
+
+/* Map register numbers held in the call frame info that gcc has
+   collected using DWARF_FRAME_REGNUM to those that should be output in
+   .debug_frame and .eh_frame.  */
+#ifndef DWARF2_FRAME_REG_OUT
+#define DWARF2_FRAME_REG_OUT(REGNO, FOR_EH) (REGNO)
+#endif
+
+/* Output a Call Frame Information opcode and its operand(s).  */
+
+static void
+output_cfi (dw_cfi_ref cfi, dw_fde_ref fde, int for_eh)
+{
+  unsigned long r;
+  if (cfi->dw_cfi_opc == DW_CFA_advance_loc)
+    dw2_asm_output_data (1, (cfi->dw_cfi_opc
+			     | (cfi->dw_cfi_oprnd1.dw_cfi_offset & 0x3f)),
+			 "DW_CFA_advance_loc " HOST_WIDE_INT_PRINT_HEX,
+			 cfi->dw_cfi_oprnd1.dw_cfi_offset);
+  else if (cfi->dw_cfi_opc == DW_CFA_offset)
+    {
+      r = DWARF2_FRAME_REG_OUT (cfi->dw_cfi_oprnd1.dw_cfi_reg_num, for_eh);
+      dw2_asm_output_data (1, (cfi->dw_cfi_opc | (r & 0x3f)),
+			   "DW_CFA_offset, column 0x%lx", r);
+      dw2_asm_output_data_uleb128 (cfi->dw_cfi_oprnd2.dw_cfi_offset, NULL);
+    }
+  else if (cfi->dw_cfi_opc == DW_CFA_restore)
+    {
+      r = DWARF2_FRAME_REG_OUT (cfi->dw_cfi_oprnd1.dw_cfi_reg_num, for_eh);
+      dw2_asm_output_data (1, (cfi->dw_cfi_opc | (r & 0x3f)),
+			   "DW_CFA_restore, column 0x%lx", r);
+    }
+  else
+    {
+      dw2_asm_output_data (1, cfi->dw_cfi_opc,
+			   "%s", dwarf_cfi_name (cfi->dw_cfi_opc));
+
+      switch (cfi->dw_cfi_opc)
+	{
+	case DW_CFA_set_loc:
+	  if (for_eh)
+	    dw2_asm_output_encoded_addr_rtx (
+		ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/1, /*global=*/0),
+		gen_rtx_SYMBOL_REF (Pmode, cfi->dw_cfi_oprnd1.dw_cfi_addr),
+		false, NULL);
+	  else
+	    dw2_asm_output_addr (DWARF2_ADDR_SIZE,
+				 cfi->dw_cfi_oprnd1.dw_cfi_addr, NULL);
+	  break;
+
+	case DW_CFA_advance_loc1:
+	  dw2_asm_output_delta (1, cfi->dw_cfi_oprnd1.dw_cfi_addr,
+				fde->dw_fde_current_label, NULL);
+	  fde->dw_fde_current_label = cfi->dw_cfi_oprnd1.dw_cfi_addr;
+	  break;
+
+	case DW_CFA_advance_loc2:
+	  dw2_asm_output_delta (2, cfi->dw_cfi_oprnd1.dw_cfi_addr,
+				fde->dw_fde_current_label, NULL);
+	  fde->dw_fde_current_label = cfi->dw_cfi_oprnd1.dw_cfi_addr;
+	  break;
+
+	case DW_CFA_advance_loc4:
+	  dw2_asm_output_delta (4, cfi->dw_cfi_oprnd1.dw_cfi_addr,
+				fde->dw_fde_current_label, NULL);
+	  fde->dw_fde_current_label = cfi->dw_cfi_oprnd1.dw_cfi_addr;
+	  break;
+
+	case DW_CFA_MIPS_advance_loc8:
+	  dw2_asm_output_delta (8, cfi->dw_cfi_oprnd1.dw_cfi_addr,
+				fde->dw_fde_current_label, NULL);
+	  fde->dw_fde_current_label = cfi->dw_cfi_oprnd1.dw_cfi_addr;
+	  break;
+
+	case DW_CFA_offset_extended:
+	case DW_CFA_def_cfa:
+	  r = DWARF2_FRAME_REG_OUT (cfi->dw_cfi_oprnd1.dw_cfi_reg_num, for_eh);
+	  dw2_asm_output_data_uleb128 (r, NULL);
+	  dw2_asm_output_data_uleb128 (cfi->dw_cfi_oprnd2.dw_cfi_offset, NULL);
+	  break;
+
+	case DW_CFA_offset_extended_sf:
+	case DW_CFA_def_cfa_sf:
+	  r = DWARF2_FRAME_REG_OUT (cfi->dw_cfi_oprnd1.dw_cfi_reg_num, for_eh);
+	  dw2_asm_output_data_uleb128 (r, NULL);
+	  dw2_asm_output_data_sleb128 (cfi->dw_cfi_oprnd2.dw_cfi_offset, NULL);
+	  break;
+
+	case DW_CFA_restore_extended:
+	case DW_CFA_undefined:
+	case DW_CFA_same_value:
+	case DW_CFA_def_cfa_register:
+	  r = DWARF2_FRAME_REG_OUT (cfi->dw_cfi_oprnd1.dw_cfi_reg_num, for_eh);
+	  dw2_asm_output_data_uleb128 (r, NULL);
+	  break;
+
+	case DW_CFA_register:
+	  r = DWARF2_FRAME_REG_OUT (cfi->dw_cfi_oprnd1.dw_cfi_reg_num, for_eh);
+	  dw2_asm_output_data_uleb128 (r, NULL);
+	  r = DWARF2_FRAME_REG_OUT (cfi->dw_cfi_oprnd2.dw_cfi_reg_num, for_eh);
+	  dw2_asm_output_data_uleb128 (r, NULL);
+	  break;
+
+	case DW_CFA_def_cfa_offset:
+	case DW_CFA_GNU_args_size:
+	  dw2_asm_output_data_uleb128 (cfi->dw_cfi_oprnd1.dw_cfi_offset, NULL);
+	  break;
+
+	case DW_CFA_def_cfa_offset_sf:
+	  dw2_asm_output_data_sleb128 (cfi->dw_cfi_oprnd1.dw_cfi_offset, NULL);
+	  break;
+
+	case DW_CFA_GNU_window_save:
+	  break;
+
+	case DW_CFA_def_cfa_expression:
+	case DW_CFA_expression:
+	  output_cfa_loc (cfi);
+	  break;
+
+	case DW_CFA_GNU_negative_offset_extended:
+	  /* Obsoleted by DW_CFA_offset_extended_sf.  */
+	  gcc_unreachable ();
+
+	default:
+	  break;
+	}
+    }
+}
+
+/* Output the call frame information used to record information
+   that relates to calculating the frame pointer, and records the
+   location of saved registers.  */
+
+static void
+output_call_frame_info (int for_eh)
+{
+  unsigned int i;
+  dw_fde_ref fde;
+  dw_cfi_ref cfi;
+  char l1[20], l2[20], section_start_label[20];
+  bool any_lsda_needed = false;
+  char augmentation[6];
+  int augmentation_size;
+  int fde_encoding = DW_EH_PE_absptr;
+  int per_encoding = DW_EH_PE_absptr;
+  int lsda_encoding = DW_EH_PE_absptr;
+  int return_reg;
+
+  /* Don't emit a CIE if there won't be any FDEs.  */
+  if (fde_table_in_use == 0)
+    return;
+
+  /* If we make FDEs linkonce, we may have to emit an empty label for
+     an FDE that wouldn't otherwise be emitted.  We want to avoid
+     having an FDE kept around when the function it refers to is
+     discarded.  Example where this matters: a primary function
+     template in C++ requires EH information, but an explicit
+     specialization doesn't.  */
+  if (TARGET_USES_WEAK_UNWIND_INFO
+      && ! flag_asynchronous_unwind_tables
+      && for_eh)
+    for (i = 0; i < fde_table_in_use; i++)
+      if ((fde_table[i].nothrow || fde_table[i].all_throwers_are_sibcalls)
+          && !fde_table[i].uses_eh_lsda
+	  && ! DECL_WEAK (fde_table[i].decl))
+	targetm.asm_out.unwind_label (asm_out_file, fde_table[i].decl,
+				      for_eh, /* empty */ 1);
+
+  /* If we don't have any functions we'll want to unwind out of, don't
+     emit any EH unwind information.  Note that if exceptions aren't
+     enabled, we won't have collected nothrow information, and if we
+     asked for asynchronous tables, we always want this info.  */
+  if (for_eh)
+    {
+      bool any_eh_needed = !flag_exceptions || flag_asynchronous_unwind_tables;
+
+      for (i = 0; i < fde_table_in_use; i++)
+	if (fde_table[i].uses_eh_lsda)
+	  any_eh_needed = any_lsda_needed = true;
+        else if (TARGET_USES_WEAK_UNWIND_INFO && DECL_WEAK (fde_table[i].decl))
+	  any_eh_needed = true;
+	else if (! fde_table[i].nothrow
+		 && ! fde_table[i].all_throwers_are_sibcalls)
+	  any_eh_needed = true;
+
+      if (! any_eh_needed)
+	return;
+    }
+
+  /* We're going to be generating comments, so turn on app.  */
+  if (flag_debug_asm)
+    app_enable ();
+
+  if (for_eh)
+    targetm.asm_out.eh_frame_section ();
+  else
+    named_section_flags (DEBUG_FRAME_SECTION, SECTION_DEBUG);
+
+  ASM_GENERATE_INTERNAL_LABEL (section_start_label, FRAME_BEGIN_LABEL, for_eh);
+  ASM_OUTPUT_LABEL (asm_out_file, section_start_label);
+
+  /* Output the CIE.  */
+  ASM_GENERATE_INTERNAL_LABEL (l1, CIE_AFTER_SIZE_LABEL, for_eh);
+  ASM_GENERATE_INTERNAL_LABEL (l2, CIE_END_LABEL, for_eh);
+  dw2_asm_output_delta (for_eh ? 4 : DWARF_OFFSET_SIZE, l2, l1,
+			"Length of Common Information Entry");
+  ASM_OUTPUT_LABEL (asm_out_file, l1);
+
+  /* Now that the CIE pointer is PC-relative for EH,
+     use 0 to identify the CIE.  */
+  dw2_asm_output_data ((for_eh ? 4 : DWARF_OFFSET_SIZE),
+		       (for_eh ? 0 : DW_CIE_ID),
+		       "CIE Identifier Tag");
+
+  dw2_asm_output_data (1, DW_CIE_VERSION, "CIE Version");
+
+  augmentation[0] = 0;
+  augmentation_size = 0;
+  if (for_eh)
+    {
+      char *p;
+
+      /* Augmentation:
+	 z	Indicates that a uleb128 is present to size the
+		augmentation section.
+	 L	Indicates the encoding (and thus presence) of
+		an LSDA pointer in the FDE augmentation.
+	 R	Indicates a non-default pointer encoding for
+		FDE code pointers.
+	 P	Indicates the presence of an encoding + language
+		personality routine in the CIE augmentation.  */
+
+      fde_encoding = ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/1, /*global=*/0);
+      per_encoding = ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/2, /*global=*/1);
+      lsda_encoding = ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/0, /*global=*/0);
+
+      p = augmentation + 1;
+      if (eh_personality_libfunc)
+	{
+	  *p++ = 'P';
+	  augmentation_size += 1 + size_of_encoded_value (per_encoding);
+	}
+      if (any_lsda_needed)
+	{
+	  *p++ = 'L';
+	  augmentation_size += 1;
+	}
+      if (fde_encoding != DW_EH_PE_absptr)
+	{
+	  *p++ = 'R';
+	  augmentation_size += 1;
+	}
+      if (p > augmentation + 1)
+	{
+	  augmentation[0] = 'z';
+	  *p = '\0';
+	}
+
+      /* Ug.  Some platforms can't do unaligned dynamic relocations at all.  */
+      if (eh_personality_libfunc && per_encoding == DW_EH_PE_aligned)
+	{
+	  int offset = (  4		/* Length */
+			+ 4		/* CIE Id */
+			+ 1		/* CIE version */
+			+ strlen (augmentation) + 1	/* Augmentation */
+			+ size_of_uleb128 (1)		/* Code alignment */
+			+ size_of_sleb128 (DWARF_CIE_DATA_ALIGNMENT)
+			+ 1		/* RA column */
+			+ 1		/* Augmentation size */
+			+ 1		/* Personality encoding */ );
+	  int pad = -offset & (PTR_SIZE - 1);
+
+	  augmentation_size += pad;
+
+	  /* Augmentations should be small, so there's scarce need to
+	     iterate for a solution.  Die if we exceed one uleb128 byte.  */
+	  gcc_assert (size_of_uleb128 (augmentation_size) == 1);
+	}
+    }
+
+  dw2_asm_output_nstring (augmentation, -1, "CIE Augmentation");
+  dw2_asm_output_data_uleb128 (1, "CIE Code Alignment Factor");
+  dw2_asm_output_data_sleb128 (DWARF_CIE_DATA_ALIGNMENT,
+			       "CIE Data Alignment Factor");
+
+  return_reg = DWARF2_FRAME_REG_OUT (DWARF_FRAME_RETURN_COLUMN, for_eh);
+  if (DW_CIE_VERSION == 1)
+    dw2_asm_output_data (1, return_reg, "CIE RA Column");
+  else
+    dw2_asm_output_data_uleb128 (return_reg, "CIE RA Column");
+
+  if (augmentation[0])
+    {
+      dw2_asm_output_data_uleb128 (augmentation_size, "Augmentation size");
+      if (eh_personality_libfunc)
+	{
+	  dw2_asm_output_data (1, per_encoding, "Personality (%s)",
+			       eh_data_format_name (per_encoding));
+	  dw2_asm_output_encoded_addr_rtx (per_encoding,
+					   eh_personality_libfunc,
+					   true, NULL);
+	}
+
+      if (any_lsda_needed)
+	dw2_asm_output_data (1, lsda_encoding, "LSDA Encoding (%s)",
+			     eh_data_format_name (lsda_encoding));
+
+      if (fde_encoding != DW_EH_PE_absptr)
+	dw2_asm_output_data (1, fde_encoding, "FDE Encoding (%s)",
+			     eh_data_format_name (fde_encoding));
+    }
+
+  for (cfi = cie_cfi_head; cfi != NULL; cfi = cfi->dw_cfi_next)
+    output_cfi (cfi, NULL, for_eh);
+
+  /* Pad the CIE out to an address sized boundary.  */
+  ASM_OUTPUT_ALIGN (asm_out_file,
+		    floor_log2 (for_eh ? PTR_SIZE : DWARF2_ADDR_SIZE));
+  ASM_OUTPUT_LABEL (asm_out_file, l2);
+
+  /* Loop through all of the FDE's.  */
+  for (i = 0; i < fde_table_in_use; i++)
+    {
+      fde = &fde_table[i];
+
+      /* Don't emit EH unwind info for leaf functions that don't need it.  */
+      if (for_eh && !flag_asynchronous_unwind_tables && flag_exceptions
+	  && (fde->nothrow || fde->all_throwers_are_sibcalls)
+	  && ! (TARGET_USES_WEAK_UNWIND_INFO && DECL_WEAK (fde_table[i].decl))
+	  && !fde->uses_eh_lsda)
+	continue;
+
+      targetm.asm_out.unwind_label (asm_out_file, fde->decl, for_eh, /* empty */ 0);
+      targetm.asm_out.internal_label (asm_out_file, FDE_LABEL, for_eh + i * 2);
+      ASM_GENERATE_INTERNAL_LABEL (l1, FDE_AFTER_SIZE_LABEL, for_eh + i * 2);
+      ASM_GENERATE_INTERNAL_LABEL (l2, FDE_END_LABEL, for_eh + i * 2);
+      dw2_asm_output_delta (for_eh ? 4 : DWARF_OFFSET_SIZE, l2, l1,
+			    "FDE Length");
+      ASM_OUTPUT_LABEL (asm_out_file, l1);
+
+      if (for_eh)
+	dw2_asm_output_delta (4, l1, section_start_label, "FDE CIE offset");
+      else
+	dw2_asm_output_offset (DWARF_OFFSET_SIZE, section_start_label,
+			       "FDE CIE offset");
+
+      if (for_eh)
+	{
+	  rtx sym_ref = gen_rtx_SYMBOL_REF (Pmode, fde->dw_fde_begin);
+	  SYMBOL_REF_FLAGS (sym_ref) |= SYMBOL_FLAG_LOCAL;
+	  dw2_asm_output_encoded_addr_rtx (fde_encoding,
+					   sym_ref,
+					   false,
+					   "FDE initial location");
+	  if (fde->dw_fde_switched_sections)
+	    {
+	      rtx sym_ref2 = gen_rtx_SYMBOL_REF (Pmode, 
+				      fde->dw_fde_unlikely_section_label);
+	      rtx sym_ref3= gen_rtx_SYMBOL_REF (Pmode, 
+				      fde->dw_fde_hot_section_label);
+	      SYMBOL_REF_FLAGS (sym_ref2) |= SYMBOL_FLAG_LOCAL;
+	      SYMBOL_REF_FLAGS (sym_ref3) |= SYMBOL_FLAG_LOCAL;
+	      dw2_asm_output_encoded_addr_rtx (fde_encoding, sym_ref3, false,
+					       "FDE initial location");
+	      dw2_asm_output_delta (size_of_encoded_value (fde_encoding),
+				    fde->dw_fde_hot_section_end_label,
+				    fde->dw_fde_hot_section_label,
+				    "FDE address range");
+	      dw2_asm_output_encoded_addr_rtx (fde_encoding, sym_ref2, false,
+					       "FDE initial location");
+	      dw2_asm_output_delta (size_of_encoded_value (fde_encoding),
+				    fde->dw_fde_unlikely_section_end_label,
+				    fde->dw_fde_unlikely_section_label,
+				    "FDE address range");
+	    }
+	  else
+	    dw2_asm_output_delta (size_of_encoded_value (fde_encoding),
+				  fde->dw_fde_end, fde->dw_fde_begin,
+				  "FDE address range");
+	}
+      else
+	{
+	  dw2_asm_output_addr (DWARF2_ADDR_SIZE, fde->dw_fde_begin,
+			       "FDE initial location");
+	  if (fde->dw_fde_switched_sections)
+	    {
+	      dw2_asm_output_addr (DWARF2_ADDR_SIZE,
+				   fde->dw_fde_hot_section_label,
+				   "FDE initial location");
+	      dw2_asm_output_delta (DWARF2_ADDR_SIZE,
+				    fde->dw_fde_hot_section_end_label,
+				    fde->dw_fde_hot_section_label,
+				    "FDE address range");
+	      dw2_asm_output_addr (DWARF2_ADDR_SIZE,
+				   fde->dw_fde_unlikely_section_label,
+				   "FDE initial location");
+	      dw2_asm_output_delta (DWARF2_ADDR_SIZE, 
+				    fde->dw_fde_unlikely_section_end_label,
+				    fde->dw_fde_unlikely_section_label,
+				    "FDE address range");
+	    }
+	  else
+	    dw2_asm_output_delta (DWARF2_ADDR_SIZE,
+				  fde->dw_fde_end, fde->dw_fde_begin,
+				  "FDE address range");
+	}
+
+      if (augmentation[0])
+	{
+	  if (any_lsda_needed)
+	    {
+	      int size = size_of_encoded_value (lsda_encoding);
+
+	      if (lsda_encoding == DW_EH_PE_aligned)
+		{
+		  int offset = (  4		/* Length */
+				+ 4		/* CIE offset */
+				+ 2 * size_of_encoded_value (fde_encoding)
+				+ 1		/* Augmentation size */ );
+		  int pad = -offset & (PTR_SIZE - 1);
+
+		  size += pad;
+		  gcc_assert (size_of_uleb128 (size) == 1);
+		}
+
+	      dw2_asm_output_data_uleb128 (size, "Augmentation size");
+
+	      if (fde->uses_eh_lsda)
+		{
+		  ASM_GENERATE_INTERNAL_LABEL (l1, "LLSDA",
+					       fde->funcdef_number);
+		  dw2_asm_output_encoded_addr_rtx (
+			lsda_encoding, gen_rtx_SYMBOL_REF (Pmode, l1),
+			false, "Language Specific Data Area");
+		}
+	      else
+		{
+		  if (lsda_encoding == DW_EH_PE_aligned)
+		    ASM_OUTPUT_ALIGN (asm_out_file, floor_log2 (PTR_SIZE));
+		  dw2_asm_output_data
+		    (size_of_encoded_value (lsda_encoding), 0,
+		     "Language Specific Data Area (none)");
+		}
+	    }
+	  else
+	    dw2_asm_output_data_uleb128 (0, "Augmentation size");
+	}
+
+      /* Loop through the Call Frame Instructions associated with
+	 this FDE.  */
+      fde->dw_fde_current_label = fde->dw_fde_begin;
+      for (cfi = fde->dw_fde_cfi; cfi != NULL; cfi = cfi->dw_cfi_next)
+	output_cfi (cfi, fde, for_eh);
+
+      /* Pad the FDE out to an address sized boundary.  */
+      ASM_OUTPUT_ALIGN (asm_out_file,
+			floor_log2 ((for_eh ? PTR_SIZE : DWARF2_ADDR_SIZE)));
+      ASM_OUTPUT_LABEL (asm_out_file, l2);
+    }
+
+  if (for_eh && targetm.terminate_dw2_eh_frame_info)
+    dw2_asm_output_data (4, 0, "End of Table");
+#ifdef MIPS_DEBUGGING_INFO
+  /* Work around Irix 6 assembler bug whereby labels at the end of a section
+     get a value of 0.  Putting .align 0 after the label fixes it.  */
+  ASM_OUTPUT_ALIGN (asm_out_file, 0);
+#endif
+
+  /* Turn off app to make assembly quicker.  */
+  if (flag_debug_asm)
+    app_disable ();
+}
+
+/* Output a marker (i.e. a label) for the beginning of a function, before
+   the prologue.  */
+
+void
+dwarf2out_begin_prologue (unsigned int line ATTRIBUTE_UNUSED,
+			  const char *file ATTRIBUTE_UNUSED)
+{
+  char label[MAX_ARTIFICIAL_LABEL_BYTES];
+  char * dup_label;
+  dw_fde_ref fde;
+
+  current_function_func_begin_label = NULL;
+
+#ifdef TARGET_UNWIND_INFO
+  /* ??? current_function_func_begin_label is also used by except.c
+     for call-site information.  We must emit this label if it might
+     be used.  */
+  if ((! flag_exceptions || USING_SJLJ_EXCEPTIONS)
+      && ! dwarf2out_do_frame ())
+    return;
+#else
+  if (! dwarf2out_do_frame ())
+    return;
+#endif
+
+  function_section (current_function_decl);
+  ASM_GENERATE_INTERNAL_LABEL (label, FUNC_BEGIN_LABEL,
+			       current_function_funcdef_no);
+  ASM_OUTPUT_DEBUG_LABEL (asm_out_file, FUNC_BEGIN_LABEL,
+			  current_function_funcdef_no);
+  dup_label = xstrdup (label);
+  current_function_func_begin_label = dup_label;
+
+#ifdef TARGET_UNWIND_INFO
+  /* We can elide the fde allocation if we're not emitting debug info.  */
+  if (! dwarf2out_do_frame ())
+    return;
+#endif
+
+  /* Expand the fde table if necessary.  */
+  if (fde_table_in_use == fde_table_allocated)
+    {
+      fde_table_allocated += FDE_TABLE_INCREMENT;
+      fde_table = ggc_realloc (fde_table,
+			       fde_table_allocated * sizeof (dw_fde_node));
+      memset (fde_table + fde_table_in_use, 0,
+	      FDE_TABLE_INCREMENT * sizeof (dw_fde_node));
+    }
+
+  /* Record the FDE associated with this function.  */
+  current_funcdef_fde = fde_table_in_use;
+
+  /* Add the new FDE at the end of the fde_table.  */
+  fde = &fde_table[fde_table_in_use++];
+  fde->decl = current_function_decl;
+  fde->dw_fde_begin = dup_label;
+  fde->dw_fde_current_label = NULL;
+  fde->dw_fde_hot_section_label = NULL;
+  fde->dw_fde_hot_section_end_label = NULL;
+  fde->dw_fde_unlikely_section_label = NULL;
+  fde->dw_fde_unlikely_section_end_label = NULL;
+  fde->dw_fde_switched_sections = false;
+  fde->dw_fde_end = NULL;
+  fde->dw_fde_cfi = NULL;
+  fde->funcdef_number = current_function_funcdef_no;
+  fde->nothrow = TREE_NOTHROW (current_function_decl);
+  fde->uses_eh_lsda = cfun->uses_eh_lsda;
+  fde->all_throwers_are_sibcalls = cfun->all_throwers_are_sibcalls;
+
+  args_size = old_args_size = 0;
+
+  /* We only want to output line number information for the genuine dwarf2
+     prologue case, not the eh frame case.  */
+#ifdef DWARF2_DEBUGGING_INFO
+  if (file)
+    dwarf2out_source_line (line, file);
+#endif
+}
+
+/* Output a marker (i.e. a label) for the absolute end of the generated code
+   for a function definition.  This gets called *after* the epilogue code has
+   been generated.  */
+
+void
+dwarf2out_end_epilogue (unsigned int line ATTRIBUTE_UNUSED,
+			const char *file ATTRIBUTE_UNUSED)
+{
+  dw_fde_ref fde;
+  char label[MAX_ARTIFICIAL_LABEL_BYTES];
+
+  /* Output a label to mark the endpoint of the code generated for this
+     function.  */
+  ASM_GENERATE_INTERNAL_LABEL (label, FUNC_END_LABEL,
+			       current_function_funcdef_no);
+  ASM_OUTPUT_LABEL (asm_out_file, label);
+  fde = &fde_table[fde_table_in_use - 1];
+  fde->dw_fde_end = xstrdup (label);
+}
+
+void
+dwarf2out_frame_init (void)
+{
+  /* Allocate the initial hunk of the fde_table.  */
+  fde_table = ggc_alloc_cleared (FDE_TABLE_INCREMENT * sizeof (dw_fde_node));
+  fde_table_allocated = FDE_TABLE_INCREMENT;
+  fde_table_in_use = 0;
+
+  /* Generate the CFA instructions common to all FDE's.  Do it now for the
+     sake of lookup_cfa.  */
+
+#ifdef DWARF2_UNWIND_INFO
+  /* On entry, the Canonical Frame Address is at SP.  */
+  dwarf2out_def_cfa (NULL, STACK_POINTER_REGNUM, INCOMING_FRAME_SP_OFFSET);
+  initial_return_save (INCOMING_RETURN_ADDR_RTX);
+#endif
+}
+
+void
+dwarf2out_frame_finish (void)
+{
+  /* Output call frame information.  */
+  if (write_symbols == DWARF2_DEBUG
+      || write_symbols == VMS_AND_DWARF2_DEBUG
+#ifdef DWARF2_FRAME_INFO
+      || DWARF2_FRAME_INFO
+#endif
+      )
+    output_call_frame_info (0);
+
+#ifndef TARGET_UNWIND_INFO
+  /* Output another copy for the unwinder.  */
+  if (! USING_SJLJ_EXCEPTIONS && (flag_unwind_tables || flag_exceptions))
+    output_call_frame_info (1);
+#endif
+}
+#endif
+
+/* And now, the subset of the debugging information support code necessary
+   for emitting location expressions.  */
+
+/* We need some way to distinguish DW_OP_addr with a direct symbol
+   relocation from DW_OP_addr with a dtp-relative symbol relocation.  */
+#define INTERNAL_DW_OP_tls_addr		(0x100 + DW_OP_addr)
+
+
+typedef struct dw_val_struct *dw_val_ref;
+typedef struct die_struct *dw_die_ref;
+typedef struct dw_loc_descr_struct *dw_loc_descr_ref;
+typedef struct dw_loc_list_struct *dw_loc_list_ref;
+
+/* Each DIE may have a series of attribute/value pairs.  Values
+   can take on several forms.  The forms that are used in this
+   implementation are listed below.  */
+
+enum dw_val_class
+{
+  dw_val_class_addr,
+  dw_val_class_offset,
+  dw_val_class_loc,
+  dw_val_class_loc_list,
+  dw_val_class_range_list,
+  dw_val_class_const,
+  dw_val_class_unsigned_const,
+  dw_val_class_long_long,
+  dw_val_class_vec,
+  dw_val_class_flag,
+  dw_val_class_die_ref,
+  dw_val_class_fde_ref,
+  dw_val_class_lbl_id,
+  dw_val_class_lbl_offset,
+  dw_val_class_str
+};
+
+/* Describe a double word constant value.  */
+/* ??? Every instance of long_long in the code really means CONST_DOUBLE.  */
+
+typedef struct dw_long_long_struct GTY(())
+{
+  unsigned long hi;
+  unsigned long low;
+}
+dw_long_long_const;
+
+/* Describe a floating point constant value, or a vector constant value.  */
+
+typedef struct dw_vec_struct GTY(())
+{
+  unsigned char * GTY((length ("%h.length"))) array;
+  unsigned length;
+  unsigned elt_size;
+}
+dw_vec_const;
+
+/* The dw_val_node describes an attribute's value, as it is
+   represented internally.  */
+
+typedef struct dw_val_struct GTY(())
+{
+  enum dw_val_class val_class;
+  union dw_val_struct_union
+    {
+      rtx GTY ((tag ("dw_val_class_addr"))) val_addr;
+      unsigned HOST_WIDE_INT GTY ((tag ("dw_val_class_offset"))) val_offset;
+      dw_loc_list_ref GTY ((tag ("dw_val_class_loc_list"))) val_loc_list;
+      dw_loc_descr_ref GTY ((tag ("dw_val_class_loc"))) val_loc;
+      HOST_WIDE_INT GTY ((default)) val_int;
+      unsigned HOST_WIDE_INT GTY ((tag ("dw_val_class_unsigned_const"))) val_unsigned;
+      dw_long_long_const GTY ((tag ("dw_val_class_long_long"))) val_long_long;
+      dw_vec_const GTY ((tag ("dw_val_class_vec"))) val_vec;
+      struct dw_val_die_union
+	{
+	  dw_die_ref die;
+	  int external;
+	} GTY ((tag ("dw_val_class_die_ref"))) val_die_ref;
+      unsigned GTY ((tag ("dw_val_class_fde_ref"))) val_fde_index;
+      struct indirect_string_node * GTY ((tag ("dw_val_class_str"))) val_str;
+      char * GTY ((tag ("dw_val_class_lbl_id"))) val_lbl_id;
+      unsigned char GTY ((tag ("dw_val_class_flag"))) val_flag;
+    }
+  GTY ((desc ("%1.val_class"))) v;
+}
+dw_val_node;
+
+/* Locations in memory are described using a sequence of stack machine
+   operations.  */
+
+typedef struct dw_loc_descr_struct GTY(())
+{
+  dw_loc_descr_ref dw_loc_next;
+  enum dwarf_location_atom dw_loc_opc;
+  dw_val_node dw_loc_oprnd1;
+  dw_val_node dw_loc_oprnd2;
+  int dw_loc_addr;
+}
+dw_loc_descr_node;
+
+/* Location lists are ranges + location descriptions for that range,
+   so you can track variables that are in different places over
+   their entire life.  */
+typedef struct dw_loc_list_struct GTY(())
+{
+  dw_loc_list_ref dw_loc_next;
+  const char *begin; /* Label for begin address of range */
+  const char *end;  /* Label for end address of range */
+  char *ll_symbol; /* Label for beginning of location list.
+		      Only on head of list */
+  const char *section; /* Section this loclist is relative to */
+  dw_loc_descr_ref expr;
+} dw_loc_list_node;
+
+#if defined (DWARF2_DEBUGGING_INFO) || defined (DWARF2_UNWIND_INFO)
+
+static const char *dwarf_stack_op_name (unsigned);
+static dw_loc_descr_ref new_loc_descr (enum dwarf_location_atom,
+				       unsigned HOST_WIDE_INT, unsigned HOST_WIDE_INT);
+static void add_loc_descr (dw_loc_descr_ref *, dw_loc_descr_ref);
+static unsigned long size_of_loc_descr (dw_loc_descr_ref);
+static unsigned long size_of_locs (dw_loc_descr_ref);
+static void output_loc_operands (dw_loc_descr_ref);
+static void output_loc_sequence (dw_loc_descr_ref);
+
+/* Convert a DWARF stack opcode into its string name.  */
+
+static const char *
+dwarf_stack_op_name (unsigned int op)
+{
+  switch (op)
+    {
+    case DW_OP_addr:
+    case INTERNAL_DW_OP_tls_addr:
+      return "DW_OP_addr";
+    case DW_OP_deref:
+      return "DW_OP_deref";
+    case DW_OP_const1u:
+      return "DW_OP_const1u";
+    case DW_OP_const1s:
+      return "DW_OP_const1s";
+    case DW_OP_const2u:
+      return "DW_OP_const2u";
+    case DW_OP_const2s:
+      return "DW_OP_const2s";
+    case DW_OP_const4u:
+      return "DW_OP_const4u";
+    case DW_OP_const4s:
+      return "DW_OP_const4s";
+    case DW_OP_const8u:
+      return "DW_OP_const8u";
+    case DW_OP_const8s:
+      return "DW_OP_const8s";
+    case DW_OP_constu:
+      return "DW_OP_constu";
+    case DW_OP_consts:
+      return "DW_OP_consts";
+    case DW_OP_dup:
+      return "DW_OP_dup";
+    case DW_OP_drop:
+      return "DW_OP_drop";
+    case DW_OP_over:
+      return "DW_OP_over";
+    case DW_OP_pick:
+      return "DW_OP_pick";
+    case DW_OP_swap:
+      return "DW_OP_swap";
+    case DW_OP_rot:
+      return "DW_OP_rot";
+    case DW_OP_xderef:
+      return "DW_OP_xderef";
+    case DW_OP_abs:
+      return "DW_OP_abs";
+    case DW_OP_and:
+      return "DW_OP_and";
+    case DW_OP_div:
+      return "DW_OP_div";
+    case DW_OP_minus:
+      return "DW_OP_minus";
+    case DW_OP_mod:
+      return "DW_OP_mod";
+    case DW_OP_mul:
+      return "DW_OP_mul";
+    case DW_OP_neg:
+      return "DW_OP_neg";
+    case DW_OP_not:
+      return "DW_OP_not";
+    case DW_OP_or:
+      return "DW_OP_or";
+    case DW_OP_plus:
+      return "DW_OP_plus";
+    case DW_OP_plus_uconst:
+      return "DW_OP_plus_uconst";
+    case DW_OP_shl:
+      return "DW_OP_shl";
+    case DW_OP_shr:
+      return "DW_OP_shr";
+    case DW_OP_shra:
+      return "DW_OP_shra";
+    case DW_OP_xor:
+      return "DW_OP_xor";
+    case DW_OP_bra:
+      return "DW_OP_bra";
+    case DW_OP_eq:
+      return "DW_OP_eq";
+    case DW_OP_ge:
+      return "DW_OP_ge";
+    case DW_OP_gt:
+      return "DW_OP_gt";
+    case DW_OP_le:
+      return "DW_OP_le";
+    case DW_OP_lt:
+      return "DW_OP_lt";
+    case DW_OP_ne:
+      return "DW_OP_ne";
+    case DW_OP_skip:
+      return "DW_OP_skip";
+    case DW_OP_lit0:
+      return "DW_OP_lit0";
+    case DW_OP_lit1:
+      return "DW_OP_lit1";
+    case DW_OP_lit2:
+      return "DW_OP_lit2";
+    case DW_OP_lit3:
+      return "DW_OP_lit3";
+    case DW_OP_lit4:
+      return "DW_OP_lit4";
+    case DW_OP_lit5:
+      return "DW_OP_lit5";
+    case DW_OP_lit6:
+      return "DW_OP_lit6";
+    case DW_OP_lit7:
+      return "DW_OP_lit7";
+    case DW_OP_lit8:
+      return "DW_OP_lit8";
+    case DW_OP_lit9:
+      return "DW_OP_lit9";
+    case DW_OP_lit10:
+      return "DW_OP_lit10";
+    case DW_OP_lit11:
+      return "DW_OP_lit11";
+    case DW_OP_lit12:
+      return "DW_OP_lit12";
+    case DW_OP_lit13:
+      return "DW_OP_lit13";
+    case DW_OP_lit14:
+      return "DW_OP_lit14";
+    case DW_OP_lit15:
+      return "DW_OP_lit15";
+    case DW_OP_lit16:
+      return "DW_OP_lit16";
+    case DW_OP_lit17:
+      return "DW_OP_lit17";
+    case DW_OP_lit18:
+      return "DW_OP_lit18";
+    case DW_OP_lit19:
+      return "DW_OP_lit19";
+    case DW_OP_lit20:
+      return "DW_OP_lit20";
+    case DW_OP_lit21:
+      return "DW_OP_lit21";
+    case DW_OP_lit22:
+      return "DW_OP_lit22";
+    case DW_OP_lit23:
+      return "DW_OP_lit23";
+    case DW_OP_lit24:
+      return "DW_OP_lit24";
+    case DW_OP_lit25:
+      return "DW_OP_lit25";
+    case DW_OP_lit26:
+      return "DW_OP_lit26";
+    case DW_OP_lit27:
+      return "DW_OP_lit27";
+    case DW_OP_lit28:
+      return "DW_OP_lit28";
+    case DW_OP_lit29:
+      return "DW_OP_lit29";
+    case DW_OP_lit30:
+      return "DW_OP_lit30";
+    case DW_OP_lit31:
+      return "DW_OP_lit31";
+    case DW_OP_reg0:
+      return "DW_OP_reg0";
+    case DW_OP_reg1:
+      return "DW_OP_reg1";
+    case DW_OP_reg2:
+      return "DW_OP_reg2";
+    case DW_OP_reg3:
+      return "DW_OP_reg3";
+    case DW_OP_reg4:
+      return "DW_OP_reg4";
+    case DW_OP_reg5:
+      return "DW_OP_reg5";
+    case DW_OP_reg6:
+      return "DW_OP_reg6";
+    case DW_OP_reg7:
+      return "DW_OP_reg7";
+    case DW_OP_reg8:
+      return "DW_OP_reg8";
+    case DW_OP_reg9:
+      return "DW_OP_reg9";
+    case DW_OP_reg10:
+      return "DW_OP_reg10";
+    case DW_OP_reg11:
+      return "DW_OP_reg11";
+    case DW_OP_reg12:
+      return "DW_OP_reg12";
+    case DW_OP_reg13:
+      return "DW_OP_reg13";
+    case DW_OP_reg14:
+      return "DW_OP_reg14";
+    case DW_OP_reg15:
+      return "DW_OP_reg15";
+    case DW_OP_reg16:
+      return "DW_OP_reg16";
+    case DW_OP_reg17:
+      return "DW_OP_reg17";
+    case DW_OP_reg18:
+      return "DW_OP_reg18";
+    case DW_OP_reg19:
+      return "DW_OP_reg19";
+    case DW_OP_reg20:
+      return "DW_OP_reg20";
+    case DW_OP_reg21:
+      return "DW_OP_reg21";
+    case DW_OP_reg22:
+      return "DW_OP_reg22";
+    case DW_OP_reg23:
+      return "DW_OP_reg23";
+    case DW_OP_reg24:
+      return "DW_OP_reg24";
+    case DW_OP_reg25:
+      return "DW_OP_reg25";
+    case DW_OP_reg26:
+      return "DW_OP_reg26";
+    case DW_OP_reg27:
+      return "DW_OP_reg27";
+    case DW_OP_reg28:
+      return "DW_OP_reg28";
+    case DW_OP_reg29:
+      return "DW_OP_reg29";
+    case DW_OP_reg30:
+      return "DW_OP_reg30";
+    case DW_OP_reg31:
+      return "DW_OP_reg31";
+    case DW_OP_breg0:
+      return "DW_OP_breg0";
+    case DW_OP_breg1:
+      return "DW_OP_breg1";
+    case DW_OP_breg2:
+      return "DW_OP_breg2";
+    case DW_OP_breg3:
+      return "DW_OP_breg3";
+    case DW_OP_breg4:
+      return "DW_OP_breg4";
+    case DW_OP_breg5:
+      return "DW_OP_breg5";
+    case DW_OP_breg6:
+      return "DW_OP_breg6";
+    case DW_OP_breg7:
+      return "DW_OP_breg7";
+    case DW_OP_breg8:
+      return "DW_OP_breg8";
+    case DW_OP_breg9:
+      return "DW_OP_breg9";
+    case DW_OP_breg10:
+      return "DW_OP_breg10";
+    case DW_OP_breg11:
+      return "DW_OP_breg11";
+    case DW_OP_breg12:
+      return "DW_OP_breg12";
+    case DW_OP_breg13:
+      return "DW_OP_breg13";
+    case DW_OP_breg14:
+      return "DW_OP_breg14";
+    case DW_OP_breg15:
+      return "DW_OP_breg15";
+    case DW_OP_breg16:
+      return "DW_OP_breg16";
+    case DW_OP_breg17:
+      return "DW_OP_breg17";
+    case DW_OP_breg18:
+      return "DW_OP_breg18";
+    case DW_OP_breg19:
+      return "DW_OP_breg19";
+    case DW_OP_breg20:
+      return "DW_OP_breg20";
+    case DW_OP_breg21:
+      return "DW_OP_breg21";
+    case DW_OP_breg22:
+      return "DW_OP_breg22";
+    case DW_OP_breg23:
+      return "DW_OP_breg23";
+    case DW_OP_breg24:
+      return "DW_OP_breg24";
+    case DW_OP_breg25:
+      return "DW_OP_breg25";
+    case DW_OP_breg26:
+      return "DW_OP_breg26";
+    case DW_OP_breg27:
+      return "DW_OP_breg27";
+    case DW_OP_breg28:
+      return "DW_OP_breg28";
+    case DW_OP_breg29:
+      return "DW_OP_breg29";
+    case DW_OP_breg30:
+      return "DW_OP_breg30";
+    case DW_OP_breg31:
+      return "DW_OP_breg31";
+    case DW_OP_regx:
+      return "DW_OP_regx";
+    case DW_OP_fbreg:
+      return "DW_OP_fbreg";
+    case DW_OP_bregx:
+      return "DW_OP_bregx";
+    case DW_OP_piece:
+      return "DW_OP_piece";
+    case DW_OP_deref_size:
+      return "DW_OP_deref_size";
+    case DW_OP_xderef_size:
+      return "DW_OP_xderef_size";
+    case DW_OP_nop:
+      return "DW_OP_nop";
+    case DW_OP_push_object_address:
+      return "DW_OP_push_object_address";
+    case DW_OP_call2:
+      return "DW_OP_call2";
+    case DW_OP_call4:
+      return "DW_OP_call4";
+    case DW_OP_call_ref:
+      return "DW_OP_call_ref";
+    case DW_OP_GNU_push_tls_address:
+      return "DW_OP_GNU_push_tls_address";
+    default:
+      return "OP_<unknown>";
+    }
+}
+
+/* Return a pointer to a newly allocated location description.  Location
+   descriptions are simple expression terms that can be strung
+   together to form more complicated location (address) descriptions.  */
+
+static inline dw_loc_descr_ref
+new_loc_descr (enum dwarf_location_atom op, unsigned HOST_WIDE_INT oprnd1,
+	       unsigned HOST_WIDE_INT oprnd2)
+{
+  dw_loc_descr_ref descr = ggc_alloc_cleared (sizeof (dw_loc_descr_node));
+
+  descr->dw_loc_opc = op;
+  descr->dw_loc_oprnd1.val_class = dw_val_class_unsigned_const;
+  descr->dw_loc_oprnd1.v.val_unsigned = oprnd1;
+  descr->dw_loc_oprnd2.val_class = dw_val_class_unsigned_const;
+  descr->dw_loc_oprnd2.v.val_unsigned = oprnd2;
+
+  return descr;
+}
+
+/* Add a location description term to a location description expression.  */
+
+static inline void
+add_loc_descr (dw_loc_descr_ref *list_head, dw_loc_descr_ref descr)
+{
+  dw_loc_descr_ref *d;
+
+  /* Find the end of the chain.  */
+  for (d = list_head; (*d) != NULL; d = &(*d)->dw_loc_next)
+    ;
+
+  *d = descr;
+}
+
+/* Return the size of a location descriptor.  */
+
+static unsigned long
+size_of_loc_descr (dw_loc_descr_ref loc)
+{
+  unsigned long size = 1;
+
+  switch (loc->dw_loc_opc)
+    {
+    case DW_OP_addr:
+    case INTERNAL_DW_OP_tls_addr:
+      size += DWARF2_ADDR_SIZE;
+      break;
+    case DW_OP_const1u:
+    case DW_OP_const1s:
+      size += 1;
+      break;
+    case DW_OP_const2u:
+    case DW_OP_const2s:
+      size += 2;
+      break;
+    case DW_OP_const4u:
+    case DW_OP_const4s:
+      size += 4;
+      break;
+    case DW_OP_const8u:
+    case DW_OP_const8s:
+      size += 8;
+      break;
+    case DW_OP_constu:
+      size += size_of_uleb128 (loc->dw_loc_oprnd1.v.val_unsigned);
+      break;
+    case DW_OP_consts:
+      size += size_of_sleb128 (loc->dw_loc_oprnd1.v.val_int);
+      break;
+    case DW_OP_pick:
+      size += 1;
+      break;
+    case DW_OP_plus_uconst:
+      size += size_of_uleb128 (loc->dw_loc_oprnd1.v.val_unsigned);
+      break;
+    case DW_OP_skip:
+    case DW_OP_bra:
+      size += 2;
+      break;
+    case DW_OP_breg0:
+    case DW_OP_breg1:
+    case DW_OP_breg2:
+    case DW_OP_breg3:
+    case DW_OP_breg4:
+    case DW_OP_breg5:
+    case DW_OP_breg6:
+    case DW_OP_breg7:
+    case DW_OP_breg8:
+    case DW_OP_breg9:
+    case DW_OP_breg10:
+    case DW_OP_breg11:
+    case DW_OP_breg12:
+    case DW_OP_breg13:
+    case DW_OP_breg14:
+    case DW_OP_breg15:
+    case DW_OP_breg16:
+    case DW_OP_breg17:
+    case DW_OP_breg18:
+    case DW_OP_breg19:
+    case DW_OP_breg20:
+    case DW_OP_breg21:
+    case DW_OP_breg22:
+    case DW_OP_breg23:
+    case DW_OP_breg24:
+    case DW_OP_breg25:
+    case DW_OP_breg26:
+    case DW_OP_breg27:
+    case DW_OP_breg28:
+    case DW_OP_breg29:
+    case DW_OP_breg30:
+    case DW_OP_breg31:
+      size += size_of_sleb128 (loc->dw_loc_oprnd1.v.val_int);
+      break;
+    case DW_OP_regx:
+      size += size_of_uleb128 (loc->dw_loc_oprnd1.v.val_unsigned);
+      break;
+    case DW_OP_fbreg:
+      size += size_of_sleb128 (loc->dw_loc_oprnd1.v.val_int);
+      break;
+    case DW_OP_bregx:
+      size += size_of_uleb128 (loc->dw_loc_oprnd1.v.val_unsigned);
+      size += size_of_sleb128 (loc->dw_loc_oprnd2.v.val_int);
+      break;
+    case DW_OP_piece:
+      size += size_of_uleb128 (loc->dw_loc_oprnd1.v.val_unsigned);
+      break;
+    case DW_OP_deref_size:
+    case DW_OP_xderef_size:
+      size += 1;
+      break;
+    case DW_OP_call2:
+      size += 2;
+      break;
+    case DW_OP_call4:
+      size += 4;
+      break;
+    case DW_OP_call_ref:
+      size += DWARF2_ADDR_SIZE;
+      break;
+    default:
+      break;
+    }
+
+  return size;
+}
+
+/* Return the size of a series of location descriptors.  */
+
+static unsigned long
+size_of_locs (dw_loc_descr_ref loc)
+{
+  unsigned long size;
+
+  for (size = 0; loc != NULL; loc = loc->dw_loc_next)
+    {
+      loc->dw_loc_addr = size;
+      size += size_of_loc_descr (loc);
+    }
+
+  return size;
+}
+
+/* Output location description stack opcode's operands (if any).  */
+
+static void
+output_loc_operands (dw_loc_descr_ref loc)
+{
+  dw_val_ref val1 = &loc->dw_loc_oprnd1;
+  dw_val_ref val2 = &loc->dw_loc_oprnd2;
+
+  switch (loc->dw_loc_opc)
+    {
+#ifdef DWARF2_DEBUGGING_INFO
+    case DW_OP_addr:
+      dw2_asm_output_addr_rtx (DWARF2_ADDR_SIZE, val1->v.val_addr, NULL);
+      break;
+    case DW_OP_const2u:
+    case DW_OP_const2s:
+      dw2_asm_output_data (2, val1->v.val_int, NULL);
+      break;
+    case DW_OP_const4u:
+    case DW_OP_const4s:
+      dw2_asm_output_data (4, val1->v.val_int, NULL);
+      break;
+    case DW_OP_const8u:
+    case DW_OP_const8s:
+      gcc_assert (HOST_BITS_PER_LONG >= 64);
+      dw2_asm_output_data (8, val1->v.val_int, NULL);
+      break;
+    case DW_OP_skip:
+    case DW_OP_bra:
+      {
+	int offset;
+
+	gcc_assert (val1->val_class == dw_val_class_loc);
+	offset = val1->v.val_loc->dw_loc_addr - (loc->dw_loc_addr + 3);
+
+	dw2_asm_output_data (2, offset, NULL);
+      }
+      break;
+#else
+    case DW_OP_addr:
+    case DW_OP_const2u:
+    case DW_OP_const2s:
+    case DW_OP_const4u:
+    case DW_OP_const4s:
+    case DW_OP_const8u:
+    case DW_OP_const8s:
+    case DW_OP_skip:
+    case DW_OP_bra:
+      /* We currently don't make any attempt to make sure these are
+	 aligned properly like we do for the main unwind info, so
+	 don't support emitting things larger than a byte if we're
+	 only doing unwinding.  */
+      gcc_unreachable ();
+#endif
+    case DW_OP_const1u:
+    case DW_OP_const1s:
+      dw2_asm_output_data (1, val1->v.val_int, NULL);
+      break;
+    case DW_OP_constu:
+      dw2_asm_output_data_uleb128 (val1->v.val_unsigned, NULL);
+      break;
+    case DW_OP_consts:
+      dw2_asm_output_data_sleb128 (val1->v.val_int, NULL);
+      break;
+    case DW_OP_pick:
+      dw2_asm_output_data (1, val1->v.val_int, NULL);
+      break;
+    case DW_OP_plus_uconst:
+      dw2_asm_output_data_uleb128 (val1->v.val_unsigned, NULL);
+      break;
+    case DW_OP_breg0:
+    case DW_OP_breg1:
+    case DW_OP_breg2:
+    case DW_OP_breg3:
+    case DW_OP_breg4:
+    case DW_OP_breg5:
+    case DW_OP_breg6:
+    case DW_OP_breg7:
+    case DW_OP_breg8:
+    case DW_OP_breg9:
+    case DW_OP_breg10:
+    case DW_OP_breg11:
+    case DW_OP_breg12:
+    case DW_OP_breg13:
+    case DW_OP_breg14:
+    case DW_OP_breg15:
+    case DW_OP_breg16:
+    case DW_OP_breg17:
+    case DW_OP_breg18:
+    case DW_OP_breg19:
+    case DW_OP_breg20:
+    case DW_OP_breg21:
+    case DW_OP_breg22:
+    case DW_OP_breg23:
+    case DW_OP_breg24:
+    case DW_OP_breg25:
+    case DW_OP_breg26:
+    case DW_OP_breg27:
+    case DW_OP_breg28:
+    case DW_OP_breg29:
+    case DW_OP_breg30:
+    case DW_OP_breg31:
+      dw2_asm_output_data_sleb128 (val1->v.val_int, NULL);
+      break;
+    case DW_OP_regx:
+      dw2_asm_output_data_uleb128 (val1->v.val_unsigned, NULL);
+      break;
+    case DW_OP_fbreg:
+      dw2_asm_output_data_sleb128 (val1->v.val_int, NULL);
+      break;
+    case DW_OP_bregx:
+      dw2_asm_output_data_uleb128 (val1->v.val_unsigned, NULL);
+      dw2_asm_output_data_sleb128 (val2->v.val_int, NULL);
+      break;
+    case DW_OP_piece:
+      dw2_asm_output_data_uleb128 (val1->v.val_unsigned, NULL);
+      break;
+    case DW_OP_deref_size:
+    case DW_OP_xderef_size:
+      dw2_asm_output_data (1, val1->v.val_int, NULL);
+      break;
+
+    case INTERNAL_DW_OP_tls_addr:
+      if (targetm.asm_out.output_dwarf_dtprel)
+	{
+	  targetm.asm_out.output_dwarf_dtprel (asm_out_file,
+					       DWARF2_ADDR_SIZE,
+					       val1->v.val_addr);
+	  fputc ('\n', asm_out_file);
+	}
+      else
+	gcc_unreachable ();
+      break;
+
+    default:
+      /* Other codes have no operands.  */
+      break;
+    }
+}
+
+/* Output a sequence of location operations.  */
+
+static void
+output_loc_sequence (dw_loc_descr_ref loc)
+{
+  for (; loc != NULL; loc = loc->dw_loc_next)
+    {
+      /* Output the opcode.  */
+      dw2_asm_output_data (1, loc->dw_loc_opc,
+			   "%s", dwarf_stack_op_name (loc->dw_loc_opc));
+
+      /* Output the operand(s) (if any).  */
+      output_loc_operands (loc);
+    }
+}
+
+/* This routine will generate the correct assembly data for a location
+   description based on a cfi entry with a complex address.  */
+
+static void
+output_cfa_loc (dw_cfi_ref cfi)
+{
+  dw_loc_descr_ref loc;
+  unsigned long size;
+
+  /* Output the size of the block.  */
+  loc = cfi->dw_cfi_oprnd1.dw_cfi_loc;
+  size = size_of_locs (loc);
+  dw2_asm_output_data_uleb128 (size, NULL);
+
+  /* Now output the operations themselves.  */
+  output_loc_sequence (loc);
+}
+
+/* This function builds a dwarf location descriptor sequence from
+   a dw_cfa_location.  */
+
+static struct dw_loc_descr_struct *
+build_cfa_loc (dw_cfa_location *cfa)
+{
+  struct dw_loc_descr_struct *head, *tmp;
+
+  if (cfa->indirect)
+    {
+      if (cfa->base_offset)
+	{
+	  if (cfa->reg <= 31)
+	    head = new_loc_descr (DW_OP_breg0 + cfa->reg, cfa->base_offset, 0);
+	  else
+	    head = new_loc_descr (DW_OP_bregx, cfa->reg, cfa->base_offset);
+	}
+      else if (cfa->reg <= 31)
+	head = new_loc_descr (DW_OP_reg0 + cfa->reg, 0, 0);
+      else
+	head = new_loc_descr (DW_OP_regx, cfa->reg, 0);
+
+      head->dw_loc_oprnd1.val_class = dw_val_class_const;
+      tmp = new_loc_descr (DW_OP_deref, 0, 0);
+      add_loc_descr (&head, tmp);
+      if (cfa->offset != 0)
+	{
+	  tmp = new_loc_descr (DW_OP_plus_uconst, cfa->offset, 0);
+	  add_loc_descr (&head, tmp);
+	}
+    }
+  else
+    {
+      if (cfa->offset == 0)
+	if (cfa->reg <= 31)
+	  head = new_loc_descr (DW_OP_reg0 + cfa->reg, 0, 0);
+	else
+	  head = new_loc_descr (DW_OP_regx, cfa->reg, 0);
+      else if (cfa->reg <= 31)
+	head = new_loc_descr (DW_OP_breg0 + cfa->reg, cfa->offset, 0);
+      else
+	head = new_loc_descr (DW_OP_bregx, cfa->reg, cfa->offset);
+    }
+
+  return head;
+}
+
+/* This function fills in aa dw_cfa_location structure from a dwarf location
+   descriptor sequence.  */
+
+static void
+get_cfa_from_loc_descr (dw_cfa_location *cfa, struct dw_loc_descr_struct *loc)
+{
+  struct dw_loc_descr_struct *ptr;
+  cfa->offset = 0;
+  cfa->base_offset = 0;
+  cfa->indirect = 0;
+  cfa->reg = -1;
+
+  for (ptr = loc; ptr != NULL; ptr = ptr->dw_loc_next)
+    {
+      enum dwarf_location_atom op = ptr->dw_loc_opc;
+
+      switch (op)
+	{
+	case DW_OP_reg0:
+	case DW_OP_reg1:
+	case DW_OP_reg2:
+	case DW_OP_reg3:
+	case DW_OP_reg4:
+	case DW_OP_reg5:
+	case DW_OP_reg6:
+	case DW_OP_reg7:
+	case DW_OP_reg8:
+	case DW_OP_reg9:
+	case DW_OP_reg10:
+	case DW_OP_reg11:
+	case DW_OP_reg12:
+	case DW_OP_reg13:
+	case DW_OP_reg14:
+	case DW_OP_reg15:
+	case DW_OP_reg16:
+	case DW_OP_reg17:
+	case DW_OP_reg18:
+	case DW_OP_reg19:
+	case DW_OP_reg20:
+	case DW_OP_reg21:
+	case DW_OP_reg22:
+	case DW_OP_reg23:
+	case DW_OP_reg24:
+	case DW_OP_reg25:
+	case DW_OP_reg26:
+	case DW_OP_reg27:
+	case DW_OP_reg28:
+	case DW_OP_reg29:
+	case DW_OP_reg30:
+	case DW_OP_reg31:
+	  cfa->reg = op - DW_OP_reg0;
+	  break;
+	case DW_OP_regx:
+	  cfa->reg = ptr->dw_loc_oprnd1.v.val_int;
+	  break;
+	case DW_OP_breg0:
+	case DW_OP_breg1:
+	case DW_OP_breg2:
+	case DW_OP_breg3:
+	case DW_OP_breg4:
+	case DW_OP_breg5:
+	case DW_OP_breg6:
+	case DW_OP_breg7:
+	case DW_OP_breg8:
+	case DW_OP_breg9:
+	case DW_OP_breg10:
+	case DW_OP_breg11:
+	case DW_OP_breg12:
+	case DW_OP_breg13:
+	case DW_OP_breg14:
+	case DW_OP_breg15:
+	case DW_OP_breg16:
+	case DW_OP_breg17:
+	case DW_OP_breg18:
+	case DW_OP_breg19:
+	case DW_OP_breg20:
+	case DW_OP_breg21:
+	case DW_OP_breg22:
+	case DW_OP_breg23:
+	case DW_OP_breg24:
+	case DW_OP_breg25:
+	case DW_OP_breg26:
+	case DW_OP_breg27:
+	case DW_OP_breg28:
+	case DW_OP_breg29:
+	case DW_OP_breg30:
+	case DW_OP_breg31:
+	  cfa->reg = op - DW_OP_breg0;
+	  cfa->base_offset = ptr->dw_loc_oprnd1.v.val_int;
+	  break;
+	case DW_OP_bregx:
+	  cfa->reg = ptr->dw_loc_oprnd1.v.val_int;
+	  cfa->base_offset = ptr->dw_loc_oprnd2.v.val_int;
+	  break;
+	case DW_OP_deref:
+	  cfa->indirect = 1;
+	  break;
+	case DW_OP_plus_uconst:
+	  cfa->offset = ptr->dw_loc_oprnd1.v.val_unsigned;
+	  break;
+	default:
+	  internal_error ("DW_LOC_OP %s not implemented",
+			  dwarf_stack_op_name (ptr->dw_loc_opc));
+	}
+    }
+}
+#endif /* .debug_frame support */
+
+/* And now, the support for symbolic debugging information.  */
+#ifdef DWARF2_DEBUGGING_INFO
+
+/* .debug_str support.  */
+static int output_indirect_string (void **, void *);
+
+static void dwarf2out_init (const char *);
+static void dwarf2out_finish (const char *);
+static void dwarf2out_define (unsigned int, const char *);
+static void dwarf2out_undef (unsigned int, const char *);
+static void dwarf2out_start_source_file (unsigned, const char *);
+static void dwarf2out_end_source_file (unsigned);
+static void dwarf2out_begin_block (unsigned, unsigned);
+static void dwarf2out_end_block (unsigned, unsigned);
+static bool dwarf2out_ignore_block (tree);
+static void dwarf2out_global_decl (tree);
+static void dwarf2out_type_decl (tree, int);
+static void dwarf2out_imported_module_or_decl (tree, tree);
+static void dwarf2out_abstract_function (tree);
+static void dwarf2out_var_location (rtx);
+static void dwarf2out_begin_function (tree);
+static void dwarf2out_switch_text_section (void);
+
+/* The debug hooks structure.  */
+
+const struct gcc_debug_hooks dwarf2_debug_hooks =
+{
+  dwarf2out_init,
+  dwarf2out_finish,
+  dwarf2out_define,
+  dwarf2out_undef,
+  dwarf2out_start_source_file,
+  dwarf2out_end_source_file,
+  dwarf2out_begin_block,
+  dwarf2out_end_block,
+  dwarf2out_ignore_block,
+  dwarf2out_source_line,
+  dwarf2out_begin_prologue,
+  debug_nothing_int_charstar,	/* end_prologue */
+  dwarf2out_end_epilogue,
+  dwarf2out_begin_function,
+  debug_nothing_int,		/* end_function */
+  dwarf2out_decl,		/* function_decl */
+  dwarf2out_global_decl,
+  dwarf2out_type_decl,		/* type_decl */
+  dwarf2out_imported_module_or_decl,
+  debug_nothing_tree,		/* deferred_inline_function */
+  /* The DWARF 2 backend tries to reduce debugging bloat by not
+     emitting the abstract description of inline functions until
+     something tries to reference them.  */
+  dwarf2out_abstract_function,	/* outlining_inline_function */
+  debug_nothing_rtx,		/* label */
+  debug_nothing_int,		/* handle_pch */
+  dwarf2out_var_location,
+  dwarf2out_switch_text_section,
+  1                             /* start_end_main_source_file */
+};
+#endif
+
+/* NOTE: In the comments in this file, many references are made to
+   "Debugging Information Entries".  This term is abbreviated as `DIE'
+   throughout the remainder of this file.  */
+
+/* An internal representation of the DWARF output is built, and then
+   walked to generate the DWARF debugging info.  The walk of the internal
+   representation is done after the entire program has been compiled.
+   The types below are used to describe the internal representation.  */
+
+/* Various DIE's use offsets relative to the beginning of the
+   .debug_info section to refer to each other.  */
+
+typedef long int dw_offset;
+
+/* Define typedefs here to avoid circular dependencies.  */
+
+typedef struct dw_attr_struct *dw_attr_ref;
+typedef struct dw_line_info_struct *dw_line_info_ref;
+typedef struct dw_separate_line_info_struct *dw_separate_line_info_ref;
+typedef struct pubname_struct *pubname_ref;
+typedef struct dw_ranges_struct *dw_ranges_ref;
+
+/* Each entry in the line_info_table maintains the file and
+   line number associated with the label generated for that
+   entry.  The label gives the PC value associated with
+   the line number entry.  */
+
+typedef struct dw_line_info_struct GTY(())
+{
+  unsigned long dw_file_num;
+  unsigned long dw_line_num;
+}
+dw_line_info_entry;
+
+/* Line information for functions in separate sections; each one gets its
+   own sequence.  */
+typedef struct dw_separate_line_info_struct GTY(())
+{
+  unsigned long dw_file_num;
+  unsigned long dw_line_num;
+  unsigned long function;
+}
+dw_separate_line_info_entry;
+
+/* Each DIE attribute has a field specifying the attribute kind,
+   a link to the next attribute in the chain, and an attribute value.
+   Attributes are typically linked below the DIE they modify.  */
+
+typedef struct dw_attr_struct GTY(())
+{
+  enum dwarf_attribute dw_attr;
+  dw_attr_ref dw_attr_next;
+  dw_val_node dw_attr_val;
+}
+dw_attr_node;
+
+/* The Debugging Information Entry (DIE) structure */
+
+typedef struct die_struct GTY(())
+{
+  enum dwarf_tag die_tag;
+  char *die_symbol;
+  dw_attr_ref die_attr;
+  dw_die_ref die_parent;
+  dw_die_ref die_child;
+  dw_die_ref die_sib;
+  dw_die_ref die_definition; /* ref from a specification to its definition */
+  dw_offset die_offset;
+  unsigned long die_abbrev;
+  int die_mark;
+  unsigned int decl_id;
+}
+die_node;
+
+/* The pubname structure */
+
+typedef struct pubname_struct GTY(())
+{
+  dw_die_ref die;
+  char *name;
+}
+pubname_entry;
+
+struct dw_ranges_struct GTY(())
+{
+  int block_num;
+};
+
+/* The limbo die list structure.  */
+typedef struct limbo_die_struct GTY(())
+{
+  dw_die_ref die;
+  tree created_for;
+  struct limbo_die_struct *next;
+}
+limbo_die_node;
+
+/* How to start an assembler comment.  */
+#ifndef ASM_COMMENT_START
+#define ASM_COMMENT_START ";#"
+#endif
+
+/* Define a macro which returns nonzero for a TYPE_DECL which was
+   implicitly generated for a tagged type.
+
+   Note that unlike the gcc front end (which generates a NULL named
+   TYPE_DECL node for each complete tagged type, each array type, and
+   each function type node created) the g++ front end generates a
+   _named_ TYPE_DECL node for each tagged type node created.
+   These TYPE_DECLs have DECL_ARTIFICIAL set, so we know not to
+   generate a DW_TAG_typedef DIE for them.  */
+
+#define TYPE_DECL_IS_STUB(decl)				\
+  (DECL_NAME (decl) == NULL_TREE			\
+   || (DECL_ARTIFICIAL (decl)				\
+       && is_tagged_type (TREE_TYPE (decl))		\
+       && ((decl == TYPE_STUB_DECL (TREE_TYPE (decl)))	\
+	   /* This is necessary for stub decls that	\
+	      appear in nested inline functions.  */	\
+	   || (DECL_ABSTRACT_ORIGIN (decl) != NULL_TREE	\
+	       && (decl_ultimate_origin (decl)		\
+		   == TYPE_STUB_DECL (TREE_TYPE (decl)))))))
+
+/* Information concerning the compilation unit's programming
+   language, and compiler version.  */
+
+/* Fixed size portion of the DWARF compilation unit header.  */
+#define DWARF_COMPILE_UNIT_HEADER_SIZE \
+  (DWARF_INITIAL_LENGTH_SIZE + DWARF_OFFSET_SIZE + 3)
+
+/* Fixed size portion of public names info.  */
+#define DWARF_PUBNAMES_HEADER_SIZE (2 * DWARF_OFFSET_SIZE + 2)
+
+/* Fixed size portion of the address range info.  */
+#define DWARF_ARANGES_HEADER_SIZE					\
+  (DWARF_ROUND (DWARF_INITIAL_LENGTH_SIZE + DWARF_OFFSET_SIZE + 4,	\
+                DWARF2_ADDR_SIZE * 2)					\
+   - DWARF_INITIAL_LENGTH_SIZE)
+
+/* Size of padding portion in the address range info.  It must be
+   aligned to twice the pointer size.  */
+#define DWARF_ARANGES_PAD_SIZE \
+  (DWARF_ROUND (DWARF_INITIAL_LENGTH_SIZE + DWARF_OFFSET_SIZE + 4, \
+                DWARF2_ADDR_SIZE * 2) \
+   - (DWARF_INITIAL_LENGTH_SIZE + DWARF_OFFSET_SIZE + 4))
+
+/* Use assembler line directives if available.  */
+#ifndef DWARF2_ASM_LINE_DEBUG_INFO
+#ifdef HAVE_AS_DWARF2_DEBUG_LINE
+#define DWARF2_ASM_LINE_DEBUG_INFO 1
+#else
+#define DWARF2_ASM_LINE_DEBUG_INFO 0
+#endif
+#endif
+
+/* Minimum line offset in a special line info. opcode.
+   This value was chosen to give a reasonable range of values.  */
+#define DWARF_LINE_BASE  -10
+
+/* First special line opcode - leave room for the standard opcodes.  */
+#define DWARF_LINE_OPCODE_BASE  10
+
+/* Range of line offsets in a special line info. opcode.  */
+#define DWARF_LINE_RANGE  (254-DWARF_LINE_OPCODE_BASE+1)
+
+/* Flag that indicates the initial value of the is_stmt_start flag.
+   In the present implementation, we do not mark any lines as
+   the beginning of a source statement, because that information
+   is not made available by the GCC front-end.  */
+#define	DWARF_LINE_DEFAULT_IS_STMT_START 1
+
+#ifdef DWARF2_DEBUGGING_INFO
+/* This location is used by calc_die_sizes() to keep track
+   the offset of each DIE within the .debug_info section.  */
+static unsigned long next_die_offset;
+#endif
+
+/* Record the root of the DIE's built for the current compilation unit.  */
+static GTY(()) dw_die_ref comp_unit_die;
+
+/* A list of DIEs with a NULL parent waiting to be relocated.  */
+static GTY(()) limbo_die_node *limbo_die_list;
+
+/* Filenames referenced by this compilation unit.  */
+static GTY(()) varray_type file_table;
+static GTY(()) varray_type file_table_emitted;
+static GTY(()) size_t file_table_last_lookup_index;
+
+/* A hash table of references to DIE's that describe declarations.
+   The key is a DECL_UID() which is a unique number identifying each decl.  */
+static GTY ((param_is (struct die_struct))) htab_t decl_die_table;
+
+/* Node of the variable location list.  */
+struct var_loc_node GTY ((chain_next ("%h.next")))
+{
+  rtx GTY (()) var_loc_note;
+  const char * GTY (()) label;
+  const char * GTY (()) section_label;
+  struct var_loc_node * GTY (()) next;
+};
+
+/* Variable location list.  */
+struct var_loc_list_def GTY (())
+{
+  struct var_loc_node * GTY (()) first;
+
+  /* Do not mark the last element of the chained list because
+     it is marked through the chain.  */
+  struct var_loc_node * GTY ((skip ("%h"))) last;
+
+  /* DECL_UID of the variable decl.  */
+  unsigned int decl_id;
+};
+typedef struct var_loc_list_def var_loc_list;
+
+
+/* Table of decl location linked lists.  */
+static GTY ((param_is (var_loc_list))) htab_t decl_loc_table;
+
+/* A pointer to the base of a list of references to DIE's that
+   are uniquely identified by their tag, presence/absence of
+   children DIE's, and list of attribute/value pairs.  */
+static GTY((length ("abbrev_die_table_allocated")))
+  dw_die_ref *abbrev_die_table;
+
+/* Number of elements currently allocated for abbrev_die_table.  */
+static GTY(()) unsigned abbrev_die_table_allocated;
+
+/* Number of elements in type_die_table currently in use.  */
+static GTY(()) unsigned abbrev_die_table_in_use;
+
+/* Size (in elements) of increments by which we may expand the
+   abbrev_die_table.  */
+#define ABBREV_DIE_TABLE_INCREMENT 256
+
+/* A pointer to the base of a table that contains line information
+   for each source code line in .text in the compilation unit.  */
+static GTY((length ("line_info_table_allocated")))
+     dw_line_info_ref line_info_table;
+
+/* Number of elements currently allocated for line_info_table.  */
+static GTY(()) unsigned line_info_table_allocated;
+
+/* Number of elements in line_info_table currently in use.  */
+static GTY(()) unsigned line_info_table_in_use;
+
+/* True if the compilation unit contains more than one .text section.  */
+static GTY(()) bool have_switched_text_section = false;
+
+/* A pointer to the base of a table that contains line information
+   for each source code line outside of .text in the compilation unit.  */
+static GTY ((length ("separate_line_info_table_allocated")))
+     dw_separate_line_info_ref separate_line_info_table;
+
+/* Number of elements currently allocated for separate_line_info_table.  */
+static GTY(()) unsigned separate_line_info_table_allocated;
+
+/* Number of elements in separate_line_info_table currently in use.  */
+static GTY(()) unsigned separate_line_info_table_in_use;
+
+/* Size (in elements) of increments by which we may expand the
+   line_info_table.  */
+#define LINE_INFO_TABLE_INCREMENT 1024
+
+/* A pointer to the base of a table that contains a list of publicly
+   accessible names.  */
+static GTY ((length ("pubname_table_allocated"))) pubname_ref pubname_table;
+
+/* Number of elements currently allocated for pubname_table.  */
+static GTY(()) unsigned pubname_table_allocated;
+
+/* Number of elements in pubname_table currently in use.  */
+static GTY(()) unsigned pubname_table_in_use;
+
+/* Size (in elements) of increments by which we may expand the
+   pubname_table.  */
+#define PUBNAME_TABLE_INCREMENT 64
+
+/* Array of dies for which we should generate .debug_arange info.  */
+static GTY((length ("arange_table_allocated"))) dw_die_ref *arange_table;
+
+/* Number of elements currently allocated for arange_table.  */
+static GTY(()) unsigned arange_table_allocated;
+
+/* Number of elements in arange_table currently in use.  */
+static GTY(()) unsigned arange_table_in_use;
+
+/* Size (in elements) of increments by which we may expand the
+   arange_table.  */
+#define ARANGE_TABLE_INCREMENT 64
+
+/* Array of dies for which we should generate .debug_ranges info.  */
+static GTY ((length ("ranges_table_allocated"))) dw_ranges_ref ranges_table;
+
+/* Number of elements currently allocated for ranges_table.  */
+static GTY(()) unsigned ranges_table_allocated;
+
+/* Number of elements in ranges_table currently in use.  */
+static GTY(()) unsigned ranges_table_in_use;
+
+/* Size (in elements) of increments by which we may expand the
+   ranges_table.  */
+#define RANGES_TABLE_INCREMENT 64
+
+/* Whether we have location lists that need outputting */
+static GTY(()) unsigned have_location_lists;
+
+/* Unique label counter.  */
+static GTY(()) unsigned int loclabel_num;
+
+#ifdef DWARF2_DEBUGGING_INFO
+/* Record whether the function being analyzed contains inlined functions.  */
+static int current_function_has_inlines;
+#endif
+#if 0 && defined (MIPS_DEBUGGING_INFO)
+static int comp_unit_has_inlines;
+#endif
+
+/* Number of file tables emitted in maybe_emit_file().  */
+static GTY(()) int emitcount = 0;
+
+/* Number of internal labels generated by gen_internal_sym().  */
+static GTY(()) int label_num;
+
+#ifdef DWARF2_DEBUGGING_INFO
+
+/* Offset from the "steady-state frame pointer" to the CFA,
+   within the current function.  */
+static HOST_WIDE_INT frame_pointer_cfa_offset;
+
+/* Forward declarations for functions defined in this file.  */
+
+static int is_pseudo_reg (rtx);
+static tree type_main_variant (tree);
+static int is_tagged_type (tree);
+static const char *dwarf_tag_name (unsigned);
+static const char *dwarf_attr_name (unsigned);
+static const char *dwarf_form_name (unsigned);
+static tree decl_ultimate_origin (tree);
+static tree block_ultimate_origin (tree);
+static tree decl_class_context (tree);
+static void add_dwarf_attr (dw_die_ref, dw_attr_ref);
+static inline enum dw_val_class AT_class (dw_attr_ref);
+static void add_AT_flag (dw_die_ref, enum dwarf_attribute, unsigned);
+static inline unsigned AT_flag (dw_attr_ref);
+static void add_AT_int (dw_die_ref, enum dwarf_attribute, HOST_WIDE_INT);
+static inline HOST_WIDE_INT AT_int (dw_attr_ref);
+static void add_AT_unsigned (dw_die_ref, enum dwarf_attribute, unsigned HOST_WIDE_INT);
+static inline unsigned HOST_WIDE_INT AT_unsigned (dw_attr_ref);
+static void add_AT_long_long (dw_die_ref, enum dwarf_attribute, unsigned long,
+			      unsigned long);
+static inline void add_AT_vec (dw_die_ref, enum dwarf_attribute, unsigned int,
+			       unsigned int, unsigned char *);
+static hashval_t debug_str_do_hash (const void *);
+static int debug_str_eq (const void *, const void *);
+static void add_AT_string (dw_die_ref, enum dwarf_attribute, const char *);
+static inline const char *AT_string (dw_attr_ref);
+static int AT_string_form (dw_attr_ref);
+static void add_AT_die_ref (dw_die_ref, enum dwarf_attribute, dw_die_ref);
+static void add_AT_specification (dw_die_ref, dw_die_ref);
+static inline dw_die_ref AT_ref (dw_attr_ref);
+static inline int AT_ref_external (dw_attr_ref);
+static inline void set_AT_ref_external (dw_attr_ref, int);
+static void add_AT_fde_ref (dw_die_ref, enum dwarf_attribute, unsigned);
+static void add_AT_loc (dw_die_ref, enum dwarf_attribute, dw_loc_descr_ref);
+static inline dw_loc_descr_ref AT_loc (dw_attr_ref);
+static void add_AT_loc_list (dw_die_ref, enum dwarf_attribute,
+			     dw_loc_list_ref);
+static inline dw_loc_list_ref AT_loc_list (dw_attr_ref);
+static void add_AT_addr (dw_die_ref, enum dwarf_attribute, rtx);
+static inline rtx AT_addr (dw_attr_ref);
+static void add_AT_lbl_id (dw_die_ref, enum dwarf_attribute, const char *);
+static void add_AT_lbl_offset (dw_die_ref, enum dwarf_attribute, const char *);
+static void add_AT_offset (dw_die_ref, enum dwarf_attribute,
+			   unsigned HOST_WIDE_INT);
+static void add_AT_range_list (dw_die_ref, enum dwarf_attribute,
+			       unsigned long);
+static inline const char *AT_lbl (dw_attr_ref);
+static dw_attr_ref get_AT (dw_die_ref, enum dwarf_attribute);
+static const char *get_AT_low_pc (dw_die_ref);
+static const char *get_AT_hi_pc (dw_die_ref);
+static const char *get_AT_string (dw_die_ref, enum dwarf_attribute);
+static int get_AT_flag (dw_die_ref, enum dwarf_attribute);
+static unsigned get_AT_unsigned (dw_die_ref, enum dwarf_attribute);
+static inline dw_die_ref get_AT_ref (dw_die_ref, enum dwarf_attribute);
+static bool is_c_family (void);
+static bool is_cxx (void);
+static bool is_java (void);
+static bool is_fortran (void);
+static bool is_ada (void);
+static void remove_AT (dw_die_ref, enum dwarf_attribute);
+static void remove_child_TAG (dw_die_ref, enum dwarf_tag);
+static inline void free_die (dw_die_ref);
+static void remove_children (dw_die_ref);
+static void add_child_die (dw_die_ref, dw_die_ref);
+static dw_die_ref new_die (enum dwarf_tag, dw_die_ref, tree);
+static dw_die_ref lookup_type_die (tree);
+static void equate_type_number_to_die (tree, dw_die_ref);
+static hashval_t decl_die_table_hash (const void *);
+static int decl_die_table_eq (const void *, const void *);
+static dw_die_ref lookup_decl_die (tree);
+static hashval_t decl_loc_table_hash (const void *);
+static int decl_loc_table_eq (const void *, const void *);
+static var_loc_list *lookup_decl_loc (tree);
+static void equate_decl_number_to_die (tree, dw_die_ref);
+static void add_var_loc_to_decl (tree, struct var_loc_node *);
+static void print_spaces (FILE *);
+static void print_die (dw_die_ref, FILE *);
+static void print_dwarf_line_table (FILE *);
+static void reverse_die_lists (dw_die_ref);
+static void reverse_all_dies (dw_die_ref);
+static dw_die_ref push_new_compile_unit (dw_die_ref, dw_die_ref);
+static dw_die_ref pop_compile_unit (dw_die_ref);
+static void loc_checksum (dw_loc_descr_ref, struct md5_ctx *);
+static void attr_checksum (dw_attr_ref, struct md5_ctx *, int *);
+static void die_checksum (dw_die_ref, struct md5_ctx *, int *);
+static int same_loc_p (dw_loc_descr_ref, dw_loc_descr_ref, int *);
+static int same_dw_val_p (dw_val_node *, dw_val_node *, int *);
+static int same_attr_p (dw_attr_ref, dw_attr_ref, int *);
+static int same_die_p (dw_die_ref, dw_die_ref, int *);
+static int same_die_p_wrap (dw_die_ref, dw_die_ref);
+static void compute_section_prefix (dw_die_ref);
+static int is_type_die (dw_die_ref);
+static int is_comdat_die (dw_die_ref);
+static int is_symbol_die (dw_die_ref);
+static void assign_symbol_names (dw_die_ref);
+static void break_out_includes (dw_die_ref);
+static hashval_t htab_cu_hash (const void *);
+static int htab_cu_eq (const void *, const void *);
+static void htab_cu_del (void *);
+static int check_duplicate_cu (dw_die_ref, htab_t, unsigned *);
+static void record_comdat_symbol_number (dw_die_ref, htab_t, unsigned);
+static void add_sibling_attributes (dw_die_ref);
+static void build_abbrev_table (dw_die_ref);
+static void output_location_lists (dw_die_ref);
+static int constant_size (long unsigned);
+static unsigned long size_of_die (dw_die_ref);
+static void calc_die_sizes (dw_die_ref);
+static void mark_dies (dw_die_ref);
+static void unmark_dies (dw_die_ref);
+static void unmark_all_dies (dw_die_ref);
+static unsigned long size_of_pubnames (void);
+static unsigned long size_of_aranges (void);
+static enum dwarf_form value_format (dw_attr_ref);
+static void output_value_format (dw_attr_ref);
+static void output_abbrev_section (void);
+static void output_die_symbol (dw_die_ref);
+static void output_die (dw_die_ref);
+static void output_compilation_unit_header (void);
+static void output_comp_unit (dw_die_ref, int);
+static const char *dwarf2_name (tree, int);
+static void add_pubname (tree, dw_die_ref);
+static void output_pubnames (void);
+static void add_arange (tree, dw_die_ref);
+static void output_aranges (void);
+static unsigned int add_ranges (tree);
+static void output_ranges (void);
+static void output_line_info (void);
+static void output_file_names (void);
+static dw_die_ref base_type_die (tree);
+static tree root_type (tree);
+static int is_base_type (tree);
+static bool is_subrange_type (tree);
+static dw_die_ref subrange_type_die (tree, dw_die_ref);
+static dw_die_ref modified_type_die (tree, int, int, dw_die_ref);
+static int type_is_enum (tree);
+static unsigned int dbx_reg_number (rtx);
+static void add_loc_descr_op_piece (dw_loc_descr_ref *, int);
+static dw_loc_descr_ref reg_loc_descriptor (rtx);
+static dw_loc_descr_ref one_reg_loc_descriptor (unsigned int);
+static dw_loc_descr_ref multiple_reg_loc_descriptor (rtx, rtx);
+static dw_loc_descr_ref int_loc_descriptor (HOST_WIDE_INT);
+static dw_loc_descr_ref based_loc_descr (rtx, HOST_WIDE_INT);
+static int is_based_loc (rtx);
+static dw_loc_descr_ref mem_loc_descriptor (rtx, enum machine_mode mode);
+static dw_loc_descr_ref concat_loc_descriptor (rtx, rtx);
+static dw_loc_descr_ref loc_descriptor (rtx);
+static dw_loc_descr_ref loc_descriptor_from_tree_1 (tree, int);
+static dw_loc_descr_ref loc_descriptor_from_tree (tree);
+static HOST_WIDE_INT ceiling (HOST_WIDE_INT, unsigned int);
+static tree field_type (tree);
+static unsigned int simple_type_align_in_bits (tree);
+static unsigned int simple_decl_align_in_bits (tree);
+static unsigned HOST_WIDE_INT simple_type_size_in_bits (tree);
+static HOST_WIDE_INT field_byte_offset (tree);
+static void add_AT_location_description	(dw_die_ref, enum dwarf_attribute,
+					 dw_loc_descr_ref);
+static void add_data_member_location_attribute (dw_die_ref, tree);
+static void add_const_value_attribute (dw_die_ref, rtx);
+static void insert_int (HOST_WIDE_INT, unsigned, unsigned char *);
+static HOST_WIDE_INT extract_int (const unsigned char *, unsigned);
+static void insert_float (rtx, unsigned char *);
+static rtx rtl_for_decl_location (tree);
+static void add_location_or_const_value_attribute (dw_die_ref, tree,
+						   enum dwarf_attribute);
+static void tree_add_const_value_attribute (dw_die_ref, tree);
+static void add_name_attribute (dw_die_ref, const char *);
+static void add_comp_dir_attribute (dw_die_ref);
+static void add_bound_info (dw_die_ref, enum dwarf_attribute, tree);
+static void add_subscript_info (dw_die_ref, tree);
+static void add_byte_size_attribute (dw_die_ref, tree);
+static void add_bit_offset_attribute (dw_die_ref, tree);
+static void add_bit_size_attribute (dw_die_ref, tree);
+static void add_prototyped_attribute (dw_die_ref, tree);
+static void add_abstract_origin_attribute (dw_die_ref, tree);
+static void add_pure_or_virtual_attribute (dw_die_ref, tree);
+static void add_src_coords_attributes (dw_die_ref, tree);
+static void add_name_and_src_coords_attributes (dw_die_ref, tree);
+static void push_decl_scope (tree);
+static void pop_decl_scope (void);
+static dw_die_ref scope_die_for (tree, dw_die_ref);
+static inline int local_scope_p (dw_die_ref);
+static inline int class_or_namespace_scope_p (dw_die_ref);
+static void add_type_attribute (dw_die_ref, tree, int, int, dw_die_ref);
+static void add_calling_convention_attribute (dw_die_ref, tree);
+static const char *type_tag (tree);
+static tree member_declared_type (tree);
+#if 0
+static const char *decl_start_label (tree);
+#endif
+static void gen_array_type_die (tree, dw_die_ref);
+#if 0
+static void gen_entry_point_die (tree, dw_die_ref);
+#endif
+static void gen_inlined_enumeration_type_die (tree, dw_die_ref);
+static void gen_inlined_structure_type_die (tree, dw_die_ref);
+static void gen_inlined_union_type_die (tree, dw_die_ref);
+static dw_die_ref gen_enumeration_type_die (tree, dw_die_ref);
+static dw_die_ref gen_formal_parameter_die (tree, dw_die_ref);
+static void gen_unspecified_parameters_die (tree, dw_die_ref);
+static void gen_formal_types_die (tree, dw_die_ref);
+static void gen_subprogram_die (tree, dw_die_ref);
+static void gen_variable_die (tree, dw_die_ref);
+static void gen_label_die (tree, dw_die_ref);
+static void gen_lexical_block_die (tree, dw_die_ref, int);
+static void gen_inlined_subroutine_die (tree, dw_die_ref, int);
+static void gen_field_die (tree, dw_die_ref);
+static void gen_ptr_to_mbr_type_die (tree, dw_die_ref);
+static dw_die_ref gen_compile_unit_die (const char *);
+static void gen_string_type_die (tree, dw_die_ref);
+static void gen_inheritance_die (tree, tree, dw_die_ref);
+static void gen_member_die (tree, dw_die_ref);
+static void gen_struct_or_union_type_die (tree, dw_die_ref);
+static void gen_subroutine_type_die (tree, dw_die_ref);
+static void gen_typedef_die (tree, dw_die_ref);
+static void gen_type_die (tree, dw_die_ref);
+static void gen_tagged_type_instantiation_die (tree, dw_die_ref);
+static void gen_block_die (tree, dw_die_ref, int);
+static void decls_for_scope (tree, dw_die_ref, int);
+static int is_redundant_typedef (tree);
+static void gen_namespace_die (tree);
+static void gen_decl_die (tree, dw_die_ref);
+static dw_die_ref force_decl_die (tree);
+static dw_die_ref force_type_die (tree);
+static dw_die_ref setup_namespace_context (tree, dw_die_ref);
+static void declare_in_namespace (tree, dw_die_ref);
+static unsigned lookup_filename (const char *);
+static void init_file_table (void);
+static void retry_incomplete_types (void);
+static void gen_type_die_for_member (tree, tree, dw_die_ref);
+static void splice_child_die (dw_die_ref, dw_die_ref);
+static int file_info_cmp (const void *, const void *);
+static dw_loc_list_ref new_loc_list (dw_loc_descr_ref, const char *,
+				     const char *, const char *, unsigned);
+static void add_loc_descr_to_loc_list (dw_loc_list_ref *, dw_loc_descr_ref,
+				       const char *, const char *,
+				       const char *);
+static void output_loc_list (dw_loc_list_ref);
+static char *gen_internal_sym (const char *);
+
+static void prune_unmark_dies (dw_die_ref);
+static void prune_unused_types_mark (dw_die_ref, int);
+static void prune_unused_types_walk (dw_die_ref);
+static void prune_unused_types_walk_attribs (dw_die_ref);
+static void prune_unused_types_prune (dw_die_ref);
+static void prune_unused_types (void);
+static int maybe_emit_file (int);
+
+/* Section names used to hold DWARF debugging information.  */
+#ifndef DEBUG_INFO_SECTION
+#define DEBUG_INFO_SECTION	".debug_info"
+#endif
+#ifndef DEBUG_ABBREV_SECTION
+#define DEBUG_ABBREV_SECTION	".debug_abbrev"
+#endif
+#ifndef DEBUG_ARANGES_SECTION
+#define DEBUG_ARANGES_SECTION	".debug_aranges"
+#endif
+#ifndef DEBUG_MACINFO_SECTION
+#define DEBUG_MACINFO_SECTION	".debug_macinfo"
+#endif
+#ifndef DEBUG_LINE_SECTION
+#define DEBUG_LINE_SECTION	".debug_line"
+#endif
+#ifndef DEBUG_LOC_SECTION
+#define DEBUG_LOC_SECTION	".debug_loc"
+#endif
+#ifndef DEBUG_PUBNAMES_SECTION
+#define DEBUG_PUBNAMES_SECTION	".debug_pubnames"
+#endif
+#ifndef DEBUG_STR_SECTION
+#define DEBUG_STR_SECTION	".debug_str"
+#endif
+#ifndef DEBUG_RANGES_SECTION
+#define DEBUG_RANGES_SECTION	".debug_ranges"
+#endif
+
+/* Standard ELF section names for compiled code and data.  */
+#ifndef TEXT_SECTION_NAME
+#define TEXT_SECTION_NAME	".text"
+#endif
+
+/* Section flags for .debug_str section.  */
+#define DEBUG_STR_SECTION_FLAGS \
+  (HAVE_GAS_SHF_MERGE && flag_merge_constants			\
+   ? SECTION_DEBUG | SECTION_MERGE | SECTION_STRINGS | 1	\
+   : SECTION_DEBUG)
+
+/* Labels we insert at beginning sections we can reference instead of
+   the section names themselves.  */
+
+#ifndef TEXT_SECTION_LABEL
+#define TEXT_SECTION_LABEL		"Ltext"
+#endif
+#ifndef COLD_TEXT_SECTION_LABEL
+#define COLD_TEXT_SECTION_LABEL         "Ltext_cold"
+#endif
+#ifndef DEBUG_LINE_SECTION_LABEL
+#define DEBUG_LINE_SECTION_LABEL	"Ldebug_line"
+#endif
+#ifndef DEBUG_INFO_SECTION_LABEL
+#define DEBUG_INFO_SECTION_LABEL	"Ldebug_info"
+#endif
+#ifndef DEBUG_ABBREV_SECTION_LABEL
+#define DEBUG_ABBREV_SECTION_LABEL	"Ldebug_abbrev"
+#endif
+#ifndef DEBUG_LOC_SECTION_LABEL
+#define DEBUG_LOC_SECTION_LABEL		"Ldebug_loc"
+#endif
+#ifndef DEBUG_RANGES_SECTION_LABEL
+#define DEBUG_RANGES_SECTION_LABEL	"Ldebug_ranges"
+#endif
+#ifndef DEBUG_MACINFO_SECTION_LABEL
+#define DEBUG_MACINFO_SECTION_LABEL     "Ldebug_macinfo"
+#endif
+
+/* Definitions of defaults for formats and names of various special
+   (artificial) labels which may be generated within this file (when the -g
+   options is used and DWARF2_DEBUGGING_INFO is in effect.
+   If necessary, these may be overridden from within the tm.h file, but
+   typically, overriding these defaults is unnecessary.  */
+
+static char text_end_label[MAX_ARTIFICIAL_LABEL_BYTES];
+static char text_section_label[MAX_ARTIFICIAL_LABEL_BYTES];
+static char cold_text_section_label[MAX_ARTIFICIAL_LABEL_BYTES];
+static char cold_end_label[MAX_ARTIFICIAL_LABEL_BYTES]; 
+static char abbrev_section_label[MAX_ARTIFICIAL_LABEL_BYTES];
+static char debug_info_section_label[MAX_ARTIFICIAL_LABEL_BYTES];
+static char debug_line_section_label[MAX_ARTIFICIAL_LABEL_BYTES];
+static char macinfo_section_label[MAX_ARTIFICIAL_LABEL_BYTES];
+static char loc_section_label[MAX_ARTIFICIAL_LABEL_BYTES];
+static char ranges_section_label[2 * MAX_ARTIFICIAL_LABEL_BYTES];
+
+#ifndef TEXT_END_LABEL
+#define TEXT_END_LABEL		"Letext"
+#endif
+#ifndef COLD_END_LABEL
+#define COLD_END_LABEL          "Letext_cold"
+#endif
+#ifndef BLOCK_BEGIN_LABEL
+#define BLOCK_BEGIN_LABEL	"LBB"
+#endif
+#ifndef BLOCK_END_LABEL
+#define BLOCK_END_LABEL		"LBE"
+#endif
+#ifndef LINE_CODE_LABEL
+#define LINE_CODE_LABEL		"LM"
+#endif
+#ifndef SEPARATE_LINE_CODE_LABEL
+#define SEPARATE_LINE_CODE_LABEL	"LSM"
+#endif
+
+/* We allow a language front-end to designate a function that is to be
+   called to "demangle" any name before it is put into a DIE.  */
+
+static const char *(*demangle_name_func) (const char *);
+
+void
+dwarf2out_set_demangle_name_func (const char *(*func) (const char *))
+{
+  demangle_name_func = func;
+}
+
+/* Test if rtl node points to a pseudo register.  */
+
+static inline int
+is_pseudo_reg (rtx rtl)
+{
+  return ((REG_P (rtl) && REGNO (rtl) >= FIRST_PSEUDO_REGISTER)
+	  || (GET_CODE (rtl) == SUBREG
+	      && REGNO (SUBREG_REG (rtl)) >= FIRST_PSEUDO_REGISTER));
+}
+
+/* Return a reference to a type, with its const and volatile qualifiers
+   removed.  */
+
+static inline tree
+type_main_variant (tree type)
+{
+  type = TYPE_MAIN_VARIANT (type);
+
+  /* ??? There really should be only one main variant among any group of
+     variants of a given type (and all of the MAIN_VARIANT values for all
+     members of the group should point to that one type) but sometimes the C
+     front-end messes this up for array types, so we work around that bug
+     here.  */
+  if (TREE_CODE (type) == ARRAY_TYPE)
+    while (type != TYPE_MAIN_VARIANT (type))
+      type = TYPE_MAIN_VARIANT (type);
+
+  return type;
+}
+
+/* Return nonzero if the given type node represents a tagged type.  */
+
+static inline int
+is_tagged_type (tree type)
+{
+  enum tree_code code = TREE_CODE (type);
+
+  return (code == RECORD_TYPE || code == UNION_TYPE
+	  || code == QUAL_UNION_TYPE || code == ENUMERAL_TYPE);
+}
+
+/* Convert a DIE tag into its string name.  */
+
+static const char *
+dwarf_tag_name (unsigned int tag)
+{
+  switch (tag)
+    {
+    case DW_TAG_padding:
+      return "DW_TAG_padding";
+    case DW_TAG_array_type:
+      return "DW_TAG_array_type";
+    case DW_TAG_class_type:
+      return "DW_TAG_class_type";
+    case DW_TAG_entry_point:
+      return "DW_TAG_entry_point";
+    case DW_TAG_enumeration_type:
+      return "DW_TAG_enumeration_type";
+    case DW_TAG_formal_parameter:
+      return "DW_TAG_formal_parameter";
+    case DW_TAG_imported_declaration:
+      return "DW_TAG_imported_declaration";
+    case DW_TAG_label:
+      return "DW_TAG_label";
+    case DW_TAG_lexical_block:
+      return "DW_TAG_lexical_block";
+    case DW_TAG_member:
+      return "DW_TAG_member";
+    case DW_TAG_pointer_type:
+      return "DW_TAG_pointer_type";
+    case DW_TAG_reference_type:
+      return "DW_TAG_reference_type";
+    case DW_TAG_compile_unit:
+      return "DW_TAG_compile_unit";
+    case DW_TAG_string_type:
+      return "DW_TAG_string_type";
+    case DW_TAG_structure_type:
+      return "DW_TAG_structure_type";
+    case DW_TAG_subroutine_type:
+      return "DW_TAG_subroutine_type";
+    case DW_TAG_typedef:
+      return "DW_TAG_typedef";
+    case DW_TAG_union_type:
+      return "DW_TAG_union_type";
+    case DW_TAG_unspecified_parameters:
+      return "DW_TAG_unspecified_parameters";
+    case DW_TAG_variant:
+      return "DW_TAG_variant";
+    case DW_TAG_common_block:
+      return "DW_TAG_common_block";
+    case DW_TAG_common_inclusion:
+      return "DW_TAG_common_inclusion";
+    case DW_TAG_inheritance:
+      return "DW_TAG_inheritance";
+    case DW_TAG_inlined_subroutine:
+      return "DW_TAG_inlined_subroutine";
+    case DW_TAG_module:
+      return "DW_TAG_module";
+    case DW_TAG_ptr_to_member_type:
+      return "DW_TAG_ptr_to_member_type";
+    case DW_TAG_set_type:
+      return "DW_TAG_set_type";
+    case DW_TAG_subrange_type:
+      return "DW_TAG_subrange_type";
+    case DW_TAG_with_stmt:
+      return "DW_TAG_with_stmt";
+    case DW_TAG_access_declaration:
+      return "DW_TAG_access_declaration";
+    case DW_TAG_base_type:
+      return "DW_TAG_base_type";
+    case DW_TAG_catch_block:
+      return "DW_TAG_catch_block";
+    case DW_TAG_const_type:
+      return "DW_TAG_const_type";
+    case DW_TAG_constant:
+      return "DW_TAG_constant";
+    case DW_TAG_enumerator:
+      return "DW_TAG_enumerator";
+    case DW_TAG_file_type:
+      return "DW_TAG_file_type";
+    case DW_TAG_friend:
+      return "DW_TAG_friend";
+    case DW_TAG_namelist:
+      return "DW_TAG_namelist";
+    case DW_TAG_namelist_item:
+      return "DW_TAG_namelist_item";
+    case DW_TAG_namespace:
+      return "DW_TAG_namespace";
+    case DW_TAG_packed_type:
+      return "DW_TAG_packed_type";
+    case DW_TAG_subprogram:
+      return "DW_TAG_subprogram";
+    case DW_TAG_template_type_param:
+      return "DW_TAG_template_type_param";
+    case DW_TAG_template_value_param:
+      return "DW_TAG_template_value_param";
+    case DW_TAG_thrown_type:
+      return "DW_TAG_thrown_type";
+    case DW_TAG_try_block:
+      return "DW_TAG_try_block";
+    case DW_TAG_variant_part:
+      return "DW_TAG_variant_part";
+    case DW_TAG_variable:
+      return "DW_TAG_variable";
+    case DW_TAG_volatile_type:
+      return "DW_TAG_volatile_type";
+    case DW_TAG_imported_module:
+      return "DW_TAG_imported_module";
+    case DW_TAG_MIPS_loop:
+      return "DW_TAG_MIPS_loop";
+    case DW_TAG_format_label:
+      return "DW_TAG_format_label";
+    case DW_TAG_function_template:
+      return "DW_TAG_function_template";
+    case DW_TAG_class_template:
+      return "DW_TAG_class_template";
+    case DW_TAG_GNU_BINCL:
+      return "DW_TAG_GNU_BINCL";
+    case DW_TAG_GNU_EINCL:
+      return "DW_TAG_GNU_EINCL";
+    default:
+      return "DW_TAG_<unknown>";
+    }
+}
+
+/* Convert a DWARF attribute code into its string name.  */
+
+static const char *
+dwarf_attr_name (unsigned int attr)
+{
+  switch (attr)
+    {
+    case DW_AT_sibling:
+      return "DW_AT_sibling";
+    case DW_AT_location:
+      return "DW_AT_location";
+    case DW_AT_name:
+      return "DW_AT_name";
+    case DW_AT_ordering:
+      return "DW_AT_ordering";
+    case DW_AT_subscr_data:
+      return "DW_AT_subscr_data";
+    case DW_AT_byte_size:
+      return "DW_AT_byte_size";
+    case DW_AT_bit_offset:
+      return "DW_AT_bit_offset";
+    case DW_AT_bit_size:
+      return "DW_AT_bit_size";
+    case DW_AT_element_list:
+      return "DW_AT_element_list";
+    case DW_AT_stmt_list:
+      return "DW_AT_stmt_list";
+    case DW_AT_low_pc:
+      return "DW_AT_low_pc";
+    case DW_AT_high_pc:
+      return "DW_AT_high_pc";
+    case DW_AT_language:
+      return "DW_AT_language";
+    case DW_AT_member:
+      return "DW_AT_member";
+    case DW_AT_discr:
+      return "DW_AT_discr";
+    case DW_AT_discr_value:
+      return "DW_AT_discr_value";
+    case DW_AT_visibility:
+      return "DW_AT_visibility";
+    case DW_AT_import:
+      return "DW_AT_import";
+    case DW_AT_string_length:
+      return "DW_AT_string_length";
+    case DW_AT_common_reference:
+      return "DW_AT_common_reference";
+    case DW_AT_comp_dir:
+      return "DW_AT_comp_dir";
+    case DW_AT_const_value:
+      return "DW_AT_const_value";
+    case DW_AT_containing_type:
+      return "DW_AT_containing_type";
+    case DW_AT_default_value:
+      return "DW_AT_default_value";
+    case DW_AT_inline:
+      return "DW_AT_inline";
+    case DW_AT_is_optional:
+      return "DW_AT_is_optional";
+    case DW_AT_lower_bound:
+      return "DW_AT_lower_bound";
+    case DW_AT_producer:
+      return "DW_AT_producer";
+    case DW_AT_prototyped:
+      return "DW_AT_prototyped";
+    case DW_AT_return_addr:
+      return "DW_AT_return_addr";
+    case DW_AT_start_scope:
+      return "DW_AT_start_scope";
+    case DW_AT_stride_size:
+      return "DW_AT_stride_size";
+    case DW_AT_upper_bound:
+      return "DW_AT_upper_bound";
+    case DW_AT_abstract_origin:
+      return "DW_AT_abstract_origin";
+    case DW_AT_accessibility:
+      return "DW_AT_accessibility";
+    case DW_AT_address_class:
+      return "DW_AT_address_class";
+    case DW_AT_artificial:
+      return "DW_AT_artificial";
+    case DW_AT_base_types:
+      return "DW_AT_base_types";
+    case DW_AT_calling_convention:
+      return "DW_AT_calling_convention";
+    case DW_AT_count:
+      return "DW_AT_count";
+    case DW_AT_data_member_location:
+      return "DW_AT_data_member_location";
+    case DW_AT_decl_column:
+      return "DW_AT_decl_column";
+    case DW_AT_decl_file:
+      return "DW_AT_decl_file";
+    case DW_AT_decl_line:
+      return "DW_AT_decl_line";
+    case DW_AT_declaration:
+      return "DW_AT_declaration";
+    case DW_AT_discr_list:
+      return "DW_AT_discr_list";
+    case DW_AT_encoding:
+      return "DW_AT_encoding";
+    case DW_AT_external:
+      return "DW_AT_external";
+    case DW_AT_frame_base:
+      return "DW_AT_frame_base";
+    case DW_AT_friend:
+      return "DW_AT_friend";
+    case DW_AT_identifier_case:
+      return "DW_AT_identifier_case";
+    case DW_AT_macro_info:
+      return "DW_AT_macro_info";
+    case DW_AT_namelist_items:
+      return "DW_AT_namelist_items";
+    case DW_AT_priority:
+      return "DW_AT_priority";
+    case DW_AT_segment:
+      return "DW_AT_segment";
+    case DW_AT_specification:
+      return "DW_AT_specification";
+    case DW_AT_static_link:
+      return "DW_AT_static_link";
+    case DW_AT_type:
+      return "DW_AT_type";
+    case DW_AT_use_location:
+      return "DW_AT_use_location";
+    case DW_AT_variable_parameter:
+      return "DW_AT_variable_parameter";
+    case DW_AT_virtuality:
+      return "DW_AT_virtuality";
+    case DW_AT_vtable_elem_location:
+      return "DW_AT_vtable_elem_location";
+
+    case DW_AT_allocated:
+      return "DW_AT_allocated";
+    case DW_AT_associated:
+      return "DW_AT_associated";
+    case DW_AT_data_location:
+      return "DW_AT_data_location";
+    case DW_AT_stride:
+      return "DW_AT_stride";
+    case DW_AT_entry_pc:
+      return "DW_AT_entry_pc";
+    case DW_AT_use_UTF8:
+      return "DW_AT_use_UTF8";
+    case DW_AT_extension:
+      return "DW_AT_extension";
+    case DW_AT_ranges:
+      return "DW_AT_ranges";
+    case DW_AT_trampoline:
+      return "DW_AT_trampoline";
+    case DW_AT_call_column:
+      return "DW_AT_call_column";
+    case DW_AT_call_file:
+      return "DW_AT_call_file";
+    case DW_AT_call_line:
+      return "DW_AT_call_line";
+
+    case DW_AT_MIPS_fde:
+      return "DW_AT_MIPS_fde";
+    case DW_AT_MIPS_loop_begin:
+      return "DW_AT_MIPS_loop_begin";
+    case DW_AT_MIPS_tail_loop_begin:
+      return "DW_AT_MIPS_tail_loop_begin";
+    case DW_AT_MIPS_epilog_begin:
+      return "DW_AT_MIPS_epilog_begin";
+    case DW_AT_MIPS_loop_unroll_factor:
+      return "DW_AT_MIPS_loop_unroll_factor";
+    case DW_AT_MIPS_software_pipeline_depth:
+      return "DW_AT_MIPS_software_pipeline_depth";
+    case DW_AT_MIPS_linkage_name:
+      return "DW_AT_MIPS_linkage_name";
+    case DW_AT_MIPS_stride:
+      return "DW_AT_MIPS_stride";
+    case DW_AT_MIPS_abstract_name:
+      return "DW_AT_MIPS_abstract_name";
+    case DW_AT_MIPS_clone_origin:
+      return "DW_AT_MIPS_clone_origin";
+    case DW_AT_MIPS_has_inlines:
+      return "DW_AT_MIPS_has_inlines";
+
+    case DW_AT_sf_names:
+      return "DW_AT_sf_names";
+    case DW_AT_src_info:
+      return "DW_AT_src_info";
+    case DW_AT_mac_info:
+      return "DW_AT_mac_info";
+    case DW_AT_src_coords:
+      return "DW_AT_src_coords";
+    case DW_AT_body_begin:
+      return "DW_AT_body_begin";
+    case DW_AT_body_end:
+      return "DW_AT_body_end";
+    case DW_AT_GNU_vector:
+      return "DW_AT_GNU_vector";
+
+    case DW_AT_VMS_rtnbeg_pd_address:
+      return "DW_AT_VMS_rtnbeg_pd_address";
+
+    default:
+      return "DW_AT_<unknown>";
+    }
+}
+
+/* Convert a DWARF value form code into its string name.  */
+
+static const char *
+dwarf_form_name (unsigned int form)
+{
+  switch (form)
+    {
+    case DW_FORM_addr:
+      return "DW_FORM_addr";
+    case DW_FORM_block2:
+      return "DW_FORM_block2";
+    case DW_FORM_block4:
+      return "DW_FORM_block4";
+    case DW_FORM_data2:
+      return "DW_FORM_data2";
+    case DW_FORM_data4:
+      return "DW_FORM_data4";
+    case DW_FORM_data8:
+      return "DW_FORM_data8";
+    case DW_FORM_string:
+      return "DW_FORM_string";
+    case DW_FORM_block:
+      return "DW_FORM_block";
+    case DW_FORM_block1:
+      return "DW_FORM_block1";
+    case DW_FORM_data1:
+      return "DW_FORM_data1";
+    case DW_FORM_flag:
+      return "DW_FORM_flag";
+    case DW_FORM_sdata:
+      return "DW_FORM_sdata";
+    case DW_FORM_strp:
+      return "DW_FORM_strp";
+    case DW_FORM_udata:
+      return "DW_FORM_udata";
+    case DW_FORM_ref_addr:
+      return "DW_FORM_ref_addr";
+    case DW_FORM_ref1:
+      return "DW_FORM_ref1";
+    case DW_FORM_ref2:
+      return "DW_FORM_ref2";
+    case DW_FORM_ref4:
+      return "DW_FORM_ref4";
+    case DW_FORM_ref8:
+      return "DW_FORM_ref8";
+    case DW_FORM_ref_udata:
+      return "DW_FORM_ref_udata";
+    case DW_FORM_indirect:
+      return "DW_FORM_indirect";
+    default:
+      return "DW_FORM_<unknown>";
+    }
+}
+
+/* Determine the "ultimate origin" of a decl.  The decl may be an inlined
+   instance of an inlined instance of a decl which is local to an inline
+   function, so we have to trace all of the way back through the origin chain
+   to find out what sort of node actually served as the original seed for the
+   given block.  */
+
+static tree
+decl_ultimate_origin (tree decl)
+{
+  if (!CODE_CONTAINS_STRUCT (TREE_CODE (decl), TS_DECL_COMMON))
+    return NULL_TREE;
+
+  /* output_inline_function sets DECL_ABSTRACT_ORIGIN for all the
+     nodes in the function to point to themselves; ignore that if
+     we're trying to output the abstract instance of this function.  */
+  if (DECL_ABSTRACT (decl) && DECL_ABSTRACT_ORIGIN (decl) == decl)
+    return NULL_TREE;
+
+  /* Since the DECL_ABSTRACT_ORIGIN for a DECL is supposed to be the
+     most distant ancestor, this should never happen.  */
+  gcc_assert (!DECL_FROM_INLINE (DECL_ORIGIN (decl)));
+
+  return DECL_ABSTRACT_ORIGIN (decl);
+}
+
+/* Determine the "ultimate origin" of a block.  The block may be an inlined
+   instance of an inlined instance of a block which is local to an inline
+   function, so we have to trace all of the way back through the origin chain
+   to find out what sort of node actually served as the original seed for the
+   given block.  */
+
+static tree
+block_ultimate_origin (tree block)
+{
+  tree immediate_origin = BLOCK_ABSTRACT_ORIGIN (block);
+
+  /* output_inline_function sets BLOCK_ABSTRACT_ORIGIN for all the
+     nodes in the function to point to themselves; ignore that if
+     we're trying to output the abstract instance of this function.  */
+  if (BLOCK_ABSTRACT (block) && immediate_origin == block)
+    return NULL_TREE;
+
+  if (immediate_origin == NULL_TREE)
+    return NULL_TREE;
+  else
+    {
+      tree ret_val;
+      tree lookahead = immediate_origin;
+
+      do
+	{
+	  ret_val = lookahead;
+	  lookahead = (TREE_CODE (ret_val) == BLOCK
+		       ? BLOCK_ABSTRACT_ORIGIN (ret_val) : NULL);
+	}
+      while (lookahead != NULL && lookahead != ret_val);
+      
+      /* The block's abstract origin chain may not be the *ultimate* origin of
+	 the block. It could lead to a DECL that has an abstract origin set.
+	 If so, we want that DECL's abstract origin (which is what DECL_ORIGIN
+	 will give us if it has one).  Note that DECL's abstract origins are
+	 supposed to be the most distant ancestor (or so decl_ultimate_origin
+	 claims), so we don't need to loop following the DECL origins.  */
+      if (DECL_P (ret_val))
+	return DECL_ORIGIN (ret_val);
+
+      return ret_val;
+    }
+}
+
+/* Get the class to which DECL belongs, if any.  In g++, the DECL_CONTEXT
+   of a virtual function may refer to a base class, so we check the 'this'
+   parameter.  */
+
+static tree
+decl_class_context (tree decl)
+{
+  tree context = NULL_TREE;
+
+  if (TREE_CODE (decl) != FUNCTION_DECL || ! DECL_VINDEX (decl))
+    context = DECL_CONTEXT (decl);
+  else
+    context = TYPE_MAIN_VARIANT
+      (TREE_TYPE (TREE_VALUE (TYPE_ARG_TYPES (TREE_TYPE (decl)))));
+
+  if (context && !TYPE_P (context))
+    context = NULL_TREE;
+
+  return context;
+}
+
+/* Add an attribute/value pair to a DIE.  We build the lists up in reverse
+   addition order, and correct that in reverse_all_dies.  */
+
+static inline void
+add_dwarf_attr (dw_die_ref die, dw_attr_ref attr)
+{
+  if (die != NULL && attr != NULL)
+    {
+      attr->dw_attr_next = die->die_attr;
+      die->die_attr = attr;
+    }
+}
+
+static inline enum dw_val_class
+AT_class (dw_attr_ref a)
+{
+  return a->dw_attr_val.val_class;
+}
+
+/* Add a flag value attribute to a DIE.  */
+
+static inline void
+add_AT_flag (dw_die_ref die, enum dwarf_attribute attr_kind, unsigned int flag)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_flag;
+  attr->dw_attr_val.v.val_flag = flag;
+  add_dwarf_attr (die, attr);
+}
+
+static inline unsigned
+AT_flag (dw_attr_ref a)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_flag);
+  return a->dw_attr_val.v.val_flag;
+}
+
+/* Add a signed integer attribute value to a DIE.  */
+
+static inline void
+add_AT_int (dw_die_ref die, enum dwarf_attribute attr_kind, HOST_WIDE_INT int_val)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_const;
+  attr->dw_attr_val.v.val_int = int_val;
+  add_dwarf_attr (die, attr);
+}
+
+static inline HOST_WIDE_INT
+AT_int (dw_attr_ref a)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_const);
+  return a->dw_attr_val.v.val_int;
+}
+
+/* Add an unsigned integer attribute value to a DIE.  */
+
+static inline void
+add_AT_unsigned (dw_die_ref die, enum dwarf_attribute attr_kind,
+		 unsigned HOST_WIDE_INT unsigned_val)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_unsigned_const;
+  attr->dw_attr_val.v.val_unsigned = unsigned_val;
+  add_dwarf_attr (die, attr);
+}
+
+static inline unsigned HOST_WIDE_INT
+AT_unsigned (dw_attr_ref a)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_unsigned_const);
+  return a->dw_attr_val.v.val_unsigned;
+}
+
+/* Add an unsigned double integer attribute value to a DIE.  */
+
+static inline void
+add_AT_long_long (dw_die_ref die, enum dwarf_attribute attr_kind,
+		  long unsigned int val_hi, long unsigned int val_low)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_long_long;
+  attr->dw_attr_val.v.val_long_long.hi = val_hi;
+  attr->dw_attr_val.v.val_long_long.low = val_low;
+  add_dwarf_attr (die, attr);
+}
+
+/* Add a floating point attribute value to a DIE and return it.  */
+
+static inline void
+add_AT_vec (dw_die_ref die, enum dwarf_attribute attr_kind,
+	    unsigned int length, unsigned int elt_size, unsigned char *array)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_vec;
+  attr->dw_attr_val.v.val_vec.length = length;
+  attr->dw_attr_val.v.val_vec.elt_size = elt_size;
+  attr->dw_attr_val.v.val_vec.array = array;
+  add_dwarf_attr (die, attr);
+}
+
+/* Hash and equality functions for debug_str_hash.  */
+
+static hashval_t
+debug_str_do_hash (const void *x)
+{
+  return htab_hash_string (((const struct indirect_string_node *)x)->str);
+}
+
+static int
+debug_str_eq (const void *x1, const void *x2)
+{
+  return strcmp ((((const struct indirect_string_node *)x1)->str),
+		 (const char *)x2) == 0;
+}
+
+/* Add a string attribute value to a DIE.  */
+
+static inline void
+add_AT_string (dw_die_ref die, enum dwarf_attribute attr_kind, const char *str)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+  struct indirect_string_node *node;
+  void **slot;
+
+  if (! debug_str_hash)
+    debug_str_hash = htab_create_ggc (10, debug_str_do_hash,
+				      debug_str_eq, NULL);
+
+  slot = htab_find_slot_with_hash (debug_str_hash, str,
+				   htab_hash_string (str), INSERT);
+  if (*slot == NULL)
+    *slot = ggc_alloc_cleared (sizeof (struct indirect_string_node));
+  node = (struct indirect_string_node *) *slot;
+  node->str = ggc_strdup (str);
+  node->refcount++;
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_str;
+  attr->dw_attr_val.v.val_str = node;
+  add_dwarf_attr (die, attr);
+}
+
+static inline const char *
+AT_string (dw_attr_ref a)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_str);
+  return a->dw_attr_val.v.val_str->str;
+}
+
+/* Find out whether a string should be output inline in DIE
+   or out-of-line in .debug_str section.  */
+
+static int
+AT_string_form (dw_attr_ref a)
+{
+  struct indirect_string_node *node;
+  unsigned int len;
+  char label[32];
+
+  gcc_assert (a && AT_class (a) == dw_val_class_str);
+
+  node = a->dw_attr_val.v.val_str;
+  if (node->form)
+    return node->form;
+
+  len = strlen (node->str) + 1;
+
+  /* If the string is shorter or equal to the size of the reference, it is
+     always better to put it inline.  */
+  if (len <= DWARF_OFFSET_SIZE || node->refcount == 0)
+    return node->form = DW_FORM_string;
+
+  /* If we cannot expect the linker to merge strings in .debug_str
+     section, only put it into .debug_str if it is worth even in this
+     single module.  */
+  if ((DEBUG_STR_SECTION_FLAGS & SECTION_MERGE) == 0
+      && (len - DWARF_OFFSET_SIZE) * node->refcount <= len)
+    return node->form = DW_FORM_string;
+
+  ASM_GENERATE_INTERNAL_LABEL (label, "LASF", dw2_string_counter);
+  ++dw2_string_counter;
+  node->label = xstrdup (label);
+
+  return node->form = DW_FORM_strp;
+}
+
+/* Add a DIE reference attribute value to a DIE.  */
+
+static inline void
+add_AT_die_ref (dw_die_ref die, enum dwarf_attribute attr_kind, dw_die_ref targ_die)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_die_ref;
+  attr->dw_attr_val.v.val_die_ref.die = targ_die;
+  attr->dw_attr_val.v.val_die_ref.external = 0;
+  add_dwarf_attr (die, attr);
+}
+
+/* Add an AT_specification attribute to a DIE, and also make the back
+   pointer from the specification to the definition.  */
+
+static inline void
+add_AT_specification (dw_die_ref die, dw_die_ref targ_die)
+{
+  add_AT_die_ref (die, DW_AT_specification, targ_die);
+  gcc_assert (!targ_die->die_definition);
+  targ_die->die_definition = die;
+}
+
+static inline dw_die_ref
+AT_ref (dw_attr_ref a)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_die_ref);
+  return a->dw_attr_val.v.val_die_ref.die;
+}
+
+static inline int
+AT_ref_external (dw_attr_ref a)
+{
+  if (a && AT_class (a) == dw_val_class_die_ref)
+    return a->dw_attr_val.v.val_die_ref.external;
+
+  return 0;
+}
+
+static inline void
+set_AT_ref_external (dw_attr_ref a, int i)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_die_ref);
+  a->dw_attr_val.v.val_die_ref.external = i;
+}
+
+/* Add an FDE reference attribute value to a DIE.  */
+
+static inline void
+add_AT_fde_ref (dw_die_ref die, enum dwarf_attribute attr_kind, unsigned int targ_fde)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_fde_ref;
+  attr->dw_attr_val.v.val_fde_index = targ_fde;
+  add_dwarf_attr (die, attr);
+}
+
+/* Add a location description attribute value to a DIE.  */
+
+static inline void
+add_AT_loc (dw_die_ref die, enum dwarf_attribute attr_kind, dw_loc_descr_ref loc)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_loc;
+  attr->dw_attr_val.v.val_loc = loc;
+  add_dwarf_attr (die, attr);
+}
+
+static inline dw_loc_descr_ref
+AT_loc (dw_attr_ref a)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_loc);
+  return a->dw_attr_val.v.val_loc;
+}
+
+static inline void
+add_AT_loc_list (dw_die_ref die, enum dwarf_attribute attr_kind, dw_loc_list_ref loc_list)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_loc_list;
+  attr->dw_attr_val.v.val_loc_list = loc_list;
+  add_dwarf_attr (die, attr);
+  have_location_lists = 1;
+}
+
+static inline dw_loc_list_ref
+AT_loc_list (dw_attr_ref a)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_loc_list);
+  return a->dw_attr_val.v.val_loc_list;
+}
+
+/* Add an address constant attribute value to a DIE.  */
+
+static inline void
+add_AT_addr (dw_die_ref die, enum dwarf_attribute attr_kind, rtx addr)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_addr;
+  attr->dw_attr_val.v.val_addr = addr;
+  add_dwarf_attr (die, attr);
+}
+
+static inline rtx
+AT_addr (dw_attr_ref a)
+{
+  gcc_assert (a && AT_class (a) == dw_val_class_addr);
+  return a->dw_attr_val.v.val_addr;
+}
+
+/* Add a label identifier attribute value to a DIE.  */
+
+static inline void
+add_AT_lbl_id (dw_die_ref die, enum dwarf_attribute attr_kind, const char *lbl_id)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_lbl_id;
+  attr->dw_attr_val.v.val_lbl_id = xstrdup (lbl_id);
+  add_dwarf_attr (die, attr);
+}
+
+/* Add a section offset attribute value to a DIE.  */
+
+static inline void
+add_AT_lbl_offset (dw_die_ref die, enum dwarf_attribute attr_kind, const char *label)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_lbl_offset;
+  attr->dw_attr_val.v.val_lbl_id = xstrdup (label);
+  add_dwarf_attr (die, attr);
+}
+
+/* Add an offset attribute value to a DIE.  */
+
+static inline void
+add_AT_offset (dw_die_ref die, enum dwarf_attribute attr_kind,
+	       unsigned HOST_WIDE_INT offset)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_offset;
+  attr->dw_attr_val.v.val_offset = offset;
+  add_dwarf_attr (die, attr);
+}
+
+/* Add an range_list attribute value to a DIE.  */
+
+static void
+add_AT_range_list (dw_die_ref die, enum dwarf_attribute attr_kind,
+		   long unsigned int offset)
+{
+  dw_attr_ref attr = ggc_alloc (sizeof (dw_attr_node));
+
+  attr->dw_attr_next = NULL;
+  attr->dw_attr = attr_kind;
+  attr->dw_attr_val.val_class = dw_val_class_range_list;
+  attr->dw_attr_val.v.val_offset = offset;
+  add_dwarf_attr (die, attr);
+}
+
+static inline const char *
+AT_lbl (dw_attr_ref a)
+{
+  gcc_assert (a && (AT_class (a) == dw_val_class_lbl_id
+		    || AT_class (a) == dw_val_class_lbl_offset));
+  return a->dw_attr_val.v.val_lbl_id;
+}
+
+/* Get the attribute of type attr_kind.  */
+
+static dw_attr_ref
+get_AT (dw_die_ref die, enum dwarf_attribute attr_kind)
+{
+  dw_attr_ref a;
+  dw_die_ref spec = NULL;
+
+  if (die != NULL)
+    {
+      for (a = die->die_attr; a != NULL; a = a->dw_attr_next)
+	if (a->dw_attr == attr_kind)
+	  return a;
+	else if (a->dw_attr == DW_AT_specification
+		 || a->dw_attr == DW_AT_abstract_origin)
+	  spec = AT_ref (a);
+
+      if (spec)
+	return get_AT (spec, attr_kind);
+    }
+
+  return NULL;
+}
+
+/* Return the "low pc" attribute value, typically associated with a subprogram
+   DIE.  Return null if the "low pc" attribute is either not present, or if it
+   cannot be represented as an assembler label identifier.  */
+
+static inline const char *
+get_AT_low_pc (dw_die_ref die)
+{
+  dw_attr_ref a = get_AT (die, DW_AT_low_pc);
+
+  return a ? AT_lbl (a) : NULL;
+}
+
+/* Return the "high pc" attribute value, typically associated with a subprogram
+   DIE.  Return null if the "high pc" attribute is either not present, or if it
+   cannot be represented as an assembler label identifier.  */
+
+static inline const char *
+get_AT_hi_pc (dw_die_ref die)
+{
+  dw_attr_ref a = get_AT (die, DW_AT_high_pc);
+
+  return a ? AT_lbl (a) : NULL;
+}
+
+/* Return the value of the string attribute designated by ATTR_KIND, or
+   NULL if it is not present.  */
+
+static inline const char *
+get_AT_string (dw_die_ref die, enum dwarf_attribute attr_kind)
+{
+  dw_attr_ref a = get_AT (die, attr_kind);
+
+  return a ? AT_string (a) : NULL;
+}
+
+/* Return the value of the flag attribute designated by ATTR_KIND, or -1
+   if it is not present.  */
+
+static inline int
+get_AT_flag (dw_die_ref die, enum dwarf_attribute attr_kind)
+{
+  dw_attr_ref a = get_AT (die, attr_kind);
+
+  return a ? AT_flag (a) : 0;
+}
+
+/* Return the value of the unsigned attribute designated by ATTR_KIND, or 0
+   if it is not present.  */
+
+static inline unsigned
+get_AT_unsigned (dw_die_ref die, enum dwarf_attribute attr_kind)
+{
+  dw_attr_ref a = get_AT (die, attr_kind);
+
+  return a ? AT_unsigned (a) : 0;
+}
+
+static inline dw_die_ref
+get_AT_ref (dw_die_ref die, enum dwarf_attribute attr_kind)
+{
+  dw_attr_ref a = get_AT (die, attr_kind);
+
+  return a ? AT_ref (a) : NULL;
+}
+
+/* Return TRUE if the language is C or C++.  */
+
+static inline bool
+is_c_family (void)
+{
+  unsigned int lang = get_AT_unsigned (comp_unit_die, DW_AT_language);
+
+  return (lang == DW_LANG_C || lang == DW_LANG_C89
+	  || lang == DW_LANG_C_plus_plus);
+}
+
+/* Return TRUE if the language is C++.  */
+
+static inline bool
+is_cxx (void)
+{
+  return (get_AT_unsigned (comp_unit_die, DW_AT_language)
+	  == DW_LANG_C_plus_plus);
+}
+
+/* Return TRUE if the language is Fortran.  */
+
+static inline bool
+is_fortran (void)
+{
+  unsigned int lang = get_AT_unsigned (comp_unit_die, DW_AT_language);
+
+  return (lang == DW_LANG_Fortran77
+	  || lang == DW_LANG_Fortran90
+	  || lang == DW_LANG_Fortran95);
+}
+
+/* Return TRUE if the language is Java.  */
+
+static inline bool
+is_java (void)
+{
+  unsigned int lang = get_AT_unsigned (comp_unit_die, DW_AT_language);
+
+  return lang == DW_LANG_Java;
+}
+
+/* Return TRUE if the language is Ada.  */
+
+static inline bool
+is_ada (void)
+{
+  unsigned int lang = get_AT_unsigned (comp_unit_die, DW_AT_language);
+
+  return lang == DW_LANG_Ada95 || lang == DW_LANG_Ada83;
+}
+
+/* Free up the memory used by A.  */
+
+static inline void free_AT (dw_attr_ref);
+static inline void
+free_AT (dw_attr_ref a)
+{
+  if (AT_class (a) == dw_val_class_str)
+    if (a->dw_attr_val.v.val_str->refcount)
+      a->dw_attr_val.v.val_str->refcount--;
+}
+
+/* Remove the specified attribute if present.  */
+
+static void
+remove_AT (dw_die_ref die, enum dwarf_attribute attr_kind)
+{
+  dw_attr_ref *p;
+  dw_attr_ref removed = NULL;
+
+  if (die != NULL)
+    {
+      for (p = &(die->die_attr); *p; p = &((*p)->dw_attr_next))
+	if ((*p)->dw_attr == attr_kind)
+	  {
+	    removed = *p;
+	    *p = (*p)->dw_attr_next;
+	    break;
+	  }
+
+      if (removed != 0)
+	free_AT (removed);
+    }
+}
+
+/* Remove child die whose die_tag is specified tag.  */
+
+static void
+remove_child_TAG (dw_die_ref die, enum dwarf_tag tag)
+{
+  dw_die_ref current, prev, next;
+  current = die->die_child;
+  prev = NULL;
+  while (current != NULL)
+    {
+      if (current->die_tag == tag)
+	{
+	  next = current->die_sib;
+	  if (prev == NULL)
+	    die->die_child = next;
+	  else
+	    prev->die_sib = next;
+	  free_die (current);
+	  current = next;
+	}
+      else
+	{
+	  prev = current;
+	  current = current->die_sib;
+	}
+    }
+}
+
+/* Free up the memory used by DIE.  */
+
+static inline void
+free_die (dw_die_ref die)
+{
+  remove_children (die);
+}
+
+/* Discard the children of this DIE.  */
+
+static void
+remove_children (dw_die_ref die)
+{
+  dw_die_ref child_die = die->die_child;
+
+  die->die_child = NULL;
+
+  while (child_die != NULL)
+    {
+      dw_die_ref tmp_die = child_die;
+      dw_attr_ref a;
+
+      child_die = child_die->die_sib;
+
+      for (a = tmp_die->die_attr; a != NULL;)
+	{
+	  dw_attr_ref tmp_a = a;
+
+	  a = a->dw_attr_next;
+	  free_AT (tmp_a);
+	}
+
+      free_die (tmp_die);
+    }
+}
+
+/* Add a child DIE below its parent.  We build the lists up in reverse
+   addition order, and correct that in reverse_all_dies.  */
+
+static inline void
+add_child_die (dw_die_ref die, dw_die_ref child_die)
+{
+  if (die != NULL && child_die != NULL)
+    {
+      gcc_assert (die != child_die);
+
+      child_die->die_parent = die;
+      child_die->die_sib = die->die_child;
+      die->die_child = child_die;
+    }
+}
+
+/* Move CHILD, which must be a child of PARENT or the DIE for which PARENT
+   is the specification, to the front of PARENT's list of children.  */
+
+static void
+splice_child_die (dw_die_ref parent, dw_die_ref child)
+{
+  dw_die_ref *p;
+
+  /* We want the declaration DIE from inside the class, not the
+     specification DIE at toplevel.  */
+  if (child->die_parent != parent)
+    {
+      dw_die_ref tmp = get_AT_ref (child, DW_AT_specification);
+
+      if (tmp)
+	child = tmp;
+    }
+
+  gcc_assert (child->die_parent == parent
+	      || (child->die_parent
+		  == get_AT_ref (parent, DW_AT_specification)));
+
+  for (p = &(child->die_parent->die_child); *p; p = &((*p)->die_sib))
+    if (*p == child)
+      {
+	*p = child->die_sib;
+	break;
+      }
+
+  child->die_parent = parent;
+  child->die_sib = parent->die_child;
+  parent->die_child = child;
+}
+
+/* Return a pointer to a newly created DIE node.  */
+
+static inline dw_die_ref
+new_die (enum dwarf_tag tag_value, dw_die_ref parent_die, tree t)
+{
+  dw_die_ref die = ggc_alloc_cleared (sizeof (die_node));
+
+  die->die_tag = tag_value;
+
+  if (parent_die != NULL)
+    add_child_die (parent_die, die);
+  else
+    {
+      limbo_die_node *limbo_node;
+
+      limbo_node = ggc_alloc_cleared (sizeof (limbo_die_node));
+      limbo_node->die = die;
+      limbo_node->created_for = t;
+      limbo_node->next = limbo_die_list;
+      limbo_die_list = limbo_node;
+    }
+
+  return die;
+}
+
+/* Return the DIE associated with the given type specifier.  */
+
+static inline dw_die_ref
+lookup_type_die (tree type)
+{
+  return TYPE_SYMTAB_DIE (type);
+}
+
+/* Equate a DIE to a given type specifier.  */
+
+static inline void
+equate_type_number_to_die (tree type, dw_die_ref type_die)
+{
+  TYPE_SYMTAB_DIE (type) = type_die;
+}
+
+/* Returns a hash value for X (which really is a die_struct).  */
+
+static hashval_t
+decl_die_table_hash (const void *x)
+{
+  return (hashval_t) ((const dw_die_ref) x)->decl_id;
+}
+
+/* Return nonzero if decl_id of die_struct X is the same as UID of decl *Y.  */
+
+static int
+decl_die_table_eq (const void *x, const void *y)
+{
+  return (((const dw_die_ref) x)->decl_id == DECL_UID ((const tree) y));
+}
+
+/* Return the DIE associated with a given declaration.  */
+
+static inline dw_die_ref
+lookup_decl_die (tree decl)
+{
+  return htab_find_with_hash (decl_die_table, decl, DECL_UID (decl));
+}
+
+/* Returns a hash value for X (which really is a var_loc_list).  */
+
+static hashval_t
+decl_loc_table_hash (const void *x)
+{
+  return (hashval_t) ((const var_loc_list *) x)->decl_id;
+}
+
+/* Return nonzero if decl_id of var_loc_list X is the same as
+   UID of decl *Y.  */
+
+static int
+decl_loc_table_eq (const void *x, const void *y)
+{
+  return (((const var_loc_list *) x)->decl_id == DECL_UID ((const tree) y));
+}
+
+/* Return the var_loc list associated with a given declaration.  */
+
+static inline var_loc_list *
+lookup_decl_loc (tree decl)
+{
+  return htab_find_with_hash (decl_loc_table, decl, DECL_UID (decl));
+}
+
+/* Equate a DIE to a particular declaration.  */
+
+static void
+equate_decl_number_to_die (tree decl, dw_die_ref decl_die)
+{
+  unsigned int decl_id = DECL_UID (decl);
+  void **slot;
+
+  slot = htab_find_slot_with_hash (decl_die_table, decl, decl_id, INSERT);
+  *slot = decl_die;
+  decl_die->decl_id = decl_id;
+}
+
+/* Add a variable location node to the linked list for DECL.  */
+
+static void
+add_var_loc_to_decl (tree decl, struct var_loc_node *loc)
+{
+  unsigned int decl_id = DECL_UID (decl);
+  var_loc_list *temp;
+  void **slot;
+
+  slot = htab_find_slot_with_hash (decl_loc_table, decl, decl_id, INSERT);
+  if (*slot == NULL)
+    {
+      temp = ggc_alloc_cleared (sizeof (var_loc_list));
+      temp->decl_id = decl_id;
+      *slot = temp;
+    }
+  else
+    temp = *slot;
+
+  if (temp->last)
+    {
+      /* If the current location is the same as the end of the list,
+	 we have nothing to do.  */
+      if (!rtx_equal_p (NOTE_VAR_LOCATION_LOC (temp->last->var_loc_note),
+			NOTE_VAR_LOCATION_LOC (loc->var_loc_note)))
+	{
+	  /* Add LOC to the end of list and update LAST.  */
+	  temp->last->next = loc;
+	  temp->last = loc;
+	}
+    }
+  /* Do not add empty location to the beginning of the list.  */
+  else if (NOTE_VAR_LOCATION_LOC (loc->var_loc_note) != NULL_RTX)
+    {
+      temp->first = loc;
+      temp->last = loc;
+    }
+}
+
+/* Keep track of the number of spaces used to indent the
+   output of the debugging routines that print the structure of
+   the DIE internal representation.  */
+static int print_indent;
+
+/* Indent the line the number of spaces given by print_indent.  */
+
+static inline void
+print_spaces (FILE *outfile)
+{
+  fprintf (outfile, "%*s", print_indent, "");
+}
+
+/* Print the information associated with a given DIE, and its children.
+   This routine is a debugging aid only.  */
+
+static void
+print_die (dw_die_ref die, FILE *outfile)
+{
+  dw_attr_ref a;
+  dw_die_ref c;
+
+  print_spaces (outfile);
+  fprintf (outfile, "DIE %4lu: %s\n",
+	   die->die_offset, dwarf_tag_name (die->die_tag));
+  print_spaces (outfile);
+  fprintf (outfile, "  abbrev id: %lu", die->die_abbrev);
+  fprintf (outfile, " offset: %lu\n", die->die_offset);
+
+  for (a = die->die_attr; a != NULL; a = a->dw_attr_next)
+    {
+      print_spaces (outfile);
+      fprintf (outfile, "  %s: ", dwarf_attr_name (a->dw_attr));
+
+      switch (AT_class (a))
+	{
+	case dw_val_class_addr:
+	  fprintf (outfile, "address");
+	  break;
+	case dw_val_class_offset:
+	  fprintf (outfile, "offset");
+	  break;
+	case dw_val_class_loc:
+	  fprintf (outfile, "location descriptor");
+	  break;
+	case dw_val_class_loc_list:
+	  fprintf (outfile, "location list -> label:%s",
+		   AT_loc_list (a)->ll_symbol);
+	  break;
+	case dw_val_class_range_list:
+	  fprintf (outfile, "range list");
+	  break;
+	case dw_val_class_const:
+	  fprintf (outfile, HOST_WIDE_INT_PRINT_DEC, AT_int (a));
+	  break;
+	case dw_val_class_unsigned_const:
+	  fprintf (outfile, HOST_WIDE_INT_PRINT_UNSIGNED, AT_unsigned (a));
+	  break;
+	case dw_val_class_long_long:
+	  fprintf (outfile, "constant (%lu,%lu)",
+		   a->dw_attr_val.v.val_long_long.hi,
+		   a->dw_attr_val.v.val_long_long.low);
+	  break;
+	case dw_val_class_vec:
+	  fprintf (outfile, "floating-point or vector constant");
+	  break;
+	case dw_val_class_flag:
+	  fprintf (outfile, "%u", AT_flag (a));
+	  break;
+	case dw_val_class_die_ref:
+	  if (AT_ref (a) != NULL)
+	    {
+	      if (AT_ref (a)->die_symbol)
+		fprintf (outfile, "die -> label: %s", AT_ref (a)->die_symbol);
+	      else
+		fprintf (outfile, "die -> %lu", AT_ref (a)->die_offset);
+	    }
+	  else
+	    fprintf (outfile, "die -> <null>");
+	  break;
+	case dw_val_class_lbl_id:
+	case dw_val_class_lbl_offset:
+	  fprintf (outfile, "label: %s", AT_lbl (a));
+	  break;
+	case dw_val_class_str:
+	  if (AT_string (a) != NULL)
+	    fprintf (outfile, "\"%s\"", AT_string (a));
+	  else
+	    fprintf (outfile, "<null>");
+	  break;
+	default:
+	  break;
+	}
+
+      fprintf (outfile, "\n");
+    }
+
+  if (die->die_child != NULL)
+    {
+      print_indent += 4;
+      for (c = die->die_child; c != NULL; c = c->die_sib)
+	print_die (c, outfile);
+
+      print_indent -= 4;
+    }
+  if (print_indent == 0)
+    fprintf (outfile, "\n");
+}
+
+/* Print the contents of the source code line number correspondence table.
+   This routine is a debugging aid only.  */
+
+static void
+print_dwarf_line_table (FILE *outfile)
+{
+  unsigned i;
+  dw_line_info_ref line_info;
+
+  fprintf (outfile, "\n\nDWARF source line information\n");
+  for (i = 1; i < line_info_table_in_use; i++)
+    {
+      line_info = &line_info_table[i];
+      fprintf (outfile, "%5d: ", i);
+      fprintf (outfile, "%-20s",
+	       VARRAY_CHAR_PTR (file_table, line_info->dw_file_num));
+      fprintf (outfile, "%6ld", line_info->dw_line_num);
+      fprintf (outfile, "\n");
+    }
+
+  fprintf (outfile, "\n\n");
+}
+
+/* Print the information collected for a given DIE.  */
+
+void
+debug_dwarf_die (dw_die_ref die)
+{
+  print_die (die, stderr);
+}
+
+/* Print all DWARF information collected for the compilation unit.
+   This routine is a debugging aid only.  */
+
+void
+debug_dwarf (void)
+{
+  print_indent = 0;
+  print_die (comp_unit_die, stderr);
+  if (! DWARF2_ASM_LINE_DEBUG_INFO)
+    print_dwarf_line_table (stderr);
+}
+
+/* We build up the lists of children and attributes by pushing new ones
+   onto the beginning of the list.  Reverse the lists for DIE so that
+   they are in order of addition.  */
+
+static void
+reverse_die_lists (dw_die_ref die)
+{
+  dw_die_ref c, cp, cn;
+  dw_attr_ref a, ap, an;
+
+  for (a = die->die_attr, ap = 0; a; a = an)
+    {
+      an = a->dw_attr_next;
+      a->dw_attr_next = ap;
+      ap = a;
+    }
+
+  die->die_attr = ap;
+
+  for (c = die->die_child, cp = 0; c; c = cn)
+    {
+      cn = c->die_sib;
+      c->die_sib = cp;
+      cp = c;
+    }
+
+  die->die_child = cp;
+}
+
+/* reverse_die_lists only reverses the single die you pass it. Since we used to
+   reverse all dies in add_sibling_attributes, which runs through all the dies,
+   it would reverse all the dies.  Now, however, since we don't call
+   reverse_die_lists in add_sibling_attributes, we need a routine to
+   recursively reverse all the dies. This is that routine.  */
+
+static void
+reverse_all_dies (dw_die_ref die)
+{
+  dw_die_ref c;
+
+  reverse_die_lists (die);
+
+  for (c = die->die_child; c; c = c->die_sib)
+    reverse_all_dies (c);
+}
+
+/* Start a new compilation unit DIE for an include file.  OLD_UNIT is the CU
+   for the enclosing include file, if any.  BINCL_DIE is the DW_TAG_GNU_BINCL
+   DIE that marks the start of the DIEs for this include file.  */
+
+static dw_die_ref
+push_new_compile_unit (dw_die_ref old_unit, dw_die_ref bincl_die)
+{
+  const char *filename = get_AT_string (bincl_die, DW_AT_name);
+  dw_die_ref new_unit = gen_compile_unit_die (filename);
+
+  new_unit->die_sib = old_unit;
+  return new_unit;
+}
+
+/* Close an include-file CU and reopen the enclosing one.  */
+
+static dw_die_ref
+pop_compile_unit (dw_die_ref old_unit)
+{
+  dw_die_ref new_unit = old_unit->die_sib;
+
+  old_unit->die_sib = NULL;
+  return new_unit;
+}
+
+#define CHECKSUM(FOO) md5_process_bytes (&(FOO), sizeof (FOO), ctx)
+#define CHECKSUM_STRING(FOO) md5_process_bytes ((FOO), strlen (FOO), ctx)
+
+/* Calculate the checksum of a location expression.  */
+
+static inline void
+loc_checksum (dw_loc_descr_ref loc, struct md5_ctx *ctx)
+{
+  CHECKSUM (loc->dw_loc_opc);
+  CHECKSUM (loc->dw_loc_oprnd1);
+  CHECKSUM (loc->dw_loc_oprnd2);
+}
+
+/* Calculate the checksum of an attribute.  */
+
+static void
+attr_checksum (dw_attr_ref at, struct md5_ctx *ctx, int *mark)
+{
+  dw_loc_descr_ref loc;
+  rtx r;
+
+  CHECKSUM (at->dw_attr);
+
+  /* We don't care about differences in file numbering.  */
+  if (at->dw_attr == DW_AT_decl_file
+      /* Or that this was compiled with a different compiler snapshot; if
+	 the output is the same, that's what matters.  */
+      || at->dw_attr == DW_AT_producer)
+    return;
+
+  switch (AT_class (at))
+    {
+    case dw_val_class_const:
+      CHECKSUM (at->dw_attr_val.v.val_int);
+      break;
+    case dw_val_class_unsigned_const:
+      CHECKSUM (at->dw_attr_val.v.val_unsigned);
+      break;
+    case dw_val_class_long_long:
+      CHECKSUM (at->dw_attr_val.v.val_long_long);
+      break;
+    case dw_val_class_vec:
+      CHECKSUM (at->dw_attr_val.v.val_vec);
+      break;
+    case dw_val_class_flag:
+      CHECKSUM (at->dw_attr_val.v.val_flag);
+      break;
+    case dw_val_class_str:
+      CHECKSUM_STRING (AT_string (at));
+      break;
+
+    case dw_val_class_addr:
+      r = AT_addr (at);
+      gcc_assert (GET_CODE (r) == SYMBOL_REF);
+      CHECKSUM_STRING (XSTR (r, 0));
+      break;
+
+    case dw_val_class_offset:
+      CHECKSUM (at->dw_attr_val.v.val_offset);
+      break;
+
+    case dw_val_class_loc:
+      for (loc = AT_loc (at); loc; loc = loc->dw_loc_next)
+	loc_checksum (loc, ctx);
+      break;
+
+    case dw_val_class_die_ref:
+      die_checksum (AT_ref (at), ctx, mark);
+      break;
+
+    case dw_val_class_fde_ref:
+    case dw_val_class_lbl_id:
+    case dw_val_class_lbl_offset:
+      break;
+
+    default:
+      break;
+    }
+}
+
+/* Calculate the checksum of a DIE.  */
+
+static void
+die_checksum (dw_die_ref die, struct md5_ctx *ctx, int *mark)
+{
+  dw_die_ref c;
+  dw_attr_ref a;
+
+  /* To avoid infinite recursion.  */
+  if (die->die_mark)
+    {
+      CHECKSUM (die->die_mark);
+      return;
+    }
+  die->die_mark = ++(*mark);
+
+  CHECKSUM (die->die_tag);
+
+  for (a = die->die_attr; a; a = a->dw_attr_next)
+    attr_checksum (a, ctx, mark);
+
+  for (c = die->die_child; c; c = c->die_sib)
+    die_checksum (c, ctx, mark);
+}
+
+#undef CHECKSUM
+#undef CHECKSUM_STRING
+
+/* Do the location expressions look same?  */
+static inline int
+same_loc_p (dw_loc_descr_ref loc1, dw_loc_descr_ref loc2, int *mark)
+{
+  return loc1->dw_loc_opc == loc2->dw_loc_opc
+	 && same_dw_val_p (&loc1->dw_loc_oprnd1, &loc2->dw_loc_oprnd1, mark)
+	 && same_dw_val_p (&loc1->dw_loc_oprnd2, &loc2->dw_loc_oprnd2, mark);
+}
+
+/* Do the values look the same?  */
+static int
+same_dw_val_p (dw_val_node *v1, dw_val_node *v2, int *mark)
+{
+  dw_loc_descr_ref loc1, loc2;
+  rtx r1, r2;
+
+  if (v1->val_class != v2->val_class)
+    return 0;
+
+  switch (v1->val_class)
+    {
+    case dw_val_class_const:
+      return v1->v.val_int == v2->v.val_int;
+    case dw_val_class_unsigned_const:
+      return v1->v.val_unsigned == v2->v.val_unsigned;
+    case dw_val_class_long_long:
+      return v1->v.val_long_long.hi == v2->v.val_long_long.hi
+	     && v1->v.val_long_long.low == v2->v.val_long_long.low;
+    case dw_val_class_vec:
+      if (v1->v.val_vec.length != v2->v.val_vec.length
+	  || v1->v.val_vec.elt_size != v2->v.val_vec.elt_size)
+	return 0;
+      if (memcmp (v1->v.val_vec.array, v2->v.val_vec.array,
+		  v1->v.val_vec.length * v1->v.val_vec.elt_size))
+	return 0;
+      return 1;
+    case dw_val_class_flag:
+      return v1->v.val_flag == v2->v.val_flag;
+    case dw_val_class_str:
+      return !strcmp(v1->v.val_str->str, v2->v.val_str->str);
+
+    case dw_val_class_addr:
+      r1 = v1->v.val_addr;
+      r2 = v2->v.val_addr;
+      if (GET_CODE (r1) != GET_CODE (r2))
+	return 0;
+      gcc_assert (GET_CODE (r1) == SYMBOL_REF);
+      return !strcmp (XSTR (r1, 0), XSTR (r2, 0));
+
+    case dw_val_class_offset:
+      return v1->v.val_offset == v2->v.val_offset;
+
+    case dw_val_class_loc:
+      for (loc1 = v1->v.val_loc, loc2 = v2->v.val_loc;
+	   loc1 && loc2;
+	   loc1 = loc1->dw_loc_next, loc2 = loc2->dw_loc_next)
+	if (!same_loc_p (loc1, loc2, mark))
+	  return 0;
+      return !loc1 && !loc2;
+
+    case dw_val_class_die_ref:
+      return same_die_p (v1->v.val_die_ref.die, v2->v.val_die_ref.die, mark);
+
+    case dw_val_class_fde_ref:
+    case dw_val_class_lbl_id:
+    case dw_val_class_lbl_offset:
+      return 1;
+
+    default:
+      return 1;
+    }
+}
+
+/* Do the attributes look the same?  */
+
+static int
+same_attr_p (dw_attr_ref at1, dw_attr_ref at2, int *mark)
+{
+  if (at1->dw_attr != at2->dw_attr)
+    return 0;
+
+  /* We don't care about differences in file numbering.  */
+  if (at1->dw_attr == DW_AT_decl_file
+      /* Or that this was compiled with a different compiler snapshot; if
+	 the output is the same, that's what matters.  */
+      || at1->dw_attr == DW_AT_producer)
+    return 1;
+
+  return same_dw_val_p (&at1->dw_attr_val, &at2->dw_attr_val, mark);
+}
+
+/* Do the dies look the same?  */
+
+static int
+same_die_p (dw_die_ref die1, dw_die_ref die2, int *mark)
+{
+  dw_die_ref c1, c2;
+  dw_attr_ref a1, a2;
+
+  /* To avoid infinite recursion.  */
+  if (die1->die_mark)
+    return die1->die_mark == die2->die_mark;
+  die1->die_mark = die2->die_mark = ++(*mark);
+
+  if (die1->die_tag != die2->die_tag)
+    return 0;
+
+  for (a1 = die1->die_attr, a2 = die2->die_attr;
+       a1 && a2;
+       a1 = a1->dw_attr_next, a2 = a2->dw_attr_next)
+    if (!same_attr_p (a1, a2, mark))
+      return 0;
+  if (a1 || a2)
+    return 0;
+
+  for (c1 = die1->die_child, c2 = die2->die_child;
+       c1 && c2;
+       c1 = c1->die_sib, c2 = c2->die_sib)
+    if (!same_die_p (c1, c2, mark))
+      return 0;
+  if (c1 || c2)
+    return 0;
+
+  return 1;
+}
+
+/* Do the dies look the same?  Wrapper around same_die_p.  */
+
+static int
+same_die_p_wrap (dw_die_ref die1, dw_die_ref die2)
+{
+  int mark = 0;
+  int ret = same_die_p (die1, die2, &mark);
+
+  unmark_all_dies (die1);
+  unmark_all_dies (die2);
+
+  return ret;
+}
+
+/* The prefix to attach to symbols on DIEs in the current comdat debug
+   info section.  */
+static char *comdat_symbol_id;
+
+/* The index of the current symbol within the current comdat CU.  */
+static unsigned int comdat_symbol_number;
+
+/* Calculate the MD5 checksum of the compilation unit DIE UNIT_DIE and its
+   children, and set comdat_symbol_id accordingly.  */
+
+static void
+compute_section_prefix (dw_die_ref unit_die)
+{
+  const char *die_name = get_AT_string (unit_die, DW_AT_name);
+  const char *base = die_name ? lbasename (die_name) : "anonymous";
+  char *name = alloca (strlen (base) + 64);
+  char *p;
+  int i, mark;
+  unsigned char checksum[16];
+  struct md5_ctx ctx;
+
+  /* Compute the checksum of the DIE, then append part of it as hex digits to
+     the name filename of the unit.  */
+
+  md5_init_ctx (&ctx);
+  mark = 0;
+  die_checksum (unit_die, &ctx, &mark);
+  unmark_all_dies (unit_die);
+  md5_finish_ctx (&ctx, checksum);
+
+  sprintf (name, "%s.", base);
+  clean_symbol_name (name);
+
+  p = name + strlen (name);
+  for (i = 0; i < 4; i++)
+    {
+      sprintf (p, "%.2x", checksum[i]);
+      p += 2;
+    }
+
+  comdat_symbol_id = unit_die->die_symbol = xstrdup (name);
+  comdat_symbol_number = 0;
+}
+
+/* Returns nonzero if DIE represents a type, in the sense of TYPE_P.  */
+
+static int
+is_type_die (dw_die_ref die)
+{
+  switch (die->die_tag)
+    {
+    case DW_TAG_array_type:
+    case DW_TAG_class_type:
+    case DW_TAG_enumeration_type:
+    case DW_TAG_pointer_type:
+    case DW_TAG_reference_type:
+    case DW_TAG_string_type:
+    case DW_TAG_structure_type:
+    case DW_TAG_subroutine_type:
+    case DW_TAG_union_type:
+    case DW_TAG_ptr_to_member_type:
+    case DW_TAG_set_type:
+    case DW_TAG_subrange_type:
+    case DW_TAG_base_type:
+    case DW_TAG_const_type:
+    case DW_TAG_file_type:
+    case DW_TAG_packed_type:
+    case DW_TAG_volatile_type:
+    case DW_TAG_typedef:
+      return 1;
+    default:
+      return 0;
+    }
+}
+
+/* Returns 1 iff C is the sort of DIE that should go into a COMDAT CU.
+   Basically, we want to choose the bits that are likely to be shared between
+   compilations (types) and leave out the bits that are specific to individual
+   compilations (functions).  */
+
+static int
+is_comdat_die (dw_die_ref c)
+{
+  /* I think we want to leave base types and __vtbl_ptr_type in the main CU, as
+     we do for stabs.  The advantage is a greater likelihood of sharing between
+     objects that don't include headers in the same order (and therefore would
+     put the base types in a different comdat).  jason 8/28/00 */
+
+  if (c->die_tag == DW_TAG_base_type)
+    return 0;
+
+  if (c->die_tag == DW_TAG_pointer_type
+      || c->die_tag == DW_TAG_reference_type
+      || c->die_tag == DW_TAG_const_type
+      || c->die_tag == DW_TAG_volatile_type)
+    {
+      dw_die_ref t = get_AT_ref (c, DW_AT_type);
+
+      return t ? is_comdat_die (t) : 0;
+    }
+
+  return is_type_die (c);
+}
+
+/* Returns 1 iff C is the sort of DIE that might be referred to from another
+   compilation unit.  */
+
+static int
+is_symbol_die (dw_die_ref c)
+{
+  return (is_type_die (c)
+	  || (get_AT (c, DW_AT_declaration)
+	      && !get_AT (c, DW_AT_specification)));
+}
+
+static char *
+gen_internal_sym (const char *prefix)
+{
+  char buf[256];
+
+  ASM_GENERATE_INTERNAL_LABEL (buf, prefix, label_num++);
+  return xstrdup (buf);
+}
+
+/* Assign symbols to all worthy DIEs under DIE.  */
+
+static void
+assign_symbol_names (dw_die_ref die)
+{
+  dw_die_ref c;
+
+  if (is_symbol_die (die))
+    {
+      if (comdat_symbol_id)
+	{
+	  char *p = alloca (strlen (comdat_symbol_id) + 64);
+
+	  sprintf (p, "%s.%s.%x", DIE_LABEL_PREFIX,
+		   comdat_symbol_id, comdat_symbol_number++);
+	  die->die_symbol = xstrdup (p);
+	}
+      else
+	die->die_symbol = gen_internal_sym ("LDIE");
+    }
+
+  for (c = die->die_child; c != NULL; c = c->die_sib)
+    assign_symbol_names (c);
+}
+
+struct cu_hash_table_entry
+{
+  dw_die_ref cu;
+  unsigned min_comdat_num, max_comdat_num;
+  struct cu_hash_table_entry *next;
+};
+
+/* Routines to manipulate hash table of CUs.  */
+static hashval_t
+htab_cu_hash (const void *of)
+{
+  const struct cu_hash_table_entry *entry = of;
+
+  return htab_hash_string (entry->cu->die_symbol);
+}
+
+static int
+htab_cu_eq (const void *of1, const void *of2)
+{
+  const struct cu_hash_table_entry *entry1 = of1;
+  const struct die_struct *entry2 = of2;
+
+  return !strcmp (entry1->cu->die_symbol, entry2->die_symbol);
+}
+
+static void
+htab_cu_del (void *what)
+{
+  struct cu_hash_table_entry *next, *entry = what;
+
+  while (entry)
+    {
+      next = entry->next;
+      free (entry);
+      entry = next;
+    }
+}
+
+/* Check whether we have already seen this CU and set up SYM_NUM
+   accordingly.  */
+static int
+check_duplicate_cu (dw_die_ref cu, htab_t htable, unsigned int *sym_num)
+{
+  struct cu_hash_table_entry dummy;
+  struct cu_hash_table_entry **slot, *entry, *last = &dummy;
+
+  dummy.max_comdat_num = 0;
+
+  slot = (struct cu_hash_table_entry **)
+    htab_find_slot_with_hash (htable, cu, htab_hash_string (cu->die_symbol),
+	INSERT);
+  entry = *slot;
+
+  for (; entry; last = entry, entry = entry->next)
+    {
+      if (same_die_p_wrap (cu, entry->cu))
+	break;
+    }
+
+  if (entry)
+    {
+      *sym_num = entry->min_comdat_num;
+      return 1;
+    }
+
+  entry = xcalloc (1, sizeof (struct cu_hash_table_entry));
+  entry->cu = cu;
+  entry->min_comdat_num = *sym_num = last->max_comdat_num;
+  entry->next = *slot;
+  *slot = entry;
+
+  return 0;
+}
+
+/* Record SYM_NUM to record of CU in HTABLE.  */
+static void
+record_comdat_symbol_number (dw_die_ref cu, htab_t htable, unsigned int sym_num)
+{
+  struct cu_hash_table_entry **slot, *entry;
+
+  slot = (struct cu_hash_table_entry **)
+    htab_find_slot_with_hash (htable, cu, htab_hash_string (cu->die_symbol),
+	NO_INSERT);
+  entry = *slot;
+
+  entry->max_comdat_num = sym_num;
+}
+
+/* Traverse the DIE (which is always comp_unit_die), and set up
+   additional compilation units for each of the include files we see
+   bracketed by BINCL/EINCL.  */
+
+static void
+break_out_includes (dw_die_ref die)
+{
+  dw_die_ref *ptr;
+  dw_die_ref unit = NULL;
+  limbo_die_node *node, **pnode;
+  htab_t cu_hash_table;
+
+  for (ptr = &(die->die_child); *ptr;)
+    {
+      dw_die_ref c = *ptr;
+
+      if (c->die_tag == DW_TAG_GNU_BINCL || c->die_tag == DW_TAG_GNU_EINCL
+	  || (unit && is_comdat_die (c)))
+	{
+	  /* This DIE is for a secondary CU; remove it from the main one.  */
+	  *ptr = c->die_sib;
+
+	  if (c->die_tag == DW_TAG_GNU_BINCL)
+	    {
+	      unit = push_new_compile_unit (unit, c);
+	      free_die (c);
+	    }
+	  else if (c->die_tag == DW_TAG_GNU_EINCL)
+	    {
+	      unit = pop_compile_unit (unit);
+	      free_die (c);
+	    }
+	  else
+	    add_child_die (unit, c);
+	}
+      else
+	{
+	  /* Leave this DIE in the main CU.  */
+	  ptr = &(c->die_sib);
+	  continue;
+	}
+    }
+
+#if 0
+  /* We can only use this in debugging, since the frontend doesn't check
+     to make sure that we leave every include file we enter.  */
+  gcc_assert (!unit);
+#endif
+
+  assign_symbol_names (die);
+  cu_hash_table = htab_create (10, htab_cu_hash, htab_cu_eq, htab_cu_del);
+  for (node = limbo_die_list, pnode = &limbo_die_list;
+       node;
+       node = node->next)
+    {
+      int is_dupl;
+
+      compute_section_prefix (node->die);
+      is_dupl = check_duplicate_cu (node->die, cu_hash_table,
+			&comdat_symbol_number);
+      assign_symbol_names (node->die);
+      if (is_dupl)
+	*pnode = node->next;
+      else
+	{
+	  pnode = &node->next;
+	  record_comdat_symbol_number (node->die, cu_hash_table,
+		comdat_symbol_number);
+	}
+    }
+  htab_delete (cu_hash_table);
+}
+
+/* Traverse the DIE and add a sibling attribute if it may have the
+   effect of speeding up access to siblings.  To save some space,
+   avoid generating sibling attributes for DIE's without children.  */
+
+static void
+add_sibling_attributes (dw_die_ref die)
+{
+  dw_die_ref c;
+
+  if (die->die_tag != DW_TAG_compile_unit
+      && die->die_sib && die->die_child != NULL)
+    /* Add the sibling link to the front of the attribute list.  */
+    add_AT_die_ref (die, DW_AT_sibling, die->die_sib);
+
+  for (c = die->die_child; c != NULL; c = c->die_sib)
+    add_sibling_attributes (c);
+}
+
+/* Output all location lists for the DIE and its children.  */
+
+static void
+output_location_lists (dw_die_ref die)
+{
+  dw_die_ref c;
+  dw_attr_ref d_attr;
+
+  for (d_attr = die->die_attr; d_attr; d_attr = d_attr->dw_attr_next)
+    if (AT_class (d_attr) == dw_val_class_loc_list)
+      output_loc_list (AT_loc_list (d_attr));
+
+  for (c = die->die_child; c != NULL; c = c->die_sib)
+    output_location_lists (c);
+
+}
+
+/* The format of each DIE (and its attribute value pairs) is encoded in an
+   abbreviation table.  This routine builds the abbreviation table and assigns
+   a unique abbreviation id for each abbreviation entry.  The children of each
+   die are visited recursively.  */
+
+static void
+build_abbrev_table (dw_die_ref die)
+{
+  unsigned long abbrev_id;
+  unsigned int n_alloc;
+  dw_die_ref c;
+  dw_attr_ref d_attr, a_attr;
+
+  /* Scan the DIE references, and mark as external any that refer to
+     DIEs from other CUs (i.e. those which are not marked).  */
+  for (d_attr = die->die_attr; d_attr; d_attr = d_attr->dw_attr_next)
+    if (AT_class (d_attr) == dw_val_class_die_ref
+	&& AT_ref (d_attr)->die_mark == 0)
+      {
+	gcc_assert (AT_ref (d_attr)->die_symbol);
+
+	set_AT_ref_external (d_attr, 1);
+      }
+
+  for (abbrev_id = 1; abbrev_id < abbrev_die_table_in_use; ++abbrev_id)
+    {
+      dw_die_ref abbrev = abbrev_die_table[abbrev_id];
+
+      if (abbrev->die_tag == die->die_tag)
+	{
+	  if ((abbrev->die_child != NULL) == (die->die_child != NULL))
+	    {
+	      a_attr = abbrev->die_attr;
+	      d_attr = die->die_attr;
+
+	      while (a_attr != NULL && d_attr != NULL)
+		{
+		  if ((a_attr->dw_attr != d_attr->dw_attr)
+		      || (value_format (a_attr) != value_format (d_attr)))
+		    break;
+
+		  a_attr = a_attr->dw_attr_next;
+		  d_attr = d_attr->dw_attr_next;
+		}
+
+	      if (a_attr == NULL && d_attr == NULL)
+		break;
+	    }
+	}
+    }
+
+  if (abbrev_id >= abbrev_die_table_in_use)
+    {
+      if (abbrev_die_table_in_use >= abbrev_die_table_allocated)
+	{
+	  n_alloc = abbrev_die_table_allocated + ABBREV_DIE_TABLE_INCREMENT;
+	  abbrev_die_table = ggc_realloc (abbrev_die_table,
+					  sizeof (dw_die_ref) * n_alloc);
+
+	  memset (&abbrev_die_table[abbrev_die_table_allocated], 0,
+		 (n_alloc - abbrev_die_table_allocated) * sizeof (dw_die_ref));
+	  abbrev_die_table_allocated = n_alloc;
+	}
+
+      ++abbrev_die_table_in_use;
+      abbrev_die_table[abbrev_id] = die;
+    }
+
+  die->die_abbrev = abbrev_id;
+  for (c = die->die_child; c != NULL; c = c->die_sib)
+    build_abbrev_table (c);
+}
+
+/* Return the power-of-two number of bytes necessary to represent VALUE.  */
+
+static int
+constant_size (long unsigned int value)
+{
+  int log;
+
+  if (value == 0)
+    log = 0;
+  else
+    log = floor_log2 (value);
+
+  log = log / 8;
+  log = 1 << (floor_log2 (log) + 1);
+
+  return log;
+}
+
+/* Return the size of a DIE as it is represented in the
+   .debug_info section.  */
+
+static unsigned long
+size_of_die (dw_die_ref die)
+{
+  unsigned long size = 0;
+  dw_attr_ref a;
+
+  size += size_of_uleb128 (die->die_abbrev);
+  for (a = die->die_attr; a != NULL; a = a->dw_attr_next)
+    {
+      switch (AT_class (a))
+	{
+	case dw_val_class_addr:
+	  size += DWARF2_ADDR_SIZE;
+	  break;
+	case dw_val_class_offset:
+	  size += DWARF_OFFSET_SIZE;
+	  break;
+	case dw_val_class_loc:
+	  {
+	    unsigned long lsize = size_of_locs (AT_loc (a));
+
+	    /* Block length.  */
+	    size += constant_size (lsize);
+	    size += lsize;
+	  }
+	  break;
+	case dw_val_class_loc_list:
+	  size += DWARF_OFFSET_SIZE;
+	  break;
+	case dw_val_class_range_list:
+	  size += DWARF_OFFSET_SIZE;
+	  break;
+	case dw_val_class_const:
+	  size += size_of_sleb128 (AT_int (a));
+	  break;
+	case dw_val_class_unsigned_const:
+	  size += constant_size (AT_unsigned (a));
+	  break;
+	case dw_val_class_long_long:
+	  size += 1 + 2*HOST_BITS_PER_LONG/HOST_BITS_PER_CHAR; /* block */
+	  break;
+	case dw_val_class_vec:
+	  size += 1 + (a->dw_attr_val.v.val_vec.length
+		       * a->dw_attr_val.v.val_vec.elt_size); /* block */
+	  break;
+	case dw_val_class_flag:
+	  size += 1;
+	  break;
+	case dw_val_class_die_ref:
+	  if (AT_ref_external (a))
+	    size += DWARF2_ADDR_SIZE;
+	  else
+	    size += DWARF_OFFSET_SIZE;
+	  break;
+	case dw_val_class_fde_ref:
+	  size += DWARF_OFFSET_SIZE;
+	  break;
+	case dw_val_class_lbl_id:
+	  size += DWARF2_ADDR_SIZE;
+	  break;
+	case dw_val_class_lbl_offset:
+	  size += DWARF_OFFSET_SIZE;
+	  break;
+	case dw_val_class_str:
+	  if (AT_string_form (a) == DW_FORM_strp)
+	    size += DWARF_OFFSET_SIZE;
+	  else
+	    size += strlen (a->dw_attr_val.v.val_str->str) + 1;
+	  break;
+	default:
+	  gcc_unreachable ();
+	}
+    }
+
+  return size;
+}
+
+/* Size the debugging information associated with a given DIE.  Visits the
+   DIE's children recursively.  Updates the global variable next_die_offset, on
+   each time through.  Uses the current value of next_die_offset to update the
+   die_offset field in each DIE.  */
+
+static void
+calc_die_sizes (dw_die_ref die)
+{
+  dw_die_ref c;
+
+  die->die_offset = next_die_offset;
+  next_die_offset += size_of_die (die);
+
+  for (c = die->die_child; c != NULL; c = c->die_sib)
+    calc_die_sizes (c);
+
+  if (die->die_child != NULL)
+    /* Count the null byte used to terminate sibling lists.  */
+    next_die_offset += 1;
+}
+
+/* Set the marks for a die and its children.  We do this so
+   that we know whether or not a reference needs to use FORM_ref_addr; only
+   DIEs in the same CU will be marked.  We used to clear out the offset
+   and use that as the flag, but ran into ordering problems.  */
+
+static void
+mark_dies (dw_die_ref die)
+{
+  dw_die_ref c;
+
+  gcc_assert (!die->die_mark);
+
+  die->die_mark = 1;
+  for (c = die->die_child; c; c = c->die_sib)
+    mark_dies (c);
+}
+
+/* Clear the marks for a die and its children.  */
+
+static void
+unmark_dies (dw_die_ref die)
+{
+  dw_die_ref c;
+
+  gcc_assert (die->die_mark);
+
+  die->die_mark = 0;
+  for (c = die->die_child; c; c = c->die_sib)
+    unmark_dies (c);
+}
+
+/* Clear the marks for a die, its children and referred dies.  */
+
+static void
+unmark_all_dies (dw_die_ref die)
+{
+  dw_die_ref c;
+  dw_attr_ref a;
+
+  if (!die->die_mark)
+    return;
+  die->die_mark = 0;
+
+  for (c = die->die_child; c; c = c->die_sib)
+    unmark_all_dies (c);
+
+  for (a = die->die_attr; a; a = a->dw_attr_next)
+    if (AT_class (a) == dw_val_class_die_ref)
+      unmark_all_dies (AT_ref (a));
+}
+
+/* Return the size of the .debug_pubnames table  generated for the
+   compilation unit.  */
+
+static unsigned long
+size_of_pubnames (void)
+{
+  unsigned long size;
+  unsigned i;
+
+  size = DWARF_PUBNAMES_HEADER_SIZE;
+  for (i = 0; i < pubname_table_in_use; i++)
+    {
+      pubname_ref p = &pubname_table[i];
+      size += DWARF_OFFSET_SIZE + strlen (p->name) + 1;
+    }
+
+  size += DWARF_OFFSET_SIZE;
+  return size;
+}
+
+/* Return the size of the information in the .debug_aranges section.  */
+
+static unsigned long
+size_of_aranges (void)
+{
+  unsigned long size;
+
+  size = DWARF_ARANGES_HEADER_SIZE;
+
+  /* Count the address/length pair for this compilation unit.  */
+  size += 2 * DWARF2_ADDR_SIZE;
+  size += 2 * DWARF2_ADDR_SIZE * arange_table_in_use;
+
+  /* Count the two zero words used to terminated the address range table.  */
+  size += 2 * DWARF2_ADDR_SIZE;
+  return size;
+}
+
+/* Select the encoding of an attribute value.  */
+
+static enum dwarf_form
+value_format (dw_attr_ref a)
+{
+  switch (a->dw_attr_val.val_class)
+    {
+    case dw_val_class_addr:
+      return DW_FORM_addr;
+    case dw_val_class_range_list:
+    case dw_val_class_offset:
+      switch (DWARF_OFFSET_SIZE)
+	{
+	case 4:
+	  return DW_FORM_data4;
+	case 8:
+	  return DW_FORM_data8;
+	default:
+	  gcc_unreachable ();
+	}
+    case dw_val_class_loc_list:
+      /* FIXME: Could be DW_FORM_data8, with a > 32 bit size
+	 .debug_loc section */
+      return DW_FORM_data4;
+    case dw_val_class_loc:
+      switch (constant_size (size_of_locs (AT_loc (a))))
+	{
+	case 1:
+	  return DW_FORM_block1;
+	case 2:
+	  return DW_FORM_block2;
+	default:
+	  gcc_unreachable ();
+	}
+    case dw_val_class_const:
+      return DW_FORM_sdata;
+    case dw_val_class_unsigned_const:
+      switch (constant_size (AT_unsigned (a)))
+	{
+	case 1:
+	  return DW_FORM_data1;
+	case 2:
+	  return DW_FORM_data2;
+	case 4:
+	  return DW_FORM_data4;
+	case 8:
+	  return DW_FORM_data8;
+	default:
+	  gcc_unreachable ();
+	}
+    case dw_val_class_long_long:
+      return DW_FORM_block1;
+    case dw_val_class_vec:
+      return DW_FORM_block1;
+    case dw_val_class_flag:
+      return DW_FORM_flag;
+    case dw_val_class_die_ref:
+      if (AT_ref_external (a))
+	return DW_FORM_ref_addr;
+      else
+	return DW_FORM_ref;
+    case dw_val_class_fde_ref:
+      return DW_FORM_data;
+    case dw_val_class_lbl_id:
+      return DW_FORM_addr;
+    case dw_val_class_lbl_offset:
+      return DW_FORM_data;
+    case dw_val_class_str:
+      return AT_string_form (a);
+
+    default:
+      gcc_unreachable ();
+    }
+}
+
+/* Output the encoding of an attribute value.  */
+
+static void
+output_value_format (dw_attr_ref a)
+{
+  enum dwarf_form form = value_format (a);
+
+  dw2_asm_output_data_uleb128 (form, "(%s)", dwarf_form_name (form));
+}
+
+/* Output the .debug_abbrev section which defines the DIE abbreviation
+   table.  */
+
+static void
+output_abbrev_section (void)
+{
+  unsigned long abbrev_id;
+
+  dw_attr_ref a_attr;
+
+  for (abbrev_id = 1; abbrev_id < abbrev_die_table_in_use; ++abbrev_id)
+    {
+      dw_die_ref abbrev = abbrev_die_table[abbrev_id];
+
+      dw2_asm_output_data_uleb128 (abbrev_id, "(abbrev code)");
+      dw2_asm_output_data_uleb128 (abbrev->die_tag, "(TAG: %s)",
+				   dwarf_tag_name (abbrev->die_tag));
+
+      if (abbrev->die_child != NULL)
+	dw2_asm_output_data (1, DW_children_yes, "DW_children_yes");
+      else
+	dw2_asm_output_data (1, DW_children_no, "DW_children_no");
+
+      for (a_attr = abbrev->die_attr; a_attr != NULL;
+	   a_attr = a_attr->dw_attr_next)
+	{
+	  dw2_asm_output_data_uleb128 (a_attr->dw_attr, "(%s)",
+				       dwarf_attr_name (a_attr->dw_attr));
+	  output_value_format (a_attr);
+	}
+
+      dw2_asm_output_data (1, 0, NULL);
+      dw2_asm_output_data (1, 0, NULL);
+    }
+
+  /* Terminate the table.  */
+  dw2_asm_output_data (1, 0, NULL);
+}
+
+/* Output a symbol we can use to refer to this DIE from another CU.  */
+
+static inline void
+output_die_symbol (dw_die_ref die)
+{
+  char *sym = die->die_symbol;
+
+  if (sym == 0)
+    return;
+
+  if (strncmp (sym, DIE_LABEL_PREFIX, sizeof (DIE_LABEL_PREFIX) - 1) == 0)
+    /* We make these global, not weak; if the target doesn't support
+       .linkonce, it doesn't support combining the sections, so debugging
+       will break.  */
+    targetm.asm_out.globalize_label (asm_out_file, sym);
+
+  ASM_OUTPUT_LABEL (asm_out_file, sym);
+}
+
+/* Return a new location list, given the begin and end range, and the
+   expression. gensym tells us whether to generate a new internal symbol for
+   this location list node, which is done for the head of the list only.  */
+
+static inline dw_loc_list_ref
+new_loc_list (dw_loc_descr_ref expr, const char *begin, const char *end,
+	      const char *section, unsigned int gensym)
+{
+  dw_loc_list_ref retlist = ggc_alloc_cleared (sizeof (dw_loc_list_node));
+
+  retlist->begin = begin;
+  retlist->end = end;
+  retlist->expr = expr;
+  retlist->section = section;
+  if (gensym)
+    retlist->ll_symbol = gen_internal_sym ("LLST");
+
+  return retlist;
+}
+
+/* Add a location description expression to a location list.  */
+
+static inline void
+add_loc_descr_to_loc_list (dw_loc_list_ref *list_head, dw_loc_descr_ref descr,
+			   const char *begin, const char *end,
+			   const char *section)
+{
+  dw_loc_list_ref *d;
+
+  /* Find the end of the chain.  */
+  for (d = list_head; (*d) != NULL; d = &(*d)->dw_loc_next)
+    ;
+
+  /* Add a new location list node to the list.  */
+  *d = new_loc_list (descr, begin, end, section, 0);
+}
+
+static void
+dwarf2out_switch_text_section (void)
+{
+  dw_fde_ref fde;
+
+  gcc_assert (cfun);
+
+  fde = &fde_table[fde_table_in_use - 1];
+  fde->dw_fde_switched_sections = true;
+  fde->dw_fde_hot_section_label = cfun->hot_section_label;
+  fde->dw_fde_hot_section_end_label = cfun->hot_section_end_label;
+  fde->dw_fde_unlikely_section_label = cfun->cold_section_label;
+  fde->dw_fde_unlikely_section_end_label = cfun->cold_section_end_label;
+  have_switched_text_section = true;
+}
+
+/* Output the location list given to us.  */
+
+static void
+output_loc_list (dw_loc_list_ref list_head)
+{
+  dw_loc_list_ref curr = list_head;
+
+  ASM_OUTPUT_LABEL (asm_out_file, list_head->ll_symbol);
+
+  /* Walk the location list, and output each range + expression.  */
+  for (curr = list_head; curr != NULL; curr = curr->dw_loc_next)
+    {
+      unsigned long size;
+      if (!separate_line_info_table_in_use && !have_switched_text_section)
+	{
+	  dw2_asm_output_delta (DWARF2_ADDR_SIZE, curr->begin, curr->section,
+				"Location list begin address (%s)",
+				list_head->ll_symbol);
+	  dw2_asm_output_delta (DWARF2_ADDR_SIZE, curr->end, curr->section,
+				"Location list end address (%s)",
+				list_head->ll_symbol);
+	}
+      else
+	{
+	  dw2_asm_output_addr (DWARF2_ADDR_SIZE, curr->begin,
+			       "Location list begin address (%s)",
+			       list_head->ll_symbol);
+	  dw2_asm_output_addr (DWARF2_ADDR_SIZE, curr->end,
+			       "Location list end address (%s)",
+			       list_head->ll_symbol);
+	}
+      size = size_of_locs (curr->expr);
+
+      /* Output the block length for this list of location operations.  */
+      gcc_assert (size <= 0xffff);
+      dw2_asm_output_data (2, size, "%s", "Location expression size");
+
+      output_loc_sequence (curr->expr);
+    }
+
+  dw2_asm_output_data (DWARF2_ADDR_SIZE, 0,
+		       "Location list terminator begin (%s)",
+		       list_head->ll_symbol);
+  dw2_asm_output_data (DWARF2_ADDR_SIZE, 0,
+		       "Location list terminator end (%s)",
+		       list_head->ll_symbol);
+}
+
+/* Output the DIE and its attributes.  Called recursively to generate
+   the definitions of each child DIE.  */
+
+static void
+output_die (dw_die_ref die)
+{
+  dw_attr_ref a;
+  dw_die_ref c;
+  unsigned long size;
+
+  /* If someone in another CU might refer to us, set up a symbol for
+     them to point to.  */
+  if (die->die_symbol)
+    output_die_symbol (die);
+
+  dw2_asm_output_data_uleb128 (die->die_abbrev, "(DIE (0x%lx) %s)",
+			       die->die_offset, dwarf_tag_name (die->die_tag));
+
+  for (a = die->die_attr; a != NULL; a = a->dw_attr_next)
+    {
+      const char *name = dwarf_attr_name (a->dw_attr);
+
+      switch (AT_class (a))
+	{
+	case dw_val_class_addr:
+	  dw2_asm_output_addr_rtx (DWARF2_ADDR_SIZE, AT_addr (a), "%s", name);
+	  break;
+
+	case dw_val_class_offset:
+	  dw2_asm_output_data (DWARF_OFFSET_SIZE, a->dw_attr_val.v.val_offset,
+			       "%s", name);
+	  break;
+
+	case dw_val_class_range_list:
+	  {
+	    char *p = strchr (ranges_section_label, '\0');
+
+	    sprintf (p, "+" HOST_WIDE_INT_PRINT_HEX,
+		     a->dw_attr_val.v.val_offset);
+	    dw2_asm_output_offset (DWARF_OFFSET_SIZE, ranges_section_label,
+				   "%s", name);
+	    *p = '\0';
+	  }
+	  break;
+
+	case dw_val_class_loc:
+	  size = size_of_locs (AT_loc (a));
+
+	  /* Output the block length for this list of location operations.  */
+	  dw2_asm_output_data (constant_size (size), size, "%s", name);
+
+	  output_loc_sequence (AT_loc (a));
+	  break;
+
+	case dw_val_class_const:
+	  /* ??? It would be slightly more efficient to use a scheme like is
+	     used for unsigned constants below, but gdb 4.x does not sign
+	     extend.  Gdb 5.x does sign extend.  */
+	  dw2_asm_output_data_sleb128 (AT_int (a), "%s", name);
+	  break;
+
+	case dw_val_class_unsigned_const:
+	  dw2_asm_output_data (constant_size (AT_unsigned (a)),
+			       AT_unsigned (a), "%s", name);
+	  break;
+
+	case dw_val_class_long_long:
+	  {
+	    unsigned HOST_WIDE_INT first, second;
+
+	    dw2_asm_output_data (1,
+				 2 * HOST_BITS_PER_LONG / HOST_BITS_PER_CHAR,
+				 "%s", name);
+
+	    if (WORDS_BIG_ENDIAN)
+	      {
+		first = a->dw_attr_val.v.val_long_long.hi;
+		second = a->dw_attr_val.v.val_long_long.low;
+	      }
+	    else
+	      {
+		first = a->dw_attr_val.v.val_long_long.low;
+		second = a->dw_attr_val.v.val_long_long.hi;
+	      }
+
+	    dw2_asm_output_data (HOST_BITS_PER_LONG / HOST_BITS_PER_CHAR,
+				 first, "long long constant");
+	    dw2_asm_output_data (HOST_BITS_PER_LONG / HOST_BITS_PER_CHAR,
+				 second, NULL);
+	  }
+	  break;
+
+	case dw_val_class_vec:
+	  {
+	    unsigned int elt_size = a->dw_attr_val.v.val_vec.elt_size;
+	    unsigned int len = a->dw_attr_val.v.val_vec.length;
+	    unsigned int i;
+	    unsigned char *p;
+
+	    dw2_asm_output_data (1, len * elt_size, "%s", name);
+	    if (elt_size > sizeof (HOST_WIDE_INT))
+	      {
+		elt_size /= 2;
+		len *= 2;
+	      }
+	    for (i = 0, p = a->dw_attr_val.v.val_vec.array;
+		 i < len;
+		 i++, p += elt_size)
+	      dw2_asm_output_data (elt_size, extract_int (p, elt_size),
+				   "fp or vector constant word %u", i);
+	    break;
+	  }
+
+	case dw_val_class_flag:
+	  dw2_asm_output_data (1, AT_flag (a), "%s", name);
+	  break;
+
+	case dw_val_class_loc_list:
+	  {
+	    char *sym = AT_loc_list (a)->ll_symbol;
+
+	    gcc_assert (sym);
+	    dw2_asm_output_offset (DWARF_OFFSET_SIZE, sym, "%s", name);
+	  }
+	  break;
+
+	case dw_val_class_die_ref:
+	  if (AT_ref_external (a))
+	    {
+	      char *sym = AT_ref (a)->die_symbol;
+
+	      gcc_assert (sym);
+	      dw2_asm_output_offset (DWARF2_ADDR_SIZE, sym, "%s", name);
+	    }
+	  else
+	    {
+	      gcc_assert (AT_ref (a)->die_offset);
+	      dw2_asm_output_data (DWARF_OFFSET_SIZE, AT_ref (a)->die_offset,
+				   "%s", name);
+	    }
+	  break;
+
+	case dw_val_class_fde_ref:
+	  {
+	    char l1[20];
+
+	    ASM_GENERATE_INTERNAL_LABEL (l1, FDE_LABEL,
+					 a->dw_attr_val.v.val_fde_index * 2);
+	    dw2_asm_output_offset (DWARF_OFFSET_SIZE, l1, "%s", name);
+	  }
+	  break;
+
+	case dw_val_class_lbl_id:
+	  dw2_asm_output_addr (DWARF2_ADDR_SIZE, AT_lbl (a), "%s", name);
+	  break;
+
+	case dw_val_class_lbl_offset:
+	  dw2_asm_output_offset (DWARF_OFFSET_SIZE, AT_lbl (a), "%s", name);
+	  break;
+
+	case dw_val_class_str:
+	  if (AT_string_form (a) == DW_FORM_strp)
+	    dw2_asm_output_offset (DWARF_OFFSET_SIZE,
+				   a->dw_attr_val.v.val_str->label,
+				   "%s: \"%s\"", name, AT_string (a));
+	  else
+	    dw2_asm_output_nstring (AT_string (a), -1, "%s", name);
+	  break;
+
+	default:
+	  gcc_unreachable ();
+	}
+    }
+
+  for (c = die->die_child; c != NULL; c = c->die_sib)
+    output_die (c);
+
+  /* Add null byte to terminate sibling list.  */
+  if (die->die_child != NULL)
+    dw2_asm_output_data (1, 0, "end of children of DIE 0x%lx",
+			 die->die_offset);
+}
+
+/* Output the compilation unit that appears at the beginning of the
+   .debug_info section, and precedes the DIE descriptions.  */
+
+static void
+output_compilation_unit_header (void)
+{
+  if (DWARF_INITIAL_LENGTH_SIZE - DWARF_OFFSET_SIZE == 4)
+    dw2_asm_output_data (4, 0xffffffff,
+      "Initial length escape value indicating 64-bit DWARF extension");
+  dw2_asm_output_data (DWARF_OFFSET_SIZE,
+                       next_die_offset - DWARF_INITIAL_LENGTH_SIZE,
+		       "Length of Compilation Unit Info");
+  dw2_asm_output_data (2, DWARF_VERSION, "DWARF version number");
+  dw2_asm_output_offset (DWARF_OFFSET_SIZE, abbrev_section_label,
+			 "Offset Into Abbrev. Section");
+  dw2_asm_output_data (1, DWARF2_ADDR_SIZE, "Pointer Size (in bytes)");
+}
+
+/* Output the compilation unit DIE and its children.  */
+
+static void
+output_comp_unit (dw_die_ref die, int output_if_empty)
+{
+  const char *secname;
+  char *oldsym, *tmp;
+
+  /* Unless we are outputting main CU, we may throw away empty ones.  */
+  if (!output_if_empty && die->die_child == NULL)
+    return;
+
+  /* Even if there are no children of this DIE, we must output the information
+     about the compilation unit.  Otherwise, on an empty translation unit, we
+     will generate a present, but empty, .debug_info section.  IRIX 6.5 `nm'
+     will then complain when examining the file.  First mark all the DIEs in
+     this CU so we know which get local refs.  */
+  mark_dies (die);
+
+  build_abbrev_table (die);
+
+  /* Initialize the beginning DIE offset - and calculate sizes/offsets.  */
+  next_die_offset = DWARF_COMPILE_UNIT_HEADER_SIZE;
+  calc_die_sizes (die);
+
+  oldsym = die->die_symbol;
+  if (oldsym)
+    {
+      tmp = alloca (strlen (oldsym) + 24);
+
+      sprintf (tmp, ".gnu.linkonce.wi.%s", oldsym);
+      secname = tmp;
+      die->die_symbol = NULL;
+    }
+  else
+    secname = (const char *) DEBUG_INFO_SECTION;
+
+  /* Output debugging information.  */
+  named_section_flags (secname, SECTION_DEBUG);
+  output_compilation_unit_header ();
+  output_die (die);
+
+  /* Leave the marks on the main CU, so we can check them in
+     output_pubnames.  */
+  if (oldsym)
+    {
+      unmark_dies (die);
+      die->die_symbol = oldsym;
+    }
+}
+
+/* The DWARF2 pubname for a nested thingy looks like "A::f".  The
+   output of lang_hooks.decl_printable_name for C++ looks like
+   "A::f(int)".  Let's drop the argument list, and maybe the scope.  */
+
+static const char *
+dwarf2_name (tree decl, int scope)
+{
+  return lang_hooks.decl_printable_name (decl, scope ? 1 : 0);
+}
+
+/* Add a new entry to .debug_pubnames if appropriate.  */
+
+static void
+add_pubname (tree decl, dw_die_ref die)
+{
+  pubname_ref p;
+
+  if (! TREE_PUBLIC (decl))
+    return;
+
+  if (pubname_table_in_use == pubname_table_allocated)
+    {
+      pubname_table_allocated += PUBNAME_TABLE_INCREMENT;
+      pubname_table
+	= ggc_realloc (pubname_table,
+		       (pubname_table_allocated * sizeof (pubname_entry)));
+      memset (pubname_table + pubname_table_in_use, 0,
+	      PUBNAME_TABLE_INCREMENT * sizeof (pubname_entry));
+    }
+
+  p = &pubname_table[pubname_table_in_use++];
+  p->die = die;
+  p->name = xstrdup (dwarf2_name (decl, 1));
+}
+
+/* Output the public names table used to speed up access to externally
+   visible names.  For now, only generate entries for externally
+   visible procedures.  */
+
+static void
+output_pubnames (void)
+{
+  unsigned i;
+  unsigned long pubnames_length = size_of_pubnames ();
+
+  if (DWARF_INITIAL_LENGTH_SIZE - DWARF_OFFSET_SIZE == 4)
+    dw2_asm_output_data (4, 0xffffffff,
+      "Initial length escape value indicating 64-bit DWARF extension");
+  dw2_asm_output_data (DWARF_OFFSET_SIZE, pubnames_length,
+		       "Length of Public Names Info");
+  dw2_asm_output_data (2, DWARF_VERSION, "DWARF Version");
+  dw2_asm_output_offset (DWARF_OFFSET_SIZE, debug_info_section_label,
+			 "Offset of Compilation Unit Info");
+  dw2_asm_output_data (DWARF_OFFSET_SIZE, next_die_offset,
+		       "Compilation Unit Length");
+
+  for (i = 0; i < pubname_table_in_use; i++)
+    {
+      pubname_ref pub = &pubname_table[i];
+
+      /* We shouldn't see pubnames for DIEs outside of the main CU.  */
+      gcc_assert (pub->die->die_mark);
+
+      dw2_asm_output_data (DWARF_OFFSET_SIZE, pub->die->die_offset,
+			   "DIE offset");
+
+      dw2_asm_output_nstring (pub->name, -1, "external name");
+    }
+
+  dw2_asm_output_data (DWARF_OFFSET_SIZE, 0, NULL);
+}
+
+/* Add a new entry to .debug_aranges if appropriate.  */
+
+static void
+add_arange (tree decl, dw_die_ref die)
+{
+  if (! DECL_SECTION_NAME (decl))
+    return;
+
+  if (arange_table_in_use == arange_table_allocated)
+    {
+      arange_table_allocated += ARANGE_TABLE_INCREMENT;
+      arange_table = ggc_realloc (arange_table,
+				  (arange_table_allocated
+				   * sizeof (dw_die_ref)));
+      memset (arange_table + arange_table_in_use, 0,
+	      ARANGE_TABLE_INCREMENT * sizeof (dw_die_ref));
+    }
+
+  arange_table[arange_table_in_use++] = die;
+}
+
+/* Output the information that goes into the .debug_aranges table.
+   Namely, define the beginning and ending address range of the
+   text section generated for this compilation unit.  */
+
+static void
+output_aranges (void)
+{
+  unsigned i;
+  unsigned long aranges_length = size_of_aranges ();
+
+  if (DWARF_INITIAL_LENGTH_SIZE - DWARF_OFFSET_SIZE == 4)
+    dw2_asm_output_data (4, 0xffffffff,
+      "Initial length escape value indicating 64-bit DWARF extension");
+  dw2_asm_output_data (DWARF_OFFSET_SIZE, aranges_length,
+		       "Length of Address Ranges Info");
+  dw2_asm_output_data (2, DWARF_VERSION, "DWARF Version");
+  dw2_asm_output_offset (DWARF_OFFSET_SIZE, debug_info_section_label,
+			 "Offset of Compilation Unit Info");
+  dw2_asm_output_data (1, DWARF2_ADDR_SIZE, "Size of Address");
+  dw2_asm_output_data (1, 0, "Size of Segment Descriptor");
+
+  /* We need to align to twice the pointer size here.  */
+  if (DWARF_ARANGES_PAD_SIZE)
+    {
+      /* Pad using a 2 byte words so that padding is correct for any
+	 pointer size.  */
+      dw2_asm_output_data (2, 0, "Pad to %d byte boundary",
+			   2 * DWARF2_ADDR_SIZE);
+      for (i = 2; i < (unsigned) DWARF_ARANGES_PAD_SIZE; i += 2)
+	dw2_asm_output_data (2, 0, NULL);
+    }
+
+  dw2_asm_output_addr (DWARF2_ADDR_SIZE, text_section_label, "Address");
+  dw2_asm_output_delta (DWARF2_ADDR_SIZE, text_end_label,
+			text_section_label, "Length");
+  if (flag_reorder_blocks_and_partition)
+    {
+      dw2_asm_output_addr (DWARF2_ADDR_SIZE, cold_text_section_label, 
+			   "Address");
+      dw2_asm_output_delta (DWARF2_ADDR_SIZE, cold_end_label,
+			    cold_text_section_label, "Length");
+    }
+
+  for (i = 0; i < arange_table_in_use; i++)
+    {
+      dw_die_ref die = arange_table[i];
+
+      /* We shouldn't see aranges for DIEs outside of the main CU.  */
+      gcc_assert (die->die_mark);
+
+      if (die->die_tag == DW_TAG_subprogram)
+	{
+	  dw2_asm_output_addr (DWARF2_ADDR_SIZE, get_AT_low_pc (die),
+			       "Address");
+	  dw2_asm_output_delta (DWARF2_ADDR_SIZE, get_AT_hi_pc (die),
+				get_AT_low_pc (die), "Length");
+	}
+      else
+	{
+	  /* A static variable; extract the symbol from DW_AT_location.
+	     Note that this code isn't currently hit, as we only emit
+	     aranges for functions (jason 9/23/99).  */
+	  dw_attr_ref a = get_AT (die, DW_AT_location);
+	  dw_loc_descr_ref loc;
+
+	  gcc_assert (a && AT_class (a) == dw_val_class_loc);
+
+	  loc = AT_loc (a);
+	  gcc_assert (loc->dw_loc_opc == DW_OP_addr);
+
+	  dw2_asm_output_addr_rtx (DWARF2_ADDR_SIZE,
+				   loc->dw_loc_oprnd1.v.val_addr, "Address");
+	  dw2_asm_output_data (DWARF2_ADDR_SIZE,
+			       get_AT_unsigned (die, DW_AT_byte_size),
+			       "Length");
+	}
+    }
+
+  /* Output the terminator words.  */
+  dw2_asm_output_data (DWARF2_ADDR_SIZE, 0, NULL);
+  dw2_asm_output_data (DWARF2_ADDR_SIZE, 0, NULL);
+}
+
+/* Add a new entry to .debug_ranges.  Return the offset at which it
+   was placed.  */
+
+static unsigned int
+add_ranges (tree block)
+{
+  unsigned int in_use = ranges_table_in_use;
+
+  if (in_use == ranges_table_allocated)
+    {
+      ranges_table_allocated += RANGES_TABLE_INCREMENT;
+      ranges_table
+	= ggc_realloc (ranges_table, (ranges_table_allocated
+				      * sizeof (struct dw_ranges_struct)));
+      memset (ranges_table + ranges_table_in_use, 0,
+	      RANGES_TABLE_INCREMENT * sizeof (struct dw_ranges_struct));
+    }
+
+  ranges_table[in_use].block_num = (block ? BLOCK_NUMBER (block) : 0);
+  ranges_table_in_use = in_use + 1;
+
+  return in_use * 2 * DWARF2_ADDR_SIZE;
+}
+
+static void
+output_ranges (void)
+{
+  unsigned i;
+  static const char *const start_fmt = "Offset 0x%x";
+  const char *fmt = start_fmt;
+
+  for (i = 0; i < ranges_table_in_use; i++)
+    {
+      int block_num = ranges_table[i].block_num;
+
+      if (block_num)
+	{
+	  char blabel[MAX_ARTIFICIAL_LABEL_BYTES];
+	  char elabel[MAX_ARTIFICIAL_LABEL_BYTES];
+
+	  ASM_GENERATE_INTERNAL_LABEL (blabel, BLOCK_BEGIN_LABEL, block_num);
+	  ASM_GENERATE_INTERNAL_LABEL (elabel, BLOCK_END_LABEL, block_num);
+
+	  /* If all code is in the text section, then the compilation
+	     unit base address defaults to DW_AT_low_pc, which is the
+	     base of the text section.  */
+	  if (!separate_line_info_table_in_use && !have_switched_text_section)
+	    {
+	      dw2_asm_output_delta (DWARF2_ADDR_SIZE, blabel,
+				    text_section_label,
+				    fmt, i * 2 * DWARF2_ADDR_SIZE);
+	      dw2_asm_output_delta (DWARF2_ADDR_SIZE, elabel,
+				    text_section_label, NULL);
+	    }
+
+	  /* Otherwise, we add a DW_AT_entry_pc attribute to force the
+	     compilation unit base address to zero, which allows us to
+	     use absolute addresses, and not worry about whether the
+	     target supports cross-section arithmetic.  */
+	  else
+	    {
+	      dw2_asm_output_addr (DWARF2_ADDR_SIZE, blabel,
+				   fmt, i * 2 * DWARF2_ADDR_SIZE);
+	      dw2_asm_output_addr (DWARF2_ADDR_SIZE, elabel, NULL);
+	    }
+
+	  fmt = NULL;
+	}
+      else
+	{
+	  dw2_asm_output_data (DWARF2_ADDR_SIZE, 0, NULL);
+	  dw2_asm_output_data (DWARF2_ADDR_SIZE, 0, NULL);
+	  fmt = start_fmt;
+	}
+    }
+}
+
+/* Data structure containing information about input files.  */
+struct file_info
+{
+  char *path;		/* Complete file name.  */
+  char *fname;		/* File name part.  */
+  int length;		/* Length of entire string.  */
+  int file_idx;		/* Index in input file table.  */
+  int dir_idx;		/* Index in directory table.  */
+};
+
+/* Data structure containing information about directories with source
+   files.  */
+struct dir_info
+{
+  char *path;		/* Path including directory name.  */
+  int length;		/* Path length.  */
+  int prefix;		/* Index of directory entry which is a prefix.  */
+  int count;		/* Number of files in this directory.  */
+  int dir_idx;		/* Index of directory used as base.  */
+  int used;		/* Used in the end?  */
+};
+
+/* Callback function for file_info comparison.  We sort by looking at
+   the directories in the path.  */
+
+static int
+file_info_cmp (const void *p1, const void *p2)
+{
+  const struct file_info *s1 = p1;
+  const struct file_info *s2 = p2;
+  unsigned char *cp1;
+  unsigned char *cp2;
+
+  /* Take care of file names without directories.  We need to make sure that
+     we return consistent values to qsort since some will get confused if
+     we return the same value when identical operands are passed in opposite
+     orders.  So if neither has a directory, return 0 and otherwise return
+     1 or -1 depending on which one has the directory.  */
+  if ((s1->path == s1->fname || s2->path == s2->fname))
+    return (s2->path == s2->fname) - (s1->path == s1->fname);
+
+  cp1 = (unsigned char *) s1->path;
+  cp2 = (unsigned char *) s2->path;
+
+  while (1)
+    {
+      ++cp1;
+      ++cp2;
+      /* Reached the end of the first path?  If so, handle like above.  */
+      if ((cp1 == (unsigned char *) s1->fname)
+	  || (cp2 == (unsigned char *) s2->fname))
+	return ((cp2 == (unsigned char *) s2->fname)
+		- (cp1 == (unsigned char *) s1->fname));
+
+      /* Character of current path component the same?  */
+      else if (*cp1 != *cp2)
+	return *cp1 - *cp2;
+    }
+}
+
+/* Output the directory table and the file name table.  We try to minimize
+   the total amount of memory needed.  A heuristic is used to avoid large
+   slowdowns with many input files.  */
+
+static void
+output_file_names (void)
+{
+  struct file_info *files;
+  struct dir_info *dirs;
+  int *saved;
+  int *savehere;
+  int *backmap;
+  size_t ndirs;
+  int idx_offset;
+  size_t i;
+  int idx;
+
+  /* Handle the case where file_table is empty.  */
+  if (VARRAY_ACTIVE_SIZE (file_table) <= 1)
+    {
+      dw2_asm_output_data (1, 0, "End directory table");
+      dw2_asm_output_data (1, 0, "End file name table");
+      return;
+    }
+
+  /* Allocate the various arrays we need.  */
+  files = alloca (VARRAY_ACTIVE_SIZE (file_table) * sizeof (struct file_info));
+  dirs = alloca (VARRAY_ACTIVE_SIZE (file_table) * sizeof (struct dir_info));
+
+  /* Sort the file names.  */
+  for (i = 1; i < VARRAY_ACTIVE_SIZE (file_table); i++)
+    {
+      char *f;
+
+      /* Skip all leading "./".  */
+      f = VARRAY_CHAR_PTR (file_table, i);
+      while (f[0] == '.' && f[1] == '/')
+	f += 2;
+
+      /* Create a new array entry.  */
+      files[i].path = f;
+      files[i].length = strlen (f);
+      files[i].file_idx = i;
+
+      /* Search for the file name part.  */
+      f = strrchr (f, '/');
+      files[i].fname = f == NULL ? files[i].path : f + 1;
+    }
+
+  qsort (files + 1, VARRAY_ACTIVE_SIZE (file_table) - 1,
+	 sizeof (files[0]), file_info_cmp);
+
+  /* Find all the different directories used.  */
+  dirs[0].path = files[1].path;
+  dirs[0].length = files[1].fname - files[1].path;
+  dirs[0].prefix = -1;
+  dirs[0].count = 1;
+  dirs[0].dir_idx = 0;
+  dirs[0].used = 0;
+  files[1].dir_idx = 0;
+  ndirs = 1;
+
+  for (i = 2; i < VARRAY_ACTIVE_SIZE (file_table); i++)
+    if (files[i].fname - files[i].path == dirs[ndirs - 1].length
+	&& memcmp (dirs[ndirs - 1].path, files[i].path,
+		   dirs[ndirs - 1].length) == 0)
+      {
+	/* Same directory as last entry.  */
+	files[i].dir_idx = ndirs - 1;
+	++dirs[ndirs - 1].count;
+      }
+    else
+      {
+	size_t j;
+
+	/* This is a new directory.  */
+	dirs[ndirs].path = files[i].path;
+	dirs[ndirs].length = files[i].fname - files[i].path;
+	dirs[ndirs].count = 1;
+	dirs[ndirs].dir_idx = ndirs;
+	dirs[ndirs].used = 0;
+	files[i].dir_idx = ndirs;
+
+	/* Search for a prefix.  */
+	dirs[ndirs].prefix = -1;
+	for (j = 0; j < ndirs; j++)
+	  if (dirs[j].length < dirs[ndirs].length
+	      && dirs[j].length > 1
+	      && (dirs[ndirs].prefix == -1
+		  || dirs[j].length > dirs[dirs[ndirs].prefix].length)
+	      && memcmp (dirs[j].path, dirs[ndirs].path, dirs[j].length) == 0)
+	    dirs[ndirs].prefix = j;
+
+	++ndirs;
+      }
+
+  /* Now to the actual work.  We have to find a subset of the directories which
+     allow expressing the file name using references to the directory table
+     with the least amount of characters.  We do not do an exhaustive search
+     where we would have to check out every combination of every single
+     possible prefix.  Instead we use a heuristic which provides nearly optimal
+     results in most cases and never is much off.  */
+  saved = alloca (ndirs * sizeof (int));
+  savehere = alloca (ndirs * sizeof (int));
+
+  memset (saved, '\0', ndirs * sizeof (saved[0]));
+  for (i = 0; i < ndirs; i++)
+    {
+      size_t j;
+      int total;
+
+      /* We can always save some space for the current directory.  But this
+	 does not mean it will be enough to justify adding the directory.  */
+      savehere[i] = dirs[i].length;
+      total = (savehere[i] - saved[i]) * dirs[i].count;
+
+      for (j = i + 1; j < ndirs; j++)
+	{
+	  savehere[j] = 0;
+	  if (saved[j] < dirs[i].length)
+	    {
+	      /* Determine whether the dirs[i] path is a prefix of the
+		 dirs[j] path.  */
+	      int k;
+
+	      k = dirs[j].prefix;
+	      while (k != -1 && k != (int) i)
+		k = dirs[k].prefix;
+
+	      if (k == (int) i)
+		{
+		  /* Yes it is.  We can possibly safe some memory but
+		     writing the filenames in dirs[j] relative to
+		     dirs[i].  */
+		  savehere[j] = dirs[i].length;
+		  total += (savehere[j] - saved[j]) * dirs[j].count;
+		}
+	    }
+	}
+
+      /* Check whether we can safe enough to justify adding the dirs[i]
+	 directory.  */
+      if (total > dirs[i].length + 1)
+	{
+	  /* It's worthwhile adding.  */
+	  for (j = i; j < ndirs; j++)
+	    if (savehere[j] > 0)
+	      {
+		/* Remember how much we saved for this directory so far.  */
+		saved[j] = savehere[j];
+
+		/* Remember the prefix directory.  */
+		dirs[j].dir_idx = i;
+	      }
+	}
+    }
+
+  /* We have to emit them in the order they appear in the file_table array
+     since the index is used in the debug info generation.  To do this
+     efficiently we generate a back-mapping of the indices first.  */
+  backmap = alloca (VARRAY_ACTIVE_SIZE (file_table) * sizeof (int));
+  for (i = 1; i < VARRAY_ACTIVE_SIZE (file_table); i++)
+    {
+      backmap[files[i].file_idx] = i;
+
+      /* Mark this directory as used.  */
+      dirs[dirs[files[i].dir_idx].dir_idx].used = 1;
+    }
+
+  /* That was it.  We are ready to emit the information.  First emit the
+     directory name table.  We have to make sure the first actually emitted
+     directory name has index one; zero is reserved for the current working
+     directory.  Make sure we do not confuse these indices with the one for the
+     constructed table (even though most of the time they are identical).  */
+  idx = 1;
+  idx_offset = dirs[0].length > 0 ? 1 : 0;
+  for (i = 1 - idx_offset; i < ndirs; i++)
+    if (dirs[i].used != 0)
+      {
+	dirs[i].used = idx++;
+	dw2_asm_output_nstring (dirs[i].path, dirs[i].length - 1,
+				"Directory Entry: 0x%x", dirs[i].used);
+      }
+
+  dw2_asm_output_data (1, 0, "End directory table");
+
+  /* Correct the index for the current working directory entry if it
+     exists.  */
+  if (idx_offset == 0)
+    dirs[0].used = 0;
+
+  /* Now write all the file names.  */
+  for (i = 1; i < VARRAY_ACTIVE_SIZE (file_table); i++)
+    {
+      int file_idx = backmap[i];
+      int dir_idx = dirs[files[file_idx].dir_idx].dir_idx;
+
+      dw2_asm_output_nstring (files[file_idx].path + dirs[dir_idx].length, -1,
+			      "File Entry: 0x%lx", (unsigned long) i);
+
+      /* Include directory index.  */
+      dw2_asm_output_data_uleb128 (dirs[dir_idx].used, NULL);
+
+      /* Modification time.  */
+      dw2_asm_output_data_uleb128 (0, NULL);
+
+      /* File length in bytes.  */
+      dw2_asm_output_data_uleb128 (0, NULL);
+    }
+
+  dw2_asm_output_data (1, 0, "End file name table");
+}
+
+
+/* Output the source line number correspondence information.  This
+   information goes into the .debug_line section.  */
+
+static void
+output_line_info (void)
+{
+  char l1[20], l2[20], p1[20], p2[20];
+  char line_label[MAX_ARTIFICIAL_LABEL_BYTES];
+  char prev_line_label[MAX_ARTIFICIAL_LABEL_BYTES];
+  unsigned opc;
+  unsigned n_op_args;
+  unsigned long lt_index;
+  unsigned long current_line;
+  long line_offset;
+  long line_delta;
+  unsigned long current_file;
+  unsigned long function;
+
+  ASM_GENERATE_INTERNAL_LABEL (l1, LINE_NUMBER_BEGIN_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (l2, LINE_NUMBER_END_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (p1, LN_PROLOG_AS_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (p2, LN_PROLOG_END_LABEL, 0);
+
+  if (DWARF_INITIAL_LENGTH_SIZE - DWARF_OFFSET_SIZE == 4)
+    dw2_asm_output_data (4, 0xffffffff,
+      "Initial length escape value indicating 64-bit DWARF extension");
+  dw2_asm_output_delta (DWARF_OFFSET_SIZE, l2, l1,
+			"Length of Source Line Info");
+  ASM_OUTPUT_LABEL (asm_out_file, l1);
+
+  dw2_asm_output_data (2, DWARF_VERSION, "DWARF Version");
+  dw2_asm_output_delta (DWARF_OFFSET_SIZE, p2, p1, "Prolog Length");
+  ASM_OUTPUT_LABEL (asm_out_file, p1);
+
+  /* Define the architecture-dependent minimum instruction length (in
+   bytes).  In this implementation of DWARF, this field is used for
+   information purposes only.  Since GCC generates assembly language,
+   we have no a priori knowledge of how many instruction bytes are
+   generated for each source line, and therefore can use only the
+   DW_LNE_set_address and DW_LNS_fixed_advance_pc line information
+   commands.  Accordingly, we fix this as `1', which is "correct
+   enough" for all architectures, and don't let the target override.  */
+  dw2_asm_output_data (1, 1,
+		       "Minimum Instruction Length");
+
+  dw2_asm_output_data (1, DWARF_LINE_DEFAULT_IS_STMT_START,
+		       "Default is_stmt_start flag");
+  dw2_asm_output_data (1, DWARF_LINE_BASE,
+		       "Line Base Value (Special Opcodes)");
+  dw2_asm_output_data (1, DWARF_LINE_RANGE,
+		       "Line Range Value (Special Opcodes)");
+  dw2_asm_output_data (1, DWARF_LINE_OPCODE_BASE,
+		       "Special Opcode Base");
+
+  for (opc = 1; opc < DWARF_LINE_OPCODE_BASE; opc++)
+    {
+      switch (opc)
+	{
+	case DW_LNS_advance_pc:
+	case DW_LNS_advance_line:
+	case DW_LNS_set_file:
+	case DW_LNS_set_column:
+	case DW_LNS_fixed_advance_pc:
+	  n_op_args = 1;
+	  break;
+	default:
+	  n_op_args = 0;
+	  break;
+	}
+
+      dw2_asm_output_data (1, n_op_args, "opcode: 0x%x has %d args",
+			   opc, n_op_args);
+    }
+
+  /* Write out the information about the files we use.  */
+  output_file_names ();
+  ASM_OUTPUT_LABEL (asm_out_file, p2);
+
+  /* We used to set the address register to the first location in the text
+     section here, but that didn't accomplish anything since we already
+     have a line note for the opening brace of the first function.  */
+
+  /* Generate the line number to PC correspondence table, encoded as
+     a series of state machine operations.  */
+  current_file = 1;
+  current_line = 1;
+
+  if (cfun
+      && (last_text_section == in_unlikely_executed_text
+	  || (last_text_section == in_named
+	      && last_text_section_name == cfun->unlikely_text_section_name)))
+    strcpy (prev_line_label, cfun->cold_section_label);
+  else
+    strcpy (prev_line_label, text_section_label);
+  for (lt_index = 1; lt_index < line_info_table_in_use; ++lt_index)
+    {
+      dw_line_info_ref line_info = &line_info_table[lt_index];
+
+#if 0
+      /* Disable this optimization for now; GDB wants to see two line notes
+	 at the beginning of a function so it can find the end of the
+	 prologue.  */
+
+      /* Don't emit anything for redundant notes.  Just updating the
+	 address doesn't accomplish anything, because we already assume
+	 that anything after the last address is this line.  */
+      if (line_info->dw_line_num == current_line
+	  && line_info->dw_file_num == current_file)
+	continue;
+#endif
+
+      /* Emit debug info for the address of the current line.
+
+	 Unfortunately, we have little choice here currently, and must always
+	 use the most general form.  GCC does not know the address delta
+	 itself, so we can't use DW_LNS_advance_pc.  Many ports do have length
+	 attributes which will give an upper bound on the address range.  We
+	 could perhaps use length attributes to determine when it is safe to
+	 use DW_LNS_fixed_advance_pc.  */
+
+      ASM_GENERATE_INTERNAL_LABEL (line_label, LINE_CODE_LABEL, lt_index);
+      if (0)
+	{
+	  /* This can handle deltas up to 0xffff.  This takes 3 bytes.  */
+	  dw2_asm_output_data (1, DW_LNS_fixed_advance_pc,
+			       "DW_LNS_fixed_advance_pc");
+	  dw2_asm_output_delta (2, line_label, prev_line_label, NULL);
+	}
+      else
+	{
+	  /* This can handle any delta.  This takes
+	     4+DWARF2_ADDR_SIZE bytes.  */
+	  dw2_asm_output_data (1, 0, "DW_LNE_set_address");
+	  dw2_asm_output_data_uleb128 (1 + DWARF2_ADDR_SIZE, NULL);
+	  dw2_asm_output_data (1, DW_LNE_set_address, NULL);
+	  dw2_asm_output_addr (DWARF2_ADDR_SIZE, line_label, NULL);
+	}
+
+      strcpy (prev_line_label, line_label);
+
+      /* Emit debug info for the source file of the current line, if
+	 different from the previous line.  */
+      if (line_info->dw_file_num != current_file)
+	{
+	  current_file = line_info->dw_file_num;
+	  dw2_asm_output_data (1, DW_LNS_set_file, "DW_LNS_set_file");
+	  dw2_asm_output_data_uleb128 (current_file, "(\"%s\")",
+				       VARRAY_CHAR_PTR (file_table,
+							current_file));
+	}
+
+      /* Emit debug info for the current line number, choosing the encoding
+	 that uses the least amount of space.  */
+      if (line_info->dw_line_num != current_line)
+	{
+	  line_offset = line_info->dw_line_num - current_line;
+	  line_delta = line_offset - DWARF_LINE_BASE;
+	  current_line = line_info->dw_line_num;
+	  if (line_delta >= 0 && line_delta < (DWARF_LINE_RANGE - 1))
+	    /* This can handle deltas from -10 to 234, using the current
+	       definitions of DWARF_LINE_BASE and DWARF_LINE_RANGE.  This
+	       takes 1 byte.  */
+	    dw2_asm_output_data (1, DWARF_LINE_OPCODE_BASE + line_delta,
+				 "line %lu", current_line);
+	  else
+	    {
+	      /* This can handle any delta.  This takes at least 4 bytes,
+		 depending on the value being encoded.  */
+	      dw2_asm_output_data (1, DW_LNS_advance_line,
+				   "advance to line %lu", current_line);
+	      dw2_asm_output_data_sleb128 (line_offset, NULL);
+	      dw2_asm_output_data (1, DW_LNS_copy, "DW_LNS_copy");
+	    }
+	}
+      else
+	/* We still need to start a new row, so output a copy insn.  */
+	dw2_asm_output_data (1, DW_LNS_copy, "DW_LNS_copy");
+    }
+
+  /* Emit debug info for the address of the end of the function.  */
+  if (0)
+    {
+      dw2_asm_output_data (1, DW_LNS_fixed_advance_pc,
+			   "DW_LNS_fixed_advance_pc");
+      dw2_asm_output_delta (2, text_end_label, prev_line_label, NULL);
+    }
+  else
+    {
+      dw2_asm_output_data (1, 0, "DW_LNE_set_address");
+      dw2_asm_output_data_uleb128 (1 + DWARF2_ADDR_SIZE, NULL);
+      dw2_asm_output_data (1, DW_LNE_set_address, NULL);
+      dw2_asm_output_addr (DWARF2_ADDR_SIZE, text_end_label, NULL);
+    }
+
+  dw2_asm_output_data (1, 0, "DW_LNE_end_sequence");
+  dw2_asm_output_data_uleb128 (1, NULL);
+  dw2_asm_output_data (1, DW_LNE_end_sequence, NULL);
+
+  function = 0;
+  current_file = 1;
+  current_line = 1;
+  for (lt_index = 0; lt_index < separate_line_info_table_in_use;)
+    {
+      dw_separate_line_info_ref line_info
+	= &separate_line_info_table[lt_index];
+
+#if 0
+      /* Don't emit anything for redundant notes.  */
+      if (line_info->dw_line_num == current_line
+	  && line_info->dw_file_num == current_file
+	  && line_info->function == function)
+	goto cont;
+#endif
+
+      /* Emit debug info for the address of the current line.  If this is
+	 a new function, or the first line of a function, then we need
+	 to handle it differently.  */
+      ASM_GENERATE_INTERNAL_LABEL (line_label, SEPARATE_LINE_CODE_LABEL,
+				   lt_index);
+      if (function != line_info->function)
+	{
+	  function = line_info->function;
+
+	  /* Set the address register to the first line in the function.  */
+	  dw2_asm_output_data (1, 0, "DW_LNE_set_address");
+	  dw2_asm_output_data_uleb128 (1 + DWARF2_ADDR_SIZE, NULL);
+	  dw2_asm_output_data (1, DW_LNE_set_address, NULL);
+	  dw2_asm_output_addr (DWARF2_ADDR_SIZE, line_label, NULL);
+	}
+      else
+	{
+	  /* ??? See the DW_LNS_advance_pc comment above.  */
+	  if (0)
+	    {
+	      dw2_asm_output_data (1, DW_LNS_fixed_advance_pc,
+				   "DW_LNS_fixed_advance_pc");
+	      dw2_asm_output_delta (2, line_label, prev_line_label, NULL);
+	    }
+	  else
+	    {
+	      dw2_asm_output_data (1, 0, "DW_LNE_set_address");
+	      dw2_asm_output_data_uleb128 (1 + DWARF2_ADDR_SIZE, NULL);
+	      dw2_asm_output_data (1, DW_LNE_set_address, NULL);
+	      dw2_asm_output_addr (DWARF2_ADDR_SIZE, line_label, NULL);
+	    }
+	}
+
+      strcpy (prev_line_label, line_label);
+
+      /* Emit debug info for the source file of the current line, if
+	 different from the previous line.  */
+      if (line_info->dw_file_num != current_file)
+	{
+	  current_file = line_info->dw_file_num;
+	  dw2_asm_output_data (1, DW_LNS_set_file, "DW_LNS_set_file");
+	  dw2_asm_output_data_uleb128 (current_file, "(\"%s\")",
+				       VARRAY_CHAR_PTR (file_table,
+							current_file));
+	}
+
+      /* Emit debug info for the current line number, choosing the encoding
+	 that uses the least amount of space.  */
+      if (line_info->dw_line_num != current_line)
+	{
+	  line_offset = line_info->dw_line_num - current_line;
+	  line_delta = line_offset - DWARF_LINE_BASE;
+	  current_line = line_info->dw_line_num;
+	  if (line_delta >= 0 && line_delta < (DWARF_LINE_RANGE - 1))
+	    dw2_asm_output_data (1, DWARF_LINE_OPCODE_BASE + line_delta,
+				 "line %lu", current_line);
+	  else
+	    {
+	      dw2_asm_output_data (1, DW_LNS_advance_line,
+				   "advance to line %lu", current_line);
+	      dw2_asm_output_data_sleb128 (line_offset, NULL);
+	      dw2_asm_output_data (1, DW_LNS_copy, "DW_LNS_copy");
+	    }
+	}
+      else
+	dw2_asm_output_data (1, DW_LNS_copy, "DW_LNS_copy");
+
+#if 0
+    cont:
+#endif
+
+      lt_index++;
+
+      /* If we're done with a function, end its sequence.  */
+      if (lt_index == separate_line_info_table_in_use
+	  || separate_line_info_table[lt_index].function != function)
+	{
+	  current_file = 1;
+	  current_line = 1;
+
+	  /* Emit debug info for the address of the end of the function.  */
+	  ASM_GENERATE_INTERNAL_LABEL (line_label, FUNC_END_LABEL, function);
+	  if (0)
+	    {
+	      dw2_asm_output_data (1, DW_LNS_fixed_advance_pc,
+				   "DW_LNS_fixed_advance_pc");
+	      dw2_asm_output_delta (2, line_label, prev_line_label, NULL);
+	    }
+	  else
+	    {
+	      dw2_asm_output_data (1, 0, "DW_LNE_set_address");
+	      dw2_asm_output_data_uleb128 (1 + DWARF2_ADDR_SIZE, NULL);
+	      dw2_asm_output_data (1, DW_LNE_set_address, NULL);
+	      dw2_asm_output_addr (DWARF2_ADDR_SIZE, line_label, NULL);
+	    }
+
+	  /* Output the marker for the end of this sequence.  */
+	  dw2_asm_output_data (1, 0, "DW_LNE_end_sequence");
+	  dw2_asm_output_data_uleb128 (1, NULL);
+	  dw2_asm_output_data (1, DW_LNE_end_sequence, NULL);
+	}
+    }
+
+  /* Output the marker for the end of the line number info.  */
+  ASM_OUTPUT_LABEL (asm_out_file, l2);
+}
+
+/* Given a pointer to a tree node for some base type, return a pointer to
+   a DIE that describes the given type.
+
+   This routine must only be called for GCC type nodes that correspond to
+   Dwarf base (fundamental) types.  */
+
+static dw_die_ref
+base_type_die (tree type)
+{
+  dw_die_ref base_type_result;
+  const char *type_name;
+  enum dwarf_type encoding;
+  tree name = TYPE_NAME (type);
+
+  if (TREE_CODE (type) == ERROR_MARK || TREE_CODE (type) == VOID_TYPE)
+    return 0;
+
+  if (name)
+    {
+      if (TREE_CODE (name) == TYPE_DECL)
+	name = DECL_NAME (name);
+
+      type_name = IDENTIFIER_POINTER (name);
+    }
+  else
+    type_name = "__unknown__";
+
+  switch (TREE_CODE (type))
+    {
+    case INTEGER_TYPE:
+      /* Carefully distinguish the C character types, without messing
+	 up if the language is not C. Note that we check only for the names
+	 that contain spaces; other names might occur by coincidence in other
+	 languages.  */
+      if (! (TYPE_PRECISION (type) == CHAR_TYPE_SIZE
+	     && (TYPE_MAIN_VARIANT (type) == char_type_node
+		 || ! strcmp (type_name, "signed char")
+		 || ! strcmp (type_name, "unsigned char"))))
+	{
+	  if (TYPE_UNSIGNED (type))
+	    encoding = DW_ATE_unsigned;
+	  else
+	    encoding = DW_ATE_signed;
+	  break;
+	}
+      /* else fall through.  */
+
+    case CHAR_TYPE:
+      /* GNU Pascal/Ada CHAR type.  Not used in C.  */
+      if (TYPE_UNSIGNED (type))
+	encoding = DW_ATE_unsigned_char;
+      else
+	encoding = DW_ATE_signed_char;
+      break;
+
+    case REAL_TYPE:
+      encoding = DW_ATE_float;
+      break;
+
+      /* Dwarf2 doesn't know anything about complex ints, so use
+	 a user defined type for it.  */
+    case COMPLEX_TYPE:
+      if (TREE_CODE (TREE_TYPE (type)) == REAL_TYPE)
+	encoding = DW_ATE_complex_float;
+      else
+	encoding = DW_ATE_lo_user;
+      break;
+
+    case BOOLEAN_TYPE:
+      /* GNU FORTRAN/Ada/C++ BOOLEAN type.  */
+      encoding = DW_ATE_boolean;
+      break;
+
+    default:
+      /* No other TREE_CODEs are Dwarf fundamental types.  */
+      gcc_unreachable ();
+    }
+
+  base_type_result = new_die (DW_TAG_base_type, comp_unit_die, type);
+  if (demangle_name_func)
+    type_name = (*demangle_name_func) (type_name);
+
+  add_AT_string (base_type_result, DW_AT_name, type_name);
+  add_AT_unsigned (base_type_result, DW_AT_byte_size,
+		   int_size_in_bytes (type));
+  add_AT_unsigned (base_type_result, DW_AT_encoding, encoding);
+
+  return base_type_result;
+}
+
+/* Given a pointer to an arbitrary ..._TYPE tree node, return a pointer to
+   the Dwarf "root" type for the given input type.  The Dwarf "root" type of
+   a given type is generally the same as the given type, except that if the
+   given type is a pointer or reference type, then the root type of the given
+   type is the root type of the "basis" type for the pointer or reference
+   type.  (This definition of the "root" type is recursive.) Also, the root
+   type of a `const' qualified type or a `volatile' qualified type is the
+   root type of the given type without the qualifiers.  */
+
+static tree
+root_type (tree type)
+{
+  if (TREE_CODE (type) == ERROR_MARK)
+    return error_mark_node;
+
+  switch (TREE_CODE (type))
+    {
+    case ERROR_MARK:
+      return error_mark_node;
+
+    case POINTER_TYPE:
+    case REFERENCE_TYPE:
+      return type_main_variant (root_type (TREE_TYPE (type)));
+
+    default:
+      return type_main_variant (type);
+    }
+}
+
+/* Given a pointer to an arbitrary ..._TYPE tree node, return nonzero if the
+   given input type is a Dwarf "fundamental" type.  Otherwise return null.  */
+
+static inline int
+is_base_type (tree type)
+{
+  switch (TREE_CODE (type))
+    {
+    case ERROR_MARK:
+    case VOID_TYPE:
+    case INTEGER_TYPE:
+    case REAL_TYPE:
+    case COMPLEX_TYPE:
+    case BOOLEAN_TYPE:
+    case CHAR_TYPE:
+      return 1;
+
+    case ARRAY_TYPE:
+    case RECORD_TYPE:
+    case UNION_TYPE:
+    case QUAL_UNION_TYPE:
+    case ENUMERAL_TYPE:
+    case FUNCTION_TYPE:
+    case METHOD_TYPE:
+    case POINTER_TYPE:
+    case REFERENCE_TYPE:
+    case OFFSET_TYPE:
+    case LANG_TYPE:
+    case VECTOR_TYPE:
+      return 0;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  return 0;
+}
+
+/* Given a pointer to a tree node, assumed to be some kind of a ..._TYPE
+   node, return the size in bits for the type if it is a constant, or else
+   return the alignment for the type if the type's size is not constant, or
+   else return BITS_PER_WORD if the type actually turns out to be an
+   ERROR_MARK node.  */
+
+static inline unsigned HOST_WIDE_INT
+simple_type_size_in_bits (tree type)
+{
+  if (TREE_CODE (type) == ERROR_MARK)
+    return BITS_PER_WORD;
+  else if (TYPE_SIZE (type) == NULL_TREE)
+    return 0;
+  else if (host_integerp (TYPE_SIZE (type), 1))
+    return tree_low_cst (TYPE_SIZE (type), 1);
+  else
+    return TYPE_ALIGN (type);
+}
+
+/* Return true if the debug information for the given type should be
+   emitted as a subrange type.  */
+
+static inline bool
+is_subrange_type (tree type)
+{
+  tree subtype = TREE_TYPE (type);
+
+  /* Subrange types are identified by the fact that they are integer
+     types, and that they have a subtype which is either an integer type
+     or an enumeral type.  */
+
+  if (TREE_CODE (type) != INTEGER_TYPE
+      || subtype == NULL_TREE)
+    return false;
+
+  if (TREE_CODE (subtype) != INTEGER_TYPE
+      && TREE_CODE (subtype) != ENUMERAL_TYPE)
+    return false;
+
+  if (TREE_CODE (type) == TREE_CODE (subtype)
+      && int_size_in_bytes (type) == int_size_in_bytes (subtype)
+      && TYPE_MIN_VALUE (type) != NULL
+      && TYPE_MIN_VALUE (subtype) != NULL
+      && tree_int_cst_equal (TYPE_MIN_VALUE (type), TYPE_MIN_VALUE (subtype))
+      && TYPE_MAX_VALUE (type) != NULL
+      && TYPE_MAX_VALUE (subtype) != NULL
+      && tree_int_cst_equal (TYPE_MAX_VALUE (type), TYPE_MAX_VALUE (subtype)))
+    {
+      /* The type and its subtype have the same representation.  If in
+         addition the two types also have the same name, then the given
+         type is not a subrange type, but rather a plain base type.  */
+      /* FIXME: brobecker/2004-03-22:
+         Sizetype INTEGER_CSTs nodes are canonicalized.  It should
+         therefore be sufficient to check the TYPE_SIZE node pointers
+         rather than checking the actual size.  Unfortunately, we have
+         found some cases, such as in the Ada "integer" type, where
+         this is not the case.  Until this problem is solved, we need to
+         keep checking the actual size.  */
+      tree type_name = TYPE_NAME (type);
+      tree subtype_name = TYPE_NAME (subtype);
+
+      if (type_name != NULL && TREE_CODE (type_name) == TYPE_DECL)
+        type_name = DECL_NAME (type_name);
+
+      if (subtype_name != NULL && TREE_CODE (subtype_name) == TYPE_DECL)
+        subtype_name = DECL_NAME (subtype_name);
+
+      if (type_name == subtype_name)
+        return false;
+    }
+
+  return true;
+}
+
+/*  Given a pointer to a tree node for a subrange type, return a pointer
+    to a DIE that describes the given type.  */
+
+static dw_die_ref
+subrange_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref subtype_die;
+  dw_die_ref subrange_die;
+  tree name = TYPE_NAME (type);
+  const HOST_WIDE_INT size_in_bytes = int_size_in_bytes (type);
+  tree subtype = TREE_TYPE (type);
+
+  if (context_die == NULL)
+    context_die = comp_unit_die;
+
+  if (TREE_CODE (subtype) == ENUMERAL_TYPE)
+    subtype_die = gen_enumeration_type_die (subtype, context_die);
+  else
+    subtype_die = base_type_die (subtype);
+
+  subrange_die = new_die (DW_TAG_subrange_type, context_die, type);
+
+  if (name != NULL)
+    {
+      if (TREE_CODE (name) == TYPE_DECL)
+        name = DECL_NAME (name);
+      add_name_attribute (subrange_die, IDENTIFIER_POINTER (name));
+    }
+
+  if (int_size_in_bytes (subtype) != size_in_bytes)
+    {
+      /* The size of the subrange type and its base type do not match,
+         so we need to generate a size attribute for the subrange type.  */
+      add_AT_unsigned (subrange_die, DW_AT_byte_size, size_in_bytes);
+    }
+
+  if (TYPE_MIN_VALUE (type) != NULL)
+    add_bound_info (subrange_die, DW_AT_lower_bound,
+                    TYPE_MIN_VALUE (type));
+  if (TYPE_MAX_VALUE (type) != NULL)
+    add_bound_info (subrange_die, DW_AT_upper_bound,
+                    TYPE_MAX_VALUE (type));
+  add_AT_die_ref (subrange_die, DW_AT_type, subtype_die);
+
+  return subrange_die;
+}
+
+/* Given a pointer to an arbitrary ..._TYPE tree node, return a debugging
+   entry that chains various modifiers in front of the given type.  */
+
+static dw_die_ref
+modified_type_die (tree type, int is_const_type, int is_volatile_type,
+		   dw_die_ref context_die)
+{
+  enum tree_code code = TREE_CODE (type);
+  dw_die_ref mod_type_die = NULL;
+  dw_die_ref sub_die = NULL;
+  tree item_type = NULL;
+
+  if (code != ERROR_MARK)
+    {
+      tree qualified_type;
+
+      /* See if we already have the appropriately qualified variant of
+	 this type.  */
+      qualified_type
+	= get_qualified_type (type,
+			      ((is_const_type ? TYPE_QUAL_CONST : 0)
+			       | (is_volatile_type
+				  ? TYPE_QUAL_VOLATILE : 0)));
+
+      /* If we do, then we can just use its DIE, if it exists.  */
+      if (qualified_type)
+	{
+	  mod_type_die = lookup_type_die (qualified_type);
+	  if (mod_type_die)
+	    return mod_type_die;
+	}
+
+      /* Handle C typedef types.  */
+      if (qualified_type && TYPE_NAME (qualified_type)
+	  && TREE_CODE (TYPE_NAME (qualified_type)) == TYPE_DECL
+	  && DECL_ORIGINAL_TYPE (TYPE_NAME (qualified_type)))
+	{
+	  tree type_name = TYPE_NAME (qualified_type);
+	  tree dtype = TREE_TYPE (type_name);
+
+	  if (qualified_type == dtype)
+	    {
+	      /* For a named type, use the typedef.  */
+	      gen_type_die (qualified_type, context_die);
+	      mod_type_die = lookup_type_die (qualified_type);
+	    }
+	  else if (is_const_type < TYPE_READONLY (dtype)
+		   || is_volatile_type < TYPE_VOLATILE (dtype))
+	    /* cv-unqualified version of named type.  Just use the unnamed
+	       type to which it refers.  */
+	    mod_type_die
+	      = modified_type_die (DECL_ORIGINAL_TYPE (type_name),
+				   is_const_type, is_volatile_type,
+				   context_die);
+
+	  /* Else cv-qualified version of named type; fall through.  */
+	}
+
+      if (mod_type_die)
+	/* OK.  */
+	;
+      else if (is_const_type)
+	{
+	  mod_type_die = new_die (DW_TAG_const_type, comp_unit_die, type);
+	  sub_die = modified_type_die (type, 0, is_volatile_type, context_die);
+	}
+      else if (is_volatile_type)
+	{
+	  mod_type_die = new_die (DW_TAG_volatile_type, comp_unit_die, type);
+	  sub_die = modified_type_die (type, 0, 0, context_die);
+	}
+      else if (code == POINTER_TYPE)
+	{
+	  mod_type_die = new_die (DW_TAG_pointer_type, comp_unit_die, type);
+	  add_AT_unsigned (mod_type_die, DW_AT_byte_size,
+			   simple_type_size_in_bits (type) / BITS_PER_UNIT);
+#if 0
+	  add_AT_unsigned (mod_type_die, DW_AT_address_class, 0);
+#endif
+	  item_type = TREE_TYPE (type);
+	}
+      else if (code == REFERENCE_TYPE)
+	{
+	  mod_type_die = new_die (DW_TAG_reference_type, comp_unit_die, type);
+	  add_AT_unsigned (mod_type_die, DW_AT_byte_size,
+			   simple_type_size_in_bits (type) / BITS_PER_UNIT);
+#if 0
+	  add_AT_unsigned (mod_type_die, DW_AT_address_class, 0);
+#endif
+	  item_type = TREE_TYPE (type);
+	}
+      else if (is_subrange_type (type))
+        mod_type_die = subrange_type_die (type, context_die);
+      else if (is_base_type (type))
+	mod_type_die = base_type_die (type);
+      else
+	{
+	  gen_type_die (type, context_die);
+
+	  /* We have to get the type_main_variant here (and pass that to the
+	     `lookup_type_die' routine) because the ..._TYPE node we have
+	     might simply be a *copy* of some original type node (where the
+	     copy was created to help us keep track of typedef names) and
+	     that copy might have a different TYPE_UID from the original
+	     ..._TYPE node.  */
+	  if (TREE_CODE (type) != VECTOR_TYPE)
+	    mod_type_die = lookup_type_die (type_main_variant (type));
+	  else
+	    /* Vectors have the debugging information in the type,
+	       not the main variant.  */
+	    mod_type_die = lookup_type_die (type);
+	  gcc_assert (mod_type_die);
+	}
+
+      /* We want to equate the qualified type to the die below.  */
+      type = qualified_type;
+    }
+
+  if (type)
+    equate_type_number_to_die (type, mod_type_die);
+  if (item_type)
+    /* We must do this after the equate_type_number_to_die call, in case
+       this is a recursive type.  This ensures that the modified_type_die
+       recursion will terminate even if the type is recursive.  Recursive
+       types are possible in Ada.  */
+    sub_die = modified_type_die (item_type,
+				 TYPE_READONLY (item_type),
+				 TYPE_VOLATILE (item_type),
+				 context_die);
+
+  if (sub_die != NULL)
+    add_AT_die_ref (mod_type_die, DW_AT_type, sub_die);
+
+  return mod_type_die;
+}
+
+/* Given a pointer to an arbitrary ..._TYPE tree node, return true if it is
+   an enumerated type.  */
+
+static inline int
+type_is_enum (tree type)
+{
+  return TREE_CODE (type) == ENUMERAL_TYPE;
+}
+
+/* Return the DBX register number described by a given RTL node.  */
+
+static unsigned int
+dbx_reg_number (rtx rtl)
+{
+  unsigned regno = REGNO (rtl);
+
+  gcc_assert (regno < FIRST_PSEUDO_REGISTER);
+
+#ifdef LEAF_REG_REMAP
+  regno = LEAF_REG_REMAP (regno);
+#endif
+
+  return DBX_REGISTER_NUMBER (regno);
+}
+
+/* Optionally add a DW_OP_piece term to a location description expression.
+   DW_OP_piece is only added if the location description expression already
+   doesn't end with DW_OP_piece.  */
+
+static void
+add_loc_descr_op_piece (dw_loc_descr_ref *list_head, int size)
+{
+  dw_loc_descr_ref loc;
+
+  if (*list_head != NULL)
+    {
+      /* Find the end of the chain.  */
+      for (loc = *list_head; loc->dw_loc_next != NULL; loc = loc->dw_loc_next)
+	;
+
+      if (loc->dw_loc_opc != DW_OP_piece)
+	loc->dw_loc_next = new_loc_descr (DW_OP_piece, size, 0);
+    }
+}
+
+/* Return a location descriptor that designates a machine register or
+   zero if there is none.  */
+
+static dw_loc_descr_ref
+reg_loc_descriptor (rtx rtl)
+{
+  rtx regs;
+
+  if (REGNO (rtl) >= FIRST_PSEUDO_REGISTER)
+    return 0;
+
+  regs = targetm.dwarf_register_span (rtl);
+
+  if (hard_regno_nregs[REGNO (rtl)][GET_MODE (rtl)] > 1 || regs)
+    return multiple_reg_loc_descriptor (rtl, regs);
+  else
+    return one_reg_loc_descriptor (dbx_reg_number (rtl));
+}
+
+/* Return a location descriptor that designates a machine register for
+   a given hard register number.  */
+
+static dw_loc_descr_ref
+one_reg_loc_descriptor (unsigned int regno)
+{
+  if (regno <= 31)
+    return new_loc_descr (DW_OP_reg0 + regno, 0, 0);
+  else
+    return new_loc_descr (DW_OP_regx, regno, 0);
+}
+
+/* Given an RTL of a register, return a location descriptor that
+   designates a value that spans more than one register.  */
+
+static dw_loc_descr_ref
+multiple_reg_loc_descriptor (rtx rtl, rtx regs)
+{
+  int nregs, size, i;
+  unsigned reg;
+  dw_loc_descr_ref loc_result = NULL;
+
+  reg = REGNO (rtl);
+#ifdef LEAF_REG_REMAP
+  reg = LEAF_REG_REMAP (reg);
+#endif
+  gcc_assert ((unsigned) DBX_REGISTER_NUMBER (reg) == dbx_reg_number (rtl));
+  nregs = hard_regno_nregs[REGNO (rtl)][GET_MODE (rtl)];
+
+  /* Simple, contiguous registers.  */
+  if (regs == NULL_RTX)
+    {
+      size = GET_MODE_SIZE (GET_MODE (rtl)) / nregs;
+
+      loc_result = NULL;
+      while (nregs--)
+	{
+	  dw_loc_descr_ref t;
+
+	  t = one_reg_loc_descriptor (DBX_REGISTER_NUMBER (reg));
+	  add_loc_descr (&loc_result, t);
+	  add_loc_descr_op_piece (&loc_result, size);
+	  ++reg;
+	}
+      return loc_result;
+    }
+
+  /* Now onto stupid register sets in non contiguous locations.  */
+
+  gcc_assert (GET_CODE (regs) == PARALLEL);
+
+  size = GET_MODE_SIZE (GET_MODE (XVECEXP (regs, 0, 0)));
+  loc_result = NULL;
+
+  for (i = 0; i < XVECLEN (regs, 0); ++i)
+    {
+      dw_loc_descr_ref t;
+
+      t = one_reg_loc_descriptor (REGNO (XVECEXP (regs, 0, i)));
+      add_loc_descr (&loc_result, t);
+      size = GET_MODE_SIZE (GET_MODE (XVECEXP (regs, 0, 0)));
+      add_loc_descr_op_piece (&loc_result, size);
+    }
+  return loc_result;
+}
+
+/* Return a location descriptor that designates a constant.  */
+
+static dw_loc_descr_ref
+int_loc_descriptor (HOST_WIDE_INT i)
+{
+  enum dwarf_location_atom op;
+
+  /* Pick the smallest representation of a constant, rather than just
+     defaulting to the LEB encoding.  */
+  if (i >= 0)
+    {
+      if (i <= 31)
+	op = DW_OP_lit0 + i;
+      else if (i <= 0xff)
+	op = DW_OP_const1u;
+      else if (i <= 0xffff)
+	op = DW_OP_const2u;
+      else if (HOST_BITS_PER_WIDE_INT == 32
+	       || i <= 0xffffffff)
+	op = DW_OP_const4u;
+      else
+	op = DW_OP_constu;
+    }
+  else
+    {
+      if (i >= -0x80)
+	op = DW_OP_const1s;
+      else if (i >= -0x8000)
+	op = DW_OP_const2s;
+      else if (HOST_BITS_PER_WIDE_INT == 32
+	       || i >= -0x80000000)
+	op = DW_OP_const4s;
+      else
+	op = DW_OP_consts;
+    }
+
+  return new_loc_descr (op, i, 0);
+}
+
+/* Return a location descriptor that designates a base+offset location.  */
+
+static dw_loc_descr_ref
+based_loc_descr (rtx reg, HOST_WIDE_INT offset)
+{
+  unsigned int regno;
+
+  /* We only use "frame base" when we're sure we're talking about the
+     post-prologue local stack frame.  We do this by *not* running
+     register elimination until this point, and recognizing the special
+     argument pointer and soft frame pointer rtx's.  */
+  if (reg == arg_pointer_rtx || reg == frame_pointer_rtx)
+    {
+      rtx elim = eliminate_regs (reg, VOIDmode, NULL_RTX);
+
+      if (elim != reg)
+	{
+	  if (GET_CODE (elim) == PLUS)
+	    {
+	      offset += INTVAL (XEXP (elim, 1));
+	      elim = XEXP (elim, 0);
+	    }
+	  gcc_assert (elim == (frame_pointer_needed ? hard_frame_pointer_rtx
+		      : stack_pointer_rtx));
+          offset += frame_pointer_cfa_offset;
+
+          return new_loc_descr (DW_OP_fbreg, offset, 0);
+	}
+    }
+
+  regno = dbx_reg_number (reg);
+  if (regno <= 31)
+    return new_loc_descr (DW_OP_breg0 + regno, offset, 0);
+  else
+    return new_loc_descr (DW_OP_bregx, regno, offset);
+}
+
+/* Return true if this RTL expression describes a base+offset calculation.  */
+
+static inline int
+is_based_loc (rtx rtl)
+{
+  return (GET_CODE (rtl) == PLUS
+	  && ((REG_P (XEXP (rtl, 0))
+	       && REGNO (XEXP (rtl, 0)) < FIRST_PSEUDO_REGISTER
+	       && GET_CODE (XEXP (rtl, 1)) == CONST_INT)));
+}
+
+/* The following routine converts the RTL for a variable or parameter
+   (resident in memory) into an equivalent Dwarf representation of a
+   mechanism for getting the address of that same variable onto the top of a
+   hypothetical "address evaluation" stack.
+
+   When creating memory location descriptors, we are effectively transforming
+   the RTL for a memory-resident object into its Dwarf postfix expression
+   equivalent.  This routine recursively descends an RTL tree, turning
+   it into Dwarf postfix code as it goes.
+
+   MODE is the mode of the memory reference, needed to handle some
+   autoincrement addressing modes.
+
+   CAN_USE_FBREG is a flag whether we can use DW_AT_frame_base in the
+   location list for RTL.
+
+   Return 0 if we can't represent the location.  */
+
+static dw_loc_descr_ref
+mem_loc_descriptor (rtx rtl, enum machine_mode mode)
+{
+  dw_loc_descr_ref mem_loc_result = NULL;
+  enum dwarf_location_atom op;
+
+  /* Note that for a dynamically sized array, the location we will generate a
+     description of here will be the lowest numbered location which is
+     actually within the array.  That's *not* necessarily the same as the
+     zeroth element of the array.  */
+
+  rtl = targetm.delegitimize_address (rtl);
+
+  switch (GET_CODE (rtl))
+    {
+    case POST_INC:
+    case POST_DEC:
+    case POST_MODIFY:
+      /* POST_INC and POST_DEC can be handled just like a SUBREG.  So we
+	 just fall into the SUBREG code.  */
+
+      /* ... fall through ...  */
+
+    case SUBREG:
+      /* The case of a subreg may arise when we have a local (register)
+	 variable or a formal (register) parameter which doesn't quite fill
+	 up an entire register.  For now, just assume that it is
+	 legitimate to make the Dwarf info refer to the whole register which
+	 contains the given subreg.  */
+      rtl = XEXP (rtl, 0);
+
+      /* ... fall through ...  */
+
+    case REG:
+      /* Whenever a register number forms a part of the description of the
+	 method for calculating the (dynamic) address of a memory resident
+	 object, DWARF rules require the register number be referred to as
+	 a "base register".  This distinction is not based in any way upon
+	 what category of register the hardware believes the given register
+	 belongs to.  This is strictly DWARF terminology we're dealing with
+	 here. Note that in cases where the location of a memory-resident
+	 data object could be expressed as: OP_ADD (OP_BASEREG (basereg),
+	 OP_CONST (0)) the actual DWARF location descriptor that we generate
+	 may just be OP_BASEREG (basereg).  This may look deceptively like
+	 the object in question was allocated to a register (rather than in
+	 memory) so DWARF consumers need to be aware of the subtle
+	 distinction between OP_REG and OP_BASEREG.  */
+      if (REGNO (rtl) < FIRST_PSEUDO_REGISTER)
+	mem_loc_result = based_loc_descr (rtl, 0);
+      break;
+
+    case MEM:
+      mem_loc_result = mem_loc_descriptor (XEXP (rtl, 0), GET_MODE (rtl));
+      if (mem_loc_result != 0)
+	add_loc_descr (&mem_loc_result, new_loc_descr (DW_OP_deref, 0, 0));
+      break;
+
+    case LO_SUM:
+	 rtl = XEXP (rtl, 1);
+
+      /* ... fall through ...  */
+
+    case LABEL_REF:
+      /* Some ports can transform a symbol ref into a label ref, because
+	 the symbol ref is too far away and has to be dumped into a constant
+	 pool.  */
+    case CONST:
+    case SYMBOL_REF:
+      /* Alternatively, the symbol in the constant pool might be referenced
+	 by a different symbol.  */
+      if (GET_CODE (rtl) == SYMBOL_REF && CONSTANT_POOL_ADDRESS_P (rtl))
+	{
+	  bool marked;
+	  rtx tmp = get_pool_constant_mark (rtl, &marked);
+
+	  if (GET_CODE (tmp) == SYMBOL_REF)
+	    {
+	      rtl = tmp;
+	      if (CONSTANT_POOL_ADDRESS_P (tmp))
+		get_pool_constant_mark (tmp, &marked);
+	      else
+		marked = true;
+	    }
+
+	  /* If all references to this pool constant were optimized away,
+	     it was not output and thus we can't represent it.
+	     FIXME: might try to use DW_OP_const_value here, though
+	     DW_OP_piece complicates it.  */
+	  if (!marked)
+	    return 0;
+	}
+
+      mem_loc_result = new_loc_descr (DW_OP_addr, 0, 0);
+      mem_loc_result->dw_loc_oprnd1.val_class = dw_val_class_addr;
+      mem_loc_result->dw_loc_oprnd1.v.val_addr = rtl;
+      VEC_safe_push (rtx, gc, used_rtx_array, rtl);
+      break;
+
+    case PRE_MODIFY:
+      /* Extract the PLUS expression nested inside and fall into
+	 PLUS code below.  */
+      rtl = XEXP (rtl, 1);
+      goto plus;
+
+    case PRE_INC:
+    case PRE_DEC:
+      /* Turn these into a PLUS expression and fall into the PLUS code
+	 below.  */
+      rtl = gen_rtx_PLUS (word_mode, XEXP (rtl, 0),
+			  GEN_INT (GET_CODE (rtl) == PRE_INC
+				   ? GET_MODE_UNIT_SIZE (mode)
+				   : -GET_MODE_UNIT_SIZE (mode)));
+
+      /* ... fall through ...  */
+
+    case PLUS:
+    plus:
+      if (is_based_loc (rtl))
+	mem_loc_result = based_loc_descr (XEXP (rtl, 0),
+					  INTVAL (XEXP (rtl, 1)));
+      else
+	{
+	  mem_loc_result = mem_loc_descriptor (XEXP (rtl, 0), mode);
+	  if (mem_loc_result == 0)
+	    break;
+
+	  if (GET_CODE (XEXP (rtl, 1)) == CONST_INT
+	      && INTVAL (XEXP (rtl, 1)) >= 0)
+	    add_loc_descr (&mem_loc_result,
+			   new_loc_descr (DW_OP_plus_uconst,
+					  INTVAL (XEXP (rtl, 1)), 0));
+	  else
+	    {
+	      add_loc_descr (&mem_loc_result,
+			     mem_loc_descriptor (XEXP (rtl, 1), mode));
+	      add_loc_descr (&mem_loc_result,
+			     new_loc_descr (DW_OP_plus, 0, 0));
+	    }
+	}
+      break;
+
+    /* If a pseudo-reg is optimized away, it is possible for it to
+       be replaced with a MEM containing a multiply or shift.  */
+    case MULT:
+      op = DW_OP_mul;
+      goto do_binop;
+
+    case ASHIFT:
+      op = DW_OP_shl;
+      goto do_binop;
+
+    case ASHIFTRT:
+      op = DW_OP_shra;
+      goto do_binop;
+
+    case LSHIFTRT:
+      op = DW_OP_shr;
+      goto do_binop;
+
+    do_binop:
+      {
+	dw_loc_descr_ref op0 = mem_loc_descriptor (XEXP (rtl, 0), mode);
+	dw_loc_descr_ref op1 = mem_loc_descriptor (XEXP (rtl, 1), mode);
+
+	if (op0 == 0 || op1 == 0)
+	  break;
+
+	mem_loc_result = op0;
+	add_loc_descr (&mem_loc_result, op1);
+	add_loc_descr (&mem_loc_result, new_loc_descr (op, 0, 0));
+	break;
+      }
+
+    case CONST_INT:
+      mem_loc_result = int_loc_descriptor (INTVAL (rtl));
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  return mem_loc_result;
+}
+
+/* Return a descriptor that describes the concatenation of two locations.
+   This is typically a complex variable.  */
+
+static dw_loc_descr_ref
+concat_loc_descriptor (rtx x0, rtx x1)
+{
+  dw_loc_descr_ref cc_loc_result = NULL;
+  dw_loc_descr_ref x0_ref = loc_descriptor (x0);
+  dw_loc_descr_ref x1_ref = loc_descriptor (x1);
+
+  if (x0_ref == 0 || x1_ref == 0)
+    return 0;
+
+  cc_loc_result = x0_ref;
+  add_loc_descr_op_piece (&cc_loc_result, GET_MODE_SIZE (GET_MODE (x0)));
+
+  add_loc_descr (&cc_loc_result, x1_ref);
+  add_loc_descr_op_piece (&cc_loc_result, GET_MODE_SIZE (GET_MODE (x1)));
+
+  return cc_loc_result;
+}
+
+/* Output a proper Dwarf location descriptor for a variable or parameter
+   which is either allocated in a register or in a memory location.  For a
+   register, we just generate an OP_REG and the register number.  For a
+   memory location we provide a Dwarf postfix expression describing how to
+   generate the (dynamic) address of the object onto the address stack.
+
+   If we don't know how to describe it, return 0.  */
+
+static dw_loc_descr_ref
+loc_descriptor (rtx rtl)
+{
+  dw_loc_descr_ref loc_result = NULL;
+
+  switch (GET_CODE (rtl))
+    {
+    case SUBREG:
+      /* The case of a subreg may arise when we have a local (register)
+	 variable or a formal (register) parameter which doesn't quite fill
+	 up an entire register.  For now, just assume that it is
+	 legitimate to make the Dwarf info refer to the whole register which
+	 contains the given subreg.  */
+      rtl = SUBREG_REG (rtl);
+
+      /* ... fall through ...  */
+
+    case REG:
+      loc_result = reg_loc_descriptor (rtl);
+      break;
+
+    case MEM:
+      loc_result = mem_loc_descriptor (XEXP (rtl, 0), GET_MODE (rtl));
+      break;
+
+    case CONCAT:
+      loc_result = concat_loc_descriptor (XEXP (rtl, 0), XEXP (rtl, 1));
+      break;
+
+    case VAR_LOCATION:
+      /* Single part.  */
+      if (GET_CODE (XEXP (rtl, 1)) != PARALLEL)
+	{
+	  loc_result = loc_descriptor (XEXP (XEXP (rtl, 1), 0));
+	  break;
+	}
+
+      rtl = XEXP (rtl, 1);
+      /* FALLTHRU */
+
+    case PARALLEL:
+      {
+	rtvec par_elems = XVEC (rtl, 0);
+	int num_elem = GET_NUM_ELEM (par_elems);
+	enum machine_mode mode;
+	int i;
+
+	/* Create the first one, so we have something to add to.  */
+	loc_result = loc_descriptor (XEXP (RTVEC_ELT (par_elems, 0), 0));
+	mode = GET_MODE (XEXP (RTVEC_ELT (par_elems, 0), 0));
+	add_loc_descr_op_piece (&loc_result, GET_MODE_SIZE (mode));
+	for (i = 1; i < num_elem; i++)
+	  {
+	    dw_loc_descr_ref temp;
+
+	    temp = loc_descriptor (XEXP (RTVEC_ELT (par_elems, i), 0));
+	    add_loc_descr (&loc_result, temp);
+	    mode = GET_MODE (XEXP (RTVEC_ELT (par_elems, i), 0));
+	    add_loc_descr_op_piece (&loc_result, GET_MODE_SIZE (mode));
+	  }
+      }
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  return loc_result;
+}
+
+/* Similar, but generate the descriptor from trees instead of rtl.  This comes
+   up particularly with variable length arrays.  WANT_ADDRESS is 2 if this is
+   a top-level invocation of loc_descriptor_from_tree; is 1 if this is not a
+   top-level invocation, and we require the address of LOC; is 0 if we require
+   the value of LOC.  */
+
+static dw_loc_descr_ref
+loc_descriptor_from_tree_1 (tree loc, int want_address)
+{
+  dw_loc_descr_ref ret, ret1;
+  int have_address = 0;
+  int unsignedp = TYPE_UNSIGNED (TREE_TYPE (loc));
+  enum dwarf_location_atom op;
+
+  /* ??? Most of the time we do not take proper care for sign/zero
+     extending the values properly.  Hopefully this won't be a real
+     problem...  */
+
+  switch (TREE_CODE (loc))
+    {
+    case ERROR_MARK:
+      return 0;
+
+    case PLACEHOLDER_EXPR:
+      /* This case involves extracting fields from an object to determine the
+	 position of other fields.  We don't try to encode this here.  The
+	 only user of this is Ada, which encodes the needed information using
+	 the names of types.  */
+      return 0;
+
+    case CALL_EXPR:
+      return 0;
+
+    case PREINCREMENT_EXPR:
+    case PREDECREMENT_EXPR:
+    case POSTINCREMENT_EXPR:
+    case POSTDECREMENT_EXPR:
+      /* There are no opcodes for these operations.  */
+      return 0;
+
+    case ADDR_EXPR:
+      /* If we already want an address, there's nothing we can do.  */
+      if (want_address)
+	return 0;
+
+      /* Otherwise, process the argument and look for the address.  */
+      return loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 0), 1);
+
+    case VAR_DECL:
+      if (DECL_THREAD_LOCAL_P (loc))
+	{
+	  rtx rtl;
+
+	  /* If this is not defined, we have no way to emit the data.  */
+	  if (!targetm.asm_out.output_dwarf_dtprel)
+	    return 0;
+
+	  /* The way DW_OP_GNU_push_tls_address is specified, we can only
+	     look up addresses of objects in the current module.  */
+	  if (DECL_EXTERNAL (loc))
+	    return 0;
+
+	  rtl = rtl_for_decl_location (loc);
+	  if (rtl == NULL_RTX)
+	    return 0;
+
+	  if (!MEM_P (rtl))
+	    return 0;
+	  rtl = XEXP (rtl, 0);
+	  if (! CONSTANT_P (rtl))
+	    return 0;
+
+	  ret = new_loc_descr (INTERNAL_DW_OP_tls_addr, 0, 0);
+	  ret->dw_loc_oprnd1.val_class = dw_val_class_addr;
+	  ret->dw_loc_oprnd1.v.val_addr = rtl;
+
+	  ret1 = new_loc_descr (DW_OP_GNU_push_tls_address, 0, 0);
+	  add_loc_descr (&ret, ret1);
+
+	  have_address = 1;
+	  break;
+	}
+      /* FALLTHRU */
+
+    case PARM_DECL:
+      if (DECL_HAS_VALUE_EXPR_P (loc))
+	return loc_descriptor_from_tree_1 (DECL_VALUE_EXPR (loc),
+					   want_address);
+      /* FALLTHRU */
+
+    case RESULT_DECL:
+      {
+	rtx rtl = rtl_for_decl_location (loc);
+
+	if (rtl == NULL_RTX)
+	  return 0;
+        else if (GET_CODE (rtl) == CONST_INT)
+	  {
+	    HOST_WIDE_INT val = INTVAL (rtl);
+	    if (TYPE_UNSIGNED (TREE_TYPE (loc)))
+	      val &= GET_MODE_MASK (DECL_MODE (loc));
+	    ret = int_loc_descriptor (val);
+	  }
+	else if (GET_CODE (rtl) == CONST_STRING)
+	  return 0;
+	else if (CONSTANT_P (rtl))
+	  {
+	    ret = new_loc_descr (DW_OP_addr, 0, 0);
+	    ret->dw_loc_oprnd1.val_class = dw_val_class_addr;
+	    ret->dw_loc_oprnd1.v.val_addr = rtl;
+	  }
+	else
+	  {
+	    enum machine_mode mode;
+
+	    /* Certain constructs can only be represented at top-level.  */
+	    if (want_address == 2)
+	      return loc_descriptor (rtl);
+
+	    mode = GET_MODE (rtl);
+	    if (MEM_P (rtl))
+	      {
+		rtl = XEXP (rtl, 0);
+		have_address = 1;
+	      }
+	    ret = mem_loc_descriptor (rtl, mode);
+	  }
+      }
+      break;
+
+    case INDIRECT_REF:
+      ret = loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 0), 0);
+      have_address = 1;
+      break;
+
+    case COMPOUND_EXPR:
+      return loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 1), want_address);
+
+    case NOP_EXPR:
+    case CONVERT_EXPR:
+    case NON_LVALUE_EXPR:
+    case VIEW_CONVERT_EXPR:
+    case SAVE_EXPR:
+    case MODIFY_EXPR:
+      return loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 0), want_address);
+
+    case COMPONENT_REF:
+    case BIT_FIELD_REF:
+    case ARRAY_REF:
+    case ARRAY_RANGE_REF:
+      {
+	tree obj, offset;
+	HOST_WIDE_INT bitsize, bitpos, bytepos;
+	enum machine_mode mode;
+	int volatilep;
+
+	obj = get_inner_reference (loc, &bitsize, &bitpos, &offset, &mode,
+				   &unsignedp, &volatilep, false);
+
+	if (obj == loc)
+	  return 0;
+
+	ret = loc_descriptor_from_tree_1 (obj, 1);
+	if (ret == 0
+	    || bitpos % BITS_PER_UNIT != 0 || bitsize % BITS_PER_UNIT != 0)
+	  return 0;
+
+	if (offset != NULL_TREE)
+	  {
+	    /* Variable offset.  */
+	    add_loc_descr (&ret, loc_descriptor_from_tree_1 (offset, 0));
+	    add_loc_descr (&ret, new_loc_descr (DW_OP_plus, 0, 0));
+	  }
+
+	bytepos = bitpos / BITS_PER_UNIT;
+	if (bytepos > 0)
+	  add_loc_descr (&ret, new_loc_descr (DW_OP_plus_uconst, bytepos, 0));
+	else if (bytepos < 0)
+	  {
+	    add_loc_descr (&ret, int_loc_descriptor (bytepos));
+	    add_loc_descr (&ret, new_loc_descr (DW_OP_plus, 0, 0));
+	  }
+
+	have_address = 1;
+	break;
+      }
+
+    case INTEGER_CST:
+      if (host_integerp (loc, 0))
+	ret = int_loc_descriptor (tree_low_cst (loc, 0));
+      else
+	return 0;
+      break;
+
+    case CONSTRUCTOR:
+      {
+	/* Get an RTL for this, if something has been emitted.  */
+	rtx rtl = lookup_constant_def (loc);
+	enum machine_mode mode;
+
+	if (!rtl || !MEM_P (rtl))
+	  return 0;
+	mode = GET_MODE (rtl);
+	rtl = XEXP (rtl, 0);
+	ret = mem_loc_descriptor (rtl, mode);
+	have_address = 1;
+	break;
+      }
+
+    case TRUTH_AND_EXPR:
+    case TRUTH_ANDIF_EXPR:
+    case BIT_AND_EXPR:
+      op = DW_OP_and;
+      goto do_binop;
+
+    case TRUTH_XOR_EXPR:
+    case BIT_XOR_EXPR:
+      op = DW_OP_xor;
+      goto do_binop;
+
+    case TRUTH_OR_EXPR:
+    case TRUTH_ORIF_EXPR:
+    case BIT_IOR_EXPR:
+      op = DW_OP_or;
+      goto do_binop;
+
+    case FLOOR_DIV_EXPR:
+    case CEIL_DIV_EXPR:
+    case ROUND_DIV_EXPR:
+    case TRUNC_DIV_EXPR:
+      op = DW_OP_div;
+      goto do_binop;
+
+    case MINUS_EXPR:
+      op = DW_OP_minus;
+      goto do_binop;
+
+    case FLOOR_MOD_EXPR:
+    case CEIL_MOD_EXPR:
+    case ROUND_MOD_EXPR:
+    case TRUNC_MOD_EXPR:
+      op = DW_OP_mod;
+      goto do_binop;
+
+    case MULT_EXPR:
+      op = DW_OP_mul;
+      goto do_binop;
+
+    case LSHIFT_EXPR:
+      op = DW_OP_shl;
+      goto do_binop;
+
+    case RSHIFT_EXPR:
+      op = (unsignedp ? DW_OP_shr : DW_OP_shra);
+      goto do_binop;
+
+    case PLUS_EXPR:
+      if (TREE_CODE (TREE_OPERAND (loc, 1)) == INTEGER_CST
+	  && host_integerp (TREE_OPERAND (loc, 1), 0))
+	{
+	  ret = loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 0), 0);
+	  if (ret == 0)
+	    return 0;
+
+	  add_loc_descr (&ret,
+			 new_loc_descr (DW_OP_plus_uconst,
+					tree_low_cst (TREE_OPERAND (loc, 1),
+						      0),
+					0));
+	  break;
+	}
+
+      op = DW_OP_plus;
+      goto do_binop;
+
+    case LE_EXPR:
+      if (TYPE_UNSIGNED (TREE_TYPE (TREE_OPERAND (loc, 0))))
+	return 0;
+
+      op = DW_OP_le;
+      goto do_binop;
+
+    case GE_EXPR:
+      if (TYPE_UNSIGNED (TREE_TYPE (TREE_OPERAND (loc, 0))))
+	return 0;
+
+      op = DW_OP_ge;
+      goto do_binop;
+
+    case LT_EXPR:
+      if (TYPE_UNSIGNED (TREE_TYPE (TREE_OPERAND (loc, 0))))
+	return 0;
+
+      op = DW_OP_lt;
+      goto do_binop;
+
+    case GT_EXPR:
+      if (TYPE_UNSIGNED (TREE_TYPE (TREE_OPERAND (loc, 0))))
+	return 0;
+
+      op = DW_OP_gt;
+      goto do_binop;
+
+    case EQ_EXPR:
+      op = DW_OP_eq;
+      goto do_binop;
+
+    case NE_EXPR:
+      op = DW_OP_ne;
+      goto do_binop;
+
+    do_binop:
+      ret = loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 0), 0);
+      ret1 = loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 1), 0);
+      if (ret == 0 || ret1 == 0)
+	return 0;
+
+      add_loc_descr (&ret, ret1);
+      add_loc_descr (&ret, new_loc_descr (op, 0, 0));
+      break;
+
+    case TRUTH_NOT_EXPR:
+    case BIT_NOT_EXPR:
+      op = DW_OP_not;
+      goto do_unop;
+
+    case ABS_EXPR:
+      op = DW_OP_abs;
+      goto do_unop;
+
+    case NEGATE_EXPR:
+      op = DW_OP_neg;
+      goto do_unop;
+
+    do_unop:
+      ret = loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 0), 0);
+      if (ret == 0)
+	return 0;
+
+      add_loc_descr (&ret, new_loc_descr (op, 0, 0));
+      break;
+
+    case MIN_EXPR:
+    case MAX_EXPR:
+      {
+        const enum tree_code code =
+          TREE_CODE (loc) == MIN_EXPR ? GT_EXPR : LT_EXPR;
+
+        loc = build3 (COND_EXPR, TREE_TYPE (loc),
+		      build2 (code, integer_type_node,
+			      TREE_OPERAND (loc, 0), TREE_OPERAND (loc, 1)),
+                      TREE_OPERAND (loc, 1), TREE_OPERAND (loc, 0));
+      }
+
+      /* ... fall through ...  */
+
+    case COND_EXPR:
+      {
+	dw_loc_descr_ref lhs
+	  = loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 1), 0);
+	dw_loc_descr_ref rhs
+	  = loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 2), 0);
+	dw_loc_descr_ref bra_node, jump_node, tmp;
+
+	ret = loc_descriptor_from_tree_1 (TREE_OPERAND (loc, 0), 0);
+	if (ret == 0 || lhs == 0 || rhs == 0)
+	  return 0;
+
+	bra_node = new_loc_descr (DW_OP_bra, 0, 0);
+	add_loc_descr (&ret, bra_node);
+
+	add_loc_descr (&ret, rhs);
+	jump_node = new_loc_descr (DW_OP_skip, 0, 0);
+	add_loc_descr (&ret, jump_node);
+
+	add_loc_descr (&ret, lhs);
+	bra_node->dw_loc_oprnd1.val_class = dw_val_class_loc;
+	bra_node->dw_loc_oprnd1.v.val_loc = lhs;
+
+	/* ??? Need a node to point the skip at.  Use a nop.  */
+	tmp = new_loc_descr (DW_OP_nop, 0, 0);
+	add_loc_descr (&ret, tmp);
+	jump_node->dw_loc_oprnd1.val_class = dw_val_class_loc;
+	jump_node->dw_loc_oprnd1.v.val_loc = tmp;
+      }
+      break;
+
+    case FIX_TRUNC_EXPR:
+    case FIX_CEIL_EXPR:
+    case FIX_FLOOR_EXPR:
+    case FIX_ROUND_EXPR:
+      return 0;
+
+    default:
+      /* Leave front-end specific codes as simply unknown.  This comes
+	 up, for instance, with the C STMT_EXPR.  */
+      if ((unsigned int) TREE_CODE (loc)
+          >= (unsigned int) LAST_AND_UNUSED_TREE_CODE)
+	return 0;
+
+#ifdef ENABLE_CHECKING
+      /* Otherwise this is a generic code; we should just lists all of
+	 these explicitly.  We forgot one.  */
+      gcc_unreachable ();
+#else
+      /* In a release build, we want to degrade gracefully: better to
+	 generate incomplete debugging information than to crash.  */
+      return NULL;
+#endif
+    }
+
+  /* Show if we can't fill the request for an address.  */
+  if (want_address && !have_address)
+    return 0;
+
+  /* If we've got an address and don't want one, dereference.  */
+  if (!want_address && have_address)
+    {
+      HOST_WIDE_INT size = int_size_in_bytes (TREE_TYPE (loc));
+
+      if (size > DWARF2_ADDR_SIZE || size == -1)
+	return 0;
+      else if (size == DWARF2_ADDR_SIZE)
+	op = DW_OP_deref;
+      else
+	op = DW_OP_deref_size;
+
+      add_loc_descr (&ret, new_loc_descr (op, size, 0));
+    }
+
+  return ret;
+}
+
+static inline dw_loc_descr_ref
+loc_descriptor_from_tree (tree loc)
+{
+  return loc_descriptor_from_tree_1 (loc, 2);
+}
+
+/* Given a value, round it up to the lowest multiple of `boundary'
+   which is not less than the value itself.  */
+
+static inline HOST_WIDE_INT
+ceiling (HOST_WIDE_INT value, unsigned int boundary)
+{
+  return (((value + boundary - 1) / boundary) * boundary);
+}
+
+/* Given a pointer to what is assumed to be a FIELD_DECL node, return a
+   pointer to the declared type for the relevant field variable, or return
+   `integer_type_node' if the given node turns out to be an
+   ERROR_MARK node.  */
+
+static inline tree
+field_type (tree decl)
+{
+  tree type;
+
+  if (TREE_CODE (decl) == ERROR_MARK)
+    return integer_type_node;
+
+  type = DECL_BIT_FIELD_TYPE (decl);
+  if (type == NULL_TREE)
+    type = TREE_TYPE (decl);
+
+  return type;
+}
+
+/* Given a pointer to a tree node, return the alignment in bits for
+   it, or else return BITS_PER_WORD if the node actually turns out to
+   be an ERROR_MARK node.  */
+
+static inline unsigned
+simple_type_align_in_bits (tree type)
+{
+  return (TREE_CODE (type) != ERROR_MARK) ? TYPE_ALIGN (type) : BITS_PER_WORD;
+}
+
+static inline unsigned
+simple_decl_align_in_bits (tree decl)
+{
+  return (TREE_CODE (decl) != ERROR_MARK) ? DECL_ALIGN (decl) : BITS_PER_WORD;
+}
+
+/* Given a pointer to a FIELD_DECL, compute and return the byte offset of the
+   lowest addressed byte of the "containing object" for the given FIELD_DECL,
+   or return 0 if we are unable to determine what that offset is, either
+   because the argument turns out to be a pointer to an ERROR_MARK node, or
+   because the offset is actually variable.  (We can't handle the latter case
+   just yet).  */
+
+static HOST_WIDE_INT
+field_byte_offset (tree decl)
+{
+  unsigned int type_align_in_bits;
+  unsigned int decl_align_in_bits;
+  unsigned HOST_WIDE_INT type_size_in_bits;
+  HOST_WIDE_INT object_offset_in_bits;
+  tree type;
+  tree field_size_tree;
+  HOST_WIDE_INT bitpos_int;
+  HOST_WIDE_INT deepest_bitpos;
+  unsigned HOST_WIDE_INT field_size_in_bits;
+
+  if (TREE_CODE (decl) == ERROR_MARK)
+    return 0;
+
+  gcc_assert (TREE_CODE (decl) == FIELD_DECL);
+
+  type = field_type (decl);
+  field_size_tree = DECL_SIZE (decl);
+
+  /* The size could be unspecified if there was an error, or for
+     a flexible array member.  */
+  if (! field_size_tree)
+    field_size_tree = bitsize_zero_node;
+
+  /* We cannot yet cope with fields whose positions are variable, so
+     for now, when we see such things, we simply return 0.  Someday, we may
+     be able to handle such cases, but it will be damn difficult.  */
+  if (! host_integerp (bit_position (decl), 0))
+    return 0;
+
+  bitpos_int = int_bit_position (decl);
+
+  /* If we don't know the size of the field, pretend it's a full word.  */
+  if (host_integerp (field_size_tree, 1))
+    field_size_in_bits = tree_low_cst (field_size_tree, 1);
+  else
+    field_size_in_bits = BITS_PER_WORD;
+
+  type_size_in_bits = simple_type_size_in_bits (type);
+  type_align_in_bits = simple_type_align_in_bits (type);
+  decl_align_in_bits = simple_decl_align_in_bits (decl);
+
+  /* The GCC front-end doesn't make any attempt to keep track of the starting
+     bit offset (relative to the start of the containing structure type) of the
+     hypothetical "containing object" for a bit-field.  Thus, when computing
+     the byte offset value for the start of the "containing object" of a
+     bit-field, we must deduce this information on our own. This can be rather
+     tricky to do in some cases.  For example, handling the following structure
+     type definition when compiling for an i386/i486 target (which only aligns
+     long long's to 32-bit boundaries) can be very tricky:
+
+	 struct S { int field1; long long field2:31; };
+
+     Fortunately, there is a simple rule-of-thumb which can be used in such
+     cases.  When compiling for an i386/i486, GCC will allocate 8 bytes for the
+     structure shown above.  It decides to do this based upon one simple rule
+     for bit-field allocation.  GCC allocates each "containing object" for each
+     bit-field at the first (i.e. lowest addressed) legitimate alignment
+     boundary (based upon the required minimum alignment for the declared type
+     of the field) which it can possibly use, subject to the condition that
+     there is still enough available space remaining in the containing object
+     (when allocated at the selected point) to fully accommodate all of the
+     bits of the bit-field itself.
+
+     This simple rule makes it obvious why GCC allocates 8 bytes for each
+     object of the structure type shown above.  When looking for a place to
+     allocate the "containing object" for `field2', the compiler simply tries
+     to allocate a 64-bit "containing object" at each successive 32-bit
+     boundary (starting at zero) until it finds a place to allocate that 64-
+     bit field such that at least 31 contiguous (and previously unallocated)
+     bits remain within that selected 64 bit field.  (As it turns out, for the
+     example above, the compiler finds it is OK to allocate the "containing
+     object" 64-bit field at bit-offset zero within the structure type.)
+
+     Here we attempt to work backwards from the limited set of facts we're
+     given, and we try to deduce from those facts, where GCC must have believed
+     that the containing object started (within the structure type). The value
+     we deduce is then used (by the callers of this routine) to generate
+     DW_AT_location and DW_AT_bit_offset attributes for fields (both bit-fields
+     and, in the case of DW_AT_location, regular fields as well).  */
+
+  /* Figure out the bit-distance from the start of the structure to the
+     "deepest" bit of the bit-field.  */
+  deepest_bitpos = bitpos_int + field_size_in_bits;
+
+  /* This is the tricky part.  Use some fancy footwork to deduce where the
+     lowest addressed bit of the containing object must be.  */
+  object_offset_in_bits = deepest_bitpos - type_size_in_bits;
+
+  /* Round up to type_align by default.  This works best for bitfields.  */
+  object_offset_in_bits += type_align_in_bits - 1;
+  object_offset_in_bits /= type_align_in_bits;
+  object_offset_in_bits *= type_align_in_bits;
+
+  if (object_offset_in_bits > bitpos_int)
+    {
+      /* Sigh, the decl must be packed.  */
+      object_offset_in_bits = deepest_bitpos - type_size_in_bits;
+
+      /* Round up to decl_align instead.  */
+      object_offset_in_bits += decl_align_in_bits - 1;
+      object_offset_in_bits /= decl_align_in_bits;
+      object_offset_in_bits *= decl_align_in_bits;
+    }
+
+  return object_offset_in_bits / BITS_PER_UNIT;
+}
+
+/* The following routines define various Dwarf attributes and any data
+   associated with them.  */
+
+/* Add a location description attribute value to a DIE.
+
+   This emits location attributes suitable for whole variables and
+   whole parameters.  Note that the location attributes for struct fields are
+   generated by the routine `data_member_location_attribute' below.  */
+
+static inline void
+add_AT_location_description (dw_die_ref die, enum dwarf_attribute attr_kind,
+			     dw_loc_descr_ref descr)
+{
+  if (descr != 0)
+    add_AT_loc (die, attr_kind, descr);
+}
+
+/* Attach the specialized form of location attribute used for data members of
+   struct and union types.  In the special case of a FIELD_DECL node which
+   represents a bit-field, the "offset" part of this special location
+   descriptor must indicate the distance in bytes from the lowest-addressed
+   byte of the containing struct or union type to the lowest-addressed byte of
+   the "containing object" for the bit-field.  (See the `field_byte_offset'
+   function above).
+
+   For any given bit-field, the "containing object" is a hypothetical object
+   (of some integral or enum type) within which the given bit-field lives.  The
+   type of this hypothetical "containing object" is always the same as the
+   declared type of the individual bit-field itself (for GCC anyway... the
+   DWARF spec doesn't actually mandate this).  Note that it is the size (in
+   bytes) of the hypothetical "containing object" which will be given in the
+   DW_AT_byte_size attribute for this bit-field.  (See the
+   `byte_size_attribute' function below.)  It is also used when calculating the
+   value of the DW_AT_bit_offset attribute.  (See the `bit_offset_attribute'
+   function below.)  */
+
+static void
+add_data_member_location_attribute (dw_die_ref die, tree decl)
+{
+  HOST_WIDE_INT offset;
+  dw_loc_descr_ref loc_descr = 0;
+
+  if (TREE_CODE (decl) == TREE_BINFO)
+    {
+      /* We're working on the TAG_inheritance for a base class.  */
+      if (BINFO_VIRTUAL_P (decl) && is_cxx ())
+	{
+	  /* For C++ virtual bases we can't just use BINFO_OFFSET, as they
+	     aren't at a fixed offset from all (sub)objects of the same
+	     type.  We need to extract the appropriate offset from our
+	     vtable.  The following dwarf expression means
+
+	       BaseAddr = ObAddr + *((*ObAddr) - Offset)
+
+	     This is specific to the V3 ABI, of course.  */
+
+	  dw_loc_descr_ref tmp;
+
+	  /* Make a copy of the object address.  */
+	  tmp = new_loc_descr (DW_OP_dup, 0, 0);
+	  add_loc_descr (&loc_descr, tmp);
+
+	  /* Extract the vtable address.  */
+	  tmp = new_loc_descr (DW_OP_deref, 0, 0);
+	  add_loc_descr (&loc_descr, tmp);
+
+	  /* Calculate the address of the offset.  */
+	  offset = tree_low_cst (BINFO_VPTR_FIELD (decl), 0);
+	  gcc_assert (offset < 0);
+
+	  tmp = int_loc_descriptor (-offset);
+	  add_loc_descr (&loc_descr, tmp);
+	  tmp = new_loc_descr (DW_OP_minus, 0, 0);
+	  add_loc_descr (&loc_descr, tmp);
+
+	  /* Extract the offset.  */
+	  tmp = new_loc_descr (DW_OP_deref, 0, 0);
+	  add_loc_descr (&loc_descr, tmp);
+
+	  /* Add it to the object address.  */
+	  tmp = new_loc_descr (DW_OP_plus, 0, 0);
+	  add_loc_descr (&loc_descr, tmp);
+	}
+      else
+	offset = tree_low_cst (BINFO_OFFSET (decl), 0);
+    }
+  else
+    offset = field_byte_offset (decl);
+
+  if (! loc_descr)
+    {
+      enum dwarf_location_atom op;
+
+      /* The DWARF2 standard says that we should assume that the structure
+	 address is already on the stack, so we can specify a structure field
+	 address by using DW_OP_plus_uconst.  */
+
+#ifdef MIPS_DEBUGGING_INFO
+      /* ??? The SGI dwarf reader does not handle the DW_OP_plus_uconst
+	 operator correctly.  It works only if we leave the offset on the
+	 stack.  */
+      op = DW_OP_constu;
+#else
+      op = DW_OP_plus_uconst;
+#endif
+
+      loc_descr = new_loc_descr (op, offset, 0);
+    }
+
+  add_AT_loc (die, DW_AT_data_member_location, loc_descr);
+}
+
+/* Writes integer values to dw_vec_const array.  */
+
+static void
+insert_int (HOST_WIDE_INT val, unsigned int size, unsigned char *dest)
+{
+  while (size != 0)
+    {
+      *dest++ = val & 0xff;
+      val >>= 8;
+      --size;
+    }
+}
+
+/* Reads integers from dw_vec_const array.  Inverse of insert_int.  */
+
+static HOST_WIDE_INT
+extract_int (const unsigned char *src, unsigned int size)
+{
+  HOST_WIDE_INT val = 0;
+
+  src += size;
+  while (size != 0)
+    {
+      val <<= 8;
+      val |= *--src & 0xff;
+      --size;
+    }
+  return val;
+}
+
+/* Writes floating point values to dw_vec_const array.  */
+
+static void
+insert_float (rtx rtl, unsigned char *array)
+{
+  REAL_VALUE_TYPE rv;
+  long val[4];
+  int i;
+
+  REAL_VALUE_FROM_CONST_DOUBLE (rv, rtl);
+  real_to_target (val, &rv, GET_MODE (rtl));
+
+  /* real_to_target puts 32-bit pieces in each long.  Pack them.  */
+  for (i = 0; i < GET_MODE_SIZE (GET_MODE (rtl)) / 4; i++)
+    {
+      insert_int (val[i], 4, array);
+      array += 4;
+    }
+}
+
+/* Attach a DW_AT_const_value attribute for a variable or a parameter which
+   does not have a "location" either in memory or in a register.  These
+   things can arise in GNU C when a constant is passed as an actual parameter
+   to an inlined function.  They can also arise in C++ where declared
+   constants do not necessarily get memory "homes".  */
+
+static void
+add_const_value_attribute (dw_die_ref die, rtx rtl)
+{
+  switch (GET_CODE (rtl))
+    {
+    case CONST_INT:
+      {
+	HOST_WIDE_INT val = INTVAL (rtl);
+
+	if (val < 0)
+	  add_AT_int (die, DW_AT_const_value, val);
+	else
+	  add_AT_unsigned (die, DW_AT_const_value, (unsigned HOST_WIDE_INT) val);
+      }
+      break;
+
+    case CONST_DOUBLE:
+      /* Note that a CONST_DOUBLE rtx could represent either an integer or a
+	 floating-point constant.  A CONST_DOUBLE is used whenever the
+	 constant requires more than one word in order to be adequately
+	 represented.  We output CONST_DOUBLEs as blocks.  */
+      {
+	enum machine_mode mode = GET_MODE (rtl);
+
+	if (GET_MODE_CLASS (mode) == MODE_FLOAT)
+	  {
+	    unsigned int length = GET_MODE_SIZE (mode);
+	    unsigned char *array = ggc_alloc (length);
+
+	    insert_float (rtl, array);
+	    add_AT_vec (die, DW_AT_const_value, length / 4, 4, array);
+	  }
+	else
+	  {
+	    /* ??? We really should be using HOST_WIDE_INT throughout.  */
+	    gcc_assert (HOST_BITS_PER_LONG == HOST_BITS_PER_WIDE_INT);
+
+	    add_AT_long_long (die, DW_AT_const_value,
+			      CONST_DOUBLE_HIGH (rtl), CONST_DOUBLE_LOW (rtl));
+	  }
+      }
+      break;
+
+    case CONST_VECTOR:
+      {
+	enum machine_mode mode = GET_MODE (rtl);
+	unsigned int elt_size = GET_MODE_UNIT_SIZE (mode);
+	unsigned int length = CONST_VECTOR_NUNITS (rtl);
+	unsigned char *array = ggc_alloc (length * elt_size);
+	unsigned int i;
+	unsigned char *p;
+
+	switch (GET_MODE_CLASS (mode))
+	  {
+	  case MODE_VECTOR_INT:
+	    for (i = 0, p = array; i < length; i++, p += elt_size)
+	      {
+		rtx elt = CONST_VECTOR_ELT (rtl, i);
+		HOST_WIDE_INT lo, hi;
+
+		switch (GET_CODE (elt))
+		  {
+		  case CONST_INT:
+		    lo = INTVAL (elt);
+		    hi = -(lo < 0);
+		    break;
+
+		  case CONST_DOUBLE:
+		    lo = CONST_DOUBLE_LOW (elt);
+		    hi = CONST_DOUBLE_HIGH (elt);
+		    break;
+
+		  default:
+		    gcc_unreachable ();
+		  }
+
+		if (elt_size <= sizeof (HOST_WIDE_INT))
+		  insert_int (lo, elt_size, p);
+		else
+		  {
+		    unsigned char *p0 = p;
+		    unsigned char *p1 = p + sizeof (HOST_WIDE_INT);
+
+		    gcc_assert (elt_size == 2 * sizeof (HOST_WIDE_INT));
+		    if (WORDS_BIG_ENDIAN)
+		      {
+			p0 = p1;
+			p1 = p;
+		      }
+		    insert_int (lo, sizeof (HOST_WIDE_INT), p0);
+		    insert_int (hi, sizeof (HOST_WIDE_INT), p1);
+		  }
+	      }
+	    break;
+
+	  case MODE_VECTOR_FLOAT:
+	    for (i = 0, p = array; i < length; i++, p += elt_size)
+	      {
+		rtx elt = CONST_VECTOR_ELT (rtl, i);
+		insert_float (elt, p);
+	      }
+	    break;
+
+	  default:
+	    gcc_unreachable ();
+	  }
+
+	add_AT_vec (die, DW_AT_const_value, length, elt_size, array);
+      }
+      break;
+
+    case CONST_STRING:
+      add_AT_string (die, DW_AT_const_value, XSTR (rtl, 0));
+      break;
+
+    case SYMBOL_REF:
+    case LABEL_REF:
+    case CONST:
+      add_AT_addr (die, DW_AT_const_value, rtl);
+      VEC_safe_push (rtx, gc, used_rtx_array, rtl);
+      break;
+
+    case PLUS:
+      /* In cases where an inlined instance of an inline function is passed
+	 the address of an `auto' variable (which is local to the caller) we
+	 can get a situation where the DECL_RTL of the artificial local
+	 variable (for the inlining) which acts as a stand-in for the
+	 corresponding formal parameter (of the inline function) will look
+	 like (plus:SI (reg:SI FRAME_PTR) (const_int ...)).  This is not
+	 exactly a compile-time constant expression, but it isn't the address
+	 of the (artificial) local variable either.  Rather, it represents the
+	 *value* which the artificial local variable always has during its
+	 lifetime.  We currently have no way to represent such quasi-constant
+	 values in Dwarf, so for now we just punt and generate nothing.  */
+      break;
+
+    default:
+      /* No other kinds of rtx should be possible here.  */
+      gcc_unreachable ();
+    }
+
+}
+
+/* Generate an RTL constant from a decl initializer INIT with decl type TYPE,
+   for use in a later add_const_value_attribute call.  */
+
+static rtx
+rtl_for_decl_init (tree init, tree type)
+{
+  rtx rtl = NULL_RTX;
+
+  /* If a variable is initialized with a string constant without embedded
+     zeros, build CONST_STRING.  */
+  if (TREE_CODE (init) == STRING_CST && TREE_CODE (type) == ARRAY_TYPE)
+    {
+      tree enttype = TREE_TYPE (type);
+      tree domain = TYPE_DOMAIN (type);
+      enum machine_mode mode = TYPE_MODE (enttype);
+
+      if (GET_MODE_CLASS (mode) == MODE_INT && GET_MODE_SIZE (mode) == 1
+	  && domain
+	  && integer_zerop (TYPE_MIN_VALUE (domain))
+	  && compare_tree_int (TYPE_MAX_VALUE (domain),
+			       TREE_STRING_LENGTH (init) - 1) == 0
+	  && ((size_t) TREE_STRING_LENGTH (init)
+	      == strlen (TREE_STRING_POINTER (init)) + 1))
+	rtl = gen_rtx_CONST_STRING (VOIDmode,
+				    ggc_strdup (TREE_STRING_POINTER (init)));
+    }
+  /* If the initializer is something that we know will expand into an
+     immediate RTL constant, expand it now.  Expanding anything else
+     tends to produce unresolved symbols; see debug/5770 and c++/6381.  */
+  /* Aggregate, vector, and complex types may contain constructors that may
+     result in code being generated when expand_expr is called, so we can't
+     handle them here.  Integer and float are useful and safe types to handle
+     here.  */
+  else if ((INTEGRAL_TYPE_P (type) || SCALAR_FLOAT_TYPE_P (type))
+	   && initializer_constant_valid_p (init, type) == null_pointer_node)
+    {
+      rtl = expand_expr (init, NULL_RTX, VOIDmode, EXPAND_INITIALIZER);
+
+      /* If expand_expr returns a MEM, it wasn't immediate.  */
+      gcc_assert (!rtl || !MEM_P (rtl));
+    }
+
+  return rtl;
+}
+
+/* Generate RTL for the variable DECL to represent its location.  */
+
+static rtx
+rtl_for_decl_location (tree decl)
+{
+  rtx rtl;
+
+  /* Here we have to decide where we are going to say the parameter "lives"
+     (as far as the debugger is concerned).  We only have a couple of
+     choices.  GCC provides us with DECL_RTL and with DECL_INCOMING_RTL.
+
+     DECL_RTL normally indicates where the parameter lives during most of the
+     activation of the function.  If optimization is enabled however, this
+     could be either NULL or else a pseudo-reg.  Both of those cases indicate
+     that the parameter doesn't really live anywhere (as far as the code
+     generation parts of GCC are concerned) during most of the function's
+     activation.  That will happen (for example) if the parameter is never
+     referenced within the function.
+
+     We could just generate a location descriptor here for all non-NULL
+     non-pseudo values of DECL_RTL and ignore all of the rest, but we can be
+     a little nicer than that if we also consider DECL_INCOMING_RTL in cases
+     where DECL_RTL is NULL or is a pseudo-reg.
+
+     Note however that we can only get away with using DECL_INCOMING_RTL as
+     a backup substitute for DECL_RTL in certain limited cases.  In cases
+     where DECL_ARG_TYPE (decl) indicates the same type as TREE_TYPE (decl),
+     we can be sure that the parameter was passed using the same type as it is
+     declared to have within the function, and that its DECL_INCOMING_RTL
+     points us to a place where a value of that type is passed.
+
+     In cases where DECL_ARG_TYPE (decl) and TREE_TYPE (decl) are different,
+     we cannot (in general) use DECL_INCOMING_RTL as a substitute for DECL_RTL
+     because in these cases DECL_INCOMING_RTL points us to a value of some
+     type which is *different* from the type of the parameter itself.  Thus,
+     if we tried to use DECL_INCOMING_RTL to generate a location attribute in
+     such cases, the debugger would end up (for example) trying to fetch a
+     `float' from a place which actually contains the first part of a
+     `double'.  That would lead to really incorrect and confusing
+     output at debug-time.
+
+     So, in general, we *do not* use DECL_INCOMING_RTL as a backup for DECL_RTL
+     in cases where DECL_ARG_TYPE (decl) != TREE_TYPE (decl).  There
+     are a couple of exceptions however.  On little-endian machines we can
+     get away with using DECL_INCOMING_RTL even when DECL_ARG_TYPE (decl) is
+     not the same as TREE_TYPE (decl), but only when DECL_ARG_TYPE (decl) is
+     an integral type that is smaller than TREE_TYPE (decl). These cases arise
+     when (on a little-endian machine) a non-prototyped function has a
+     parameter declared to be of type `short' or `char'.  In such cases,
+     TREE_TYPE (decl) will be `short' or `char', DECL_ARG_TYPE (decl) will
+     be `int', and DECL_INCOMING_RTL will point to the lowest-order byte of the
+     passed `int' value.  If the debugger then uses that address to fetch
+     a `short' or a `char' (on a little-endian machine) the result will be
+     the correct data, so we allow for such exceptional cases below.
+
+     Note that our goal here is to describe the place where the given formal
+     parameter lives during most of the function's activation (i.e. between the
+     end of the prologue and the start of the epilogue).  We'll do that as best
+     as we can. Note however that if the given formal parameter is modified
+     sometime during the execution of the function, then a stack backtrace (at
+     debug-time) will show the function as having been called with the *new*
+     value rather than the value which was originally passed in.  This happens
+     rarely enough that it is not a major problem, but it *is* a problem, and
+     I'd like to fix it.
+
+     A future version of dwarf2out.c may generate two additional attributes for
+     any given DW_TAG_formal_parameter DIE which will describe the "passed
+     type" and the "passed location" for the given formal parameter in addition
+     to the attributes we now generate to indicate the "declared type" and the
+     "active location" for each parameter.  This additional set of attributes
+     could be used by debuggers for stack backtraces. Separately, note that
+     sometimes DECL_RTL can be NULL and DECL_INCOMING_RTL can be NULL also.
+     This happens (for example) for inlined-instances of inline function formal
+     parameters which are never referenced.  This really shouldn't be
+     happening.  All PARM_DECL nodes should get valid non-NULL
+     DECL_INCOMING_RTL values.  FIXME.  */
+
+  /* Use DECL_RTL as the "location" unless we find something better.  */
+  rtl = DECL_RTL_IF_SET (decl);
+
+  /* When generating abstract instances, ignore everything except
+     constants, symbols living in memory, and symbols living in
+     fixed registers.  */
+  if (! reload_completed)
+    {
+      if (rtl
+	  && (CONSTANT_P (rtl)
+	      || (MEM_P (rtl)
+	          && CONSTANT_P (XEXP (rtl, 0)))
+	      || (REG_P (rtl)
+	          && TREE_CODE (decl) == VAR_DECL
+		  && TREE_STATIC (decl))))
+	{
+	  rtl = targetm.delegitimize_address (rtl);
+	  return rtl;
+	}
+      rtl = NULL_RTX;
+    }
+  else if (TREE_CODE (decl) == PARM_DECL)
+    {
+      if (rtl == NULL_RTX || is_pseudo_reg (rtl))
+	{
+	  tree declared_type = TREE_TYPE (decl);
+	  tree passed_type = DECL_ARG_TYPE (decl);
+	  enum machine_mode dmode = TYPE_MODE (declared_type);
+	  enum machine_mode pmode = TYPE_MODE (passed_type);
+
+	  /* This decl represents a formal parameter which was optimized out.
+	     Note that DECL_INCOMING_RTL may be NULL in here, but we handle
+	     all cases where (rtl == NULL_RTX) just below.  */
+	  if (dmode == pmode)
+	    rtl = DECL_INCOMING_RTL (decl);
+	  else if (SCALAR_INT_MODE_P (dmode)
+		   && GET_MODE_SIZE (dmode) <= GET_MODE_SIZE (pmode)
+		   && DECL_INCOMING_RTL (decl))
+	    {
+	      rtx inc = DECL_INCOMING_RTL (decl);
+	      if (REG_P (inc))
+		rtl = inc;
+	      else if (MEM_P (inc))
+		{
+		  if (BYTES_BIG_ENDIAN)
+		    rtl = adjust_address_nv (inc, dmode,
+					     GET_MODE_SIZE (pmode)
+					     - GET_MODE_SIZE (dmode));
+		  else
+		    rtl = inc;
+		}
+	    }
+	}
+
+      /* If the parm was passed in registers, but lives on the stack, then
+	 make a big endian correction if the mode of the type of the
+	 parameter is not the same as the mode of the rtl.  */
+      /* ??? This is the same series of checks that are made in dbxout.c before
+	 we reach the big endian correction code there.  It isn't clear if all
+	 of these checks are necessary here, but keeping them all is the safe
+	 thing to do.  */
+      else if (MEM_P (rtl)
+	       && XEXP (rtl, 0) != const0_rtx
+	       && ! CONSTANT_P (XEXP (rtl, 0))
+	       /* Not passed in memory.  */
+	       && !MEM_P (DECL_INCOMING_RTL (decl))
+	       /* Not passed by invisible reference.  */
+	       && (!REG_P (XEXP (rtl, 0))
+		   || REGNO (XEXP (rtl, 0)) == HARD_FRAME_POINTER_REGNUM
+		   || REGNO (XEXP (rtl, 0)) == STACK_POINTER_REGNUM
+#if ARG_POINTER_REGNUM != HARD_FRAME_POINTER_REGNUM
+		   || REGNO (XEXP (rtl, 0)) == ARG_POINTER_REGNUM
+#endif
+		     )
+	       /* Big endian correction check.  */
+	       && BYTES_BIG_ENDIAN
+	       && TYPE_MODE (TREE_TYPE (decl)) != GET_MODE (rtl)
+	       && (GET_MODE_SIZE (TYPE_MODE (TREE_TYPE (decl)))
+		   < UNITS_PER_WORD))
+	{
+	  int offset = (UNITS_PER_WORD
+			- GET_MODE_SIZE (TYPE_MODE (TREE_TYPE (decl))));
+
+	  rtl = gen_rtx_MEM (TYPE_MODE (TREE_TYPE (decl)),
+			     plus_constant (XEXP (rtl, 0), offset));
+	}
+    }
+  else if (TREE_CODE (decl) == VAR_DECL
+	   && rtl
+	   && MEM_P (rtl)
+	   && GET_MODE (rtl) != TYPE_MODE (TREE_TYPE (decl))
+	   && BYTES_BIG_ENDIAN)
+    {
+      int rsize = GET_MODE_SIZE (GET_MODE (rtl));
+      int dsize = GET_MODE_SIZE (TYPE_MODE (TREE_TYPE (decl)));
+
+      /* If a variable is declared "register" yet is smaller than
+	 a register, then if we store the variable to memory, it
+	 looks like we're storing a register-sized value, when in
+	 fact we are not.  We need to adjust the offset of the
+	 storage location to reflect the actual value's bytes,
+	 else gdb will not be able to display it.  */
+      if (rsize > dsize)
+	rtl = gen_rtx_MEM (TYPE_MODE (TREE_TYPE (decl)),
+			   plus_constant (XEXP (rtl, 0), rsize-dsize));
+    }
+
+  /* A variable with no DECL_RTL but a DECL_INITIAL is a compile-time constant,
+     and will have been substituted directly into all expressions that use it.
+     C does not have such a concept, but C++ and other languages do.  */
+  if (!rtl && TREE_CODE (decl) == VAR_DECL && DECL_INITIAL (decl))
+    rtl = rtl_for_decl_init (DECL_INITIAL (decl), TREE_TYPE (decl));
+
+  if (rtl)
+    rtl = targetm.delegitimize_address (rtl);
+
+  /* If we don't look past the constant pool, we risk emitting a
+     reference to a constant pool entry that isn't referenced from
+     code, and thus is not emitted.  */
+  if (rtl)
+    rtl = avoid_constant_pool_reference (rtl);
+
+  return rtl;
+}
+
+/* We need to figure out what section we should use as the base for the
+   address ranges where a given location is valid.
+   1. If this particular DECL has a section associated with it, use that.
+   2. If this function has a section associated with it, use that.
+   3. Otherwise, use the text section.
+   XXX: If you split a variable across multiple sections, we won't notice.  */
+
+static const char *
+secname_for_decl (tree decl)
+{
+  const char *secname;
+
+  if (VAR_OR_FUNCTION_DECL_P (decl) && DECL_SECTION_NAME (decl))
+    {
+      tree sectree = DECL_SECTION_NAME (decl);
+      secname = TREE_STRING_POINTER (sectree);
+    }
+  else if (current_function_decl && DECL_SECTION_NAME (current_function_decl))
+    {
+      tree sectree = DECL_SECTION_NAME (current_function_decl);
+      secname = TREE_STRING_POINTER (sectree);
+    }
+  else if (cfun
+	   && (last_text_section == in_unlikely_executed_text
+	       || (last_text_section == in_named
+		   && last_text_section_name
+		      == cfun->unlikely_text_section_name)))
+    secname = cfun->cold_section_label;
+  else
+    secname = text_section_label;
+
+  return secname;
+}
+
+/* Generate *either* a DW_AT_location attribute or else a DW_AT_const_value
+   data attribute for a variable or a parameter.  We generate the
+   DW_AT_const_value attribute only in those cases where the given variable
+   or parameter does not have a true "location" either in memory or in a
+   register.  This can happen (for example) when a constant is passed as an
+   actual argument in a call to an inline function.  (It's possible that
+   these things can crop up in other ways also.)  Note that one type of
+   constant value which can be passed into an inlined function is a constant
+   pointer.  This can happen for example if an actual argument in an inlined
+   function call evaluates to a compile-time constant address.  */
+
+static void
+add_location_or_const_value_attribute (dw_die_ref die, tree decl,
+				       enum dwarf_attribute attr)
+{
+  rtx rtl;
+  dw_loc_descr_ref descr;
+  var_loc_list *loc_list;
+  struct var_loc_node *node;
+  if (TREE_CODE (decl) == ERROR_MARK)
+    return;
+
+  gcc_assert (TREE_CODE (decl) == VAR_DECL || TREE_CODE (decl) == PARM_DECL
+	      || TREE_CODE (decl) == RESULT_DECL);
+	     
+  /* See if we possibly have multiple locations for this variable.  */
+  loc_list = lookup_decl_loc (decl);
+
+  /* If it truly has multiple locations, the first and last node will
+     differ.  */
+  if (loc_list && loc_list->first != loc_list->last)
+    {
+      const char *endname, *secname;
+      dw_loc_list_ref list;
+      rtx varloc;
+
+      /* Now that we know what section we are using for a base,
+         actually construct the list of locations.
+	 The first location information is what is passed to the
+	 function that creates the location list, and the remaining
+	 locations just get added on to that list.
+	 Note that we only know the start address for a location
+	 (IE location changes), so to build the range, we use
+	 the range [current location start, next location start].
+	 This means we have to special case the last node, and generate
+	 a range of [last location start, end of function label].  */
+
+      node = loc_list->first;
+      varloc = NOTE_VAR_LOCATION (node->var_loc_note);
+      secname = secname_for_decl (decl);
+
+      list = new_loc_list (loc_descriptor (varloc),
+			   node->label, node->next->label, secname, 1);
+      node = node->next;
+
+      for (; node->next; node = node->next)
+	if (NOTE_VAR_LOCATION_LOC (node->var_loc_note) != NULL_RTX)
+	  {
+	    /* The variable has a location between NODE->LABEL and
+	       NODE->NEXT->LABEL.  */
+	    varloc = NOTE_VAR_LOCATION (node->var_loc_note);
+	    add_loc_descr_to_loc_list (&list, loc_descriptor (varloc),
+				       node->label, node->next->label, secname);
+	  }
+
+      /* If the variable has a location at the last label
+	 it keeps its location until the end of function.  */
+      if (NOTE_VAR_LOCATION_LOC (node->var_loc_note) != NULL_RTX)
+	{
+	  char label_id[MAX_ARTIFICIAL_LABEL_BYTES];
+
+	  varloc = NOTE_VAR_LOCATION (node->var_loc_note);
+	  if (!current_function_decl)
+	    endname = text_end_label;
+	  else
+	    {
+	      ASM_GENERATE_INTERNAL_LABEL (label_id, FUNC_END_LABEL,
+					   current_function_funcdef_no);
+	      endname = ggc_strdup (label_id);
+	    }
+	  add_loc_descr_to_loc_list (&list, loc_descriptor (varloc),
+				     node->label, endname, secname);
+	}
+
+      /* Finally, add the location list to the DIE, and we are done.  */
+      add_AT_loc_list (die, attr, list);
+      return;
+    }
+
+  /* Try to get some constant RTL for this decl, and use that as the value of
+     the location.  */
+  
+  rtl = rtl_for_decl_location (decl);
+  if (rtl && (CONSTANT_P (rtl) || GET_CODE (rtl) == CONST_STRING))
+    {
+      add_const_value_attribute (die, rtl);
+      return;
+    }
+  
+  /* If we have tried to generate the location otherwise, and it
+     didn't work out (we wouldn't be here if we did), and we have a one entry
+     location list, try generating a location from that.  */
+  if (loc_list && loc_list->first)
+    {
+      node = loc_list->first;
+      descr = loc_descriptor (NOTE_VAR_LOCATION (node->var_loc_note));
+      if (descr)
+	{
+	  add_AT_location_description (die, attr, descr);
+	  return;
+	}
+    }
+
+  /* We couldn't get any rtl, so try directly generating the location
+     description from the tree.  */
+  descr = loc_descriptor_from_tree (decl);
+  if (descr)
+    {
+      add_AT_location_description (die, attr, descr);
+      return;
+    }
+}
+
+/* If we don't have a copy of this variable in memory for some reason (such
+   as a C++ member constant that doesn't have an out-of-line definition),
+   we should tell the debugger about the constant value.  */
+
+static void
+tree_add_const_value_attribute (dw_die_ref var_die, tree decl)
+{
+  tree init = DECL_INITIAL (decl);
+  tree type = TREE_TYPE (decl);
+  rtx rtl;
+
+  if (TREE_READONLY (decl) && ! TREE_THIS_VOLATILE (decl) && init)
+    /* OK */;
+  else
+    return;
+
+  rtl = rtl_for_decl_init (init, type);
+  if (rtl)
+    add_const_value_attribute (var_die, rtl);
+}
+
+#ifdef DWARF2_UNWIND_INFO
+/* Convert the CFI instructions for the current function into a location
+   list.  This is used for DW_AT_frame_base when we targeting a dwarf2
+   consumer that does not support the dwarf3 DW_OP_call_frame_cfa.  */
+
+static dw_loc_list_ref
+convert_cfa_to_loc_list (void)
+{
+  dw_fde_ref fde;
+  dw_loc_list_ref list, *list_tail;
+  dw_cfi_ref cfi;
+  dw_cfa_location last_cfa, next_cfa;
+  const char *start_label, *last_label, *section;
+
+  fde = &fde_table[fde_table_in_use - 1];
+
+  section = secname_for_decl (current_function_decl);
+  list_tail = &list;
+  list = NULL;
+
+  next_cfa.reg = INVALID_REGNUM;
+  next_cfa.offset = 0;
+  next_cfa.indirect = 0;
+  next_cfa.base_offset = 0;
+
+  start_label = fde->dw_fde_begin;
+
+  /* ??? Bald assumption that the CIE opcode list does not contain
+     advance opcodes.  */
+  for (cfi = cie_cfi_head; cfi; cfi = cfi->dw_cfi_next)
+    lookup_cfa_1 (cfi, &next_cfa);
+
+  last_cfa = next_cfa;
+  last_label = start_label;
+
+  for (cfi = fde->dw_fde_cfi; cfi; cfi = cfi->dw_cfi_next)
+    switch (cfi->dw_cfi_opc)
+      {
+      case DW_CFA_advance_loc1:
+      case DW_CFA_advance_loc2:
+      case DW_CFA_advance_loc4:
+	if (!cfa_equal_p (&last_cfa, &next_cfa))
+	  {
+	    *list_tail = new_loc_list (build_cfa_loc (&last_cfa), start_label,
+				       last_label, section, list == NULL);
+
+	    list_tail = &(*list_tail)->dw_loc_next;
+	    last_cfa = next_cfa;
+	    start_label = last_label;
+	  }
+	last_label = cfi->dw_cfi_oprnd1.dw_cfi_addr;
+	break;
+
+      case DW_CFA_advance_loc:
+	/* The encoding is complex enough that we should never emit this.  */
+      case DW_CFA_remember_state:
+      case DW_CFA_restore_state:
+	/* We don't handle these two in this function.  It would be possible
+	   if it were to be required.  */
+	gcc_unreachable ();
+
+      default:
+	lookup_cfa_1 (cfi, &next_cfa);
+	break;
+      }
+
+  if (!cfa_equal_p (&last_cfa, &next_cfa))
+    {
+      *list_tail = new_loc_list (build_cfa_loc (&last_cfa), start_label,
+				 last_label, section, list == NULL);
+      list_tail = &(*list_tail)->dw_loc_next;
+      start_label = last_label;
+    }
+  *list_tail = new_loc_list (build_cfa_loc (&next_cfa), start_label,
+			     fde->dw_fde_end, section, list == NULL);
+
+  return list;
+}
+
+/* Compute a displacement from the "steady-state frame pointer" to
+   the CFA, and store it in frame_pointer_cfa_offset.  */
+
+static void
+compute_frame_pointer_to_cfa_displacement (void)
+{
+  HOST_WIDE_INT offset;
+  rtx reg, elim;
+
+#ifdef FRAME_POINTER_CFA_OFFSET
+  reg = frame_pointer_rtx;
+  offset = FRAME_POINTER_CFA_OFFSET (current_function_decl);
+#else
+  reg = arg_pointer_rtx;
+  offset = ARG_POINTER_CFA_OFFSET (current_function_decl);
+#endif
+
+  elim = eliminate_regs (reg, VOIDmode, NULL_RTX);
+  if (GET_CODE (elim) == PLUS)
+    {
+      offset += INTVAL (XEXP (elim, 1));
+      elim = XEXP (elim, 0);
+    }
+  gcc_assert (elim == (frame_pointer_needed ? hard_frame_pointer_rtx
+		       : stack_pointer_rtx));
+
+  frame_pointer_cfa_offset = -offset;
+}
+#endif
+
+/* Generate a DW_AT_name attribute given some string value to be included as
+   the value of the attribute.  */
+
+static void
+add_name_attribute (dw_die_ref die, const char *name_string)
+{
+  if (name_string != NULL && *name_string != 0)
+    {
+      if (demangle_name_func)
+	name_string = (*demangle_name_func) (name_string);
+
+      add_AT_string (die, DW_AT_name, name_string);
+    }
+}
+
+/* Generate a DW_AT_comp_dir attribute for DIE.  */
+
+static void
+add_comp_dir_attribute (dw_die_ref die)
+{
+  const char *wd = get_src_pwd ();
+  if (wd != NULL)
+    add_AT_string (die, DW_AT_comp_dir, wd);
+}
+
+/* Given a tree node describing an array bound (either lower or upper) output
+   a representation for that bound.  */
+
+static void
+add_bound_info (dw_die_ref subrange_die, enum dwarf_attribute bound_attr, tree bound)
+{
+  switch (TREE_CODE (bound))
+    {
+    case ERROR_MARK:
+      return;
+
+    /* All fixed-bounds are represented by INTEGER_CST nodes.  */
+    case INTEGER_CST:
+      if (! host_integerp (bound, 0)
+	  || (bound_attr == DW_AT_lower_bound
+	      && (((is_c_family () || is_java ()) &&  integer_zerop (bound))
+		  || (is_fortran () && integer_onep (bound)))))
+	/* Use the default.  */
+	;
+      else
+	add_AT_unsigned (subrange_die, bound_attr, tree_low_cst (bound, 0));
+      break;
+
+    case CONVERT_EXPR:
+    case NOP_EXPR:
+    case NON_LVALUE_EXPR:
+    case VIEW_CONVERT_EXPR:
+      add_bound_info (subrange_die, bound_attr, TREE_OPERAND (bound, 0));
+      break;
+
+    case SAVE_EXPR:
+      break;
+
+    case VAR_DECL:
+    case PARM_DECL:
+    case RESULT_DECL:
+      {
+	dw_die_ref decl_die = lookup_decl_die (bound);
+
+	/* ??? Can this happen, or should the variable have been bound
+	   first?  Probably it can, since I imagine that we try to create
+	   the types of parameters in the order in which they exist in
+	   the list, and won't have created a forward reference to a
+	   later parameter.  */
+	if (decl_die != NULL)
+	  add_AT_die_ref (subrange_die, bound_attr, decl_die);
+	break;
+      }
+
+    default:
+      {
+	/* Otherwise try to create a stack operation procedure to
+	   evaluate the value of the array bound.  */
+
+	dw_die_ref ctx, decl_die;
+	dw_loc_descr_ref loc;
+
+	loc = loc_descriptor_from_tree (bound);
+	if (loc == NULL)
+	  break;
+
+	if (current_function_decl == 0)
+	  ctx = comp_unit_die;
+	else
+	  ctx = lookup_decl_die (current_function_decl);
+
+	decl_die = new_die (DW_TAG_variable, ctx, bound);
+	add_AT_flag (decl_die, DW_AT_artificial, 1);
+	add_type_attribute (decl_die, TREE_TYPE (bound), 1, 0, ctx);
+	add_AT_loc (decl_die, DW_AT_location, loc);
+
+	add_AT_die_ref (subrange_die, bound_attr, decl_die);
+	break;
+      }
+    }
+}
+
+/* Note that the block of subscript information for an array type also
+   includes information about the element type of type given array type.  */
+
+static void
+add_subscript_info (dw_die_ref type_die, tree type)
+{
+#ifndef MIPS_DEBUGGING_INFO
+  unsigned dimension_number;
+#endif
+  tree lower, upper;
+  dw_die_ref subrange_die;
+
+  /* The GNU compilers represent multidimensional array types as sequences of
+     one dimensional array types whose element types are themselves array
+     types.  Here we squish that down, so that each multidimensional array
+     type gets only one array_type DIE in the Dwarf debugging info. The draft
+     Dwarf specification say that we are allowed to do this kind of
+     compression in C (because there is no difference between an array or
+     arrays and a multidimensional array in C) but for other source languages
+     (e.g. Ada) we probably shouldn't do this.  */
+
+  /* ??? The SGI dwarf reader fails for multidimensional arrays with a
+     const enum type.  E.g. const enum machine_mode insn_operand_mode[2][10].
+     We work around this by disabling this feature.  See also
+     gen_array_type_die.  */
+#ifndef MIPS_DEBUGGING_INFO
+  for (dimension_number = 0;
+       TREE_CODE (type) == ARRAY_TYPE;
+       type = TREE_TYPE (type), dimension_number++)
+#endif
+    {
+      tree domain = TYPE_DOMAIN (type);
+
+      /* Arrays come in three flavors: Unspecified bounds, fixed bounds,
+	 and (in GNU C only) variable bounds.  Handle all three forms
+	 here.  */
+      subrange_die = new_die (DW_TAG_subrange_type, type_die, NULL);
+      if (domain)
+	{
+	  /* We have an array type with specified bounds.  */
+	  lower = TYPE_MIN_VALUE (domain);
+	  upper = TYPE_MAX_VALUE (domain);
+
+	  /* Define the index type.  */
+	  if (TREE_TYPE (domain))
+	    {
+	      /* ??? This is probably an Ada unnamed subrange type.  Ignore the
+		 TREE_TYPE field.  We can't emit debug info for this
+		 because it is an unnamed integral type.  */
+	      if (TREE_CODE (domain) == INTEGER_TYPE
+		  && TYPE_NAME (domain) == NULL_TREE
+		  && TREE_CODE (TREE_TYPE (domain)) == INTEGER_TYPE
+		  && TYPE_NAME (TREE_TYPE (domain)) == NULL_TREE)
+		;
+	      else
+		add_type_attribute (subrange_die, TREE_TYPE (domain), 0, 0,
+				    type_die);
+	    }
+
+	  /* ??? If upper is NULL, the array has unspecified length,
+	     but it does have a lower bound.  This happens with Fortran
+	       dimension arr(N:*)
+	     Since the debugger is definitely going to need to know N
+	     to produce useful results, go ahead and output the lower
+	     bound solo, and hope the debugger can cope.  */
+
+	  add_bound_info (subrange_die, DW_AT_lower_bound, lower);
+	  if (upper)
+	    add_bound_info (subrange_die, DW_AT_upper_bound, upper);
+	}
+
+      /* Otherwise we have an array type with an unspecified length.  The
+	 DWARF-2 spec does not say how to handle this; let's just leave out the
+	 bounds.  */
+    }
+}
+
+static void
+add_byte_size_attribute (dw_die_ref die, tree tree_node)
+{
+  unsigned size;
+
+  switch (TREE_CODE (tree_node))
+    {
+    case ERROR_MARK:
+      size = 0;
+      break;
+    case ENUMERAL_TYPE:
+    case RECORD_TYPE:
+    case UNION_TYPE:
+    case QUAL_UNION_TYPE:
+      size = int_size_in_bytes (tree_node);
+      break;
+    case FIELD_DECL:
+      /* For a data member of a struct or union, the DW_AT_byte_size is
+	 generally given as the number of bytes normally allocated for an
+	 object of the *declared* type of the member itself.  This is true
+	 even for bit-fields.  */
+      size = simple_type_size_in_bits (field_type (tree_node)) / BITS_PER_UNIT;
+      break;
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Note that `size' might be -1 when we get to this point.  If it is, that
+     indicates that the byte size of the entity in question is variable.  We
+     have no good way of expressing this fact in Dwarf at the present time,
+     so just let the -1 pass on through.  */
+  add_AT_unsigned (die, DW_AT_byte_size, size);
+}
+
+/* For a FIELD_DECL node which represents a bit-field, output an attribute
+   which specifies the distance in bits from the highest order bit of the
+   "containing object" for the bit-field to the highest order bit of the
+   bit-field itself.
+
+   For any given bit-field, the "containing object" is a hypothetical object
+   (of some integral or enum type) within which the given bit-field lives.  The
+   type of this hypothetical "containing object" is always the same as the
+   declared type of the individual bit-field itself.  The determination of the
+   exact location of the "containing object" for a bit-field is rather
+   complicated.  It's handled by the `field_byte_offset' function (above).
+
+   Note that it is the size (in bytes) of the hypothetical "containing object"
+   which will be given in the DW_AT_byte_size attribute for this bit-field.
+   (See `byte_size_attribute' above).  */
+
+static inline void
+add_bit_offset_attribute (dw_die_ref die, tree decl)
+{
+  HOST_WIDE_INT object_offset_in_bytes = field_byte_offset (decl);
+  tree type = DECL_BIT_FIELD_TYPE (decl);
+  HOST_WIDE_INT bitpos_int;
+  HOST_WIDE_INT highest_order_object_bit_offset;
+  HOST_WIDE_INT highest_order_field_bit_offset;
+  HOST_WIDE_INT unsigned bit_offset;
+
+  /* Must be a field and a bit field.  */
+  gcc_assert (type && TREE_CODE (decl) == FIELD_DECL);
+
+  /* We can't yet handle bit-fields whose offsets are variable, so if we
+     encounter such things, just return without generating any attribute
+     whatsoever.  Likewise for variable or too large size.  */
+  if (! host_integerp (bit_position (decl), 0)
+      || ! host_integerp (DECL_SIZE (decl), 1))
+    return;
+
+  bitpos_int = int_bit_position (decl);
+
+  /* Note that the bit offset is always the distance (in bits) from the
+     highest-order bit of the "containing object" to the highest-order bit of
+     the bit-field itself.  Since the "high-order end" of any object or field
+     is different on big-endian and little-endian machines, the computation
+     below must take account of these differences.  */
+  highest_order_object_bit_offset = object_offset_in_bytes * BITS_PER_UNIT;
+  highest_order_field_bit_offset = bitpos_int;
+
+  if (! BYTES_BIG_ENDIAN)
+    {
+      highest_order_field_bit_offset += tree_low_cst (DECL_SIZE (decl), 0);
+      highest_order_object_bit_offset += simple_type_size_in_bits (type);
+    }
+
+  bit_offset
+    = (! BYTES_BIG_ENDIAN
+       ? highest_order_object_bit_offset - highest_order_field_bit_offset
+       : highest_order_field_bit_offset - highest_order_object_bit_offset);
+
+  add_AT_unsigned (die, DW_AT_bit_offset, bit_offset);
+}
+
+/* For a FIELD_DECL node which represents a bit field, output an attribute
+   which specifies the length in bits of the given field.  */
+
+static inline void
+add_bit_size_attribute (dw_die_ref die, tree decl)
+{
+  /* Must be a field and a bit field.  */
+  gcc_assert (TREE_CODE (decl) == FIELD_DECL
+	      && DECL_BIT_FIELD_TYPE (decl));
+
+  if (host_integerp (DECL_SIZE (decl), 1))
+    add_AT_unsigned (die, DW_AT_bit_size, tree_low_cst (DECL_SIZE (decl), 1));
+}
+
+/* If the compiled language is ANSI C, then add a 'prototyped'
+   attribute, if arg types are given for the parameters of a function.  */
+
+static inline void
+add_prototyped_attribute (dw_die_ref die, tree func_type)
+{
+  if (get_AT_unsigned (comp_unit_die, DW_AT_language) == DW_LANG_C89
+      && TYPE_ARG_TYPES (func_type) != NULL)
+    add_AT_flag (die, DW_AT_prototyped, 1);
+}
+
+/* Add an 'abstract_origin' attribute below a given DIE.  The DIE is found
+   by looking in either the type declaration or object declaration
+   equate table.  */
+
+static inline void
+add_abstract_origin_attribute (dw_die_ref die, tree origin)
+{
+  dw_die_ref origin_die = NULL;
+
+  if (TREE_CODE (origin) != FUNCTION_DECL)
+    {
+      /* We may have gotten separated from the block for the inlined
+	 function, if we're in an exception handler or some such; make
+	 sure that the abstract function has been written out.
+
+	 Doing this for nested functions is wrong, however; functions are
+	 distinct units, and our context might not even be inline.  */
+      tree fn = origin;
+
+      if (TYPE_P (fn))
+	fn = TYPE_STUB_DECL (fn);
+      
+      fn = decl_function_context (fn);
+      if (fn)
+	dwarf2out_abstract_function (fn);
+    }
+
+  if (DECL_P (origin))
+    origin_die = lookup_decl_die (origin);
+  else if (TYPE_P (origin))
+    origin_die = lookup_type_die (origin);
+
+  /* XXX: Functions that are never lowered don't always have correct block
+     trees (in the case of java, they simply have no block tree, in some other
+     languages).  For these functions, there is nothing we can really do to
+     output correct debug info for inlined functions in all cases.  Rather
+     than die, we'll just produce deficient debug info now, in that we will
+     have variables without a proper abstract origin.  In the future, when all
+     functions are lowered, we should re-add a gcc_assert (origin_die)
+     here.  */
+
+  if (origin_die)
+      add_AT_die_ref (die, DW_AT_abstract_origin, origin_die);
+}
+
+/* We do not currently support the pure_virtual attribute.  */
+
+static inline void
+add_pure_or_virtual_attribute (dw_die_ref die, tree func_decl)
+{
+  if (DECL_VINDEX (func_decl))
+    {
+      add_AT_unsigned (die, DW_AT_virtuality, DW_VIRTUALITY_virtual);
+
+      if (host_integerp (DECL_VINDEX (func_decl), 0))
+	add_AT_loc (die, DW_AT_vtable_elem_location,
+		    new_loc_descr (DW_OP_constu,
+				   tree_low_cst (DECL_VINDEX (func_decl), 0),
+				   0));
+
+      /* GNU extension: Record what type this method came from originally.  */
+      if (debug_info_level > DINFO_LEVEL_TERSE)
+	add_AT_die_ref (die, DW_AT_containing_type,
+			lookup_type_die (DECL_CONTEXT (func_decl)));
+    }
+}
+
+/* Add source coordinate attributes for the given decl.  */
+
+static void
+add_src_coords_attributes (dw_die_ref die, tree decl)
+{
+  expanded_location s = expand_location (DECL_SOURCE_LOCATION (decl));
+  unsigned file_index = lookup_filename (s.file);
+
+  add_AT_unsigned (die, DW_AT_decl_file, file_index);
+  add_AT_unsigned (die, DW_AT_decl_line, s.line);
+}
+
+/* Add a DW_AT_name attribute and source coordinate attribute for the
+   given decl, but only if it actually has a name.  */
+
+static void
+add_name_and_src_coords_attributes (dw_die_ref die, tree decl)
+{
+  tree decl_name;
+
+  decl_name = DECL_NAME (decl);
+  if (decl_name != NULL && IDENTIFIER_POINTER (decl_name) != NULL)
+    {
+      add_name_attribute (die, dwarf2_name (decl, 0));
+      if (! DECL_ARTIFICIAL (decl))
+	add_src_coords_attributes (die, decl);
+
+      if ((TREE_CODE (decl) == FUNCTION_DECL || TREE_CODE (decl) == VAR_DECL)
+	  && TREE_PUBLIC (decl)
+	  && DECL_ASSEMBLER_NAME (decl) != DECL_NAME (decl)
+	  && !DECL_ABSTRACT (decl)
+	  && !(TREE_CODE (decl) == VAR_DECL && DECL_REGISTER (decl)))
+	add_AT_string (die, DW_AT_MIPS_linkage_name,
+		       IDENTIFIER_POINTER (DECL_ASSEMBLER_NAME (decl)));
+    }
+
+#ifdef VMS_DEBUGGING_INFO
+  /* Get the function's name, as described by its RTL.  This may be different
+     from the DECL_NAME name used in the source file.  */
+  if (TREE_CODE (decl) == FUNCTION_DECL && TREE_ASM_WRITTEN (decl))
+    {
+      add_AT_addr (die, DW_AT_VMS_rtnbeg_pd_address,
+		   XEXP (DECL_RTL (decl), 0));
+      VEC_safe_push (tree, gc, used_rtx_array, XEXP (DECL_RTL (decl), 0));
+    }
+#endif
+}
+
+/* Push a new declaration scope.  */
+
+static void
+push_decl_scope (tree scope)
+{
+  VEC_safe_push (tree, gc, decl_scope_table, scope);
+}
+
+/* Pop a declaration scope.  */
+
+static inline void
+pop_decl_scope (void)
+{
+  VEC_pop (tree, decl_scope_table);
+}
+
+/* Return the DIE for the scope that immediately contains this type.
+   Non-named types get global scope.  Named types nested in other
+   types get their containing scope if it's open, or global scope
+   otherwise.  All other types (i.e. function-local named types) get
+   the current active scope.  */
+
+static dw_die_ref
+scope_die_for (tree t, dw_die_ref context_die)
+{
+  dw_die_ref scope_die = NULL;
+  tree containing_scope;
+  int i;
+
+  /* Non-types always go in the current scope.  */
+  gcc_assert (TYPE_P (t));
+
+  containing_scope = TYPE_CONTEXT (t);
+
+  /* Use the containing namespace if it was passed in (for a declaration).  */
+  if (containing_scope && TREE_CODE (containing_scope) == NAMESPACE_DECL)
+    {
+      if (context_die == lookup_decl_die (containing_scope))
+	/* OK */;
+      else
+	containing_scope = NULL_TREE;
+    }
+
+  /* Ignore function type "scopes" from the C frontend.  They mean that
+     a tagged type is local to a parmlist of a function declarator, but
+     that isn't useful to DWARF.  */
+  if (containing_scope && TREE_CODE (containing_scope) == FUNCTION_TYPE)
+    containing_scope = NULL_TREE;
+
+  if (containing_scope == NULL_TREE)
+    scope_die = comp_unit_die;
+  else if (TYPE_P (containing_scope))
+    {
+      /* For types, we can just look up the appropriate DIE.  But
+	 first we check to see if we're in the middle of emitting it
+	 so we know where the new DIE should go.  */
+      for (i = VEC_length (tree, decl_scope_table) - 1; i >= 0; --i)
+	if (VEC_index (tree, decl_scope_table, i) == containing_scope)
+	  break;
+
+      if (i < 0)
+	{
+	  gcc_assert (debug_info_level <= DINFO_LEVEL_TERSE
+		      || TREE_ASM_WRITTEN (containing_scope));
+
+	  /* If none of the current dies are suitable, we get file scope.  */
+	  scope_die = comp_unit_die;
+	}
+      else
+	scope_die = lookup_type_die (containing_scope);
+    }
+  else
+    scope_die = context_die;
+
+  return scope_die;
+}
+
+/* Returns nonzero if CONTEXT_DIE is internal to a function.  */
+
+static inline int
+local_scope_p (dw_die_ref context_die)
+{
+  for (; context_die; context_die = context_die->die_parent)
+    if (context_die->die_tag == DW_TAG_inlined_subroutine
+	|| context_die->die_tag == DW_TAG_subprogram)
+      return 1;
+
+  return 0;
+}
+
+/* Returns nonzero if CONTEXT_DIE is a class or namespace, for deciding
+   whether or not to treat a DIE in this context as a declaration.  */
+
+static inline int
+class_or_namespace_scope_p (dw_die_ref context_die)
+{
+  return (context_die
+	  && (context_die->die_tag == DW_TAG_structure_type
+	      || context_die->die_tag == DW_TAG_union_type
+	      || context_die->die_tag == DW_TAG_namespace));
+}
+
+/* Many forms of DIEs require a "type description" attribute.  This
+   routine locates the proper "type descriptor" die for the type given
+   by 'type', and adds a DW_AT_type attribute below the given die.  */
+
+static void
+add_type_attribute (dw_die_ref object_die, tree type, int decl_const,
+		    int decl_volatile, dw_die_ref context_die)
+{
+  enum tree_code code  = TREE_CODE (type);
+  dw_die_ref type_die  = NULL;
+
+  /* ??? If this type is an unnamed subrange type of an integral or
+     floating-point type, use the inner type.  This is because we have no
+     support for unnamed types in base_type_die.  This can happen if this is
+     an Ada subrange type.  Correct solution is emit a subrange type die.  */
+  if ((code == INTEGER_TYPE || code == REAL_TYPE)
+      && TREE_TYPE (type) != 0 && TYPE_NAME (type) == 0)
+    type = TREE_TYPE (type), code = TREE_CODE (type);
+
+  if (code == ERROR_MARK
+      /* Handle a special case.  For functions whose return type is void, we
+	 generate *no* type attribute.  (Note that no object may have type
+	 `void', so this only applies to function return types).  */
+      || code == VOID_TYPE)
+    return;
+
+  type_die = modified_type_die (type,
+				decl_const || TYPE_READONLY (type),
+				decl_volatile || TYPE_VOLATILE (type),
+				context_die);
+
+  if (type_die != NULL)
+    add_AT_die_ref (object_die, DW_AT_type, type_die);
+}
+
+/* Given an object die, add the calling convention attribute for the
+   function call type.  */
+static void
+add_calling_convention_attribute (dw_die_ref subr_die, tree type)
+{
+  enum dwarf_calling_convention value = DW_CC_normal;
+
+  value = targetm.dwarf_calling_convention (type);
+
+  /* Only add the attribute if the backend requests it, and
+     is not DW_CC_normal.  */
+  if (value && (value != DW_CC_normal))
+    add_AT_unsigned (subr_die, DW_AT_calling_convention, value);
+}
+
+/* Given a tree pointer to a struct, class, union, or enum type node, return
+   a pointer to the (string) tag name for the given type, or zero if the type
+   was declared without a tag.  */
+
+static const char *
+type_tag (tree type)
+{
+  const char *name = 0;
+
+  if (TYPE_NAME (type) != 0)
+    {
+      tree t = 0;
+
+      /* Find the IDENTIFIER_NODE for the type name.  */
+      if (TREE_CODE (TYPE_NAME (type)) == IDENTIFIER_NODE)
+	t = TYPE_NAME (type);
+
+      /* The g++ front end makes the TYPE_NAME of *each* tagged type point to
+	 a TYPE_DECL node, regardless of whether or not a `typedef' was
+	 involved.  */
+      else if (TREE_CODE (TYPE_NAME (type)) == TYPE_DECL
+	       && ! DECL_IGNORED_P (TYPE_NAME (type)))
+	t = DECL_NAME (TYPE_NAME (type));
+
+      /* Now get the name as a string, or invent one.  */
+      if (t != 0)
+	name = IDENTIFIER_POINTER (t);
+    }
+
+  return (name == 0 || *name == '\0') ? 0 : name;
+}
+
+/* Return the type associated with a data member, make a special check
+   for bit field types.  */
+
+static inline tree
+member_declared_type (tree member)
+{
+  return (DECL_BIT_FIELD_TYPE (member)
+	  ? DECL_BIT_FIELD_TYPE (member) : TREE_TYPE (member));
+}
+
+/* Get the decl's label, as described by its RTL. This may be different
+   from the DECL_NAME name used in the source file.  */
+
+#if 0
+static const char *
+decl_start_label (tree decl)
+{
+  rtx x;
+  const char *fnname;
+
+  x = DECL_RTL (decl);
+  gcc_assert (MEM_P (x));
+
+  x = XEXP (x, 0);
+  gcc_assert (GET_CODE (x) == SYMBOL_REF);
+
+  fnname = XSTR (x, 0);
+  return fnname;
+}
+#endif
+
+/* These routines generate the internal representation of the DIE's for
+   the compilation unit.  Debugging information is collected by walking
+   the declaration trees passed in from dwarf2out_decl().  */
+
+static void
+gen_array_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref scope_die = scope_die_for (type, context_die);
+  dw_die_ref array_die;
+  tree element_type;
+
+  /* ??? The SGI dwarf reader fails for array of array of enum types unless
+     the inner array type comes before the outer array type.  Thus we must
+     call gen_type_die before we call new_die.  See below also.  */
+#ifdef MIPS_DEBUGGING_INFO
+  gen_type_die (TREE_TYPE (type), context_die);
+#endif
+
+  array_die = new_die (DW_TAG_array_type, scope_die, type);
+  add_name_attribute (array_die, type_tag (type));
+  equate_type_number_to_die (type, array_die);
+
+  if (TREE_CODE (type) == VECTOR_TYPE)
+    {
+      /* The frontend feeds us a representation for the vector as a struct
+	 containing an array.  Pull out the array type.  */
+      type = TREE_TYPE (TYPE_FIELDS (TYPE_DEBUG_REPRESENTATION_TYPE (type)));
+      add_AT_flag (array_die, DW_AT_GNU_vector, 1);
+    }
+
+#if 0
+  /* We default the array ordering.  SDB will probably do
+     the right things even if DW_AT_ordering is not present.  It's not even
+     an issue until we start to get into multidimensional arrays anyway.  If
+     SDB is ever caught doing the Wrong Thing for multi-dimensional arrays,
+     then we'll have to put the DW_AT_ordering attribute back in.  (But if
+     and when we find out that we need to put these in, we will only do so
+     for multidimensional arrays.  */
+  add_AT_unsigned (array_die, DW_AT_ordering, DW_ORD_row_major);
+#endif
+
+#ifdef MIPS_DEBUGGING_INFO
+  /* The SGI compilers handle arrays of unknown bound by setting
+     AT_declaration and not emitting any subrange DIEs.  */
+  if (! TYPE_DOMAIN (type))
+    add_AT_flag (array_die, DW_AT_declaration, 1);
+  else
+#endif
+    add_subscript_info (array_die, type);
+
+  /* Add representation of the type of the elements of this array type.  */
+  element_type = TREE_TYPE (type);
+
+  /* ??? The SGI dwarf reader fails for multidimensional arrays with a
+     const enum type.  E.g. const enum machine_mode insn_operand_mode[2][10].
+     We work around this by disabling this feature.  See also
+     add_subscript_info.  */
+#ifndef MIPS_DEBUGGING_INFO
+  while (TREE_CODE (element_type) == ARRAY_TYPE)
+    element_type = TREE_TYPE (element_type);
+
+  gen_type_die (element_type, context_die);
+#endif
+
+  add_type_attribute (array_die, element_type, 0, 0, context_die);
+}
+
+#if 0
+static void
+gen_entry_point_die (tree decl, dw_die_ref context_die)
+{
+  tree origin = decl_ultimate_origin (decl);
+  dw_die_ref decl_die = new_die (DW_TAG_entry_point, context_die, decl);
+
+  if (origin != NULL)
+    add_abstract_origin_attribute (decl_die, origin);
+  else
+    {
+      add_name_and_src_coords_attributes (decl_die, decl);
+      add_type_attribute (decl_die, TREE_TYPE (TREE_TYPE (decl)),
+			  0, 0, context_die);
+    }
+
+  if (DECL_ABSTRACT (decl))
+    equate_decl_number_to_die (decl, decl_die);
+  else
+    add_AT_lbl_id (decl_die, DW_AT_low_pc, decl_start_label (decl));
+}
+#endif
+
+/* Walk through the list of incomplete types again, trying once more to
+   emit full debugging info for them.  */
+
+static void
+retry_incomplete_types (void)
+{
+  int i;
+
+  for (i = VEC_length (tree, incomplete_types) - 1; i >= 0; i--)
+    gen_type_die (VEC_index (tree, incomplete_types, i), comp_unit_die);
+}
+
+/* Generate a DIE to represent an inlined instance of an enumeration type.  */
+
+static void
+gen_inlined_enumeration_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref type_die = new_die (DW_TAG_enumeration_type, context_die, type);
+
+  /* We do not check for TREE_ASM_WRITTEN (type) being set, as the type may
+     be incomplete and such types are not marked.  */
+  add_abstract_origin_attribute (type_die, type);
+}
+
+/* Generate a DIE to represent an inlined instance of a structure type.  */
+
+static void
+gen_inlined_structure_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref type_die = new_die (DW_TAG_structure_type, context_die, type);
+
+  /* We do not check for TREE_ASM_WRITTEN (type) being set, as the type may
+     be incomplete and such types are not marked.  */
+  add_abstract_origin_attribute (type_die, type);
+}
+
+/* Generate a DIE to represent an inlined instance of a union type.  */
+
+static void
+gen_inlined_union_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref type_die = new_die (DW_TAG_union_type, context_die, type);
+
+  /* We do not check for TREE_ASM_WRITTEN (type) being set, as the type may
+     be incomplete and such types are not marked.  */
+  add_abstract_origin_attribute (type_die, type);
+}
+
+/* Generate a DIE to represent an enumeration type.  Note that these DIEs
+   include all of the information about the enumeration values also. Each
+   enumerated type name/value is listed as a child of the enumerated type
+   DIE.  */
+
+static dw_die_ref
+gen_enumeration_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref type_die = lookup_type_die (type);
+
+  if (type_die == NULL)
+    {
+      type_die = new_die (DW_TAG_enumeration_type,
+			  scope_die_for (type, context_die), type);
+      equate_type_number_to_die (type, type_die);
+      add_name_attribute (type_die, type_tag (type));
+    }
+  else if (! TYPE_SIZE (type))
+    return type_die;
+  else
+    remove_AT (type_die, DW_AT_declaration);
+
+  /* Handle a GNU C/C++ extension, i.e. incomplete enum types.  If the
+     given enum type is incomplete, do not generate the DW_AT_byte_size
+     attribute or the DW_AT_element_list attribute.  */
+  if (TYPE_SIZE (type))
+    {
+      tree link;
+
+      TREE_ASM_WRITTEN (type) = 1;
+      add_byte_size_attribute (type_die, type);
+      if (TYPE_STUB_DECL (type) != NULL_TREE)
+	add_src_coords_attributes (type_die, TYPE_STUB_DECL (type));
+
+      /* If the first reference to this type was as the return type of an
+	 inline function, then it may not have a parent.  Fix this now.  */
+      if (type_die->die_parent == NULL)
+	add_child_die (scope_die_for (type, context_die), type_die);
+
+      for (link = TYPE_VALUES (type);
+	   link != NULL; link = TREE_CHAIN (link))
+	{
+	  dw_die_ref enum_die = new_die (DW_TAG_enumerator, type_die, link);
+	  tree value = TREE_VALUE (link);
+
+	  add_name_attribute (enum_die,
+			      IDENTIFIER_POINTER (TREE_PURPOSE (link)));
+
+	  if (host_integerp (value, TYPE_UNSIGNED (TREE_TYPE (value))))
+	    /* DWARF2 does not provide a way of indicating whether or
+	       not enumeration constants are signed or unsigned.  GDB
+	       always assumes the values are signed, so we output all
+	       values as if they were signed.  That means that
+	       enumeration constants with very large unsigned values
+	       will appear to have negative values in the debugger.  */
+	    add_AT_int (enum_die, DW_AT_const_value,
+			tree_low_cst (value, tree_int_cst_sgn (value) > 0));
+	}
+    }
+  else
+    add_AT_flag (type_die, DW_AT_declaration, 1);
+
+  return type_die;
+}
+
+/* Generate a DIE to represent either a real live formal parameter decl or to
+   represent just the type of some formal parameter position in some function
+   type.
+
+   Note that this routine is a bit unusual because its argument may be a
+   ..._DECL node (i.e. either a PARM_DECL or perhaps a VAR_DECL which
+   represents an inlining of some PARM_DECL) or else some sort of a ..._TYPE
+   node.  If it's the former then this function is being called to output a
+   DIE to represent a formal parameter object (or some inlining thereof).  If
+   it's the latter, then this function is only being called to output a
+   DW_TAG_formal_parameter DIE to stand as a placeholder for some formal
+   argument type of some subprogram type.  */
+
+static dw_die_ref
+gen_formal_parameter_die (tree node, dw_die_ref context_die)
+{
+  dw_die_ref parm_die
+    = new_die (DW_TAG_formal_parameter, context_die, node);
+  tree origin;
+
+  switch (TREE_CODE_CLASS (TREE_CODE (node)))
+    {
+    case tcc_declaration:
+      origin = decl_ultimate_origin (node);
+      if (origin != NULL)
+	add_abstract_origin_attribute (parm_die, origin);
+      else
+	{
+	  add_name_and_src_coords_attributes (parm_die, node);
+	  add_type_attribute (parm_die, TREE_TYPE (node),
+			      TREE_READONLY (node),
+			      TREE_THIS_VOLATILE (node),
+			      context_die);
+	  if (DECL_ARTIFICIAL (node))
+	    add_AT_flag (parm_die, DW_AT_artificial, 1);
+	}
+
+      equate_decl_number_to_die (node, parm_die);
+      if (! DECL_ABSTRACT (node))
+	add_location_or_const_value_attribute (parm_die, node, DW_AT_location);
+
+      break;
+
+    case tcc_type:
+      /* We were called with some kind of a ..._TYPE node.  */
+      add_type_attribute (parm_die, node, 0, 0, context_die);
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  return parm_die;
+}
+
+/* Generate a special type of DIE used as a stand-in for a trailing ellipsis
+   at the end of an (ANSI prototyped) formal parameters list.  */
+
+static void
+gen_unspecified_parameters_die (tree decl_or_type, dw_die_ref context_die)
+{
+  new_die (DW_TAG_unspecified_parameters, context_die, decl_or_type);
+}
+
+/* Generate a list of nameless DW_TAG_formal_parameter DIEs (and perhaps a
+   DW_TAG_unspecified_parameters DIE) to represent the types of the formal
+   parameters as specified in some function type specification (except for
+   those which appear as part of a function *definition*).  */
+
+static void
+gen_formal_types_die (tree function_or_method_type, dw_die_ref context_die)
+{
+  tree link;
+  tree formal_type = NULL;
+  tree first_parm_type;
+  tree arg;
+
+  if (TREE_CODE (function_or_method_type) == FUNCTION_DECL)
+    {
+      arg = DECL_ARGUMENTS (function_or_method_type);
+      function_or_method_type = TREE_TYPE (function_or_method_type);
+    }
+  else
+    arg = NULL_TREE;
+
+  first_parm_type = TYPE_ARG_TYPES (function_or_method_type);
+
+  /* Make our first pass over the list of formal parameter types and output a
+     DW_TAG_formal_parameter DIE for each one.  */
+  for (link = first_parm_type; link; )
+    {
+      dw_die_ref parm_die;
+
+      formal_type = TREE_VALUE (link);
+      if (formal_type == void_type_node)
+	break;
+
+      /* Output a (nameless) DIE to represent the formal parameter itself.  */
+      parm_die = gen_formal_parameter_die (formal_type, context_die);
+      if ((TREE_CODE (function_or_method_type) == METHOD_TYPE
+	   && link == first_parm_type)
+	  || (arg && DECL_ARTIFICIAL (arg)))
+	add_AT_flag (parm_die, DW_AT_artificial, 1);
+
+      link = TREE_CHAIN (link);
+      if (arg)
+	arg = TREE_CHAIN (arg);
+    }
+
+  /* If this function type has an ellipsis, add a
+     DW_TAG_unspecified_parameters DIE to the end of the parameter list.  */
+  if (formal_type != void_type_node)
+    gen_unspecified_parameters_die (function_or_method_type, context_die);
+
+  /* Make our second (and final) pass over the list of formal parameter types
+     and output DIEs to represent those types (as necessary).  */
+  for (link = TYPE_ARG_TYPES (function_or_method_type);
+       link && TREE_VALUE (link);
+       link = TREE_CHAIN (link))
+    gen_type_die (TREE_VALUE (link), context_die);
+}
+
+/* We want to generate the DIE for TYPE so that we can generate the
+   die for MEMBER, which has been defined; we will need to refer back
+   to the member declaration nested within TYPE.  If we're trying to
+   generate minimal debug info for TYPE, processing TYPE won't do the
+   trick; we need to attach the member declaration by hand.  */
+
+static void
+gen_type_die_for_member (tree type, tree member, dw_die_ref context_die)
+{
+  gen_type_die (type, context_die);
+
+  /* If we're trying to avoid duplicate debug info, we may not have
+     emitted the member decl for this function.  Emit it now.  */
+  if (TYPE_DECL_SUPPRESS_DEBUG (TYPE_STUB_DECL (type))
+      && ! lookup_decl_die (member))
+    {
+      dw_die_ref type_die;
+      gcc_assert (!decl_ultimate_origin (member));
+
+      push_decl_scope (type);
+      type_die = lookup_type_die (type);
+      if (TREE_CODE (member) == FUNCTION_DECL)
+	gen_subprogram_die (member, type_die);
+      else if (TREE_CODE (member) == FIELD_DECL)
+	{
+	  /* Ignore the nameless fields that are used to skip bits but handle
+	     C++ anonymous unions and structs.  */
+	  if (DECL_NAME (member) != NULL_TREE
+	      || TREE_CODE (TREE_TYPE (member)) == UNION_TYPE
+	      || TREE_CODE (TREE_TYPE (member)) == RECORD_TYPE)
+	    {
+	      gen_type_die (member_declared_type (member), type_die);
+	      gen_field_die (member, type_die);
+	    }
+	}
+      else
+	gen_variable_die (member, type_die);
+
+      pop_decl_scope ();
+    }
+}
+
+/* Generate the DWARF2 info for the "abstract" instance of a function which we
+   may later generate inlined and/or out-of-line instances of.  */
+
+static void
+dwarf2out_abstract_function (tree decl)
+{
+  dw_die_ref old_die;
+  tree save_fn;
+  tree context;
+  int was_abstract = DECL_ABSTRACT (decl);
+
+  /* Make sure we have the actual abstract inline, not a clone.  */
+  decl = DECL_ORIGIN (decl);
+
+  old_die = lookup_decl_die (decl);
+  if (old_die && get_AT (old_die, DW_AT_inline))
+    /* We've already generated the abstract instance.  */
+    return;
+
+  /* Be sure we've emitted the in-class declaration DIE (if any) first, so
+     we don't get confused by DECL_ABSTRACT.  */
+  if (debug_info_level > DINFO_LEVEL_TERSE)
+    {
+      context = decl_class_context (decl);
+      if (context)
+	gen_type_die_for_member
+	  (context, decl, decl_function_context (decl) ? NULL : comp_unit_die);
+    }
+
+  /* Pretend we've just finished compiling this function.  */
+  save_fn = current_function_decl;
+  current_function_decl = decl;
+
+  set_decl_abstract_flags (decl, 1);
+  dwarf2out_decl (decl);
+  if (! was_abstract)
+    set_decl_abstract_flags (decl, 0);
+
+  current_function_decl = save_fn;
+}
+
+/* Generate a DIE to represent a declared function (either file-scope or
+   block-local).  */
+
+static void
+gen_subprogram_die (tree decl, dw_die_ref context_die)
+{
+  char label_id[MAX_ARTIFICIAL_LABEL_BYTES];
+  tree origin = decl_ultimate_origin (decl);
+  dw_die_ref subr_die;
+  tree fn_arg_types;
+  tree outer_scope;
+  dw_die_ref old_die = lookup_decl_die (decl);
+  int declaration = (current_function_decl != decl
+		     || class_or_namespace_scope_p (context_die));
+
+  /* It is possible to have both DECL_ABSTRACT and DECLARATION be true if we
+     started to generate the abstract instance of an inline, decided to output
+     its containing class, and proceeded to emit the declaration of the inline
+     from the member list for the class.  If so, DECLARATION takes priority;
+     we'll get back to the abstract instance when done with the class.  */
+
+  /* The class-scope declaration DIE must be the primary DIE.  */
+  if (origin && declaration && class_or_namespace_scope_p (context_die))
+    {
+      origin = NULL;
+      gcc_assert (!old_die);
+    }
+
+  /* Now that the C++ front end lazily declares artificial member fns, we
+     might need to retrofit the declaration into its class.  */
+  if (!declaration && !origin && !old_die
+      && DECL_CONTEXT (decl) && TYPE_P (DECL_CONTEXT (decl))
+      && !class_or_namespace_scope_p (context_die)
+      && debug_info_level > DINFO_LEVEL_TERSE)
+    old_die = force_decl_die (decl);
+
+  if (origin != NULL)
+    {
+      gcc_assert (!declaration || local_scope_p (context_die));
+
+      /* Fixup die_parent for the abstract instance of a nested
+	 inline function.  */
+      if (old_die && old_die->die_parent == NULL)
+	add_child_die (context_die, old_die);
+
+      subr_die = new_die (DW_TAG_subprogram, context_die, decl);
+      add_abstract_origin_attribute (subr_die, origin);
+    }
+  else if (old_die)
+    {
+      expanded_location s = expand_location (DECL_SOURCE_LOCATION (decl));
+      unsigned file_index = lookup_filename (s.file);
+
+      if (!get_AT_flag (old_die, DW_AT_declaration)
+	  /* We can have a normal definition following an inline one in the
+	     case of redefinition of GNU C extern inlines.
+	     It seems reasonable to use AT_specification in this case.  */
+	  && !get_AT (old_die, DW_AT_inline))
+	{
+	  /* Detect and ignore this case, where we are trying to output
+	     something we have already output.  */
+	  return;
+	}
+
+      /* If the definition comes from the same place as the declaration,
+	 maybe use the old DIE.  We always want the DIE for this function
+	 that has the *_pc attributes to be under comp_unit_die so the
+	 debugger can find it.  We also need to do this for abstract
+	 instances of inlines, since the spec requires the out-of-line copy
+	 to have the same parent.  For local class methods, this doesn't
+	 apply; we just use the old DIE.  */
+      if ((old_die->die_parent == comp_unit_die || context_die == NULL)
+	  && (DECL_ARTIFICIAL (decl)
+	      || (get_AT_unsigned (old_die, DW_AT_decl_file) == file_index
+		  && (get_AT_unsigned (old_die, DW_AT_decl_line)
+		      == (unsigned) s.line))))
+	{
+	  subr_die = old_die;
+
+	  /* Clear out the declaration attribute and the formal parameters.
+	     Do not remove all children, because it is possible that this
+	     declaration die was forced using force_decl_die(). In such
+	     cases die that forced declaration die (e.g. TAG_imported_module)
+	     is one of the children that we do not want to remove.  */
+	  remove_AT (subr_die, DW_AT_declaration);
+	  remove_child_TAG (subr_die, DW_TAG_formal_parameter);
+	}
+      else
+	{
+	  subr_die = new_die (DW_TAG_subprogram, context_die, decl);
+	  add_AT_specification (subr_die, old_die);
+	  if (get_AT_unsigned (old_die, DW_AT_decl_file) != file_index)
+	    add_AT_unsigned (subr_die, DW_AT_decl_file, file_index);
+	  if (get_AT_unsigned (old_die, DW_AT_decl_line)
+	      != (unsigned) s.line)
+	    add_AT_unsigned
+	      (subr_die, DW_AT_decl_line, s.line);
+	}
+    }
+  else
+    {
+      subr_die = new_die (DW_TAG_subprogram, context_die, decl);
+
+      if (TREE_PUBLIC (decl))
+	add_AT_flag (subr_die, DW_AT_external, 1);
+
+      add_name_and_src_coords_attributes (subr_die, decl);
+      if (debug_info_level > DINFO_LEVEL_TERSE)
+	{
+	  add_prototyped_attribute (subr_die, TREE_TYPE (decl));
+	  add_type_attribute (subr_die, TREE_TYPE (TREE_TYPE (decl)),
+			      0, 0, context_die);
+	}
+
+      add_pure_or_virtual_attribute (subr_die, decl);
+      if (DECL_ARTIFICIAL (decl))
+	add_AT_flag (subr_die, DW_AT_artificial, 1);
+
+      if (TREE_PROTECTED (decl))
+	add_AT_unsigned (subr_die, DW_AT_accessibility, DW_ACCESS_protected);
+      else if (TREE_PRIVATE (decl))
+	add_AT_unsigned (subr_die, DW_AT_accessibility, DW_ACCESS_private);
+    }
+
+  if (declaration)
+    {
+      if (!old_die || !get_AT (old_die, DW_AT_inline))
+	{
+	  add_AT_flag (subr_die, DW_AT_declaration, 1);
+
+	  /* The first time we see a member function, it is in the context of
+	     the class to which it belongs.  We make sure of this by emitting
+	     the class first.  The next time is the definition, which is
+	     handled above.  The two may come from the same source text.
+
+	     Note that force_decl_die() forces function declaration die. It is
+	     later reused to represent definition.  */
+	  equate_decl_number_to_die (decl, subr_die);
+	}
+    }
+  else if (DECL_ABSTRACT (decl))
+    {
+      if (DECL_DECLARED_INLINE_P (decl))
+	{
+          if (cgraph_function_possibly_inlined_p (decl))
+	    add_AT_unsigned (subr_die, DW_AT_inline, DW_INL_declared_inlined);
+	  else
+	    add_AT_unsigned (subr_die, DW_AT_inline, DW_INL_declared_not_inlined);
+	}
+      else
+	{
+	  if (cgraph_function_possibly_inlined_p (decl))
+            add_AT_unsigned (subr_die, DW_AT_inline, DW_INL_inlined);
+	  else
+            add_AT_unsigned (subr_die, DW_AT_inline, DW_INL_not_inlined);
+	}
+
+      equate_decl_number_to_die (decl, subr_die);
+    }
+  else if (!DECL_EXTERNAL (decl))
+    {
+      if (!old_die || !get_AT (old_die, DW_AT_inline))
+	equate_decl_number_to_die (decl, subr_die);
+
+      if (!flag_reorder_blocks_and_partition)
+	{
+	  ASM_GENERATE_INTERNAL_LABEL (label_id, FUNC_BEGIN_LABEL,
+				       current_function_funcdef_no);
+	  add_AT_lbl_id (subr_die, DW_AT_low_pc, label_id);
+	  ASM_GENERATE_INTERNAL_LABEL (label_id, FUNC_END_LABEL,
+				       current_function_funcdef_no);
+	  add_AT_lbl_id (subr_die, DW_AT_high_pc, label_id);
+	  
+	  add_pubname (decl, subr_die);
+	  add_arange (decl, subr_die);
+	}
+      else
+	{  /* Do nothing for now; maybe need to duplicate die, one for
+	      hot section and ond for cold section, then use the hot/cold
+	      section begin/end labels to generate the aranges...  */
+	  /*
+	    add_AT_lbl_id (subr_die, DW_AT_low_pc, hot_section_label);
+	    add_AT_lbl_id (subr_die, DW_AT_high_pc, hot_section_end_label);
+	    add_AT_lbl_id (subr_die, DW_AT_lo_user, unlikely_section_label);
+	    add_AT_lbl_id (subr_die, DW_AT_hi_user, cold_section_end_label);
+
+	    add_pubname (decl, subr_die);
+	    add_arange (decl, subr_die);
+	    add_arange (decl, subr_die);
+	   */
+	}
+
+#ifdef MIPS_DEBUGGING_INFO
+      /* Add a reference to the FDE for this routine.  */
+      add_AT_fde_ref (subr_die, DW_AT_MIPS_fde, current_funcdef_fde);
+#endif
+
+#ifdef DWARF2_UNWIND_INFO
+      /* We define the "frame base" as the function's CFA.  This is more
+	 convenient for several reasons: (1) It's stable across the prologue
+	 and epilogue, which makes it better than just a frame pointer,
+	 (2) With dwarf3, there exists a one-byte encoding that allows us
+	 to reference the .debug_frame data by proxy, but failing that,
+	 (3) We can at least reuse the code inspection and interpretation
+	 code that determines the CFA position at various points in the
+	 function.  */
+      /* ??? Use some command-line or configury switch to enable the use
+	 of dwarf3 DW_OP_call_frame_cfa.  At present there are no dwarf
+	 consumers that understand it; fall back to "pure" dwarf2 and
+	 convert the CFA data into a location list.  */
+      {
+	dw_loc_list_ref list = convert_cfa_to_loc_list ();
+	if (list->dw_loc_next)
+	  add_AT_loc_list (subr_die, DW_AT_frame_base, list);
+	else
+	  add_AT_loc (subr_die, DW_AT_frame_base, list->expr);
+      }
+
+      /* Compute a displacement from the "steady-state frame pointer" to
+	 the CFA.  The former is what all stack slots and argument slots
+	 will reference in the rtl; the later is what we've told the 
+	 debugger about.  We'll need to adjust all frame_base references
+	 by this displacement.  */
+      compute_frame_pointer_to_cfa_displacement ();
+#else
+      /* For targets which support DWARF2, but not DWARF2 call-frame info,
+	 we just use the stack pointer or frame pointer.  */
+      /* ??? Should investigate getting better info via callbacks, or else
+	 by interpreting the IA-64 unwind info.  */
+      {
+	rtx fp_reg
+	  = frame_pointer_needed ? hard_frame_pointer_rtx : stack_pointer_rtx;
+	add_AT_loc (subr_die, DW_AT_frame_base, reg_loc_descriptor (fp_reg));
+      }
+#endif
+
+      if (cfun->static_chain_decl)
+	add_AT_location_description (subr_die, DW_AT_static_link,
+		 loc_descriptor_from_tree (cfun->static_chain_decl));
+    }
+
+  /* Now output descriptions of the arguments for this function. This gets
+     (unnecessarily?) complex because of the fact that the DECL_ARGUMENT list
+     for a FUNCTION_DECL doesn't indicate cases where there was a trailing
+     `...' at the end of the formal parameter list.  In order to find out if
+     there was a trailing ellipsis or not, we must instead look at the type
+     associated with the FUNCTION_DECL.  This will be a node of type
+     FUNCTION_TYPE. If the chain of type nodes hanging off of this
+     FUNCTION_TYPE node ends with a void_type_node then there should *not* be
+     an ellipsis at the end.  */
+
+  /* In the case where we are describing a mere function declaration, all we
+     need to do here (and all we *can* do here) is to describe the *types* of
+     its formal parameters.  */
+  if (debug_info_level <= DINFO_LEVEL_TERSE)
+    ;
+  else if (declaration)
+    gen_formal_types_die (decl, subr_die);
+  else
+    {
+      /* Generate DIEs to represent all known formal parameters.  */
+      tree arg_decls = DECL_ARGUMENTS (decl);
+      tree parm;
+
+      /* When generating DIEs, generate the unspecified_parameters DIE
+	 instead if we come across the arg "__builtin_va_alist" */
+      for (parm = arg_decls; parm; parm = TREE_CHAIN (parm))
+	if (TREE_CODE (parm) == PARM_DECL)
+	  {
+	    if (DECL_NAME (parm)
+		&& !strcmp (IDENTIFIER_POINTER (DECL_NAME (parm)),
+			    "__builtin_va_alist"))
+	      gen_unspecified_parameters_die (parm, subr_die);
+	    else
+	      gen_decl_die (parm, subr_die);
+	  }
+
+      /* Decide whether we need an unspecified_parameters DIE at the end.
+	 There are 2 more cases to do this for: 1) the ansi ... declaration -
+	 this is detectable when the end of the arg list is not a
+	 void_type_node 2) an unprototyped function declaration (not a
+	 definition).  This just means that we have no info about the
+	 parameters at all.  */
+      fn_arg_types = TYPE_ARG_TYPES (TREE_TYPE (decl));
+      if (fn_arg_types != NULL)
+	{
+	  /* This is the prototyped case, check for....  */
+	  if (TREE_VALUE (tree_last (fn_arg_types)) != void_type_node)
+	    gen_unspecified_parameters_die (decl, subr_die);
+	}
+      else if (DECL_INITIAL (decl) == NULL_TREE)
+	gen_unspecified_parameters_die (decl, subr_die);
+    }
+
+  /* Output Dwarf info for all of the stuff within the body of the function
+     (if it has one - it may be just a declaration).  */
+  outer_scope = DECL_INITIAL (decl);
+
+  /* OUTER_SCOPE is a pointer to the outermost BLOCK node created to represent
+     a function.  This BLOCK actually represents the outermost binding contour
+     for the function, i.e. the contour in which the function's formal
+     parameters and labels get declared. Curiously, it appears that the front
+     end doesn't actually put the PARM_DECL nodes for the current function onto
+     the BLOCK_VARS list for this outer scope, but are strung off of the
+     DECL_ARGUMENTS list for the function instead.
+
+     The BLOCK_VARS list for the `outer_scope' does provide us with a list of
+     the LABEL_DECL nodes for the function however, and we output DWARF info
+     for those in decls_for_scope.  Just within the `outer_scope' there will be
+     a BLOCK node representing the function's outermost pair of curly braces,
+     and any blocks used for the base and member initializers of a C++
+     constructor function.  */
+  if (! declaration && TREE_CODE (outer_scope) != ERROR_MARK)
+    {
+      /* Emit a DW_TAG_variable DIE for a named return value.  */
+      if (DECL_NAME (DECL_RESULT (decl)))
+	gen_decl_die (DECL_RESULT (decl), subr_die);
+
+      current_function_has_inlines = 0;
+      decls_for_scope (outer_scope, subr_die, 0);
+
+#if 0 && defined (MIPS_DEBUGGING_INFO)
+      if (current_function_has_inlines)
+	{
+	  add_AT_flag (subr_die, DW_AT_MIPS_has_inlines, 1);
+	  if (! comp_unit_has_inlines)
+	    {
+	      add_AT_flag (comp_unit_die, DW_AT_MIPS_has_inlines, 1);
+	      comp_unit_has_inlines = 1;
+	    }
+	}
+#endif
+    }
+  /* Add the calling convention attribute if requested.  */
+  add_calling_convention_attribute (subr_die, TREE_TYPE (decl));
+
+}
+
+/* Generate a DIE to represent a declared data object.  */
+
+static void
+gen_variable_die (tree decl, dw_die_ref context_die)
+{
+  tree origin = decl_ultimate_origin (decl);
+  dw_die_ref var_die = new_die (DW_TAG_variable, context_die, decl);
+
+  dw_die_ref old_die = lookup_decl_die (decl);
+  int declaration = (DECL_EXTERNAL (decl)
+		     /* If DECL is COMDAT and has not actually been
+			emitted, we cannot take its address; there
+			might end up being no definition anywhere in
+			the program.  For example, consider the C++
+			test case:
+
+                          template <class T>
+                          struct S { static const int i = 7; };
+
+                          template <class T>
+                          const int S<T>::i;
+
+                          int f() { return S<int>::i; }
+			  
+			Here, S<int>::i is not DECL_EXTERNAL, but no
+			definition is required, so the compiler will
+			not emit a definition.  */  
+		     || (TREE_CODE (decl) == VAR_DECL
+			 && DECL_COMDAT (decl) && !TREE_ASM_WRITTEN (decl))
+		     || class_or_namespace_scope_p (context_die));
+
+  if (origin != NULL)
+    add_abstract_origin_attribute (var_die, origin);
+
+  /* Loop unrolling can create multiple blocks that refer to the same
+     static variable, so we must test for the DW_AT_declaration flag.
+
+     ??? Loop unrolling/reorder_blocks should perhaps be rewritten to
+     copy decls and set the DECL_ABSTRACT flag on them instead of
+     sharing them.
+
+     ??? Duplicated blocks have been rewritten to use .debug_ranges.
+
+     ??? The declare_in_namespace support causes us to get two DIEs for one
+     variable, both of which are declarations.  We want to avoid considering
+     one to be a specification, so we must test that this DIE is not a
+     declaration.  */
+  else if (old_die && TREE_STATIC (decl) && ! declaration
+	   && get_AT_flag (old_die, DW_AT_declaration) == 1)
+    {
+      /* This is a definition of a C++ class level static.  */
+      add_AT_specification (var_die, old_die);
+      if (DECL_NAME (decl))
+	{
+	  expanded_location s = expand_location (DECL_SOURCE_LOCATION (decl));
+	  unsigned file_index = lookup_filename (s.file);
+
+	  if (get_AT_unsigned (old_die, DW_AT_decl_file) != file_index)
+	    add_AT_unsigned (var_die, DW_AT_decl_file, file_index);
+
+	  if (get_AT_unsigned (old_die, DW_AT_decl_line)
+	      != (unsigned) s.line)
+
+	    add_AT_unsigned (var_die, DW_AT_decl_line, s.line);
+	}
+    }
+  else
+    {
+      add_name_and_src_coords_attributes (var_die, decl);
+      add_type_attribute (var_die, TREE_TYPE (decl), TREE_READONLY (decl),
+			  TREE_THIS_VOLATILE (decl), context_die);
+
+      if (TREE_PUBLIC (decl))
+	add_AT_flag (var_die, DW_AT_external, 1);
+
+      if (DECL_ARTIFICIAL (decl))
+	add_AT_flag (var_die, DW_AT_artificial, 1);
+
+      if (TREE_PROTECTED (decl))
+	add_AT_unsigned (var_die, DW_AT_accessibility, DW_ACCESS_protected);
+      else if (TREE_PRIVATE (decl))
+	add_AT_unsigned (var_die, DW_AT_accessibility, DW_ACCESS_private);
+    }
+
+  if (declaration)
+    add_AT_flag (var_die, DW_AT_declaration, 1);
+
+  if (DECL_ABSTRACT (decl) || declaration)
+    equate_decl_number_to_die (decl, var_die);
+
+  if (! declaration && ! DECL_ABSTRACT (decl))
+    {
+      add_location_or_const_value_attribute (var_die, decl, DW_AT_location);
+      add_pubname (decl, var_die);
+    }
+  else
+    tree_add_const_value_attribute (var_die, decl);
+}
+
+/* Generate a DIE to represent a label identifier.  */
+
+static void
+gen_label_die (tree decl, dw_die_ref context_die)
+{
+  tree origin = decl_ultimate_origin (decl);
+  dw_die_ref lbl_die = new_die (DW_TAG_label, context_die, decl);
+  rtx insn;
+  char label[MAX_ARTIFICIAL_LABEL_BYTES];
+
+  if (origin != NULL)
+    add_abstract_origin_attribute (lbl_die, origin);
+  else
+    add_name_and_src_coords_attributes (lbl_die, decl);
+
+  if (DECL_ABSTRACT (decl))
+    equate_decl_number_to_die (decl, lbl_die);
+  else
+    {
+      insn = DECL_RTL_IF_SET (decl);
+
+      /* Deleted labels are programmer specified labels which have been
+	 eliminated because of various optimizations.  We still emit them
+	 here so that it is possible to put breakpoints on them.  */
+      if (insn
+	  && (LABEL_P (insn)
+	      || ((NOTE_P (insn)
+	           && NOTE_LINE_NUMBER (insn) == NOTE_INSN_DELETED_LABEL))))
+	{
+	  /* When optimization is enabled (via -O) some parts of the compiler
+	     (e.g. jump.c and cse.c) may try to delete CODE_LABEL insns which
+	     represent source-level labels which were explicitly declared by
+	     the user.  This really shouldn't be happening though, so catch
+	     it if it ever does happen.  */
+	  gcc_assert (!INSN_DELETED_P (insn));
+
+	  ASM_GENERATE_INTERNAL_LABEL (label, "L", CODE_LABEL_NUMBER (insn));
+	  add_AT_lbl_id (lbl_die, DW_AT_low_pc, label);
+	}
+    }
+}
+
+/* A helper function for gen_inlined_subroutine_die.  Add source coordinate
+   attributes to the DIE for a block STMT, to describe where the inlined
+   function was called from.  This is similar to add_src_coords_attributes.  */
+
+static inline void
+add_call_src_coords_attributes (tree stmt, dw_die_ref die)
+{
+  expanded_location s = expand_location (BLOCK_SOURCE_LOCATION (stmt));
+  unsigned file_index = lookup_filename (s.file);
+
+  add_AT_unsigned (die, DW_AT_call_file, file_index);
+  add_AT_unsigned (die, DW_AT_call_line, s.line);
+}
+
+/* A helper function for gen_lexical_block_die and gen_inlined_subroutine_die.
+   Add low_pc and high_pc attributes to the DIE for a block STMT.  */
+
+static inline void
+add_high_low_attributes (tree stmt, dw_die_ref die)
+{
+  char label[MAX_ARTIFICIAL_LABEL_BYTES];
+
+  if (BLOCK_FRAGMENT_CHAIN (stmt))
+    {
+      tree chain;
+
+      add_AT_range_list (die, DW_AT_ranges, add_ranges (stmt));
+
+      chain = BLOCK_FRAGMENT_CHAIN (stmt);
+      do
+	{
+	  add_ranges (chain);
+	  chain = BLOCK_FRAGMENT_CHAIN (chain);
+	}
+      while (chain);
+      add_ranges (NULL);
+    }
+  else
+    {
+      ASM_GENERATE_INTERNAL_LABEL (label, BLOCK_BEGIN_LABEL,
+				   BLOCK_NUMBER (stmt));
+      add_AT_lbl_id (die, DW_AT_low_pc, label);
+      ASM_GENERATE_INTERNAL_LABEL (label, BLOCK_END_LABEL,
+				   BLOCK_NUMBER (stmt));
+      add_AT_lbl_id (die, DW_AT_high_pc, label);
+    }
+}
+
+/* Generate a DIE for a lexical block.  */
+
+static void
+gen_lexical_block_die (tree stmt, dw_die_ref context_die, int depth)
+{
+  dw_die_ref stmt_die = new_die (DW_TAG_lexical_block, context_die, stmt);
+
+  if (! BLOCK_ABSTRACT (stmt))
+    add_high_low_attributes (stmt, stmt_die);
+
+  decls_for_scope (stmt, stmt_die, depth);
+}
+
+/* Generate a DIE for an inlined subprogram.  */
+
+static void
+gen_inlined_subroutine_die (tree stmt, dw_die_ref context_die, int depth)
+{
+  tree decl = block_ultimate_origin (stmt);
+
+  /* Emit info for the abstract instance first, if we haven't yet.  We
+     must emit this even if the block is abstract, otherwise when we
+     emit the block below (or elsewhere), we may end up trying to emit
+     a die whose origin die hasn't been emitted, and crashing.  */
+  dwarf2out_abstract_function (decl);
+
+  if (! BLOCK_ABSTRACT (stmt))
+    {
+      dw_die_ref subr_die
+	= new_die (DW_TAG_inlined_subroutine, context_die, stmt);
+
+      add_abstract_origin_attribute (subr_die, decl);
+      add_high_low_attributes (stmt, subr_die);
+      add_call_src_coords_attributes (stmt, subr_die);
+
+      decls_for_scope (stmt, subr_die, depth);
+      current_function_has_inlines = 1;
+    }
+  else
+    /* We may get here if we're the outer block of function A that was
+       inlined into function B that was inlined into function C.  When
+       generating debugging info for C, dwarf2out_abstract_function(B)
+       would mark all inlined blocks as abstract, including this one.
+       So, we wouldn't (and shouldn't) expect labels to be generated
+       for this one.  Instead, just emit debugging info for
+       declarations within the block.  This is particularly important
+       in the case of initializers of arguments passed from B to us:
+       if they're statement expressions containing declarations, we
+       wouldn't generate dies for their abstract variables, and then,
+       when generating dies for the real variables, we'd die (pun
+       intended :-)  */
+    gen_lexical_block_die (stmt, context_die, depth);
+}
+
+/* Generate a DIE for a field in a record, or structure.  */
+
+static void
+gen_field_die (tree decl, dw_die_ref context_die)
+{
+  dw_die_ref decl_die;
+
+  if (TREE_TYPE (decl) == error_mark_node)
+    return;
+
+  decl_die = new_die (DW_TAG_member, context_die, decl);
+  add_name_and_src_coords_attributes (decl_die, decl);
+  add_type_attribute (decl_die, member_declared_type (decl),
+		      TREE_READONLY (decl), TREE_THIS_VOLATILE (decl),
+		      context_die);
+
+  if (DECL_BIT_FIELD_TYPE (decl))
+    {
+      add_byte_size_attribute (decl_die, decl);
+      add_bit_size_attribute (decl_die, decl);
+      add_bit_offset_attribute (decl_die, decl);
+    }
+
+  if (TREE_CODE (DECL_FIELD_CONTEXT (decl)) != UNION_TYPE)
+    add_data_member_location_attribute (decl_die, decl);
+
+  if (DECL_ARTIFICIAL (decl))
+    add_AT_flag (decl_die, DW_AT_artificial, 1);
+
+  if (TREE_PROTECTED (decl))
+    add_AT_unsigned (decl_die, DW_AT_accessibility, DW_ACCESS_protected);
+  else if (TREE_PRIVATE (decl))
+    add_AT_unsigned (decl_die, DW_AT_accessibility, DW_ACCESS_private);
+
+  /* Equate decl number to die, so that we can look up this decl later on.  */
+  equate_decl_number_to_die (decl, decl_die);
+}
+
+#if 0
+/* Don't generate either pointer_type DIEs or reference_type DIEs here.
+   Use modified_type_die instead.
+   We keep this code here just in case these types of DIEs may be needed to
+   represent certain things in other languages (e.g. Pascal) someday.  */
+
+static void
+gen_pointer_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref ptr_die
+    = new_die (DW_TAG_pointer_type, scope_die_for (type, context_die), type);
+
+  equate_type_number_to_die (type, ptr_die);
+  add_type_attribute (ptr_die, TREE_TYPE (type), 0, 0, context_die);
+  add_AT_unsigned (mod_type_die, DW_AT_byte_size, PTR_SIZE);
+}
+
+/* Don't generate either pointer_type DIEs or reference_type DIEs here.
+   Use modified_type_die instead.
+   We keep this code here just in case these types of DIEs may be needed to
+   represent certain things in other languages (e.g. Pascal) someday.  */
+
+static void
+gen_reference_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref ref_die
+    = new_die (DW_TAG_reference_type, scope_die_for (type, context_die), type);
+
+  equate_type_number_to_die (type, ref_die);
+  add_type_attribute (ref_die, TREE_TYPE (type), 0, 0, context_die);
+  add_AT_unsigned (mod_type_die, DW_AT_byte_size, PTR_SIZE);
+}
+#endif
+
+/* Generate a DIE for a pointer to a member type.  */
+
+static void
+gen_ptr_to_mbr_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref ptr_die
+    = new_die (DW_TAG_ptr_to_member_type,
+	       scope_die_for (type, context_die), type);
+
+  equate_type_number_to_die (type, ptr_die);
+  add_AT_die_ref (ptr_die, DW_AT_containing_type,
+		  lookup_type_die (TYPE_OFFSET_BASETYPE (type)));
+  add_type_attribute (ptr_die, TREE_TYPE (type), 0, 0, context_die);
+}
+
+/* Generate the DIE for the compilation unit.  */
+
+static dw_die_ref
+gen_compile_unit_die (const char *filename)
+{
+  dw_die_ref die;
+  char producer[250];
+  const char *language_string = lang_hooks.name;
+  int language;
+
+  die = new_die (DW_TAG_compile_unit, NULL, NULL);
+
+  if (filename)
+    {
+      add_name_attribute (die, filename);
+      /* Don't add cwd for <built-in>.  */
+      if (filename[0] != DIR_SEPARATOR && filename[0] != '<')
+	add_comp_dir_attribute (die);
+    }
+
+  sprintf (producer, "%s %s", language_string, version_string);
+
+#ifdef MIPS_DEBUGGING_INFO
+  /* The MIPS/SGI compilers place the 'cc' command line options in the producer
+     string.  The SGI debugger looks for -g, -g1, -g2, or -g3; if they do
+     not appear in the producer string, the debugger reaches the conclusion
+     that the object file is stripped and has no debugging information.
+     To get the MIPS/SGI debugger to believe that there is debugging
+     information in the object file, we add a -g to the producer string.  */
+  if (debug_info_level > DINFO_LEVEL_TERSE)
+    strcat (producer, " -g");
+#endif
+
+  add_AT_string (die, DW_AT_producer, producer);
+
+  if (strcmp (language_string, "GNU C++") == 0)
+    language = DW_LANG_C_plus_plus;
+  else if (strcmp (language_string, "GNU Ada") == 0)
+    language = DW_LANG_Ada95;
+  else if (strcmp (language_string, "GNU F77") == 0)
+    language = DW_LANG_Fortran77;
+  else if (strcmp (language_string, "GNU F95") == 0)
+    language = DW_LANG_Fortran95;
+  else if (strcmp (language_string, "GNU Pascal") == 0)
+    language = DW_LANG_Pascal83;
+  else if (strcmp (language_string, "GNU Java") == 0)
+    language = DW_LANG_Java;
+  else
+    language = DW_LANG_C89;
+
+  add_AT_unsigned (die, DW_AT_language, language);
+  return die;
+}
+
+/* Generate a DIE for a string type.  */
+
+static void
+gen_string_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref type_die
+    = new_die (DW_TAG_string_type, scope_die_for (type, context_die), type);
+
+  equate_type_number_to_die (type, type_die);
+
+  /* ??? Fudge the string length attribute for now.
+     TODO: add string length info.  */
+#if 0
+  string_length_attribute (TYPE_MAX_VALUE (TYPE_DOMAIN (type)));
+  bound_representation (upper_bound, 0, 'u');
+#endif
+}
+
+/* Generate the DIE for a base class.  */
+
+static void
+gen_inheritance_die (tree binfo, tree access, dw_die_ref context_die)
+{
+  dw_die_ref die = new_die (DW_TAG_inheritance, context_die, binfo);
+
+  add_type_attribute (die, BINFO_TYPE (binfo), 0, 0, context_die);
+  add_data_member_location_attribute (die, binfo);
+
+  if (BINFO_VIRTUAL_P (binfo))
+    add_AT_unsigned (die, DW_AT_virtuality, DW_VIRTUALITY_virtual);
+
+  if (access == access_public_node)
+    add_AT_unsigned (die, DW_AT_accessibility, DW_ACCESS_public);
+  else if (access == access_protected_node)
+    add_AT_unsigned (die, DW_AT_accessibility, DW_ACCESS_protected);
+}
+
+/* Generate a DIE for a class member.  */
+
+static void
+gen_member_die (tree type, dw_die_ref context_die)
+{
+  tree member;
+  tree binfo = TYPE_BINFO (type);
+  dw_die_ref child;
+
+  /* If this is not an incomplete type, output descriptions of each of its
+     members. Note that as we output the DIEs necessary to represent the
+     members of this record or union type, we will also be trying to output
+     DIEs to represent the *types* of those members. However the `type'
+     function (above) will specifically avoid generating type DIEs for member
+     types *within* the list of member DIEs for this (containing) type except
+     for those types (of members) which are explicitly marked as also being
+     members of this (containing) type themselves.  The g++ front- end can
+     force any given type to be treated as a member of some other (containing)
+     type by setting the TYPE_CONTEXT of the given (member) type to point to
+     the TREE node representing the appropriate (containing) type.  */
+
+  /* First output info about the base classes.  */
+  if (binfo)
+    {
+      VEC(tree,gc) *accesses = BINFO_BASE_ACCESSES (binfo);
+      int i;
+      tree base;
+
+      for (i = 0; BINFO_BASE_ITERATE (binfo, i, base); i++)
+	gen_inheritance_die (base,
+			     (accesses ? VEC_index (tree, accesses, i)
+			      : access_public_node), context_die);
+    }
+
+  /* Now output info about the data members and type members.  */
+  for (member = TYPE_FIELDS (type); member; member = TREE_CHAIN (member))
+    {
+      /* If we thought we were generating minimal debug info for TYPE
+	 and then changed our minds, some of the member declarations
+	 may have already been defined.  Don't define them again, but
+	 do put them in the right order.  */
+
+      child = lookup_decl_die (member);
+      if (child)
+	splice_child_die (context_die, child);
+      else
+	gen_decl_die (member, context_die);
+    }
+
+  /* Now output info about the function members (if any).  */
+  for (member = TYPE_METHODS (type); member; member = TREE_CHAIN (member))
+    {
+      /* Don't include clones in the member list.  */
+      if (DECL_ABSTRACT_ORIGIN (member))
+	continue;
+
+      child = lookup_decl_die (member);
+      if (child)
+	splice_child_die (context_die, child);
+      else
+	gen_decl_die (member, context_die);
+    }
+}
+
+/* Generate a DIE for a structure or union type.  If TYPE_DECL_SUPPRESS_DEBUG
+   is set, we pretend that the type was never defined, so we only get the
+   member DIEs needed by later specification DIEs.  */
+
+static void
+gen_struct_or_union_type_die (tree type, dw_die_ref context_die)
+{
+  dw_die_ref type_die = lookup_type_die (type);
+  dw_die_ref scope_die = 0;
+  int nested = 0;
+  int complete = (TYPE_SIZE (type)
+		  && (! TYPE_STUB_DECL (type)
+		      || ! TYPE_DECL_SUPPRESS_DEBUG (TYPE_STUB_DECL (type))));
+  int ns_decl = (context_die && context_die->die_tag == DW_TAG_namespace);
+
+  if (type_die && ! complete)
+    return;
+
+  if (TYPE_CONTEXT (type) != NULL_TREE
+      && (AGGREGATE_TYPE_P (TYPE_CONTEXT (type))
+	  || TREE_CODE (TYPE_CONTEXT (type)) == NAMESPACE_DECL))
+    nested = 1;
+
+  scope_die = scope_die_for (type, context_die);
+
+  if (! type_die || (nested && scope_die == comp_unit_die))
+    /* First occurrence of type or toplevel definition of nested class.  */
+    {
+      dw_die_ref old_die = type_die;
+
+      type_die = new_die (TREE_CODE (type) == RECORD_TYPE
+			  ? DW_TAG_structure_type : DW_TAG_union_type,
+			  scope_die, type);
+      equate_type_number_to_die (type, type_die);
+      if (old_die)
+	add_AT_specification (type_die, old_die);
+      else
+	add_name_attribute (type_die, type_tag (type));
+    }
+  else
+    remove_AT (type_die, DW_AT_declaration);
+
+  /* If this type has been completed, then give it a byte_size attribute and
+     then give a list of members.  */
+  if (complete && !ns_decl)
+    {
+      /* Prevent infinite recursion in cases where the type of some member of
+	 this type is expressed in terms of this type itself.  */
+      TREE_ASM_WRITTEN (type) = 1;
+      add_byte_size_attribute (type_die, type);
+      if (TYPE_STUB_DECL (type) != NULL_TREE)
+	add_src_coords_attributes (type_die, TYPE_STUB_DECL (type));
+
+      /* If the first reference to this type was as the return type of an
+	 inline function, then it may not have a parent.  Fix this now.  */
+      if (type_die->die_parent == NULL)
+	add_child_die (scope_die, type_die);
+
+      push_decl_scope (type);
+      gen_member_die (type, type_die);
+      pop_decl_scope ();
+
+      /* GNU extension: Record what type our vtable lives in.  */
+      if (TYPE_VFIELD (type))
+	{
+	  tree vtype = DECL_FCONTEXT (TYPE_VFIELD (type));
+
+	  gen_type_die (vtype, context_die);
+	  add_AT_die_ref (type_die, DW_AT_containing_type,
+			  lookup_type_die (vtype));
+	}
+    }
+  else
+    {
+      add_AT_flag (type_die, DW_AT_declaration, 1);
+
+      /* We don't need to do this for function-local types.  */
+      if (TYPE_STUB_DECL (type)
+	  && ! decl_function_context (TYPE_STUB_DECL (type)))
+	VEC_safe_push (tree, gc, incomplete_types, type);
+    }
+}
+
+/* Generate a DIE for a subroutine _type_.  */
+
+static void
+gen_subroutine_type_die (tree type, dw_die_ref context_die)
+{
+  tree return_type = TREE_TYPE (type);
+  dw_die_ref subr_die
+    = new_die (DW_TAG_subroutine_type,
+	       scope_die_for (type, context_die), type);
+
+  equate_type_number_to_die (type, subr_die);
+  add_prototyped_attribute (subr_die, type);
+  add_type_attribute (subr_die, return_type, 0, 0, context_die);
+  gen_formal_types_die (type, subr_die);
+}
+
+/* Generate a DIE for a type definition.  */
+
+static void
+gen_typedef_die (tree decl, dw_die_ref context_die)
+{
+  dw_die_ref type_die;
+  tree origin;
+
+  if (TREE_ASM_WRITTEN (decl))
+    return;
+
+  TREE_ASM_WRITTEN (decl) = 1;
+  type_die = new_die (DW_TAG_typedef, context_die, decl);
+  origin = decl_ultimate_origin (decl);
+  if (origin != NULL)
+    add_abstract_origin_attribute (type_die, origin);
+  else
+    {
+      tree type;
+
+      add_name_and_src_coords_attributes (type_die, decl);
+      if (DECL_ORIGINAL_TYPE (decl))
+	{
+	  type = DECL_ORIGINAL_TYPE (decl);
+
+	  gcc_assert (type != TREE_TYPE (decl));
+	  equate_type_number_to_die (TREE_TYPE (decl), type_die);
+	}
+      else
+	type = TREE_TYPE (decl);
+
+      add_type_attribute (type_die, type, TREE_READONLY (decl),
+			  TREE_THIS_VOLATILE (decl), context_die);
+    }
+
+  if (DECL_ABSTRACT (decl))
+    equate_decl_number_to_die (decl, type_die);
+}
+
+/* Generate a type description DIE.  */
+
+static void
+gen_type_die (tree type, dw_die_ref context_die)
+{
+  int need_pop;
+
+  if (type == NULL_TREE || type == error_mark_node)
+    return;
+
+  if (TYPE_NAME (type) && TREE_CODE (TYPE_NAME (type)) == TYPE_DECL
+      && DECL_ORIGINAL_TYPE (TYPE_NAME (type)))
+    {
+      if (TREE_ASM_WRITTEN (type))
+	return;
+
+      /* Prevent broken recursion; we can't hand off to the same type.  */
+      gcc_assert (DECL_ORIGINAL_TYPE (TYPE_NAME (type)) != type);
+
+      TREE_ASM_WRITTEN (type) = 1;
+      gen_decl_die (TYPE_NAME (type), context_die);
+      return;
+    }
+
+  /* We are going to output a DIE to represent the unqualified version
+     of this type (i.e. without any const or volatile qualifiers) so
+     get the main variant (i.e. the unqualified version) of this type
+     now.  (Vectors are special because the debugging info is in the
+     cloned type itself).  */
+  if (TREE_CODE (type) != VECTOR_TYPE)
+    type = type_main_variant (type);
+
+  if (TREE_ASM_WRITTEN (type))
+    return;
+
+  switch (TREE_CODE (type))
+    {
+    case ERROR_MARK:
+      break;
+
+    case POINTER_TYPE:
+    case REFERENCE_TYPE:
+      /* We must set TREE_ASM_WRITTEN in case this is a recursive type.  This
+	 ensures that the gen_type_die recursion will terminate even if the
+	 type is recursive.  Recursive types are possible in Ada.  */
+      /* ??? We could perhaps do this for all types before the switch
+	 statement.  */
+      TREE_ASM_WRITTEN (type) = 1;
+
+      /* For these types, all that is required is that we output a DIE (or a
+	 set of DIEs) to represent the "basis" type.  */
+      gen_type_die (TREE_TYPE (type), context_die);
+      break;
+
+    case OFFSET_TYPE:
+      /* This code is used for C++ pointer-to-data-member types.
+	 Output a description of the relevant class type.  */
+      gen_type_die (TYPE_OFFSET_BASETYPE (type), context_die);
+
+      /* Output a description of the type of the object pointed to.  */
+      gen_type_die (TREE_TYPE (type), context_die);
+
+      /* Now output a DIE to represent this pointer-to-data-member type
+	 itself.  */
+      gen_ptr_to_mbr_type_die (type, context_die);
+      break;
+
+    case FUNCTION_TYPE:
+      /* Force out return type (in case it wasn't forced out already).  */
+      gen_type_die (TREE_TYPE (type), context_die);
+      gen_subroutine_type_die (type, context_die);
+      break;
+
+    case METHOD_TYPE:
+      /* Force out return type (in case it wasn't forced out already).  */
+      gen_type_die (TREE_TYPE (type), context_die);
+      gen_subroutine_type_die (type, context_die);
+      break;
+
+    case ARRAY_TYPE:
+      if (TYPE_STRING_FLAG (type) && TREE_CODE (TREE_TYPE (type)) == CHAR_TYPE)
+	{
+	  gen_type_die (TREE_TYPE (type), context_die);
+	  gen_string_type_die (type, context_die);
+	}
+      else
+	gen_array_type_die (type, context_die);
+      break;
+
+    case VECTOR_TYPE:
+      gen_array_type_die (type, context_die);
+      break;
+
+    case ENUMERAL_TYPE:
+    case RECORD_TYPE:
+    case UNION_TYPE:
+    case QUAL_UNION_TYPE:
+      /* If this is a nested type whose containing class hasn't been written
+	 out yet, writing it out will cover this one, too.  This does not apply
+	 to instantiations of member class templates; they need to be added to
+	 the containing class as they are generated.  FIXME: This hurts the
+	 idea of combining type decls from multiple TUs, since we can't predict
+	 what set of template instantiations we'll get.  */
+      if (TYPE_CONTEXT (type)
+	  && AGGREGATE_TYPE_P (TYPE_CONTEXT (type))
+	  && ! TREE_ASM_WRITTEN (TYPE_CONTEXT (type)))
+	{
+	  gen_type_die (TYPE_CONTEXT (type), context_die);
+
+	  if (TREE_ASM_WRITTEN (type))
+	    return;
+
+	  /* If that failed, attach ourselves to the stub.  */
+	  push_decl_scope (TYPE_CONTEXT (type));
+	  context_die = lookup_type_die (TYPE_CONTEXT (type));
+	  need_pop = 1;
+	}
+      else
+	{
+	  declare_in_namespace (type, context_die);
+	  need_pop = 0;
+	}
+
+      if (TREE_CODE (type) == ENUMERAL_TYPE)
+	gen_enumeration_type_die (type, context_die);
+      else
+	gen_struct_or_union_type_die (type, context_die);
+
+      if (need_pop)
+	pop_decl_scope ();
+
+      /* Don't set TREE_ASM_WRITTEN on an incomplete struct; we want to fix
+	 it up if it is ever completed.  gen_*_type_die will set it for us
+	 when appropriate.  */
+      return;
+
+    case VOID_TYPE:
+    case INTEGER_TYPE:
+    case REAL_TYPE:
+    case COMPLEX_TYPE:
+    case BOOLEAN_TYPE:
+    case CHAR_TYPE:
+      /* No DIEs needed for fundamental types.  */
+      break;
+
+    case LANG_TYPE:
+      /* No Dwarf representation currently defined.  */
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  TREE_ASM_WRITTEN (type) = 1;
+}
+
+/* Generate a DIE for a tagged type instantiation.  */
+
+static void
+gen_tagged_type_instantiation_die (tree type, dw_die_ref context_die)
+{
+  if (type == NULL_TREE || type == error_mark_node)
+    return;
+
+  /* We are going to output a DIE to represent the unqualified version of
+     this type (i.e. without any const or volatile qualifiers) so make sure
+     that we have the main variant (i.e. the unqualified version) of this
+     type now.  */
+  gcc_assert (type == type_main_variant (type));
+
+  /* Do not check TREE_ASM_WRITTEN (type) as it may not be set if this is
+     an instance of an unresolved type.  */
+
+  switch (TREE_CODE (type))
+    {
+    case ERROR_MARK:
+      break;
+
+    case ENUMERAL_TYPE:
+      gen_inlined_enumeration_type_die (type, context_die);
+      break;
+
+    case RECORD_TYPE:
+      gen_inlined_structure_type_die (type, context_die);
+      break;
+
+    case UNION_TYPE:
+    case QUAL_UNION_TYPE:
+      gen_inlined_union_type_die (type, context_die);
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+}
+
+/* Generate a DW_TAG_lexical_block DIE followed by DIEs to represent all of the
+   things which are local to the given block.  */
+
+static void
+gen_block_die (tree stmt, dw_die_ref context_die, int depth)
+{
+  int must_output_die = 0;
+  tree origin;
+  tree decl;
+  enum tree_code origin_code;
+
+  /* Ignore blocks that are NULL.  */
+  if (stmt == NULL_TREE)
+    return;
+
+  /* If the block is one fragment of a non-contiguous block, do not
+     process the variables, since they will have been done by the
+     origin block.  Do process subblocks.  */
+  if (BLOCK_FRAGMENT_ORIGIN (stmt))
+    {
+      tree sub;
+
+      for (sub = BLOCK_SUBBLOCKS (stmt); sub; sub = BLOCK_CHAIN (sub))
+	gen_block_die (sub, context_die, depth + 1);
+
+      return;
+    }
+
+  /* Determine the "ultimate origin" of this block.  This block may be an
+     inlined instance of an inlined instance of inline function, so we have
+     to trace all of the way back through the origin chain to find out what
+     sort of node actually served as the original seed for the creation of
+     the current block.  */
+  origin = block_ultimate_origin (stmt);
+  origin_code = (origin != NULL) ? TREE_CODE (origin) : ERROR_MARK;
+
+  /* Determine if we need to output any Dwarf DIEs at all to represent this
+     block.  */
+  if (origin_code == FUNCTION_DECL)
+    /* The outer scopes for inlinings *must* always be represented.  We
+       generate DW_TAG_inlined_subroutine DIEs for them.  (See below.) */
+    must_output_die = 1;
+  else
+    {
+      /* In the case where the current block represents an inlining of the
+	 "body block" of an inline function, we must *NOT* output any DIE for
+	 this block because we have already output a DIE to represent the whole
+	 inlined function scope and the "body block" of any function doesn't
+	 really represent a different scope according to ANSI C rules.  So we
+	 check here to make sure that this block does not represent a "body
+	 block inlining" before trying to set the MUST_OUTPUT_DIE flag.  */
+      if (! is_body_block (origin ? origin : stmt))
+	{
+	  /* Determine if this block directly contains any "significant"
+	     local declarations which we will need to output DIEs for.  */
+	  if (debug_info_level > DINFO_LEVEL_TERSE)
+	    /* We are not in terse mode so *any* local declaration counts
+	       as being a "significant" one.  */
+	    must_output_die = (BLOCK_VARS (stmt) != NULL 
+			       && (TREE_USED (stmt) 
+				   || TREE_ASM_WRITTEN (stmt)
+				   || BLOCK_ABSTRACT (stmt)));
+	  else
+	    /* We are in terse mode, so only local (nested) function
+	       definitions count as "significant" local declarations.  */
+	    for (decl = BLOCK_VARS (stmt);
+		 decl != NULL; decl = TREE_CHAIN (decl))
+	      if (TREE_CODE (decl) == FUNCTION_DECL
+		  && DECL_INITIAL (decl))
+		{
+		  must_output_die = 1;
+		  break;
+		}
+	}
+    }
+
+  /* It would be a waste of space to generate a Dwarf DW_TAG_lexical_block
+     DIE for any block which contains no significant local declarations at
+     all.  Rather, in such cases we just call `decls_for_scope' so that any
+     needed Dwarf info for any sub-blocks will get properly generated. Note
+     that in terse mode, our definition of what constitutes a "significant"
+     local declaration gets restricted to include only inlined function
+     instances and local (nested) function definitions.  */
+  if (must_output_die)
+    {
+      if (origin_code == FUNCTION_DECL)
+	gen_inlined_subroutine_die (stmt, context_die, depth);
+      else
+	gen_lexical_block_die (stmt, context_die, depth);
+    }
+  else
+    decls_for_scope (stmt, context_die, depth);
+}
+
+/* Generate all of the decls declared within a given scope and (recursively)
+   all of its sub-blocks.  */
+
+static void
+decls_for_scope (tree stmt, dw_die_ref context_die, int depth)
+{
+  tree decl;
+  tree subblocks;
+
+  /* Ignore NULL blocks.  */
+  if (stmt == NULL_TREE)
+    return;
+
+  if (TREE_USED (stmt))
+    {
+      /* Output the DIEs to represent all of the data objects and typedefs
+	 declared directly within this block but not within any nested
+	 sub-blocks.  Also, nested function and tag DIEs have been
+	 generated with a parent of NULL; fix that up now.  */
+      for (decl = BLOCK_VARS (stmt); decl != NULL; decl = TREE_CHAIN (decl))
+	{
+	  dw_die_ref die;
+	  
+	  if (TREE_CODE (decl) == FUNCTION_DECL)
+	    die = lookup_decl_die (decl);
+	  else if (TREE_CODE (decl) == TYPE_DECL && TYPE_DECL_IS_STUB (decl))
+	    die = lookup_type_die (TREE_TYPE (decl));
+	  else
+	    die = NULL;
+	  
+	  if (die != NULL && die->die_parent == NULL)
+	    add_child_die (context_die, die);
+	  /* Do not produce debug information for static variables since
+	     these might be optimized out.  We are called for these later
+	     in cgraph_varpool_analyze_pending_decls. */
+	  if (TREE_CODE (decl) == VAR_DECL && TREE_STATIC (decl))
+	    ;
+	  else
+	    gen_decl_die (decl, context_die);
+	}
+    }
+
+  /* If we're at -g1, we're not interested in subblocks.  */
+  if (debug_info_level <= DINFO_LEVEL_TERSE)
+    return;
+
+  /* Output the DIEs to represent all sub-blocks (and the items declared
+     therein) of this block.  */
+  for (subblocks = BLOCK_SUBBLOCKS (stmt);
+       subblocks != NULL;
+       subblocks = BLOCK_CHAIN (subblocks))
+    gen_block_die (subblocks, context_die, depth + 1);
+}
+
+/* Is this a typedef we can avoid emitting?  */
+
+static inline int
+is_redundant_typedef (tree decl)
+{
+  if (TYPE_DECL_IS_STUB (decl))
+    return 1;
+
+  if (DECL_ARTIFICIAL (decl)
+      && DECL_CONTEXT (decl)
+      && is_tagged_type (DECL_CONTEXT (decl))
+      && TREE_CODE (TYPE_NAME (DECL_CONTEXT (decl))) == TYPE_DECL
+      && DECL_NAME (decl) == DECL_NAME (TYPE_NAME (DECL_CONTEXT (decl))))
+    /* Also ignore the artificial member typedef for the class name.  */
+    return 1;
+
+  return 0;
+}
+
+/* Returns the DIE for decl.  A DIE will always be returned.  */
+
+static dw_die_ref
+force_decl_die (tree decl)
+{
+  dw_die_ref decl_die;
+  unsigned saved_external_flag;
+  tree save_fn = NULL_TREE;
+  decl_die = lookup_decl_die (decl);
+  if (!decl_die)
+    {
+      dw_die_ref context_die;
+      tree decl_context = DECL_CONTEXT (decl);
+      if (decl_context)
+	{
+	  /* Find die that represents this context.  */
+	  if (TYPE_P (decl_context))
+	    context_die = force_type_die (decl_context);
+	  else
+	    context_die = force_decl_die (decl_context);
+	}
+      else
+	context_die = comp_unit_die;
+
+      decl_die = lookup_decl_die (decl);
+      if (decl_die)
+	return decl_die;
+
+      switch (TREE_CODE (decl))
+	{
+	case FUNCTION_DECL:
+	  /* Clear current_function_decl, so that gen_subprogram_die thinks
+	     that this is a declaration. At this point, we just want to force
+	     declaration die.  */
+	  save_fn = current_function_decl;
+	  current_function_decl = NULL_TREE;
+	  gen_subprogram_die (decl, context_die);
+	  current_function_decl = save_fn;
+	  break;
+
+	case VAR_DECL:
+	  /* Set external flag to force declaration die. Restore it after
+	   gen_decl_die() call.  */
+	  saved_external_flag = DECL_EXTERNAL (decl);
+	  DECL_EXTERNAL (decl) = 1;
+	  gen_decl_die (decl, context_die);
+	  DECL_EXTERNAL (decl) = saved_external_flag;
+	  break;
+
+	case NAMESPACE_DECL:
+	  dwarf2out_decl (decl);
+	  break;
+
+	default:
+	  gcc_unreachable ();
+	}
+
+      /* We should be able to find the DIE now.  */
+      if (!decl_die)
+	decl_die = lookup_decl_die (decl);
+      gcc_assert (decl_die);
+    }
+
+  return decl_die;
+}
+
+/* Returns the DIE for TYPE.  A DIE is always returned.  */
+
+static dw_die_ref
+force_type_die (tree type)
+{
+  dw_die_ref type_die;
+
+  type_die = lookup_type_die (type);
+  if (!type_die)
+    {
+      dw_die_ref context_die;
+      if (TYPE_CONTEXT (type))
+	{
+	  if (TYPE_P (TYPE_CONTEXT (type)))
+	    context_die = force_type_die (TYPE_CONTEXT (type));
+	  else
+	    context_die = force_decl_die (TYPE_CONTEXT (type));
+	}
+      else
+	context_die = comp_unit_die;
+
+      type_die = lookup_type_die (type);
+      if (type_die)
+	return type_die;
+      gen_type_die (type, context_die);
+      type_die = lookup_type_die (type);
+      gcc_assert (type_die);
+    }
+  return type_die;
+}
+
+/* Force out any required namespaces to be able to output DECL,
+   and return the new context_die for it, if it's changed.  */
+
+static dw_die_ref
+setup_namespace_context (tree thing, dw_die_ref context_die)
+{
+  tree context = (DECL_P (thing)
+		  ? DECL_CONTEXT (thing) : TYPE_CONTEXT (thing));
+  if (context && TREE_CODE (context) == NAMESPACE_DECL)
+    /* Force out the namespace.  */
+    context_die = force_decl_die (context);
+
+  return context_die;
+}
+
+/* Emit a declaration DIE for THING (which is either a DECL or a tagged
+   type) within its namespace, if appropriate.
+
+   For compatibility with older debuggers, namespace DIEs only contain
+   declarations; all definitions are emitted at CU scope.  */
+
+static void
+declare_in_namespace (tree thing, dw_die_ref context_die)
+{
+  dw_die_ref ns_context;
+
+  if (debug_info_level <= DINFO_LEVEL_TERSE)
+    return;
+
+  /* If this decl is from an inlined function, then don't try to emit it in its
+     namespace, as we will get confused.  It would have already been emitted
+     when the abstract instance of the inline function was emitted anyways.  */
+  if (DECL_P (thing) && DECL_ABSTRACT_ORIGIN (thing))
+    return;
+
+  ns_context = setup_namespace_context (thing, context_die);
+
+  if (ns_context != context_die)
+    {
+      if (DECL_P (thing))
+	gen_decl_die (thing, ns_context);
+      else
+	gen_type_die (thing, ns_context);
+    }
+}
+
+/* Generate a DIE for a namespace or namespace alias.  */
+
+static void
+gen_namespace_die (tree decl)
+{
+  dw_die_ref context_die = setup_namespace_context (decl, comp_unit_die);
+
+  /* Namespace aliases have a DECL_ABSTRACT_ORIGIN of the namespace
+     they are an alias of.  */
+  if (DECL_ABSTRACT_ORIGIN (decl) == NULL)
+    {
+      /* Output a real namespace.  */
+      dw_die_ref namespace_die
+	= new_die (DW_TAG_namespace, context_die, decl);
+      add_name_and_src_coords_attributes (namespace_die, decl);
+      equate_decl_number_to_die (decl, namespace_die);
+    }
+  else
+    {
+      /* Output a namespace alias.  */
+
+      /* Force out the namespace we are an alias of, if necessary.  */
+      dw_die_ref origin_die
+	= force_decl_die (DECL_ABSTRACT_ORIGIN (decl));
+
+      /* Now create the namespace alias DIE.  */
+      dw_die_ref namespace_die
+	= new_die (DW_TAG_imported_declaration, context_die, decl);
+      add_name_and_src_coords_attributes (namespace_die, decl);
+      add_AT_die_ref (namespace_die, DW_AT_import, origin_die);
+      equate_decl_number_to_die (decl, namespace_die);
+    }
+}
+
+/* Generate Dwarf debug information for a decl described by DECL.  */
+
+static void
+gen_decl_die (tree decl, dw_die_ref context_die)
+{
+  tree origin;
+
+  if (DECL_P (decl) && DECL_IGNORED_P (decl))
+    return;
+
+  switch (TREE_CODE (decl))
+    {
+    case ERROR_MARK:
+      break;
+
+    case CONST_DECL:
+      /* The individual enumerators of an enum type get output when we output
+	 the Dwarf representation of the relevant enum type itself.  */
+      break;
+
+    case FUNCTION_DECL:
+      /* Don't output any DIEs to represent mere function declarations,
+	 unless they are class members or explicit block externs.  */
+      if (DECL_INITIAL (decl) == NULL_TREE && DECL_CONTEXT (decl) == NULL_TREE
+	  && (current_function_decl == NULL_TREE || DECL_ARTIFICIAL (decl)))
+	break;
+
+#if 0
+      /* FIXME */
+      /* This doesn't work because the C frontend sets DECL_ABSTRACT_ORIGIN
+	 on local redeclarations of global functions.  That seems broken.  */
+      if (current_function_decl != decl)
+	/* This is only a declaration.  */;
+#endif
+
+      /* If we're emitting a clone, emit info for the abstract instance.  */
+      if (DECL_ORIGIN (decl) != decl)
+	dwarf2out_abstract_function (DECL_ABSTRACT_ORIGIN (decl));
+
+      /* If we're emitting an out-of-line copy of an inline function,
+	 emit info for the abstract instance and set up to refer to it.  */
+      else if (cgraph_function_possibly_inlined_p (decl)
+	       && ! DECL_ABSTRACT (decl)
+	       && ! class_or_namespace_scope_p (context_die)
+	       /* dwarf2out_abstract_function won't emit a die if this is just
+		  a declaration.  We must avoid setting DECL_ABSTRACT_ORIGIN in
+		  that case, because that works only if we have a die.  */
+	       && DECL_INITIAL (decl) != NULL_TREE)
+	{
+	  dwarf2out_abstract_function (decl);
+	  set_decl_origin_self (decl);
+	}
+
+      /* Otherwise we're emitting the primary DIE for this decl.  */
+      else if (debug_info_level > DINFO_LEVEL_TERSE)
+	{
+	  /* Before we describe the FUNCTION_DECL itself, make sure that we
+	     have described its return type.  */
+	  gen_type_die (TREE_TYPE (TREE_TYPE (decl)), context_die);
+
+	  /* And its virtual context.  */
+	  if (DECL_VINDEX (decl) != NULL_TREE)
+	    gen_type_die (DECL_CONTEXT (decl), context_die);
+
+	  /* And its containing type.  */
+	  origin = decl_class_context (decl);
+	  if (origin != NULL_TREE)
+	    gen_type_die_for_member (origin, decl, context_die);
+
+	  /* And its containing namespace.  */
+	  declare_in_namespace (decl, context_die);
+	}
+
+      /* Now output a DIE to represent the function itself.  */
+      gen_subprogram_die (decl, context_die);
+      break;
+
+    case TYPE_DECL:
+      /* If we are in terse mode, don't generate any DIEs to represent any
+	 actual typedefs.  */
+      if (debug_info_level <= DINFO_LEVEL_TERSE)
+	break;
+
+      /* In the special case of a TYPE_DECL node representing the declaration
+	 of some type tag, if the given TYPE_DECL is marked as having been
+	 instantiated from some other (original) TYPE_DECL node (e.g. one which
+	 was generated within the original definition of an inline function) we
+	 have to generate a special (abbreviated) DW_TAG_structure_type,
+	 DW_TAG_union_type, or DW_TAG_enumeration_type DIE here.  */
+      if (TYPE_DECL_IS_STUB (decl) && decl_ultimate_origin (decl) != NULL_TREE)
+	{
+	  gen_tagged_type_instantiation_die (TREE_TYPE (decl), context_die);
+	  break;
+	}
+
+      if (is_redundant_typedef (decl))
+	gen_type_die (TREE_TYPE (decl), context_die);
+      else
+	/* Output a DIE to represent the typedef itself.  */
+	gen_typedef_die (decl, context_die);
+      break;
+
+    case LABEL_DECL:
+      if (debug_info_level >= DINFO_LEVEL_NORMAL)
+	gen_label_die (decl, context_die);
+      break;
+
+    case VAR_DECL:
+    case RESULT_DECL:
+      /* If we are in terse mode, don't generate any DIEs to represent any
+	 variable declarations or definitions.  */
+      if (debug_info_level <= DINFO_LEVEL_TERSE)
+	break;
+
+      /* Output any DIEs that are needed to specify the type of this data
+	 object.  */
+      gen_type_die (TREE_TYPE (decl), context_die);
+
+      /* And its containing type.  */
+      origin = decl_class_context (decl);
+      if (origin != NULL_TREE)
+	gen_type_die_for_member (origin, decl, context_die);
+
+      /* And its containing namespace.  */
+      declare_in_namespace (decl, context_die);
+
+      /* Now output the DIE to represent the data object itself.  This gets
+	 complicated because of the possibility that the VAR_DECL really
+	 represents an inlined instance of a formal parameter for an inline
+	 function.  */
+      origin = decl_ultimate_origin (decl);
+      if (origin != NULL_TREE && TREE_CODE (origin) == PARM_DECL)
+	gen_formal_parameter_die (decl, context_die);
+      else
+	gen_variable_die (decl, context_die);
+      break;
+
+    case FIELD_DECL:
+      /* Ignore the nameless fields that are used to skip bits but handle C++
+	 anonymous unions and structs.  */
+      if (DECL_NAME (decl) != NULL_TREE
+	  || TREE_CODE (TREE_TYPE (decl)) == UNION_TYPE
+	  || TREE_CODE (TREE_TYPE (decl)) == RECORD_TYPE)
+	{
+	  gen_type_die (member_declared_type (decl), context_die);
+	  gen_field_die (decl, context_die);
+	}
+      break;
+
+    case PARM_DECL:
+      gen_type_die (TREE_TYPE (decl), context_die);
+      gen_formal_parameter_die (decl, context_die);
+      break;
+
+    case NAMESPACE_DECL:
+      gen_namespace_die (decl);
+      break;
+
+    default:
+      /* Probably some frontend-internal decl.  Assume we don't care.  */
+      gcc_assert ((int)TREE_CODE (decl) > NUM_TREE_CODES);
+      break;
+    }
+}
+
+/* Add Ada "use" clause information for SGI Workshop debugger.  */
+
+void
+dwarf2out_add_library_unit_info (const char *filename, const char *context_list)
+{
+  unsigned int file_index;
+
+  if (filename != NULL)
+    {
+      dw_die_ref unit_die = new_die (DW_TAG_module, comp_unit_die, NULL);
+      tree context_list_decl
+	= build_decl (LABEL_DECL, get_identifier (context_list),
+		      void_type_node);
+
+      TREE_PUBLIC (context_list_decl) = TRUE;
+      add_name_attribute (unit_die, context_list);
+      file_index = lookup_filename (filename);
+      add_AT_unsigned (unit_die, DW_AT_decl_file, file_index);
+      add_pubname (context_list_decl, unit_die);
+    }
+}
+
+/* Output debug information for global decl DECL.  Called from toplev.c after
+   compilation proper has finished.  */
+
+static void
+dwarf2out_global_decl (tree decl)
+{
+  /* Output DWARF2 information for file-scope tentative data object
+     declarations, file-scope (extern) function declarations (which had no
+     corresponding body) and file-scope tagged type declarations and
+     definitions which have not yet been forced out.  */
+  if (TREE_CODE (decl) != FUNCTION_DECL || !DECL_INITIAL (decl))
+    dwarf2out_decl (decl);
+}
+
+/* Output debug information for type decl DECL.  Called from toplev.c
+   and from language front ends (to record built-in types).  */
+static void
+dwarf2out_type_decl (tree decl, int local)
+{
+  if (!local)
+    dwarf2out_decl (decl);
+}
+
+/* Output debug information for imported module or decl.  */
+
+static void
+dwarf2out_imported_module_or_decl (tree decl, tree context)
+{
+  dw_die_ref imported_die, at_import_die;
+  dw_die_ref scope_die;
+  unsigned file_index;
+  expanded_location xloc;
+
+  if (debug_info_level <= DINFO_LEVEL_TERSE)
+    return;
+
+  gcc_assert (decl);
+
+  /* To emit DW_TAG_imported_module or DW_TAG_imported_decl, we need two DIEs.
+     We need decl DIE for reference and scope die. First, get DIE for the decl
+     itself.  */
+
+  /* Get the scope die for decl context. Use comp_unit_die for global module
+     or decl. If die is not found for non globals, force new die.  */
+  if (!context)
+    scope_die = comp_unit_die;
+  else if (TYPE_P (context))
+    scope_die = force_type_die (context);
+  else
+    scope_die = force_decl_die (context);
+
+  /* For TYPE_DECL or CONST_DECL, lookup TREE_TYPE.  */
+  if (TREE_CODE (decl) == TYPE_DECL || TREE_CODE (decl) == CONST_DECL)
+    at_import_die = force_type_die (TREE_TYPE (decl));
+  else
+    {
+      at_import_die = lookup_decl_die (decl);
+      if (!at_import_die)
+	{
+	  /* If we're trying to avoid duplicate debug info, we may not have
+	     emitted the member decl for this field.  Emit it now.  */
+	  if (TREE_CODE (decl) == FIELD_DECL)
+	    {
+	      tree type = DECL_CONTEXT (decl);
+	      dw_die_ref type_context_die;
+
+	      if (TYPE_CONTEXT (type))
+		if (TYPE_P (TYPE_CONTEXT (type)))
+		  type_context_die = force_type_die (TYPE_CONTEXT (type));
+	      else
+		type_context_die = force_decl_die (TYPE_CONTEXT (type));
+	      else
+		type_context_die = comp_unit_die;
+	      gen_type_die_for_member (type, decl, type_context_die);
+	    }
+	  at_import_die = force_decl_die (decl);
+	}
+    }
+
+  /* OK, now we have DIEs for decl as well as scope. Emit imported die.  */
+  if (TREE_CODE (decl) == NAMESPACE_DECL)
+    imported_die = new_die (DW_TAG_imported_module, scope_die, context);
+  else
+    imported_die = new_die (DW_TAG_imported_declaration, scope_die, context);
+
+  xloc = expand_location (input_location);
+  file_index = lookup_filename (xloc.file);
+  add_AT_unsigned (imported_die, DW_AT_decl_file, file_index);
+  add_AT_unsigned (imported_die, DW_AT_decl_line, xloc.line);
+  add_AT_die_ref (imported_die, DW_AT_import, at_import_die);
+}
+
+/* Write the debugging output for DECL.  */
+
+void
+dwarf2out_decl (tree decl)
+{
+  dw_die_ref context_die = comp_unit_die;
+
+  switch (TREE_CODE (decl))
+    {
+    case ERROR_MARK:
+      return;
+
+    case FUNCTION_DECL:
+      /* What we would really like to do here is to filter out all mere
+	 file-scope declarations of file-scope functions which are never
+	 referenced later within this translation unit (and keep all of ones
+	 that *are* referenced later on) but we aren't clairvoyant, so we have
+	 no idea which functions will be referenced in the future (i.e. later
+	 on within the current translation unit). So here we just ignore all
+	 file-scope function declarations which are not also definitions.  If
+	 and when the debugger needs to know something about these functions,
+	 it will have to hunt around and find the DWARF information associated
+	 with the definition of the function.
+
+	 We can't just check DECL_EXTERNAL to find out which FUNCTION_DECL
+	 nodes represent definitions and which ones represent mere
+	 declarations.  We have to check DECL_INITIAL instead. That's because
+	 the C front-end supports some weird semantics for "extern inline"
+	 function definitions.  These can get inlined within the current
+	 translation unit (and thus, we need to generate Dwarf info for their
+	 abstract instances so that the Dwarf info for the concrete inlined
+	 instances can have something to refer to) but the compiler never
+	 generates any out-of-lines instances of such things (despite the fact
+	 that they *are* definitions).
+
+	 The important point is that the C front-end marks these "extern
+	 inline" functions as DECL_EXTERNAL, but we need to generate DWARF for
+	 them anyway. Note that the C++ front-end also plays some similar games
+	 for inline function definitions appearing within include files which
+	 also contain `#pragma interface' pragmas.  */
+      if (DECL_INITIAL (decl) == NULL_TREE)
+	return;
+
+      /* If we're a nested function, initially use a parent of NULL; if we're
+	 a plain function, this will be fixed up in decls_for_scope.  If
+	 we're a method, it will be ignored, since we already have a DIE.  */
+      if (decl_function_context (decl)
+	  /* But if we're in terse mode, we don't care about scope.  */
+	  && debug_info_level > DINFO_LEVEL_TERSE)
+	context_die = NULL;
+      break;
+
+    case VAR_DECL:
+      /* Ignore this VAR_DECL if it refers to a file-scope extern data object
+	 declaration and if the declaration was never even referenced from
+	 within this entire compilation unit.  We suppress these DIEs in
+	 order to save space in the .debug section (by eliminating entries
+	 which are probably useless).  Note that we must not suppress
+	 block-local extern declarations (whether used or not) because that
+	 would screw-up the debugger's name lookup mechanism and cause it to
+	 miss things which really ought to be in scope at a given point.  */
+      if (DECL_EXTERNAL (decl) && !TREE_USED (decl))
+	return;
+
+      /* For local statics lookup proper context die.  */
+      if (TREE_STATIC (decl) && decl_function_context (decl))
+	context_die = lookup_decl_die (DECL_CONTEXT (decl));
+
+      /* If we are in terse mode, don't generate any DIEs to represent any
+	 variable declarations or definitions.  */
+      if (debug_info_level <= DINFO_LEVEL_TERSE)
+	return;
+      break;
+
+    case NAMESPACE_DECL:
+      if (debug_info_level <= DINFO_LEVEL_TERSE)
+	return;
+      if (lookup_decl_die (decl) != NULL)
+        return;
+      break;
+
+    case TYPE_DECL:
+      /* Don't emit stubs for types unless they are needed by other DIEs.  */
+      if (TYPE_DECL_SUPPRESS_DEBUG (decl))
+	return;
+
+      /* Don't bother trying to generate any DIEs to represent any of the
+	 normal built-in types for the language we are compiling.  */
+      if (DECL_IS_BUILTIN (decl))
+	{
+	  /* OK, we need to generate one for `bool' so GDB knows what type
+	     comparisons have.  */
+	  if ((get_AT_unsigned (comp_unit_die, DW_AT_language)
+	       == DW_LANG_C_plus_plus)
+	      && TREE_CODE (TREE_TYPE (decl)) == BOOLEAN_TYPE
+	      && ! DECL_IGNORED_P (decl))
+	    modified_type_die (TREE_TYPE (decl), 0, 0, NULL);
+
+	  return;
+	}
+
+      /* If we are in terse mode, don't generate any DIEs for types.  */
+      if (debug_info_level <= DINFO_LEVEL_TERSE)
+	return;
+
+      /* If we're a function-scope tag, initially use a parent of NULL;
+	 this will be fixed up in decls_for_scope.  */
+      if (decl_function_context (decl))
+	context_die = NULL;
+
+      break;
+
+    default:
+      return;
+    }
+
+  gen_decl_die (decl, context_die);
+}
+
+/* Output a marker (i.e. a label) for the beginning of the generated code for
+   a lexical block.  */
+
+static void
+dwarf2out_begin_block (unsigned int line ATTRIBUTE_UNUSED,
+		       unsigned int blocknum)
+{
+  current_function_section (current_function_decl);
+  ASM_OUTPUT_DEBUG_LABEL (asm_out_file, BLOCK_BEGIN_LABEL, blocknum);
+}
+
+/* Output a marker (i.e. a label) for the end of the generated code for a
+   lexical block.  */
+
+static void
+dwarf2out_end_block (unsigned int line ATTRIBUTE_UNUSED, unsigned int blocknum)
+{
+  current_function_section (current_function_decl);
+  ASM_OUTPUT_DEBUG_LABEL (asm_out_file, BLOCK_END_LABEL, blocknum);
+}
+
+/* Returns nonzero if it is appropriate not to emit any debugging
+   information for BLOCK, because it doesn't contain any instructions.
+
+   Don't allow this for blocks with nested functions or local classes
+   as we would end up with orphans, and in the presence of scheduling
+   we may end up calling them anyway.  */
+
+static bool
+dwarf2out_ignore_block (tree block)
+{
+  tree decl;
+
+  for (decl = BLOCK_VARS (block); decl; decl = TREE_CHAIN (decl))
+    if (TREE_CODE (decl) == FUNCTION_DECL
+	|| (TREE_CODE (decl) == TYPE_DECL && TYPE_DECL_IS_STUB (decl)))
+      return 0;
+
+  return 1;
+}
+
+/* Lookup FILE_NAME (in the list of filenames that we know about here in
+   dwarf2out.c) and return its "index".  The index of each (known) filename is
+   just a unique number which is associated with only that one filename.  We
+   need such numbers for the sake of generating labels (in the .debug_sfnames
+   section) and references to those files numbers (in the .debug_srcinfo
+   and.debug_macinfo sections).  If the filename given as an argument is not
+   found in our current list, add it to the list and assign it the next
+   available unique index number.  In order to speed up searches, we remember
+   the index of the filename was looked up last.  This handles the majority of
+   all searches.  */
+
+static unsigned
+lookup_filename (const char *file_name)
+{
+  size_t i, n;
+  char *save_file_name;
+
+  /* Check to see if the file name that was searched on the previous
+     call matches this file name.  If so, return the index.  */
+  if (file_table_last_lookup_index != 0)
+    {
+      const char *last
+	= VARRAY_CHAR_PTR (file_table, file_table_last_lookup_index);
+      if (strcmp (file_name, last) == 0)
+	return file_table_last_lookup_index;
+    }
+
+  /* Didn't match the previous lookup, search the table.  */
+  n = VARRAY_ACTIVE_SIZE (file_table);
+  for (i = 1; i < n; i++)
+    if (strcmp (file_name, VARRAY_CHAR_PTR (file_table, i)) == 0)
+      {
+	file_table_last_lookup_index = i;
+	return i;
+      }
+
+  /* Add the new entry to the end of the filename table.  */
+  file_table_last_lookup_index = n;
+  save_file_name = (char *) ggc_strdup (file_name);
+  VARRAY_PUSH_CHAR_PTR (file_table, save_file_name);
+  VARRAY_PUSH_UINT (file_table_emitted, 0);
+
+  /* If the assembler is emitting the file table, and we aren't eliminating
+     unused debug types, then we must emit .file here.  If we are eliminating
+     unused debug types, then this will be done by the maybe_emit_file call in
+     prune_unused_types_walk_attribs.  */
+
+  if (DWARF2_ASM_LINE_DEBUG_INFO && ! flag_eliminate_unused_debug_types)
+    return maybe_emit_file (i);
+
+  return i;
+}
+
+/* If the assembler will construct the file table, then translate the compiler
+   internal file table number into the assembler file table number, and emit
+   a .file directive if we haven't already emitted one yet.  The file table
+   numbers are different because we prune debug info for unused variables and
+   types, which may include filenames.  */
+
+static int
+maybe_emit_file (int fileno)
+{
+  if (DWARF2_ASM_LINE_DEBUG_INFO && fileno > 0)
+    {
+      if (!VARRAY_UINT (file_table_emitted, fileno))
+	{
+	  VARRAY_UINT (file_table_emitted, fileno) = ++emitcount;
+	  fprintf (asm_out_file, "\t.file %u ",
+		   VARRAY_UINT (file_table_emitted, fileno));
+	  output_quoted_string (asm_out_file,
+				VARRAY_CHAR_PTR (file_table, fileno));
+	  fputc ('\n', asm_out_file);
+	}
+      return VARRAY_UINT (file_table_emitted, fileno);
+    }
+  else
+    return fileno;
+}
+
+/* Initialize the compiler internal file table.  */
+
+static void
+init_file_table (void)
+{
+  /* Allocate the initial hunk of the file_table.  */
+  VARRAY_CHAR_PTR_INIT (file_table, 64, "file_table");
+  VARRAY_UINT_INIT (file_table_emitted, 64, "file_table_emitted");
+
+  /* Skip the first entry - file numbers begin at 1.  */
+  VARRAY_PUSH_CHAR_PTR (file_table, NULL);
+  VARRAY_PUSH_UINT (file_table_emitted, 0);
+  file_table_last_lookup_index = 0;
+}
+
+/* Called by the final INSN scan whenever we see a var location.  We
+   use it to drop labels in the right places, and throw the location in
+   our lookup table.  */
+
+static void
+dwarf2out_var_location (rtx loc_note)
+{
+  char loclabel[MAX_ARTIFICIAL_LABEL_BYTES];
+  struct var_loc_node *newloc;
+  rtx prev_insn;
+  static rtx last_insn;
+  static const char *last_label;
+  tree decl;
+
+  if (!DECL_P (NOTE_VAR_LOCATION_DECL (loc_note)))
+    return;
+  prev_insn = PREV_INSN (loc_note);
+
+  newloc = ggc_alloc_cleared (sizeof (struct var_loc_node));
+  /* If the insn we processed last time is the previous insn
+     and it is also a var location note, use the label we emitted
+     last time.  */
+  if (last_insn != NULL_RTX
+      && last_insn == prev_insn
+      && NOTE_P (prev_insn)
+      && NOTE_LINE_NUMBER (prev_insn) == NOTE_INSN_VAR_LOCATION)
+    {
+      newloc->label = last_label;
+    }
+  else
+    {
+      ASM_GENERATE_INTERNAL_LABEL (loclabel, "LVL", loclabel_num);
+      ASM_OUTPUT_DEBUG_LABEL (asm_out_file, "LVL", loclabel_num);
+      loclabel_num++;
+      newloc->label = ggc_strdup (loclabel);
+    }
+  newloc->var_loc_note = loc_note;
+  newloc->next = NULL;
+
+  if (cfun
+      && (last_text_section == in_unlikely_executed_text
+	  || (last_text_section == in_named
+	      && last_text_section_name == cfun->unlikely_text_section_name)))
+    newloc->section_label = cfun->cold_section_label;
+  else
+    newloc->section_label = text_section_label;
+
+  last_insn = loc_note;
+  last_label = newloc->label;
+  decl = NOTE_VAR_LOCATION_DECL (loc_note);
+  if (DECL_DEBUG_EXPR_IS_FROM (decl) && DECL_DEBUG_EXPR (decl) 
+      && DECL_P (DECL_DEBUG_EXPR (decl)))
+    decl = DECL_DEBUG_EXPR (decl); 
+  add_var_loc_to_decl (decl, newloc);
+}
+
+/* We need to reset the locations at the beginning of each
+   function. We can't do this in the end_function hook, because the
+   declarations that use the locations won't have been outputted when
+   that hook is called.  */
+
+static void
+dwarf2out_begin_function (tree unused ATTRIBUTE_UNUSED)
+{
+  htab_empty (decl_loc_table);
+}
+
+/* Output a label to mark the beginning of a source code line entry
+   and record information relating to this source line, in
+   'line_info_table' for later output of the .debug_line section.  */
+
+static void
+dwarf2out_source_line (unsigned int line, const char *filename)
+{
+  if (debug_info_level >= DINFO_LEVEL_NORMAL
+      && line != 0)
+    {
+      current_function_section (current_function_decl);
+
+      /* If requested, emit something human-readable.  */
+      if (flag_debug_asm)
+	fprintf (asm_out_file, "\t%s %s:%d\n", ASM_COMMENT_START,
+		 filename, line);
+
+      if (DWARF2_ASM_LINE_DEBUG_INFO)
+	{
+	  unsigned file_num = lookup_filename (filename);
+
+	  file_num = maybe_emit_file (file_num);
+
+	  /* Emit the .loc directive understood by GNU as.  */
+	  fprintf (asm_out_file, "\t.loc %d %d 0\n", file_num, line);
+
+	  /* Indicate that line number info exists.  */
+	  line_info_table_in_use++;
+
+	  /* Indicate that multiple line number tables exist.  */
+	  if (DECL_SECTION_NAME (current_function_decl))
+	    separate_line_info_table_in_use++;
+	}
+      else if (DECL_SECTION_NAME (current_function_decl))
+	{
+	  dw_separate_line_info_ref line_info;
+	  targetm.asm_out.internal_label (asm_out_file, SEPARATE_LINE_CODE_LABEL,
+				     separate_line_info_table_in_use);
+
+	  /* Expand the line info table if necessary.  */
+	  if (separate_line_info_table_in_use
+	      == separate_line_info_table_allocated)
+	    {
+	      separate_line_info_table_allocated += LINE_INFO_TABLE_INCREMENT;
+	      separate_line_info_table
+		= ggc_realloc (separate_line_info_table,
+			       separate_line_info_table_allocated
+			       * sizeof (dw_separate_line_info_entry));
+	      memset (separate_line_info_table
+		       + separate_line_info_table_in_use,
+		      0,
+		      (LINE_INFO_TABLE_INCREMENT
+		       * sizeof (dw_separate_line_info_entry)));
+	    }
+
+	  /* Add the new entry at the end of the line_info_table.  */
+	  line_info
+	    = &separate_line_info_table[separate_line_info_table_in_use++];
+	  line_info->dw_file_num = lookup_filename (filename);
+	  line_info->dw_line_num = line;
+	  line_info->function = current_function_funcdef_no;
+	}
+      else
+	{
+	  dw_line_info_ref line_info;
+
+	  targetm.asm_out.internal_label (asm_out_file, LINE_CODE_LABEL,
+				     line_info_table_in_use);
+
+	  /* Expand the line info table if necessary.  */
+	  if (line_info_table_in_use == line_info_table_allocated)
+	    {
+	      line_info_table_allocated += LINE_INFO_TABLE_INCREMENT;
+	      line_info_table
+		= ggc_realloc (line_info_table,
+			       (line_info_table_allocated
+				* sizeof (dw_line_info_entry)));
+	      memset (line_info_table + line_info_table_in_use, 0,
+		      LINE_INFO_TABLE_INCREMENT * sizeof (dw_line_info_entry));
+	    }
+
+	  /* Add the new entry at the end of the line_info_table.  */
+	  line_info = &line_info_table[line_info_table_in_use++];
+	  line_info->dw_file_num = lookup_filename (filename);
+	  line_info->dw_line_num = line;
+	}
+    }
+}
+
+/* Record the beginning of a new source file.  */
+
+static void
+dwarf2out_start_source_file (unsigned int lineno, const char *filename)
+{
+  if (flag_eliminate_dwarf2_dups)
+    {
+      /* Record the beginning of the file for break_out_includes.  */
+      dw_die_ref bincl_die;
+
+      bincl_die = new_die (DW_TAG_GNU_BINCL, comp_unit_die, NULL);
+      add_AT_string (bincl_die, DW_AT_name, filename);
+    }
+
+  if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+    {
+      int fileno;
+
+      named_section_flags (DEBUG_MACINFO_SECTION, SECTION_DEBUG);
+      dw2_asm_output_data (1, DW_MACINFO_start_file, "Start new file");
+      dw2_asm_output_data_uleb128 (lineno, "Included from line number %d",
+				   lineno);
+
+      fileno = maybe_emit_file (lookup_filename (filename));
+      dw2_asm_output_data_uleb128 (fileno, "Filename we just started");
+    }
+}
+
+/* Record the end of a source file.  */
+
+static void
+dwarf2out_end_source_file (unsigned int lineno ATTRIBUTE_UNUSED)
+{
+  if (flag_eliminate_dwarf2_dups)
+    /* Record the end of the file for break_out_includes.  */
+    new_die (DW_TAG_GNU_EINCL, comp_unit_die, NULL);
+
+  if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+    {
+      named_section_flags (DEBUG_MACINFO_SECTION, SECTION_DEBUG);
+      dw2_asm_output_data (1, DW_MACINFO_end_file, "End file");
+    }
+}
+
+/* Called from debug_define in toplev.c.  The `buffer' parameter contains
+   the tail part of the directive line, i.e. the part which is past the
+   initial whitespace, #, whitespace, directive-name, whitespace part.  */
+
+static void
+dwarf2out_define (unsigned int lineno ATTRIBUTE_UNUSED,
+		  const char *buffer ATTRIBUTE_UNUSED)
+{
+  if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+    {
+      named_section_flags (DEBUG_MACINFO_SECTION, SECTION_DEBUG);
+      dw2_asm_output_data (1, DW_MACINFO_define, "Define macro");
+      dw2_asm_output_data_uleb128 (lineno, "At line number %d", lineno);
+      dw2_asm_output_nstring (buffer, -1, "The macro");
+    }
+}
+
+/* Called from debug_undef in toplev.c.  The `buffer' parameter contains
+   the tail part of the directive line, i.e. the part which is past the
+   initial whitespace, #, whitespace, directive-name, whitespace part.  */
+
+static void
+dwarf2out_undef (unsigned int lineno ATTRIBUTE_UNUSED,
+		 const char *buffer ATTRIBUTE_UNUSED)
+{
+  if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+    {
+      named_section_flags (DEBUG_MACINFO_SECTION, SECTION_DEBUG);
+      dw2_asm_output_data (1, DW_MACINFO_undef, "Undefine macro");
+      dw2_asm_output_data_uleb128 (lineno, "At line number %d", lineno);
+      dw2_asm_output_nstring (buffer, -1, "The macro");
+    }
+}
+
+/* Set up for Dwarf output at the start of compilation.  */
+
+static void
+dwarf2out_init (const char *filename ATTRIBUTE_UNUSED)
+{
+  init_file_table ();
+
+  /* Allocate the decl_die_table.  */
+  decl_die_table = htab_create_ggc (10, decl_die_table_hash,
+				    decl_die_table_eq, NULL);
+
+  /* Allocate the decl_loc_table.  */
+  decl_loc_table = htab_create_ggc (10, decl_loc_table_hash,
+				    decl_loc_table_eq, NULL);
+
+  /* Allocate the initial hunk of the decl_scope_table.  */
+  decl_scope_table = VEC_alloc (tree, gc, 256);
+
+  /* Allocate the initial hunk of the abbrev_die_table.  */
+  abbrev_die_table = ggc_alloc_cleared (ABBREV_DIE_TABLE_INCREMENT
+					* sizeof (dw_die_ref));
+  abbrev_die_table_allocated = ABBREV_DIE_TABLE_INCREMENT;
+  /* Zero-th entry is allocated, but unused.  */
+  abbrev_die_table_in_use = 1;
+
+  /* Allocate the initial hunk of the line_info_table.  */
+  line_info_table = ggc_alloc_cleared (LINE_INFO_TABLE_INCREMENT
+				       * sizeof (dw_line_info_entry));
+  line_info_table_allocated = LINE_INFO_TABLE_INCREMENT;
+
+  /* Zero-th entry is allocated, but unused.  */
+  line_info_table_in_use = 1;
+
+  /* Generate the initial DIE for the .debug section.  Note that the (string)
+     value given in the DW_AT_name attribute of the DW_TAG_compile_unit DIE
+     will (typically) be a relative pathname and that this pathname should be
+     taken as being relative to the directory from which the compiler was
+     invoked when the given (base) source file was compiled.  We will fill
+     in this value in dwarf2out_finish.  */
+  comp_unit_die = gen_compile_unit_die (NULL);
+
+  incomplete_types = VEC_alloc (tree, gc, 64);
+
+  used_rtx_array = VEC_alloc (rtx, gc, 32);
+
+  ASM_GENERATE_INTERNAL_LABEL (text_end_label, TEXT_END_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (abbrev_section_label,
+			       DEBUG_ABBREV_SECTION_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (text_section_label, TEXT_SECTION_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (cold_text_section_label, 
+			       COLD_TEXT_SECTION_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (cold_end_label, COLD_END_LABEL, 0);
+
+  ASM_GENERATE_INTERNAL_LABEL (debug_info_section_label,
+			       DEBUG_INFO_SECTION_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (debug_line_section_label,
+			       DEBUG_LINE_SECTION_LABEL, 0);
+  ASM_GENERATE_INTERNAL_LABEL (ranges_section_label,
+			       DEBUG_RANGES_SECTION_LABEL, 0);
+  named_section_flags (DEBUG_ABBREV_SECTION, SECTION_DEBUG);
+  ASM_OUTPUT_LABEL (asm_out_file, abbrev_section_label);
+  named_section_flags (DEBUG_INFO_SECTION, SECTION_DEBUG);
+  ASM_OUTPUT_LABEL (asm_out_file, debug_info_section_label);
+  named_section_flags (DEBUG_LINE_SECTION, SECTION_DEBUG);
+  ASM_OUTPUT_LABEL (asm_out_file, debug_line_section_label);
+
+  if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+    {
+      named_section_flags (DEBUG_MACINFO_SECTION, SECTION_DEBUG);
+      ASM_GENERATE_INTERNAL_LABEL (macinfo_section_label,
+				   DEBUG_MACINFO_SECTION_LABEL, 0);
+      ASM_OUTPUT_LABEL (asm_out_file, macinfo_section_label);
+    }
+
+  text_section ();
+  ASM_OUTPUT_LABEL (asm_out_file, text_section_label);
+  if (flag_reorder_blocks_and_partition)
+    {
+      unlikely_text_section ();
+      ASM_OUTPUT_LABEL (asm_out_file, cold_text_section_label);
+    }
+}
+
+/* A helper function for dwarf2out_finish called through
+   ht_forall.  Emit one queued .debug_str string.  */
+
+static int
+output_indirect_string (void **h, void *v ATTRIBUTE_UNUSED)
+{
+  struct indirect_string_node *node = (struct indirect_string_node *) *h;
+
+  if (node->form == DW_FORM_strp)
+    {
+      named_section_flags (DEBUG_STR_SECTION, DEBUG_STR_SECTION_FLAGS);
+      ASM_OUTPUT_LABEL (asm_out_file, node->label);
+      assemble_string (node->str, strlen (node->str) + 1);
+    }
+
+  return 1;
+}
+
+
+
+/* Clear the marks for a die and its children.
+   Be cool if the mark isn't set.  */
+
+static void
+prune_unmark_dies (dw_die_ref die)
+{
+  dw_die_ref c;
+  die->die_mark = 0;
+  for (c = die->die_child; c; c = c->die_sib)
+    prune_unmark_dies (c);
+}
+
+
+/* Given DIE that we're marking as used, find any other dies
+   it references as attributes and mark them as used.  */
+
+static void
+prune_unused_types_walk_attribs (dw_die_ref die)
+{
+  dw_attr_ref a;
+
+  for (a = die->die_attr; a != NULL; a = a->dw_attr_next)
+    {
+      if (a->dw_attr_val.val_class == dw_val_class_die_ref)
+	{
+	  /* A reference to another DIE.
+	     Make sure that it will get emitted.  */
+	  prune_unused_types_mark (a->dw_attr_val.v.val_die_ref.die, 1);
+	}
+      else if (a->dw_attr == DW_AT_decl_file || a->dw_attr == DW_AT_call_file)
+	{
+	  /* A reference to a file.  Make sure the file name is emitted.  */
+	  a->dw_attr_val.v.val_unsigned =
+	    maybe_emit_file (a->dw_attr_val.v.val_unsigned);
+	}
+    }
+}
+
+
+/* Mark DIE as being used.  If DOKIDS is true, then walk down
+   to DIE's children.  */
+
+static void
+prune_unused_types_mark (dw_die_ref die, int dokids)
+{
+  dw_die_ref c;
+
+  if (die->die_mark == 0)
+    {
+      /* We haven't done this node yet.  Mark it as used.  */
+      die->die_mark = 1;
+
+      /* We also have to mark its parents as used.
+	 (But we don't want to mark our parents' kids due to this.)  */
+      if (die->die_parent)
+	prune_unused_types_mark (die->die_parent, 0);
+
+      /* Mark any referenced nodes.  */
+      prune_unused_types_walk_attribs (die);
+
+      /* If this node is a specification,
+         also mark the definition, if it exists.  */
+      if (get_AT_flag (die, DW_AT_declaration) && die->die_definition)
+        prune_unused_types_mark (die->die_definition, 1);
+    }
+
+  if (dokids && die->die_mark != 2)
+    {
+      /* We need to walk the children, but haven't done so yet.
+	 Remember that we've walked the kids.  */
+      die->die_mark = 2;
+
+      /* Walk them.  */
+      for (c = die->die_child; c; c = c->die_sib)
+	{
+	  /* If this is an array type, we need to make sure our
+	     kids get marked, even if they're types.  */
+	  if (die->die_tag == DW_TAG_array_type)
+	    prune_unused_types_mark (c, 1);
+	  else
+	    prune_unused_types_walk (c);
+	}
+    }
+}
+
+
+/* Walk the tree DIE and mark types that we actually use.  */
+
+static void
+prune_unused_types_walk (dw_die_ref die)
+{
+  dw_die_ref c;
+
+  /* Don't do anything if this node is already marked.  */
+  if (die->die_mark)
+    return;
+
+  switch (die->die_tag) {
+  case DW_TAG_const_type:
+  case DW_TAG_packed_type:
+  case DW_TAG_pointer_type:
+  case DW_TAG_reference_type:
+  case DW_TAG_volatile_type:
+  case DW_TAG_typedef:
+  case DW_TAG_array_type:
+  case DW_TAG_structure_type:
+  case DW_TAG_union_type:
+  case DW_TAG_class_type:
+  case DW_TAG_friend:
+  case DW_TAG_variant_part:
+  case DW_TAG_enumeration_type:
+  case DW_TAG_subroutine_type:
+  case DW_TAG_string_type:
+  case DW_TAG_set_type:
+  case DW_TAG_subrange_type:
+  case DW_TAG_ptr_to_member_type:
+  case DW_TAG_file_type:
+    /* It's a type node --- don't mark it.  */
+    return;
+
+  default:
+    /* Mark everything else.  */
+    break;
+  }
+
+  die->die_mark = 1;
+
+  /* Now, mark any dies referenced from here.  */
+  prune_unused_types_walk_attribs (die);
+
+  /* Mark children.  */
+  for (c = die->die_child; c; c = c->die_sib)
+    prune_unused_types_walk (c);
+}
+
+
+/* Remove from the tree DIE any dies that aren't marked.  */
+
+static void
+prune_unused_types_prune (dw_die_ref die)
+{
+  dw_die_ref c, p, n;
+
+  gcc_assert (die->die_mark);
+
+  p = NULL;
+  for (c = die->die_child; c; c = n)
+    {
+      n = c->die_sib;
+      if (c->die_mark)
+	{
+	  prune_unused_types_prune (c);
+	  p = c;
+	}
+      else
+	{
+	  if (p)
+	    p->die_sib = n;
+	  else
+	    die->die_child = n;
+	  free_die (c);
+	}
+    }
+}
+
+
+/* Remove dies representing declarations that we never use.  */
+
+static void
+prune_unused_types (void)
+{
+  unsigned int i;
+  limbo_die_node *node;
+
+  /* Clear all the marks.  */
+  prune_unmark_dies (comp_unit_die);
+  for (node = limbo_die_list; node; node = node->next)
+    prune_unmark_dies (node->die);
+
+  /* Set the mark on nodes that are actually used.  */
+  prune_unused_types_walk (comp_unit_die);
+  for (node = limbo_die_list; node; node = node->next)
+    prune_unused_types_walk (node->die);
+
+  /* Also set the mark on nodes referenced from the
+     pubname_table or arange_table.  */
+  for (i = 0; i < pubname_table_in_use; i++)
+    prune_unused_types_mark (pubname_table[i].die, 1);
+  for (i = 0; i < arange_table_in_use; i++)
+    prune_unused_types_mark (arange_table[i], 1);
+
+  /* Get rid of nodes that aren't marked.  */
+  prune_unused_types_prune (comp_unit_die);
+  for (node = limbo_die_list; node; node = node->next)
+    prune_unused_types_prune (node->die);
+
+  /* Leave the marks clear.  */
+  prune_unmark_dies (comp_unit_die);
+  for (node = limbo_die_list; node; node = node->next)
+    prune_unmark_dies (node->die);
+}
+
+/* Output stuff that dwarf requires at the end of every file,
+   and generate the DWARF-2 debugging info.  */
+
+static void
+dwarf2out_finish (const char *filename)
+{
+  limbo_die_node *node, *next_node;
+  dw_die_ref die = 0;
+
+  /* Add the name for the main input file now.  We delayed this from
+     dwarf2out_init to avoid complications with PCH.  */
+  add_name_attribute (comp_unit_die, filename);
+  if (filename[0] != DIR_SEPARATOR)
+    add_comp_dir_attribute (comp_unit_die);
+  else if (get_AT (comp_unit_die, DW_AT_comp_dir) == NULL)
+    {
+      size_t i;
+      for (i = 1; i < VARRAY_ACTIVE_SIZE (file_table); i++)
+	if (VARRAY_CHAR_PTR (file_table, i)[0] != DIR_SEPARATOR
+	    /* Don't add cwd for <built-in>.  */
+	    && VARRAY_CHAR_PTR (file_table, i)[0] != '<')
+	  {
+	    add_comp_dir_attribute (comp_unit_die);
+	    break;
+	  }
+    }
+
+  /* Traverse the limbo die list, and add parent/child links.  The only
+     dies without parents that should be here are concrete instances of
+     inline functions, and the comp_unit_die.  We can ignore the comp_unit_die.
+     For concrete instances, we can get the parent die from the abstract
+     instance.  */
+  for (node = limbo_die_list; node; node = next_node)
+    {
+      next_node = node->next;
+      die = node->die;
+
+      if (die->die_parent == NULL)
+	{
+	  dw_die_ref origin = get_AT_ref (die, DW_AT_abstract_origin);
+
+	  if (origin)
+	    add_child_die (origin->die_parent, die);
+	  else if (die == comp_unit_die)
+	    ;
+	  else if (errorcount > 0 || sorrycount > 0)
+	    /* It's OK to be confused by errors in the input.  */
+	    add_child_die (comp_unit_die, die);
+	  else
+	    {
+	      /* In certain situations, the lexical block containing a
+		 nested function can be optimized away, which results
+		 in the nested function die being orphaned.  Likewise
+		 with the return type of that nested function.  Force
+		 this to be a child of the containing function.
+
+		 It may happen that even the containing function got fully
+		 inlined and optimized out.  In that case we are lost and
+		 assign the empty child.  This should not be big issue as
+		 the function is likely unreachable too.  */
+	      tree context = NULL_TREE;
+
+	      gcc_assert (node->created_for);
+
+	      if (DECL_P (node->created_for))
+		context = DECL_CONTEXT (node->created_for);
+	      else if (TYPE_P (node->created_for))
+		context = TYPE_CONTEXT (node->created_for);
+
+	      gcc_assert (context && TREE_CODE (context) == FUNCTION_DECL);
+
+	      origin = lookup_decl_die (context);
+	      if (origin)
+	        add_child_die (origin, die);
+	      else
+	        add_child_die (comp_unit_die, die);
+	    }
+	}
+    }
+
+  limbo_die_list = NULL;
+
+  /* Walk through the list of incomplete types again, trying once more to
+     emit full debugging info for them.  */
+  retry_incomplete_types ();
+
+  /* We need to reverse all the dies before break_out_includes, or
+     we'll see the end of an include file before the beginning.  */
+  reverse_all_dies (comp_unit_die);
+
+  if (flag_eliminate_unused_debug_types)
+    prune_unused_types ();
+
+  /* Generate separate CUs for each of the include files we've seen.
+     They will go into limbo_die_list.  */
+  if (flag_eliminate_dwarf2_dups)
+    break_out_includes (comp_unit_die);
+
+  /* Traverse the DIE's and add add sibling attributes to those DIE's
+     that have children.  */
+  add_sibling_attributes (comp_unit_die);
+  for (node = limbo_die_list; node; node = node->next)
+    add_sibling_attributes (node->die);
+
+  /* Output a terminator label for the .text section.  */
+  text_section ();
+  targetm.asm_out.internal_label (asm_out_file, TEXT_END_LABEL, 0);
+  if (flag_reorder_blocks_and_partition)
+    {
+      unlikely_text_section ();
+      targetm.asm_out.internal_label (asm_out_file, COLD_END_LABEL, 0);
+    }
+
+  /* Output the source line correspondence table.  We must do this
+     even if there is no line information.  Otherwise, on an empty
+     translation unit, we will generate a present, but empty,
+     .debug_info section.  IRIX 6.5 `nm' will then complain when
+     examining the file.  */
+  if (! DWARF2_ASM_LINE_DEBUG_INFO)
+    {
+      named_section_flags (DEBUG_LINE_SECTION, SECTION_DEBUG);
+      output_line_info ();
+    }
+
+  /* Output location list section if necessary.  */
+  if (have_location_lists)
+    {
+      /* Output the location lists info.  */
+      named_section_flags (DEBUG_LOC_SECTION, SECTION_DEBUG);
+      ASM_GENERATE_INTERNAL_LABEL (loc_section_label,
+				   DEBUG_LOC_SECTION_LABEL, 0);
+      ASM_OUTPUT_LABEL (asm_out_file, loc_section_label);
+      output_location_lists (die);
+      have_location_lists = 0;
+    }
+
+  /* We can only use the low/high_pc attributes if all of the code was
+     in .text.  */
+  if (!separate_line_info_table_in_use && !have_switched_text_section)
+    {
+      add_AT_lbl_id (comp_unit_die, DW_AT_low_pc, text_section_label);
+      add_AT_lbl_id (comp_unit_die, DW_AT_high_pc, text_end_label);
+    }
+
+  /* If it wasn't, we need to give .debug_loc and .debug_ranges an appropriate
+     "base address".  Use zero so that these addresses become absolute.  */
+  else if (have_location_lists || ranges_table_in_use)
+    add_AT_addr (comp_unit_die, DW_AT_entry_pc, const0_rtx);
+
+  if (debug_info_level >= DINFO_LEVEL_NORMAL)
+    add_AT_lbl_offset (comp_unit_die, DW_AT_stmt_list,
+		       debug_line_section_label);
+
+  if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+    add_AT_lbl_offset (comp_unit_die, DW_AT_macro_info, macinfo_section_label);
+
+  /* Output all of the compilation units.  We put the main one last so that
+     the offsets are available to output_pubnames.  */
+  for (node = limbo_die_list; node; node = node->next)
+    output_comp_unit (node->die, 0);
+
+  output_comp_unit (comp_unit_die, 0);
+
+  /* Output the abbreviation table.  */
+  named_section_flags (DEBUG_ABBREV_SECTION, SECTION_DEBUG);
+  output_abbrev_section ();
+
+  /* Output public names table if necessary.  */
+  if (pubname_table_in_use)
+    {
+      named_section_flags (DEBUG_PUBNAMES_SECTION, SECTION_DEBUG);
+      output_pubnames ();
+    }
+
+  /* Output the address range information.  We only put functions in the arange
+     table, so don't write it out if we don't have any.  */
+  if (fde_table_in_use)
+    {
+      named_section_flags (DEBUG_ARANGES_SECTION, SECTION_DEBUG);
+      output_aranges ();
+    }
+
+  /* Output ranges section if necessary.  */
+  if (ranges_table_in_use)
+    {
+      named_section_flags (DEBUG_RANGES_SECTION, SECTION_DEBUG);
+      ASM_OUTPUT_LABEL (asm_out_file, ranges_section_label);
+      output_ranges ();
+    }
+
+  /* Have to end the macro section.  */
+  if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+    {
+      named_section_flags (DEBUG_MACINFO_SECTION, SECTION_DEBUG);
+      dw2_asm_output_data (1, 0, "End compilation unit");
+    }
+
+  /* If we emitted any DW_FORM_strp form attribute, output the string
+     table too.  */
+  if (debug_str_hash)
+    htab_traverse (debug_str_hash, output_indirect_string, NULL);
+}
+#else
+
+/* This should never be used, but its address is needed for comparisons.  */
+const struct gcc_debug_hooks dwarf2_debug_hooks;
+
+#endif /* DWARF2_DEBUGGING_INFO */
+
+#include "gt-dwarf2out.h"
diff -Naur gcc-4.1-20051216.orig/gcc/dwarf2out.c.rej gcc-4.1-20051216-src/gcc/dwarf2out.c.rej
--- gcc-4.1-20051216.orig/gcc/dwarf2out.c.rej	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/dwarf2out.c.rej	2005-12-18 22:24:40.000000000 +0100
@@ -0,0 +1,1232 @@
+***************
+*** 239,247 ****
+     of this structure.  */
+  typedef struct cfa_loc GTY(())
+  {
+-   unsigned long reg;
+    HOST_WIDE_INT offset;
+    HOST_WIDE_INT base_offset;
+    int indirect;            /* 1 if CFA is accessed via a dereference.  */
+  } dw_cfa_location;
+  
+--- 239,247 ----
+     of this structure.  */
+  typedef struct cfa_loc GTY(())
+  {
+    HOST_WIDE_INT offset;
+    HOST_WIDE_INT base_offset;
++   unsigned int reg;
+    int indirect;            /* 1 if CFA is accessed via a dereference.  */
+  } dw_cfa_location;
+  
+***************
+*** 431,442 ****
+  #ifndef DWARF_FRAME_REGNUM
+  #define DWARF_FRAME_REGNUM(REG) DBX_REGISTER_NUMBER (REG)
+  #endif
+- 
+- /* The offset from the incoming value of %sp to the top of the stack frame
+-    for the current function.  */
+- #ifndef INCOMING_FRAME_SP_OFFSET
+- #define INCOMING_FRAME_SP_OFFSET 0
+- #endif
+  
+  /* Hook used by __throw.  */
+  
+--- 431,436 ----
+  #ifndef DWARF_FRAME_REGNUM
+  #define DWARF_FRAME_REGNUM(REG) DBX_REGISTER_NUMBER (REG)
+  #endif
+  
+  /* Hook used by __throw.  */
+  
+***************
+*** 663,669 ****
+  
+  /* Subroutine of lookup_cfa.  */
+  
+- static inline void
+  lookup_cfa_1 (dw_cfi_ref cfi, dw_cfa_location *loc)
+  {
+    switch (cfi->dw_cfi_opc)
+--- 657,663 ----
+  
+  /* Subroutine of lookup_cfa.  */
+  
++ static void
+  lookup_cfa_1 (dw_cfi_ref cfi, dw_cfa_location *loc)
+  {
+    switch (cfi->dw_cfi_opc)
+***************
+*** 693,699 ****
+  {
+    dw_cfi_ref cfi;
+  
+-   loc->reg = (unsigned long) -1;
+    loc->offset = 0;
+    loc->indirect = 0;
+    loc->base_offset = 0;
+--- 687,693 ----
+  {
+    dw_cfi_ref cfi;
+  
++   loc->reg = INVALID_REGNUM;
+    loc->offset = 0;
+    loc->indirect = 0;
+    loc->base_offset = 0;
+***************
+*** 773,781 ****
+    lookup_cfa (&old_cfa);
+  
+    /* If nothing changed, no need to issue any call frame instructions.  */
+-   if (loc.reg == old_cfa.reg && loc.offset == old_cfa.offset
+-       && loc.indirect == old_cfa.indirect
+-       && (loc.indirect == 0 || loc.base_offset == old_cfa.base_offset))
+      return;
+  
+    cfi = new_cfi ();
+--- 779,785 ----
+    lookup_cfa (&old_cfa);
+  
+    /* If nothing changed, no need to issue any call frame instructions.  */
++   if (cfa_equal_p (&loc, &old_cfa))
+      return;
+  
+    cfi = new_cfi ();
+***************
+*** 790,796 ****
+      }
+  
+  #ifndef MIPS_DEBUGGING_INFO  /* SGI dbx thinks this means no offset.  */
+-   else if (loc.offset == old_cfa.offset && old_cfa.reg != (unsigned long) -1
+  	   && !loc.indirect)
+      {
+        /* Construct a "DW_CFA_def_cfa_register <register>" instruction,
+--- 794,801 ----
+      }
+  
+  #ifndef MIPS_DEBUGGING_INFO  /* SGI dbx thinks this means no offset.  */
++   else if (loc.offset == old_cfa.offset
++ 	   && old_cfa.reg != INVALID_REGNUM
+  	   && !loc.indirect)
+      {
+        /* Construct a "DW_CFA_def_cfa_register <register>" instruction,
+***************
+*** 3285,3311 ****
+  {
+    struct dw_loc_descr_struct *head, *tmp;
+  
+-   gcc_assert (cfa->indirect);
+- 
+-   if (cfa->base_offset)
+      {
+-       if (cfa->reg <= 31)
+- 	head = new_loc_descr (DW_OP_breg0 + cfa->reg, cfa->base_offset, 0);
+        else
+- 	head = new_loc_descr (DW_OP_bregx, cfa->reg, cfa->base_offset);
+      }
+-   else if (cfa->reg <= 31)
+-     head = new_loc_descr (DW_OP_reg0 + cfa->reg, 0, 0);
+    else
+-     head = new_loc_descr (DW_OP_regx, cfa->reg, 0);
+- 
+-   head->dw_loc_oprnd1.val_class = dw_val_class_const;
+-   tmp = new_loc_descr (DW_OP_deref, 0, 0);
+-   add_loc_descr (&head, tmp);
+-   if (cfa->offset != 0)
+      {
+-       tmp = new_loc_descr (DW_OP_plus_uconst, cfa->offset, 0);
+-       add_loc_descr (&head, tmp);
+      }
+  
+    return head;
+--- 3294,3333 ----
+  {
+    struct dw_loc_descr_struct *head, *tmp;
+  
++   if (cfa->indirect)
+      {
++       if (cfa->base_offset)
++ 	{
++ 	  if (cfa->reg <= 31)
++ 	    head = new_loc_descr (DW_OP_breg0 + cfa->reg, cfa->base_offset, 0);
++ 	  else
++ 	    head = new_loc_descr (DW_OP_bregx, cfa->reg, cfa->base_offset);
++ 	}
++       else if (cfa->reg <= 31)
++ 	head = new_loc_descr (DW_OP_reg0 + cfa->reg, 0, 0);
+        else
++ 	head = new_loc_descr (DW_OP_regx, cfa->reg, 0);
++ 
++       head->dw_loc_oprnd1.val_class = dw_val_class_const;
++       tmp = new_loc_descr (DW_OP_deref, 0, 0);
++       add_loc_descr (&head, tmp);
++       if (cfa->offset != 0)
++ 	{
++ 	  tmp = new_loc_descr (DW_OP_plus_uconst, cfa->offset, 0);
++ 	  add_loc_descr (&head, tmp);
++ 	}
+      }
+    else
+      {
++       if (cfa->offset == 0)
++ 	if (cfa->reg <= 31)
++ 	  head = new_loc_descr (DW_OP_reg0 + cfa->reg, 0, 0);
++ 	else
++ 	  head = new_loc_descr (DW_OP_regx, cfa->reg, 0);
++       else if (cfa->reg <= 31)
++ 	head = new_loc_descr (DW_OP_breg0 + cfa->reg, cfa->offset, 0);
++       else
++ 	head = new_loc_descr (DW_OP_bregx, cfa->reg, cfa->offset);
+      }
+  
+    return head;
+***************
+*** 4042,4052 ****
+  static dw_loc_descr_ref one_reg_loc_descriptor (unsigned int);
+  static dw_loc_descr_ref multiple_reg_loc_descriptor (rtx, rtx);
+  static dw_loc_descr_ref int_loc_descriptor (HOST_WIDE_INT);
+- static dw_loc_descr_ref based_loc_descr (unsigned, HOST_WIDE_INT, bool);
+  static int is_based_loc (rtx);
+- static dw_loc_descr_ref mem_loc_descriptor (rtx, enum machine_mode mode, bool);
+  static dw_loc_descr_ref concat_loc_descriptor (rtx, rtx);
+- static dw_loc_descr_ref loc_descriptor (rtx, bool);
+  static dw_loc_descr_ref loc_descriptor_from_tree_1 (tree, int);
+  static dw_loc_descr_ref loc_descriptor_from_tree (tree);
+  static HOST_WIDE_INT ceiling (HOST_WIDE_INT, unsigned int);
+--- 4068,4078 ----
+  static dw_loc_descr_ref one_reg_loc_descriptor (unsigned int);
+  static dw_loc_descr_ref multiple_reg_loc_descriptor (rtx, rtx);
+  static dw_loc_descr_ref int_loc_descriptor (HOST_WIDE_INT);
++ static dw_loc_descr_ref based_loc_descr (rtx, HOST_WIDE_INT);
+  static int is_based_loc (rtx);
++ static dw_loc_descr_ref mem_loc_descriptor (rtx, enum machine_mode mode);
+  static dw_loc_descr_ref concat_loc_descriptor (rtx, rtx);
++ static dw_loc_descr_ref loc_descriptor (rtx);
+  static dw_loc_descr_ref loc_descriptor_from_tree_1 (tree, int);
+  static dw_loc_descr_ref loc_descriptor_from_tree (tree);
+  static HOST_WIDE_INT ceiling (HOST_WIDE_INT, unsigned int);
+***************
+*** 8470,8477 ****
+  {
+    unsigned regno = REGNO (rtl);
+  
+    gcc_assert (regno < FIRST_PSEUDO_REGISTER);
+  
+    return DBX_REGISTER_NUMBER (regno);
+  }
+  
+--- 8498,8515 ----
+  {
+    unsigned regno = REGNO (rtl);
+  
++   /* We do not want to see registers that should have been eliminated.  */
++   gcc_assert (HARD_FRAME_POINTER_REGNUM == ARG_POINTER_REGNUM
++ 	      || rtl != arg_pointer_rtx);
++   gcc_assert (HARD_FRAME_POINTER_REGNUM == FRAME_POINTER_REGNUM
++ 	      || rtl != frame_pointer_rtx);
++ 
+    gcc_assert (regno < FIRST_PSEUDO_REGISTER);
+  
++ #ifdef LEAF_REG_REMAP
++   regno = LEAF_REG_REMAP (regno);
++ #endif
++ 
+    return DBX_REGISTER_NUMBER (regno);
+  }
+  
+***************
+*** 8501,8520 ****
+  static dw_loc_descr_ref
+  reg_loc_descriptor (rtx rtl)
+  {
+-   unsigned reg;
+    rtx regs;
+  
+    if (REGNO (rtl) >= FIRST_PSEUDO_REGISTER)
+      return 0;
+  
+-   reg = dbx_reg_number (rtl);
+    regs = targetm.dwarf_register_span (rtl);
+  
+-   if (hard_regno_nregs[REGNO (rtl)][GET_MODE (rtl)] > 1
+-       || regs)
+      return multiple_reg_loc_descriptor (rtl, regs);
+    else
+-     return one_reg_loc_descriptor (reg);
+  }
+  
+  /* Return a location descriptor that designates a machine register for
+--- 8539,8555 ----
+  static dw_loc_descr_ref
+  reg_loc_descriptor (rtx rtl)
+  {
+    rtx regs;
+  
+    if (REGNO (rtl) >= FIRST_PSEUDO_REGISTER)
+      return 0;
+  
+    regs = targetm.dwarf_register_span (rtl);
+  
++   if (hard_regno_nregs[REGNO (rtl)][GET_MODE (rtl)] > 1 || regs)
+      return multiple_reg_loc_descriptor (rtl, regs);
+    else
++     return one_reg_loc_descriptor (dbx_reg_number (rtl));
+  }
+  
+  /* Return a location descriptor that designates a machine register for
+***************
+*** 8618,8642 ****
+    return new_loc_descr (op, i, 0);
+  }
+  
+  /* Return a location descriptor that designates a base+offset location.  */
+  
+  static dw_loc_descr_ref
+- based_loc_descr (unsigned int reg, HOST_WIDE_INT offset, bool can_use_fbreg)
+  {
+    dw_loc_descr_ref loc_result;
+-   /* For the "frame base", we use the frame pointer or stack pointer
+-      registers, since the RTL for local variables is relative to one of
+-      them.  */
+-   unsigned fp_reg = DBX_REGISTER_NUMBER (frame_pointer_needed
+- 					 ? HARD_FRAME_POINTER_REGNUM
+- 					 : STACK_POINTER_REGNUM);
+- 
+-   if (reg == fp_reg && can_use_fbreg)
+-     loc_result = new_loc_descr (DW_OP_fbreg, offset, 0);
+-   else if (reg <= 31)
+-     loc_result = new_loc_descr (DW_OP_breg0 + reg, offset, 0);
+    else
+-     loc_result = new_loc_descr (DW_OP_bregx, reg, offset);
+  
+    return loc_result;
+  }
+--- 8653,8705 ----
+    return new_loc_descr (op, i, 0);
+  }
+  
++ /* Return an offset from an eliminable register to the post-prologue
++    frame pointer.  */
++ 
++ static HOST_WIDE_INT
++ eliminate_reg_to_offset (rtx reg)
++ {
++   HOST_WIDE_INT offset = 0;
++ 
++   reg = eliminate_regs (reg, VOIDmode, NULL_RTX);
++   if (GET_CODE (reg) == PLUS)
++     {
++       offset = INTVAL (XEXP (reg, 1));
++       reg = XEXP (reg, 0);
++     }
++   gcc_assert (reg == (frame_pointer_needed ? hard_frame_pointer_rtx
++ 		      : stack_pointer_rtx));
++ 
++   return offset;
++ }
++ 
+  /* Return a location descriptor that designates a base+offset location.  */
+  
+  static dw_loc_descr_ref
++ based_loc_descr (rtx reg, HOST_WIDE_INT offset)
+  {
+    dw_loc_descr_ref loc_result;
++ 
++   /* We only use "frame base" when we're sure we're talking about the
++      post-prologue local stack frame.  We do this by *not* running
++      register elimination until this point, and recognizing the special
++      argument pointer and soft frame pointer rtx's.  */
++   if (reg == arg_pointer_rtx || reg == frame_pointer_rtx)
++     {
++       offset += eliminate_reg_to_offset (reg);
++       offset += frame_pointer_cfa_offset;
++ 
++       loc_result = new_loc_descr (DW_OP_fbreg, offset, 0);
++     }
+    else
++     {
++       unsigned int regno = dbx_reg_number (reg);
++ 
++       if (regno <= 31)
++ 	loc_result = new_loc_descr (DW_OP_breg0 + regno, offset, 0);
++       else
++ 	loc_result = new_loc_descr (DW_OP_bregx, regno, offset);
++     }
+  
+    return loc_result;
+  }
+***************
+*** 8665,8679 ****
+     MODE is the mode of the memory reference, needed to handle some
+     autoincrement addressing modes.
+  
+-    CAN_USE_FBREG is a flag whether we can use DW_AT_frame_base in the location
+-    list for RTL. We can't use it when we are emitting location list for
+-    virtual variable frame_base_decl (i.e. a location list for DW_AT_frame_base)
+-    which describes how frame base changes when !frame_pointer_needed.
+  
+     Return 0 if we can't represent the location.  */
+  
+  static dw_loc_descr_ref
+- mem_loc_descriptor (rtx rtl, enum machine_mode mode, bool can_use_fbreg)
+  {
+    dw_loc_descr_ref mem_loc_result = NULL;
+    enum dwarf_location_atom op;
+--- 8728,8740 ----
+     MODE is the mode of the memory reference, needed to handle some
+     autoincrement addressing modes.
+  
++    CAN_USE_FBREG is a flag whether we can use DW_AT_frame_base in the
++    location list for RTL.
+  
+     Return 0 if we can't represent the location.  */
+  
+  static dw_loc_descr_ref
++ mem_loc_descriptor (rtx rtl, enum machine_mode mode)
+  {
+    dw_loc_descr_ref mem_loc_result = NULL;
+    enum dwarf_location_atom op;
+***************
+*** 8720,8732 ****
+  	 memory) so DWARF consumers need to be aware of the subtle
+  	 distinction between OP_REG and OP_BASEREG.  */
+        if (REGNO (rtl) < FIRST_PSEUDO_REGISTER)
+- 	mem_loc_result = based_loc_descr (dbx_reg_number (rtl), 0,
+- 					  can_use_fbreg);
+        break;
+  
+      case MEM:
+-       mem_loc_result = mem_loc_descriptor (XEXP (rtl, 0), GET_MODE (rtl),
+- 					   can_use_fbreg);
+        if (mem_loc_result != 0)
+  	add_loc_descr (&mem_loc_result, new_loc_descr (DW_OP_deref, 0, 0));
+        break;
+--- 8781,8791 ----
+  	 memory) so DWARF consumers need to be aware of the subtle
+  	 distinction between OP_REG and OP_BASEREG.  */
+        if (REGNO (rtl) < FIRST_PSEUDO_REGISTER)
++ 	mem_loc_result = based_loc_descr (rtl, 0);
+        break;
+  
+      case MEM:
++       mem_loc_result = mem_loc_descriptor (XEXP (rtl, 0), GET_MODE (rtl));
+        if (mem_loc_result != 0)
+  	add_loc_descr (&mem_loc_result, new_loc_descr (DW_OP_deref, 0, 0));
+        break;
+***************
+*** 8792,8804 ****
+      case PLUS:
+      plus:
+        if (is_based_loc (rtl))
+- 	mem_loc_result = based_loc_descr (dbx_reg_number (XEXP (rtl, 0)),
+- 					  INTVAL (XEXP (rtl, 1)),
+- 					  can_use_fbreg);
+        else
+  	{
+- 	  mem_loc_result = mem_loc_descriptor (XEXP (rtl, 0), mode,
+- 					       can_use_fbreg);
+  	  if (mem_loc_result == 0)
+  	    break;
+  
+--- 8851,8861 ----
+      case PLUS:
+      plus:
+        if (is_based_loc (rtl))
++ 	mem_loc_result = based_loc_descr (XEXP (rtl, 0),
++ 					  INTVAL (XEXP (rtl, 1)));
+        else
+  	{
++ 	  mem_loc_result = mem_loc_descriptor (XEXP (rtl, 0), mode);
+  	  if (mem_loc_result == 0)
+  	    break;
+  
+***************
+*** 8810,8817 ****
+  	  else
+  	    {
+  	      add_loc_descr (&mem_loc_result,
+- 			     mem_loc_descriptor (XEXP (rtl, 1), mode,
+- 						 can_use_fbreg));
+  	      add_loc_descr (&mem_loc_result,
+  			     new_loc_descr (DW_OP_plus, 0, 0));
+  	    }
+--- 8867,8873 ----
+  	  else
+  	    {
+  	      add_loc_descr (&mem_loc_result,
++ 			     mem_loc_descriptor (XEXP (rtl, 1), mode));
+  	      add_loc_descr (&mem_loc_result,
+  			     new_loc_descr (DW_OP_plus, 0, 0));
+  	    }
+***************
+*** 8838,8847 ****
+  
+      do_binop:
+        {
+- 	dw_loc_descr_ref op0 = mem_loc_descriptor (XEXP (rtl, 0), mode,
+- 						   can_use_fbreg);
+- 	dw_loc_descr_ref op1 = mem_loc_descriptor (XEXP (rtl, 1), mode,
+- 						   can_use_fbreg);
+  
+  	if (op0 == 0 || op1 == 0)
+  	  break;
+--- 8894,8901 ----
+  
+      do_binop:
+        {
++ 	dw_loc_descr_ref op0 = mem_loc_descriptor (XEXP (rtl, 0), mode);
++ 	dw_loc_descr_ref op1 = mem_loc_descriptor (XEXP (rtl, 1), mode);
+  
+  	if (op0 == 0 || op1 == 0)
+  	  break;
+***************
+*** 8870,8877 ****
+  concat_loc_descriptor (rtx x0, rtx x1)
+  {
+    dw_loc_descr_ref cc_loc_result = NULL;
+-   dw_loc_descr_ref x0_ref = loc_descriptor (x0, false);
+-   dw_loc_descr_ref x1_ref = loc_descriptor (x1, false);
+  
+    if (x0_ref == 0 || x1_ref == 0)
+      return 0;
+--- 8924,8931 ----
+  concat_loc_descriptor (rtx x0, rtx x1)
+  {
+    dw_loc_descr_ref cc_loc_result = NULL;
++   dw_loc_descr_ref x0_ref = loc_descriptor (x0);
++   dw_loc_descr_ref x1_ref = loc_descriptor (x1);
+  
+    if (x0_ref == 0 || x1_ref == 0)
+      return 0;
+***************
+*** 8894,8900 ****
+     If we don't know how to describe it, return 0.  */
+  
+  static dw_loc_descr_ref
+- loc_descriptor (rtx rtl, bool can_use_fbreg)
+  {
+    dw_loc_descr_ref loc_result = NULL;
+  
+--- 8948,8954 ----
+     If we don't know how to describe it, return 0.  */
+  
+  static dw_loc_descr_ref
++ loc_descriptor (rtx rtl)
+  {
+    dw_loc_descr_ref loc_result = NULL;
+  
+***************
+*** 8915,8922 ****
+        break;
+  
+      case MEM:
+-       loc_result = mem_loc_descriptor (XEXP (rtl, 0), GET_MODE (rtl),
+- 				       can_use_fbreg);
+        break;
+  
+      case CONCAT:
+--- 8969,8975 ----
+        break;
+  
+      case MEM:
++       loc_result = mem_loc_descriptor (XEXP (rtl, 0), GET_MODE (rtl));
+        break;
+  
+      case CONCAT:
+***************
+*** 8927,8933 ****
+        /* Single part.  */
+        if (GET_CODE (XEXP (rtl, 1)) != PARALLEL)
+  	{
+- 	  loc_result = loc_descriptor (XEXP (XEXP (rtl, 1), 0), can_use_fbreg);
+  	  break;
+  	}
+  
+--- 8980,8986 ----
+        /* Single part.  */
+        if (GET_CODE (XEXP (rtl, 1)) != PARALLEL)
+  	{
++ 	  loc_result = loc_descriptor (XEXP (XEXP (rtl, 1), 0));
+  	  break;
+  	}
+  
+***************
+*** 8942,8957 ****
+  	int i;
+  
+  	/* Create the first one, so we have something to add to.  */
+- 	loc_result = loc_descriptor (XEXP (RTVEC_ELT (par_elems, 0), 0),
+- 				     can_use_fbreg);
+  	mode = GET_MODE (XEXP (RTVEC_ELT (par_elems, 0), 0));
+  	add_loc_descr_op_piece (&loc_result, GET_MODE_SIZE (mode));
+  	for (i = 1; i < num_elem; i++)
+  	  {
+  	    dw_loc_descr_ref temp;
+  
+- 	    temp = loc_descriptor (XEXP (RTVEC_ELT (par_elems, i), 0),
+- 				   can_use_fbreg);
+  	    add_loc_descr (&loc_result, temp);
+  	    mode = GET_MODE (XEXP (RTVEC_ELT (par_elems, i), 0));
+  	    add_loc_descr_op_piece (&loc_result, GET_MODE_SIZE (mode));
+--- 8995,9008 ----
+  	int i;
+  
+  	/* Create the first one, so we have something to add to.  */
++ 	loc_result = loc_descriptor (XEXP (RTVEC_ELT (par_elems, 0), 0));
+  	mode = GET_MODE (XEXP (RTVEC_ELT (par_elems, 0), 0));
+  	add_loc_descr_op_piece (&loc_result, GET_MODE_SIZE (mode));
+  	for (i = 1; i < num_elem; i++)
+  	  {
+  	    dw_loc_descr_ref temp;
+  
++ 	    temp = loc_descriptor (XEXP (RTVEC_ELT (par_elems, i), 0));
+  	    add_loc_descr (&loc_result, temp);
+  	    mode = GET_MODE (XEXP (RTVEC_ELT (par_elems, i), 0));
+  	    add_loc_descr_op_piece (&loc_result, GET_MODE_SIZE (mode));
+***************
+*** 9083,9089 ****
+  
+  	    /* Certain constructs can only be represented at top-level.  */
+  	    if (want_address == 2)
+- 	      return loc_descriptor (rtl, false);
+  
+  	    mode = GET_MODE (rtl);
+  	    if (MEM_P (rtl))
+--- 9134,9140 ----
+  
+  	    /* Certain constructs can only be represented at top-level.  */
+  	    if (want_address == 2)
++ 	      return loc_descriptor (rtl);
+  
+  	    mode = GET_MODE (rtl);
+  	    if (MEM_P (rtl))
+***************
+*** 9091,9097 ****
+  		rtl = XEXP (rtl, 0);
+  		have_address = 1;
+  	      }
+- 	    ret = mem_loc_descriptor (rtl, mode, false);
+  	  }
+        }
+        break;
+--- 9142,9148 ----
+  		rtl = XEXP (rtl, 0);
+  		have_address = 1;
+  	      }
++ 	    ret = mem_loc_descriptor (rtl, mode);
+  	  }
+        }
+        break;
+***************
+*** 9170,9176 ****
+  	  return 0;
+  	mode = GET_MODE (rtl);
+  	rtl = XEXP (rtl, 0);
+- 	ret = mem_loc_descriptor (rtl, mode, false);
+  	have_address = 1;
+  	break;
+        }
+--- 9221,9227 ----
+  	  return 0;
+  	mode = GET_MODE (rtl);
+  	rtl = XEXP (rtl, 0);
++ 	ret = mem_loc_descriptor (rtl, mode);
+  	have_address = 1;
+  	break;
+        }
+***************
+*** 10060,10078 ****
+  			   plus_constant (XEXP (rtl, 0), rsize-dsize));
+      }
+  
+-   if (rtl != NULL_RTX)
+-     {
+-       rtl = eliminate_regs (rtl, 0, NULL_RTX);
+- #ifdef LEAF_REG_REMAP
+-       if (current_function_uses_only_leaf_regs)
+- 	leaf_renumber_regs_insn (rtl);
+- #endif
+-     }
+- 
+    /* A variable with no DECL_RTL but a DECL_INITIAL is a compile-time constant,
+       and will have been substituted directly into all expressions that use it.
+       C does not have such a concept, but C++ and other languages do.  */
+-   else if (TREE_CODE (decl) == VAR_DECL && DECL_INITIAL (decl))
+      {
+        /* If a variable is initialized with a string constant without embedded
+  	 zeros, build CONST_STRING.  */
+--- 10104,10113 ----
+  			   plus_constant (XEXP (rtl, 0), rsize-dsize));
+      }
+  
+    /* A variable with no DECL_RTL but a DECL_INITIAL is a compile-time constant,
+       and will have been substituted directly into all expressions that use it.
+       C does not have such a concept, but C++ and other languages do.  */
++   if (!rtl && TREE_CODE (decl) == VAR_DECL && DECL_INITIAL (decl))
+      {
+        /* If a variable is initialized with a string constant without embedded
+  	 zeros, build CONST_STRING.  */
+***************
+*** 10120,10148 ****
+    return rtl;
+  }
+  
+- /* Return true if DECL's containing function has a frame base attribute.
+-    Return false otherwise.  */
+  
+- static bool
+- containing_function_has_frame_base (tree decl)
+  {
+-   tree declcontext = decl_function_context (decl);
+-   dw_die_ref context;
+-   dw_attr_ref attr;
+-   
+-   if (!declcontext)
+-     return false;
+  
+-   context = lookup_decl_die (declcontext);
+-   if (!context)
+-     return false;
+  
+-   for (attr = context->die_attr; attr; attr = attr->dw_attr_next)
+-     if (attr->dw_attr == DW_AT_frame_base)
+-       return true;
+-   return false;
+  }
+-   
+  /* Generate *either* a DW_AT_location attribute or else a DW_AT_const_value
+     data attribute for a variable or a parameter.  We generate the
+     DW_AT_const_value attribute only in those cases where the given variable
+--- 10155,10188 ----
+    return rtl;
+  }
+  
++ /* We need to figure out what section we should use as the base for the
++    address ranges where a given location is valid.
++    1. If this particular DECL has a section associated with it, use that.
++    2. If this function has a section associated with it, use that.
++    3. Otherwise, use the text section.
++    XXX: If you split a variable across multiple sections, we won't notice.  */
+  
++ static const char *
++ secname_for_decl (tree decl)
+  {
++   const char *secname;
+  
++   if (DECL_SECTION_NAME (decl))
++     {
++       tree sectree = DECL_SECTION_NAME (decl);
++       secname = TREE_STRING_POINTER (sectree);
++     }
++   else if (current_function_decl && DECL_SECTION_NAME (current_function_decl))
++     {
++       tree sectree = DECL_SECTION_NAME (current_function_decl);
++       secname = TREE_STRING_POINTER (sectree);
++     }
++   else
++     secname = text_section_label;
+  
++   return secname;
+  }
++ 
+  /* Generate *either* a DW_AT_location attribute or else a DW_AT_const_value
+     data attribute for a variable or a parameter.  We generate the
+     DW_AT_const_value attribute only in those cases where the given variable
+***************
+*** 10161,10167 ****
+    rtx rtl;
+    dw_loc_descr_ref descr;
+    var_loc_list *loc_list;
+-   bool can_use_fb;
+    struct var_loc_node *node;
+    if (TREE_CODE (decl) == ERROR_MARK)
+      return;
+--- 10201,10206 ----
+    rtx rtl;
+    dw_loc_descr_ref descr;
+    var_loc_list *loc_list;
+    struct var_loc_node *node;
+    if (TREE_CODE (decl) == ERROR_MARK)
+      return;
+***************
+*** 10169,10176 ****
+    gcc_assert (TREE_CODE (decl) == VAR_DECL || TREE_CODE (decl) == PARM_DECL
+  	      || TREE_CODE (decl) == RESULT_DECL);
+  	     
+-   can_use_fb = containing_function_has_frame_base (decl);
+- 
+    /* See if we possibly have multiple locations for this variable.  */
+    loc_list = lookup_decl_loc (decl);
+  
+--- 10208,10213 ----
+    gcc_assert (TREE_CODE (decl) == VAR_DECL || TREE_CODE (decl) == PARM_DECL
+  	      || TREE_CODE (decl) == RESULT_DECL);
+  	     
+    /* See if we possibly have multiple locations for this variable.  */
+    loc_list = lookup_decl_loc (decl);
+  
+***************
+*** 10178,10213 ****
+       differ.  */
+    if (loc_list && loc_list->first != loc_list->last)
+      {
+-       const char *secname;
+-       const char *endname;
+        dw_loc_list_ref list;
+        rtx varloc;
+  
+- 
+-       /* We need to figure out what section we should use as the base
+- 	 for the address ranges where a given location is valid.
+- 	 1. If this particular DECL has a section associated with it,
+- 	 use that.
+- 	 2. If this function has a section associated with it, use
+- 	 that.
+- 	 3. Otherwise, use the text section.
+- 	 XXX: If you split a variable across multiple sections, this
+- 	 won't notice.  */
+- 
+-       if (DECL_SECTION_NAME (decl))
+- 	{
+- 	  tree sectree = DECL_SECTION_NAME (decl);
+- 	  secname = TREE_STRING_POINTER (sectree);
+- 	}
+-       else if (current_function_decl
+- 	       && DECL_SECTION_NAME (current_function_decl))
+- 	{
+- 	  tree sectree = DECL_SECTION_NAME (current_function_decl);
+- 	  secname = TREE_STRING_POINTER (sectree);
+- 	}
+-       else
+- 	secname = text_section_label;
+- 
+        /* Now that we know what section we are using for a base,
+           actually construct the list of locations.
+  	 The first location information is what is passed to the
+--- 10215,10224 ----
+       differ.  */
+    if (loc_list && loc_list->first != loc_list->last)
+      {
++       const char *endname, *secname;
+        dw_loc_list_ref list;
+        rtx varloc;
+  
+        /* Now that we know what section we are using for a base,
+           actually construct the list of locations.
+  	 The first location information is what is passed to the
+***************
+*** 10221,10227 ****
+  
+        node = loc_list->first;
+        varloc = NOTE_VAR_LOCATION (node->var_loc_note);
+-       list = new_loc_list (loc_descriptor (varloc, can_use_fb),
+  			   node->label, node->next->label, secname, 1);
+        node = node->next;
+  
+--- 10232,10240 ----
+  
+        node = loc_list->first;
+        varloc = NOTE_VAR_LOCATION (node->var_loc_note);
++       secname = secname_for_decl (decl);
++ 
++       list = new_loc_list (loc_descriptor (varloc),
+  			   node->label, node->next->label, secname, 1);
+        node = node->next;
+  
+***************
+*** 10231,10239 ****
+  	    /* The variable has a location between NODE->LABEL and
+  	       NODE->NEXT->LABEL.  */
+  	    varloc = NOTE_VAR_LOCATION (node->var_loc_note);
+- 	    add_loc_descr_to_loc_list (&list,
+- 				       loc_descriptor (varloc,
+- 						       can_use_fb),
+  				       node->label, node->next->label, secname);
+  	  }
+  
+--- 10244,10250 ----
+  	    /* The variable has a location between NODE->LABEL and
+  	       NODE->NEXT->LABEL.  */
+  	    varloc = NOTE_VAR_LOCATION (node->var_loc_note);
++ 	    add_loc_descr_to_loc_list (&list, loc_descriptor (varloc),
+  				       node->label, node->next->label, secname);
+  	  }
+  
+***************
+*** 10252,10260 ****
+  					   current_function_funcdef_no);
+  	      endname = ggc_strdup (label_id);
+  	    }
+- 	  add_loc_descr_to_loc_list (&list,
+- 				     loc_descriptor (varloc,
+- 						     can_use_fb),
+  				     node->label, endname, secname);
+  	}
+  
+--- 10263,10269 ----
+  					   current_function_funcdef_no);
+  	      endname = ggc_strdup (label_id);
+  	    }
++ 	  add_loc_descr_to_loc_list (&list, loc_descriptor (varloc),
+  				     node->label, endname, secname);
+  	}
+  
+***************
+*** 10273,10297 ****
+        return;
+      }
+    
+-   /* We couldn't get any rtl, and we had no >1 element location list, so try
+-      directly generating the location description from the tree.  */
+-   descr = loc_descriptor_from_tree (decl);
+-   if (descr)
+-     {
+-       add_AT_location_description (die, attr, descr);
+-       return;
+-     }
+-   
+-   /* Lastly, if we have tried to generate the location otherwise, and it
+       didn't work out (we wouldn't be here if we did), and we have a one entry
+       location list, try generating a location from that.  */
+    if (loc_list && loc_list->first)
+      {
+        node = loc_list->first;
+-       descr = loc_descriptor (NOTE_VAR_LOCATION (node->var_loc_note), 
+- 			      can_use_fb);
+        if (descr)
+- 	add_AT_location_description (die, attr, descr);
+      }
+  }
+  
+--- 10282,10308 ----
+        return;
+      }
+    
++   /* If we have tried to generate the location otherwise, and it
+       didn't work out (we wouldn't be here if we did), and we have a one entry
+       location list, try generating a location from that.  */
+    if (loc_list && loc_list->first)
+      {
+        node = loc_list->first;
++       descr = loc_descriptor (NOTE_VAR_LOCATION (node->var_loc_note));
+        if (descr)
++ 	{
++ 	  add_AT_location_description (die, attr, descr);
++ 	  return;
++ 	}
++     }
++ 
++   /* We couldn't get any rtl, so try directly generating the location
++      description from the tree.  */
++   descr = loc_descriptor_from_tree (decl);
++   if (descr)
++     {
++       add_AT_location_description (die, attr, descr);
++       return;
+      }
+  }
+  
+***************
+*** 11357,11368 ****
+    char label_id[MAX_ARTIFICIAL_LABEL_BYTES];
+    tree origin = decl_ultimate_origin (decl);
+    dw_die_ref subr_die;
+-   rtx fp_reg;
+    tree fn_arg_types;
+    tree outer_scope;
+    dw_die_ref old_die = lookup_decl_die (decl);
+    int declaration = (current_function_decl != decl
+  		     || class_or_namespace_scope_p (context_die));
+  
+    /* It is possible to have both DECL_ABSTRACT and DECLARATION be true if we
+       started to generate the abstract instance of an inline, decided to output
+--- 11485,11496 ----
+    char label_id[MAX_ARTIFICIAL_LABEL_BYTES];
+    tree origin = decl_ultimate_origin (decl);
+    dw_die_ref subr_die;
+    tree fn_arg_types;
+    tree outer_scope;
+    dw_die_ref old_die = lookup_decl_die (decl);
+    int declaration = (current_function_decl != decl
+  		     || class_or_namespace_scope_p (context_die));
++   CUMULATIVE_ARGS cum;
+  
+    /* It is possible to have both DECL_ABSTRACT and DECLARATION be true if we
+       started to generate the abstract instance of an inline, decided to output
+***************
+*** 11520,11539 ****
+        add_AT_fde_ref (subr_die, DW_AT_MIPS_fde, current_funcdef_fde);
+  #endif
+  
+-       /* Define the "frame base" location for this routine.  We use the
+- 	 frame pointer or stack pointer registers, since the RTL for local
+- 	 variables is relative to one of them.  */
+-       if (frame_base_decl && lookup_decl_loc (frame_base_decl) != NULL)
+- 	{
+- 	  add_location_or_const_value_attribute (subr_die, frame_base_decl,
+- 						 DW_AT_frame_base);
+- 	}
+-       else
+- 	{
+- 	  fp_reg
+- 	    = frame_pointer_needed ? hard_frame_pointer_rtx : stack_pointer_rtx;
+- 	  add_AT_loc (subr_die, DW_AT_frame_base, reg_loc_descriptor (fp_reg));
+- 	}
+  
+        if (cfun->static_chain_decl)
+  	add_AT_location_description (subr_die, DW_AT_static_link,
+--- 11648,11679 ----
+        add_AT_fde_ref (subr_die, DW_AT_MIPS_fde, current_funcdef_fde);
+  #endif
+  
++       /* We define the "frame base" as the function's CFA.  This is more
++ 	 convenient for several reasons: (1) It's stable across the prologue
++ 	 and epilogue, which makes it better than just a frame pointer,
++ 	 (2) With dwarf3, there exists a one-byte encoding that allows us
++ 	 to reference the .debug_frame data by proxy, but failing that,
++ 	 (3) We can at least reuse the code inspection and interpretation
++ 	 code that determines the CFA position at various points in the
++ 	 function.  */
++       /* ??? Use some command-line or configury switch to enable the use
++ 	 of dwarf3 DW_OP_call_frame_cfa.  At present there are no dwarf
++ 	 consumers that understand it; fall back to "pure" dwarf2 and
++ 	 convert the CFA data into a location list.  */
++       {
++ 	dw_loc_list_ref list = convert_cfa_to_loc_list ();
++ 	if (list->dw_loc_next)
++ 	  add_AT_loc_list (subr_die, DW_AT_frame_base, list);
++ 	else
++ 	  add_AT_loc (subr_die, DW_AT_frame_base, list->expr);
++       }
++ 
++       /* Compute a displacement from the "steady-state frame pointer" to
++ 	 the CFA.  The former is what all stack slots and argument slots
++ 	 will reference in the rtl; the later is what we've told the 
++ 	 debugger about.  We'll need to adjust all frame_base references
++ 	 by this displacement.  */
++       compute_frame_pointer_to_cfa_displacement ();
+  
+        if (cfun->static_chain_decl)
+  	add_AT_location_description (subr_die, DW_AT_static_link,
+***************
+*** 11778,11818 ****
+      }
+  }
+  
+- /* Generate a DIE for a lexical block.  */
+  
+- static void
+- gen_lexical_block_die (tree stmt, dw_die_ref context_die, int depth)
+  {
+-   dw_die_ref stmt_die = new_die (DW_TAG_lexical_block, context_die, stmt);
+    char label[MAX_ARTIFICIAL_LABEL_BYTES];
+  
+-   if (! BLOCK_ABSTRACT (stmt))
+      {
+-       if (BLOCK_FRAGMENT_CHAIN (stmt))
+- 	{
+- 	  tree chain;
+  
+- 	  add_AT_range_list (stmt_die, DW_AT_ranges, add_ranges (stmt));
+  
+- 	  chain = BLOCK_FRAGMENT_CHAIN (stmt);
+- 	  do
+- 	    {
+- 	      add_ranges (chain);
+- 	      chain = BLOCK_FRAGMENT_CHAIN (chain);
+- 	    }
+- 	  while (chain);
+- 	  add_ranges (NULL);
+- 	}
+-       else
+  	{
+- 	  ASM_GENERATE_INTERNAL_LABEL (label, BLOCK_BEGIN_LABEL,
+- 				       BLOCK_NUMBER (stmt));
+- 	  add_AT_lbl_id (stmt_die, DW_AT_low_pc, label);
+- 	  ASM_GENERATE_INTERNAL_LABEL (label, BLOCK_END_LABEL,
+- 				       BLOCK_NUMBER (stmt));
+- 	  add_AT_lbl_id (stmt_die, DW_AT_high_pc, label);
+  	}
+      }
+  
+    decls_for_scope (stmt, stmt_die, depth);
+  }
+--- 11929,11991 ----
+      }
+  }
+  
++ /* A helper function for gen_inlined_subroutine_die.  Add source coordinate
++    attributes to the DIE for a block STMT, to describe where the inlined
++    function was called from.  This is similar to add_src_coords_attributes.  */
+  
++ static inline void
++ add_call_src_coords_attributes (tree stmt, dw_die_ref die)
++ {
++   expanded_location s = expand_location (BLOCK_SOURCE_LOCATION (stmt));
++   unsigned file_index = lookup_filename (s.file);
++ 
++   add_AT_unsigned (die, DW_AT_call_file, file_index);
++   add_AT_unsigned (die, DW_AT_call_line, s.line);
++ }
++ 
++ /* A helper function for gen_lexical_block_die and gen_inlined_subroutine_die.
++    Add low_pc and high_pc attributes to the DIE for a block STMT.  */
++ 
++ static inline void
++ add_high_low_attributes (tree stmt, dw_die_ref die)
+  {
+    char label[MAX_ARTIFICIAL_LABEL_BYTES];
+  
++   if (BLOCK_FRAGMENT_CHAIN (stmt))
+      {
++       tree chain;
+  
++       add_AT_range_list (die, DW_AT_ranges, add_ranges (stmt));
+  
++       chain = BLOCK_FRAGMENT_CHAIN (stmt);
++       do
+  	{
++ 	  add_ranges (chain);
++ 	  chain = BLOCK_FRAGMENT_CHAIN (chain);
+  	}
++       while (chain);
++       add_ranges (NULL);
+      }
++   else
++     {
++       ASM_GENERATE_INTERNAL_LABEL (label, BLOCK_BEGIN_LABEL,
++ 				   BLOCK_NUMBER (stmt));
++       add_AT_lbl_id (die, DW_AT_low_pc, label);
++       ASM_GENERATE_INTERNAL_LABEL (label, BLOCK_END_LABEL,
++ 				   BLOCK_NUMBER (stmt));
++       add_AT_lbl_id (die, DW_AT_high_pc, label);
++     }
++ }
++ 
++ /* Generate a DIE for a lexical block.  */
++ 
++ static void
++ gen_lexical_block_die (tree stmt, dw_die_ref context_die, int depth)
++ {
++   dw_die_ref stmt_die = new_die (DW_TAG_lexical_block, context_die, stmt);
++ 
++   if (! BLOCK_ABSTRACT (stmt))
++     add_high_low_attributes (stmt, stmt_die);
+  
+    decls_for_scope (stmt, stmt_die, depth);
+  }
+***************
+*** 11834,11848 ****
+      {
+        dw_die_ref subr_die
+  	= new_die (DW_TAG_inlined_subroutine, context_die, stmt);
+-       char label[MAX_ARTIFICIAL_LABEL_BYTES];
+  
+        add_abstract_origin_attribute (subr_die, decl);
+-       ASM_GENERATE_INTERNAL_LABEL (label, BLOCK_BEGIN_LABEL,
+- 				   BLOCK_NUMBER (stmt));
+-       add_AT_lbl_id (subr_die, DW_AT_low_pc, label);
+-       ASM_GENERATE_INTERNAL_LABEL (label, BLOCK_END_LABEL,
+- 				   BLOCK_NUMBER (stmt));
+-       add_AT_lbl_id (subr_die, DW_AT_high_pc, label);
+        decls_for_scope (stmt, subr_die, depth);
+        current_function_has_inlines = 1;
+      }
+--- 12007,12017 ----
+      {
+        dw_die_ref subr_die
+  	= new_die (DW_TAG_inlined_subroutine, context_die, stmt);
+  
+        add_abstract_origin_attribute (subr_die, decl);
++       add_high_low_attributes (stmt, subr_die);
++       add_call_src_coords_attributes (stmt, subr_die);
++ 
+        decls_for_scope (stmt, subr_die, depth);
+        current_function_has_inlines = 1;
+      }
+***************
+*** 13243,13248 ****
+      return fileno;
+  }
+  
+  static void
+  init_file_table (void)
+  {
+--- 13420,13427 ----
+      return fileno;
+  }
+  
++ /* Initialize the compiler internal file table.  */
++ 
+  static void
+  init_file_table (void)
+  {
+***************
+*** 13325,13331 ****
+    if (debug_info_level >= DINFO_LEVEL_NORMAL
+        && line != 0)
+      {
+-       function_section (current_function_decl);
+  
+        /* If requested, emit something human-readable.  */
+        if (flag_debug_asm)
+--- 13504,13513 ----
+    if (debug_info_level >= DINFO_LEVEL_NORMAL
+        && line != 0)
+      {
++       /* (TIGCC 20050424) We also get called for top-level ASM with no
++                           current_function_decl, so don't crash in that case. */
++       if (current_function_decl)
++         function_section (current_function_decl);
+  
+        /* If requested, emit something human-readable.  */
+        if (flag_debug_asm)
+***************
+*** 13596,13608 ****
+  
+    if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+      {
+        named_section_flags (DEBUG_MACINFO_SECTION, SECTION_DEBUG);
+        dw2_asm_output_data (1, DW_MACINFO_start_file, "Start new file");
+        dw2_asm_output_data_uleb128 (lineno, "Included from line number %d",
+  				   lineno);
+-       maybe_emit_file (lookup_filename (filename));
+-       dw2_asm_output_data_uleb128 (lookup_filename (filename),
+- 				   "Filename we just started");
+      }
+  }
+  
+--- 13778,13792 ----
+  
+    if (debug_info_level >= DINFO_LEVEL_VERBOSE)
+      {
++       int fileno;
+        named_section_flags (DEBUG_MACINFO_SECTION, SECTION_DEBUG);
+        dw2_asm_output_data (1, DW_MACINFO_start_file, "Start new file");
+        dw2_asm_output_data_uleb128 (lineno, "Included from line number %d",
+  				   lineno);
++       /* (TIGCC 20050505) The file number used by maybe_emit_file is not
++                           necessarily the one we passed to it. */
++       fileno = maybe_emit_file (lookup_filename (filename));
++       dw2_asm_output_data_uleb128 (fileno, "Filename we just started");
+      }
+  }
+  
+***************
+*** 13780,13786 ****
+  	     Make sure that it will get emitted.  */
+  	  prune_unused_types_mark (a->dw_attr_val.v.val_die_ref.die, 1);
+  	}
+-       else if (a->dw_attr == DW_AT_decl_file)
+  	{
+  	  /* A reference to a file.  Make sure the file name is emitted.  */
+  	  a->dw_attr_val.v.val_unsigned =
+--- 13964,13970 ----
+  	     Make sure that it will get emitted.  */
+  	  prune_unused_types_mark (a->dw_attr_val.v.val_die_ref.die, 1);
+  	}
++       else if (a->dw_attr == DW_AT_decl_file || a->dw_attr == DW_AT_call_file)
+  	{
+  	  /* A reference to a file.  Make sure the file name is emitted.  */
+  	  a->dw_attr_val.v.val_unsigned =
diff -Naur gcc-4.1-20051216.orig/gcc/emit-rtl.c gcc-4.1-20051216-src/gcc/emit-rtl.c
--- gcc-4.1-20051216.orig/gcc/emit-rtl.c	2005-09-05 18:45:20.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/emit-rtl.c	2005-12-18 22:24:40.000000000 +0100
@@ -104,8 +104,10 @@
 REAL_VALUE_TYPE dconstm2;
 REAL_VALUE_TYPE dconsthalf;
 REAL_VALUE_TYPE dconstthird;
+#if 0
 REAL_VALUE_TYPE dconstpi;
 REAL_VALUE_TYPE dconste;
+#endif /* 0 */
 
 /* All references to the following fixed hard registers go through
    these unique rtl objects.  On machines where the frame-pointer and
@@ -240,8 +242,8 @@
     return (CONST_DOUBLE_LOW (a) == CONST_DOUBLE_LOW (b)
 	    && CONST_DOUBLE_HIGH (a) == CONST_DOUBLE_HIGH (b));
   else
-    return real_identical (CONST_DOUBLE_REAL_VALUE (a),
-			   CONST_DOUBLE_REAL_VALUE (b));
+    return REAL_VALUES_IDENTICAL (*CONST_DOUBLE_REAL_VALUE (a),
+			   *CONST_DOUBLE_REAL_VALUE (b));
 }
 
 /* Returns a hash code for X (which is a really a mem_attrs *).  */
@@ -1331,10 +1333,62 @@
       && (GET_MODE_SIZE (mode) < UNITS_PER_WORD))
     return 0;
 
-  /* If we want a word outside OP, return zero.  */
+  /* If we want a word outside OP, return zero, except for special BFmode cases.  */
   if (mode != BLKmode
       && (offset + 1) * UNITS_PER_WORD > GET_MODE_SIZE (mode))
+  {
+  if (mode == BFmode)
+  {
+   if (GET_CODE (op) == MEM)
+    {
+      rtx addr = plus_constant (XEXP (op, 0), offset * UNITS_PER_WORD);
+      rtx new;
+
+      if (validate_address)
+	{
+	  if (reload_completed)
+	    {
+	      if (! strict_memory_address_p (HImode, addr))
+		return 0;
+	    }
+	  else
+	    addr = memory_address (HImode, addr);
+	}
+
+      new = gen_rtx_MEM (HImode, addr);
+
+      MEM_COPY_ATTRIBUTES (new, op);
+      MEM_READONLY_P (new) = MEM_READONLY_P (op);
+
+      return new;
+    }
+  else if (REG_P (op))
+    {
+      if (REGNO (op) < FIRST_PSEUDO_REGISTER
+	  && REGNO (op) + offset >= FIRST_PSEUDO_REGISTER)
+	return 0;
+
+      if (REGNO (op) < FIRST_PSEUDO_REGISTER
+	  && (! HARD_REGNO_MODE_OK (REGNO (op), HImode)
+	      || ! HARD_REGNO_MODE_OK (REGNO (op) + offset, HImode)))
+	return 0;
+      else if (REGNO (op) >= FIRST_PSEUDO_REGISTER
+	       || (REG_FUNCTION_VALUE_P (op))
+	       || op == frame_pointer_rtx
+#if FRAME_POINTER_REGNUM != ARG_POINTER_REGNUM
+	       || op == arg_pointer_rtx
+#endif
+	       || op == stack_pointer_rtx)
+	return gen_rtx_SUBREG (HImode, op, offset);
+      else
+	return gen_rtx_REG (HImode, REGNO (op) + offset);
+    }
+  else if (GET_CODE (op) == SUBREG)
+    return gen_rtx_SUBREG (HImode, SUBREG_REG (op), offset + SUBREG_BYTE (op) / UNITS_PER_WORD);
+  }
+  else
     return const0_rtx;
+  }
 
   /* Form a new MEM at the requested address.  */
   if (MEM_P (op))
@@ -5307,17 +5361,17 @@
   REAL_VALUE_FROM_INT (dconstm1, -1, -1, double_mode);
   REAL_VALUE_FROM_INT (dconstm2, -2, -1, double_mode);
 
-  dconsthalf = dconst1;
-  SET_REAL_EXP (&dconsthalf, REAL_EXP (&dconsthalf) - 1);
-
+  real_arithmetic (&dconsthalf, RDIV_EXPR, &dconst1, &dconst2);
   real_arithmetic (&dconstthird, RDIV_EXPR, &dconst1, &dconst3);
 
+#if 0
   /* Initialize mathematical constants for constant folding builtins.
      These constants need to be given to at least 160 bits precision.  */
   real_from_string (&dconstpi,
     "3.1415926535897932384626433832795028841971693993751058209749445923078");
   real_from_string (&dconste,
     "2.7182818284590452353602874713526624977572470936999595749669676277241");
+#endif /* 0 */
 
   for (i = 0; i < (int) ARRAY_SIZE (const_tiny_rtx); i++)
     {
diff -Naur gcc-4.1-20051216.orig/gcc/explow.c gcc-4.1-20051216-src/gcc/explow.c
--- gcc-4.1-20051216.orig/gcc/explow.c	2005-08-02 22:39:24.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/explow.c	2005-12-18 22:24:40.000000000 +0100
@@ -569,6 +569,10 @@
 {
   rtx temp = gen_reg_rtx (mode);
 
+  if (GET_MODE (x) == BFmode && mode != BFmode)
+    convert_move (x, temp, 0);
+  else
+  {
   /* If not an operand, must be an address with PLUS and MULT so
      do the computation.  */
   if (! general_operand (x, VOIDmode))
@@ -577,6 +581,7 @@
   gcc_assert (GET_MODE (x) == mode || GET_MODE (x) == VOIDmode);
   if (x != temp)
     emit_move_insn (temp, x);
+  }
   return temp;
 }
 
diff -Naur gcc-4.1-20051216.orig/gcc/expr.c gcc-4.1-20051216-src/gcc/expr.c
--- gcc-4.1-20051216.orig/gcc/expr.c	2005-12-13 09:17:18.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/expr.c	2005-12-19 01:00:21.000000000 +0100
@@ -748,7 +748,7 @@
   if (GET_MODE (x) != VOIDmode)
     oldmode = GET_MODE (x);
 
-  if (mode == oldmode)
+  if (mode == oldmode || oldmode == BFmode)
     return x;
 
   /* There is one case that we must handle specially: If we are converting
@@ -1351,6 +1351,7 @@
   dst_tree = make_tree (ptr_type_node, dst_addr);
   src_tree = make_tree (ptr_type_node, src_addr);
 
+#if 0
   size_mode = TYPE_MODE (sizetype);
 
   size = convert_to_mode (size_mode, size, 1);
@@ -1360,8 +1361,8 @@
      memcpy in this context.  This could be a user call to memcpy and
      the user may wish to examine the return value from memcpy.  For
      targets where libcalls and normal calls have different conventions
-     for returning pointers, we could end up generating incorrect code.  */
-
+     for returning pointers, we could end up generating incorrect code.
+     (TIGCC 20050205) NO, the "incorrect" code is actually correct for us!  */
   size_tree = make_tree (sizetype, size);
 
   fn = emit_block_move_libcall_fn (true);
@@ -1376,6 +1377,14 @@
   CALL_EXPR_TAILCALL (call_expr) = tailcall;
 
   retval = expand_expr (call_expr, NULL_RTX, VOIDmode, 0);
+#endif /* 0 */
+
+  emit_library_call_value (memcpy_libfunc, retval, LCT_NORMAL,
+                           VOIDmode, 3, dst_addr, Pmode,
+                           src_addr, Pmode,
+                           convert_to_mode (TYPE_MODE (sizetype),
+                                            size, TYPE_UNSIGNED (sizetype)),
+                           TYPE_MODE (sizetype));
 
   return retval;
 }
@@ -2498,6 +2507,7 @@
 
   object = copy_to_mode_reg (Pmode, XEXP (object, 0));
 
+#if 0
   size_mode = TYPE_MODE (sizetype);
   size = convert_to_mode (size_mode, size, 1);
   size = copy_to_mode_reg (size_mode, size);
@@ -2506,7 +2516,8 @@
      memset in this context.  This could be a user call to memset and
      the user may wish to examine the return value from memset.  For
      targets where libcalls and normal calls have different conventions
-     for returning pointers, we could end up generating incorrect code.  */
+     for returning pointers, we could end up generating incorrect code.
+     (TIGCC 20050205) NO, the "incorrect" code is actually correct for us!  */
 
   object_tree = make_tree (ptr_type_node, object);
   size_tree = make_tree (sizetype, size);
@@ -2523,6 +2534,15 @@
   CALL_EXPR_TAILCALL (call_expr) = tailcall;
 
   retval = expand_expr (call_expr, NULL_RTX, VOIDmode, 0);
+#endif /* 0 */
+
+  /* Note: Our memset libcall expects a short integer zero even with -mlong.  */
+  emit_library_call_value (memset_libfunc, retval, LCT_NORMAL,
+                           VOIDmode, 3, object, Pmode,
+                           const0_rtx, TYPE_MODE (short_integer_type_node),
+                           convert_to_mode (TYPE_MODE (sizetype),
+                                            size, TYPE_UNSIGNED (sizetype)),
+                           TYPE_MODE (sizetype));
 
   return retval;
 }
@@ -2541,8 +2561,10 @@
       tree fn, args;
 
       fn = get_identifier ("memset");
+      /* TIGCC Patch: The memset libcall expects a short integer zero even with
+         -mlong.  */
       args = build_function_type_list (ptr_type_node, ptr_type_node,
-				       integer_type_node, sizetype,
+				       short_integer_type_node, sizetype,
 				       NULL_TREE);
 
       fn = build_decl (FUNCTION_DECL, fn, args);
@@ -2950,14 +2972,21 @@
   if (push_operand (x, mode))
     return emit_move_complex_push (mode, x, y);
 
+  /* For memory to memory moves, optimal behavior can be had with the
+     existing block move logic.  */
+  /* (TIGCC 20050323) ... and this is indeed the case for our target, despite
+     claims to the contrary in PR rtl-optimization/20306. -- Kevin Kofler  */
+  if (MEM_P (x) && MEM_P (y))
+    {
+      emit_block_move (x, y, GEN_INT (GET_MODE_SIZE (mode)),
+		       BLOCK_OP_NO_LIBCALL);
+      return get_last_insn ();
+    }
+
   /* See if we can coerce the target into moving both values at once.  */
 
-  /* Move floating point as parts.  */
-  if (GET_MODE_CLASS (mode) == MODE_COMPLEX_FLOAT
-      && mov_optab->handlers[GET_MODE_INNER (mode)].insn_code != CODE_FOR_nothing)
-    try_int = false;
   /* Not possible if the values are inherently not adjacent.  */
-  else if (GET_CODE (x) == CONCAT || GET_CODE (y) == CONCAT)
+  if (GET_CODE (x) == CONCAT || GET_CODE (y) == CONCAT)
     try_int = false;
   /* Is possible if both are registers (or subregs of registers).  */
   else if (register_operand (x, mode) && register_operand (y, mode))
@@ -2975,18 +3004,7 @@
 
   if (try_int)
     {
-      rtx ret;
-
-      /* For memory to memory moves, optimal behavior can be had with the
-	 existing block move logic.  */
-      if (MEM_P (x) && MEM_P (y))
-	{
-	  emit_block_move (x, y, GEN_INT (GET_MODE_SIZE (mode)),
-			   BLOCK_OP_NO_LIBCALL);
-	  return get_last_insn ();
-	}
-
-      ret = emit_move_via_integer (mode, x, y, true);
+      rtx ret = emit_move_via_integer (mode, x, y, true);
       if (ret)
 	return ret;
     }
@@ -3226,6 +3244,9 @@
   else
     oldcost = rtx_cost (force_const_mem (dstmode, y), SET);
 
+/* (TIGCC) We do not implement exact_real_truncate and there is no narrower
+           float mode anyway. -- Kevin Kofler */
+#if 0
   for (srcmode = GET_CLASS_NARROWEST_MODE (GET_MODE_CLASS (orig_srcmode));
        srcmode != orig_srcmode;
        srcmode = GET_MODE_WIDER_MODE (srcmode))
@@ -3275,6 +3296,7 @@
 
       return last_insn;
     }
+#endif /* 0 */
 
   return NULL_RTX;
 }
diff -Naur gcc-4.1-20051216.orig/gcc/final.c gcc-4.1-20051216-src/gcc/final.c
--- gcc-4.1-20051216.orig/gcc/final.c	2005-11-09 18:11:53.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/final.c	2005-12-18 22:24:40.000000000 +0100
@@ -3079,11 +3079,23 @@
 	    else if (letter == 'l')
 	      output_asm_label (operands[opnum]);
 	    else if (letter == 'a')
+	    {
 	      output_address (operands[opnum]);
+	      /* TIGCC Patch: This is a very bad try to implement addresses
+	         relative to a register.  See m68k.c
+	         (TIGCC 20040808) Added CONST here (and below) too. -- Kevin Kofler  */
+	      if (TARGET_REG_RELATIVE && (GET_CODE (operands[opnum]) == SYMBOL_REF || GET_CODE (operands[opnum]) == LABEL_REF || GET_CODE (operands[opnum]) == CODE_LABEL || GET_CODE (operands[opnum]) == CONST))
+		fprintf (asm_out_file, "-__relation(%%%s)", TARGET_RELATION_REG);
+	    }
 	    else if (letter == 'c')
 	      {
 		if (CONSTANT_ADDRESS_P (operands[opnum]))
+		{
 		  output_addr_const (asm_out_file, operands[opnum]);
+		  /* TIGCC Patch: See above  */
+		  if (TARGET_REG_RELATIVE && (GET_CODE (operands[opnum]) == SYMBOL_REF || GET_CODE (operands[opnum]) == LABEL_REF || GET_CODE (operands[opnum]) == CODE_LABEL || GET_CODE (operands[opnum]) == CONST))
+		    fprintf (asm_out_file, "-__relation(%%%s)", TARGET_RELATION_REG);
+		}
 		else
 		  output_operand (operands[opnum], 'c');
 	      }
@@ -3096,6 +3108,9 @@
 		  {
 		    putc ('-', asm_out_file);
 		    output_addr_const (asm_out_file, operands[opnum]);
+		    /* TIGCC Patch: See above */
+		    if (TARGET_REG_RELATIVE && (GET_CODE (operands[opnum]) == SYMBOL_REF || GET_CODE (operands[opnum]) == LABEL_REF || GET_CODE (operands[opnum]) == CODE_LABEL))
+		      fprintf (asm_out_file, "-__relation(%%%s)", TARGET_RELATION_REG);
 		  }
 	      }
 	    else
@@ -3607,6 +3622,8 @@
     }
   else
     {
+      gcc_unreachable ();
+#if 0
       REAL_VALUE_TYPE r;
       long l[2];
       REAL_VALUE_FROM_CONST_DOUBLE (r, value);
@@ -3635,6 +3652,7 @@
 
       *first = GEN_INT (l[0]);
       *second = GEN_INT (l[1]);
+#endif /* 0 */
     }
 }
 
diff -Naur gcc-4.1-20051216.orig/gcc/flags.h gcc-4.1-20051216-src/gcc/flags.h
--- gcc-4.1-20051216.orig/gcc/flags.h	2005-06-29 05:01:27.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/flags.h	2005-12-18 22:24:40.000000000 +0100
@@ -287,4 +287,10 @@
 #define HONOR_SIGN_DEPENDENT_ROUNDING(MODE) \
   (MODE_HAS_SIGN_DEPENDENT_ROUNDING (MODE) && flag_rounding_math)
 
+/* (TIGCC) Make compound literals (cast constructors) global for backwards compatibility.  */
+extern int flag_global_compound_literals;
+
+/* (TIGCC 20040727) When merging constants, also merge constant pools.  */
+extern int flag_merge_constant_pools;
+
 #endif /* ! GCC_FLAGS_H */
diff -Naur gcc-4.1-20051216.orig/gcc/fold-const.c gcc-4.1-20051216-src/gcc/fold-const.c
--- gcc-4.1-20051216.orig/gcc/fold-const.c	2005-11-26 00:12:32.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/fold-const.c	2005-12-19 03:00:36.000000000 +0100
@@ -1555,7 +1555,7 @@
       if ((flag_rounding_math
 	   || (REAL_MODE_FORMAT_COMPOSITE_P (mode)
 	       && !flag_unsafe_math_optimizations))
-	  && (inexact || !real_identical (&result, &value)))
+	  && (inexact || !REAL_VALUES_IDENTICAL (result, value)))
 	return NULL_TREE;
 
       t = build_real (type, result);
@@ -1778,6 +1778,7 @@
      FP-to-integer conversion is unspecified upon overflow.  */
 
   HOST_WIDE_INT high, low;
+#if 0
   REAL_VALUE_TYPE r;
   REAL_VALUE_TYPE x = TREE_REAL_CST (arg1);
 
@@ -1802,9 +1803,12 @@
     default:
       gcc_unreachable ();
     }
+#else
+  REAL_VALUE_TYPE r = TREE_REAL_CST (arg1);
+#endif /* 0 */
 
   /* If R is NaN, return zero and show we have an overflow.  */
-  if (REAL_VALUE_ISNAN (r))
+  if (REAL_VALUE_ISNANUINF (r))
     {
       overflow = 1;
       high = 0;
@@ -2113,7 +2117,7 @@
 /* When pedantic, return an expr equal to X but certainly not valid as a
    pedantic lvalue.  Otherwise, return X.  */
 
-static tree
+tree
 pedantic_non_lvalue (tree x)
 {
   if (pedantic_lvalues)
@@ -5711,6 +5715,10 @@
   if (!HONOR_SIGNED_ZEROS (TYPE_MODE (type)))
     return true;
 
+  /* (TIGCC 20050210) This is invalid independently of the rounding mode and the
+                      type of the zero for 3-sign-zeros. */
+  return false;
+
   /* Treat x + -0 as x - 0 and x - -0 as x + 0.  */
   if (TREE_CODE (addend) == REAL_CST
       && REAL_VALUE_MINUS_ZERO (TREE_REAL_CST (addend)))
@@ -5896,6 +5904,7 @@
 	}
       break;
 
+#if 0 /* (TIGCC 20050205) */
     case EQ_EXPR:
     case GE_EXPR:
       /* x == +Inf and x >= +Inf are always equal to x > DBL_MAX.  */
@@ -5924,6 +5933,7 @@
       temp = fold_build2 (neg ? LT_EXPR : GT_EXPR, type,
 			  arg0, build_real (TREE_TYPE (arg0), max));
       return fold_build1 (TRUTH_NOT_EXPR, type, temp);
+#endif /* 0 */
 
     default:
       break;
@@ -7839,8 +7849,11 @@
 	     when x is NaN, since x * 0 is also NaN.  Nor are they the
 	     same in modes with signed zeros, since multiplying a
 	     negative value by 0 gives -0, not +0.  */
+	  /* (TIGCC 20050210) We can do this for UNSIGNED_ZERO even when honoring
+	                      signed zeros. */
 	  if (!HONOR_NANS (TYPE_MODE (TREE_TYPE (arg0)))
-	      && !HONOR_SIGNED_ZEROS (TYPE_MODE (TREE_TYPE (arg0)))
+	      && (!HONOR_SIGNED_ZEROS (TYPE_MODE (TREE_TYPE (arg0)))
+	          || real_uzerop (arg1))
 	      && real_zerop (arg1))
 	    return omit_one_operand (type, arg1, arg0);
 	  /* In IEEE floating point, x*1 is not equivalent to x for snans.  */
@@ -9056,7 +9069,7 @@
 				  build_real (TREE_TYPE (arg1), dconst0));
 
 	    /* x != NaN is always true, other ops are always false.  */
-	    if (REAL_VALUE_ISNAN (cst)
+	    if (REAL_VALUE_ISNANUINF (cst)
 		&& ! HONOR_SNANS (TYPE_MODE (TREE_TYPE (arg1))))
 	      {
 		tem = (code == NE_EXPR) ? integer_one_node : integer_zero_node;
@@ -9829,7 +9842,7 @@
 
       /* If the first operand is NaN, the result is constant.  */
       if (TREE_CODE (arg0) == REAL_CST
-	  && REAL_VALUE_ISNAN (TREE_REAL_CST (arg0))
+	  && REAL_VALUE_ISNANUINF (TREE_REAL_CST (arg0))
 	  && (code != LTGT_EXPR || ! flag_trapping_math))
 	{
 	  t1 = (code == ORDERED_EXPR || code == LTGT_EXPR)
@@ -9840,7 +9853,7 @@
 
       /* If the second operand is NaN, the result is constant.  */
       if (TREE_CODE (arg1) == REAL_CST
-	  && REAL_VALUE_ISNAN (TREE_REAL_CST (arg1))
+	  && REAL_VALUE_ISNANUINF (TREE_REAL_CST (arg1))
 	  && (code != LTGT_EXPR || ! flag_trapping_math))
 	{
 	  t1 = (code == ORDERED_EXPR || code == LTGT_EXPR)
@@ -9878,12 +9891,12 @@
     case COMPOUND_EXPR:
       /* When pedantic, a compound expression can be neither an lvalue
 	 nor an integer constant expression.  */
-      if (TREE_SIDE_EFFECTS (arg0) || TREE_CONSTANT (arg1))
+      if (TREE_SIDE_EFFECTS (arg0) || pedantic)
 	return NULL_TREE;
       /* Don't let (0, 0) be null pointer constant.  */
-      tem = integer_zerop (arg1) ? build1 (NOP_EXPR, type, arg1)
-				 : fold_convert (type, arg1);
-      return pedantic_non_lvalue (tem);
+      if (integer_zerop (arg1))
+	return build1 (NOP_EXPR, type, arg1);
+      return convert (type, arg1);
 
     case COMPLEX_EXPR:
       if (wins)
@@ -10178,6 +10191,21 @@
     } /* switch (code) */
 }
 
+/* Return 1 if EXPR is the real constant UNSIGNED_ZERO.  */
+
+static int
+real_uzerop (tree expr)
+{
+  STRIP_NOPS (expr);
+
+  return ((TREE_CODE (expr) == REAL_CST
+	   && ! TREE_CONSTANT_OVERFLOW (expr)
+	   && REAL_VALUES_IDENTICAL (TREE_REAL_CST (expr), UNSIGNED_ZERO))
+	  || (TREE_CODE (expr) == COMPLEX_CST
+	      && real_uzerop (TREE_REALPART (expr))
+	      && real_uzerop (TREE_IMAGPART (expr))));
+}
+
 /* Perform constant folding and related simplification of EXPR.
    The related simplifications include x*1 => x, x*0 => 0, etc.,
    and application of the associative law.
@@ -11269,7 +11297,11 @@
       }
 
     case REAL_CST:
-      t = build_real (type, REAL_VALUE_NEGATE (TREE_REAL_CST (arg0)));
+	    {
+	      REAL_VALUE_TYPE x = TREE_REAL_CST (arg0);
+	      x = REAL_VALUE_NEGATE (x);
+	      t = build_real (type, x);
+	    }
       break;
 
     default:
@@ -11315,10 +11347,14 @@
       break;
 
     case REAL_CST:
-      if (REAL_VALUE_NEGATIVE (TREE_REAL_CST (arg0)))
-	t = build_real (type, REAL_VALUE_NEGATE (TREE_REAL_CST (arg0)));
-      else
-	t =  arg0;
+  	    {
+	      REAL_VALUE_TYPE x = TREE_REAL_CST (arg0);
+	      if (REAL_VALUE_NEGATIVE (x))
+		t = build_real (type,
+				REAL_VALUE_NEGATE (x));
+	      else
+		t =  arg0;
+	    }
       break;
 
     default:
@@ -11366,7 +11402,7 @@
       const REAL_VALUE_TYPE *c1 = TREE_REAL_CST_PTR (op1);
 
       /* Handle the cases where either operand is a NaN.  */
-      if (real_isnan (c0) || real_isnan (c1))
+      if (REAL_VALUE_ISNANUINF (*c0) || REAL_VALUE_ISNANUINF (*c1))
 	{
 	  switch (code)
 	    {
diff -Naur gcc-4.1-20051216.orig/gcc/function.c gcc-4.1-20051216-src/gcc/function.c
--- gcc-4.1-20051216.orig/gcc/function.c	2005-12-02 07:16:21.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/function.c	2005-12-18 22:24:47.000000000 +0100
@@ -5557,3 +5557,28 @@
 
 
 #include "gt-function.h"
+
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+/* Return 1 if an argument for the current function was passed in
+   register REGNO.  */
+
+int
+function_arg_regno_p (int regno)
+{
+  tree parm = DECL_ARGUMENTS (current_function_decl);
+  for (; parm; parm = TREE_CHAIN (parm))
+    {
+      rtx incoming = DECL_INCOMING_RTL (parm);
+      if (GET_CODE (incoming) == REG)
+	{
+	  int incoming_reg;
+	  incoming_reg = REGNO (incoming);
+	  if (regno >= incoming_reg &&
+	      regno < incoming_reg + HARD_REGNO_NREGS (incoming_reg,
+						       GET_MODE (incoming)))
+	    return 1;
+	}
+    }
+  return 0;
+}
+/* end-TIGCC-local (regparms) */
diff -Naur gcc-4.1-20051216.orig/gcc/function.h gcc-4.1-20051216-src/gcc/function.h
--- gcc-4.1-20051216.orig/gcc/function.h	2005-08-19 23:16:20.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/function.h	2005-12-18 22:24:47.000000000 +0100
@@ -574,4 +574,10 @@
 extern bool reference_callee_copied (CUMULATIVE_ARGS *, enum machine_mode,
 				     tree, bool);
 
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+/* Return 1 if an argument for the current function was passed in
+   register REGNO.  */
+int function_arg_regno_p (int regno);
+/* end-TIGCC-local (regparms) */
+
 #endif  /* GCC_FUNCTION_H */
diff -Naur gcc-4.1-20051216.orig/gcc/gcc.c gcc-4.1-20051216-src/gcc/gcc.c
--- gcc-4.1-20051216.orig/gcc/gcc.c	2005-11-19 21:44:07.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/gcc.c	2005-12-19 01:04:29.000000000 +0100
@@ -1458,6 +1458,7 @@
 #define MD_STARTFILE_PREFIX_1 ""
 #endif
 
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
 static const char *const standard_exec_prefix = STANDARD_EXEC_PREFIX;
 static const char *const standard_exec_prefix_1 = "/usr/libexec/gcc/";
 static const char *const standard_exec_prefix_2 = "/usr/lib/gcc/";
@@ -1475,6 +1476,7 @@
 static const char *tooldir_prefix;
 
 static const char *const standard_bindir_prefix = STANDARD_BINDIR_PREFIX;
+#endif /* 0 */
 
 static const char *standard_libexec_prefix = STANDARD_LIBEXEC_PREFIX;
 
@@ -1546,6 +1548,7 @@
   INIT_STATIC_SPEC ("multilib_options",		&multilib_options),
   INIT_STATIC_SPEC ("linker",			&linker_name_spec),
   INIT_STATIC_SPEC ("link_libgcc",		&link_libgcc_spec),
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
   INIT_STATIC_SPEC ("md_exec_prefix",		&md_exec_prefix),
   INIT_STATIC_SPEC ("md_startfile_prefix",	&md_startfile_prefix),
   INIT_STATIC_SPEC ("md_startfile_prefix_1",	&md_startfile_prefix_1),
@@ -1553,6 +1556,7 @@
   INIT_STATIC_SPEC ("sysroot_spec",             &sysroot_spec),
   INIT_STATIC_SPEC ("sysroot_suffix_spec",	&sysroot_suffix_spec),
   INIT_STATIC_SPEC ("sysroot_hdrs_suffix_spec",	&sysroot_hdrs_suffix_spec),
+#endif /* 0 */
 };
 
 #ifdef EXTRA_SPECS		/* additional specs needed */
@@ -3149,7 +3153,9 @@
 process_command (int argc, const char **argv)
 {
   int i;
+#if 0 /* (TIGCC 20040104) Don't use environment variables. */
   const char *temp;
+#endif /* 0 */
   char *temp1;
   const char *spec_lang = 0;
   int last_language_n_infiles;
@@ -3159,7 +3165,9 @@
   int j;
 #endif
 
+#if 0 /* (TIGCC 20040104) Don't use environment variables. */
   GET_ENVIRONMENT (gcc_exec_prefix, "GCC_EXEC_PREFIX");
+#endif /* 0 */
 
   n_switches = 0;
   n_infiles = 0;
@@ -3241,7 +3249,7 @@
      see if we can create it from the pathname specified in argv[0].  */
 
   gcc_libexec_prefix = standard_libexec_prefix;
-#ifndef VMS
+#if 0
   /* FIXME: make_relative_prefix doesn't yet work for VMS.  */
   if (!gcc_exec_prefix)
     {
@@ -3260,6 +3268,7 @@
 #else
 #endif
 
+#if 0 /* (TIGCC 20040104) Don't use environment variables. */
   if (gcc_exec_prefix)
     {
       int len = strlen (gcc_exec_prefix);
@@ -3383,6 +3392,7 @@
 	    endp++;
 	}
     }
+#endif /* 0 */
 
   /* Convert new-style -- options to old-style.  */
   translate_options (&argc, (const char *const **) &argv);
@@ -3807,6 +3817,7 @@
 
   /* Set up the search paths before we go looking for config files.  */
 
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
   /* These come before the md prefixes so that we will find gcc's subcommands
      (such as cpp) rather than those of the host system.  */
   /* Use 2 as fourth arg meaning try just the machine as a suffix,
@@ -3868,6 +3879,7 @@
   add_prefix (&startfile_prefixes,
 	      concat (tooldir_prefix, "lib", dir_separator_str, NULL),
 	      "BINUTILS", PREFIX_PRIORITY_LAST, 0, 1);
+#endif /* 0 */
 
 #if defined(TARGET_SYSTEM_ROOT_RELOCATABLE) && !defined(VMS)
   /* If the normal TARGET_SYSTEM_ROOT is inside of $exec_prefix,
@@ -6146,6 +6158,7 @@
   else
     init_spec ();
 
+#if 0
   /* We need to check standard_exec_prefix/just_machine_suffix/specs
      for any override of as, ld and libraries.  */
   specs_file = alloca (strlen (standard_exec_prefix)
@@ -6179,7 +6192,9 @@
 		      PREFIX_PRIORITY_LAST, 0, 0);
 	}
     }
+#endif /* 0 */
 
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
   /* Process sysroot_suffix_spec.  */
   if (*sysroot_suffix_spec != 0
       && do_spec_2 (sysroot_suffix_spec) == 0)
@@ -6269,6 +6284,7 @@
 			      standard_startfile_prefix_2, "BINUTILS",
 			      PREFIX_PRIORITY_LAST, 0, 1);
     }
+#endif /* 0 */
 
   /* Process any user specified specs in the order given on the command
      line.  */
@@ -6279,10 +6295,12 @@
       read_specs (filename ? filename : uptr->filename, FALSE);
     }
 
+#if 0 /* (TIGCC 20040104) Don't use environment variables. */
   /* If we have a GCC_EXEC_PREFIX envvar, modify it for cpp's sake.  */
   if (gcc_exec_prefix)
     gcc_exec_prefix = concat (gcc_exec_prefix, spec_machine, dir_separator_str,
 			      spec_version, dir_separator_str, NULL);
+#endif /* 0 */
 
   /* Now we have the specs.
      Set the `valid' bits for switches that match anything in any spec.  */
@@ -6303,7 +6321,8 @@
 
   if (print_search_dirs)
     {
-      printf (_("install: %s%s\n"), standard_exec_prefix, machine_suffix);
+/* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
+      printf (_("install: relocatable TIGCC installation\n"));
       printf (_("programs: %s\n"), build_search_list (&exec_prefixes, "", 0));
       printf (_("libraries: %s\n"), build_search_list (&startfile_prefixes, "", 0));
       return (0);
diff -Naur gcc-4.1-20051216.orig/gcc/gcse.c gcc-4.1-20051216-src/gcc/gcse.c
--- gcc-4.1-20051216.orig/gcc/gcse.c	2005-11-12 20:29:30.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/gcse.c	2005-12-18 22:24:47.000000000 +0100
@@ -3053,11 +3053,14 @@
   rtx newreg = NULL, newcnst = NULL;
 
   /* Rule out USE instructions and ASM statements as we don't want to
-     change the hard registers mentioned.  */
+     change the hard registers mentioned.
+     (TIGCC) The same thing goes for global register variables. CalcRogue gets
+             miscompiled without this patch.  */
   if (REG_P (x)
       && (REGNO (x) >= FIRST_PSEUDO_REGISTER
           || (GET_CODE (PATTERN (insn)) != USE
-	      && asm_noperands (PATTERN (insn)) < 0)))
+	      && asm_noperands (PATTERN (insn)) < 0
+	      && ! global_regs[REGNO (x)])))
     {
       cselib_val *val = cselib_lookup (x, GET_MODE (x), 0);
       struct elt_loc_list *l;
diff -Naur gcc-4.1-20051216.orig/gcc/genmodes.c gcc-4.1-20051216-src/gcc/genmodes.c
--- gcc-4.1-20051216.orig/gcc/genmodes.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/genmodes.c	2005-12-18 22:24:47.000000000 +0100
@@ -1068,6 +1068,7 @@
 static void
 emit_real_format_for_mode (void)
 {
+#if 0
   struct mode_data *m;
 
   /* The entities pointed to by this table are constant, whether
@@ -1093,6 +1094,7 @@
       tagged_printf ("&%s", m->format, m->name);
 
   print_closer ();
+#endif /* 0 */
 }
 
 static void
@@ -1177,10 +1179,12 @@
 	}
     }
       
+#if 0
   /* Real mode formats don't have to propagate anywhere.  */
   for (a = adj_format; a; a = a->next)
     printf ("\n  /* %s:%d */\n  REAL_MODE_FORMAT (%smode) = %s;\n",
 	    a->file, a->line, a->mode->name, a->adjustment);
+#endif /* 0 */
 
   puts ("}");
 }
diff -Naur gcc-4.1-20051216.orig/gcc/gimplify.c gcc-4.1-20051216-src/gcc/gimplify.c
--- gcc-4.1-20051216.orig/gcc/gimplify.c	2005-11-11 18:14:49.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/gimplify.c	2005-12-18 22:24:47.000000000 +0100
@@ -1899,6 +1899,7 @@
   /* There is a sequence point before the call, so any side effects in
      the calling expression must occur before the actual call.  Force
      gimplify_expr to use an internal post queue.  */
+  if (!flag_no_function_cse)
   ret = gimplify_expr (&TREE_OPERAND (*expr_p, 0), pre_p, NULL,
 		       is_gimple_call_addr, fb_rvalue);
 
@@ -1917,6 +1918,12 @@
   if (PUSH_ARGS_REVERSED)
     TREE_OPERAND (*expr_p, 1) = nreverse (TREE_OPERAND (*expr_p, 1));
 
+  /* (TIGCC 20050206) Gimplify the function expression only after the arguments
+                      if -fno-function-cse. */
+  if (flag_no_function_cse)
+  ret = gimplify_expr (&TREE_OPERAND (*expr_p, 0), pre_p, NULL,
+		       is_gimple_call_addr, fb_rvalue);
+
   /* Try this again in case gimplification exposed something.  */
   if (ret != GS_ERROR && decl && DECL_BUILT_IN (decl))
     {
diff -Naur gcc-4.1-20051216.orig/gcc/ifcvt.c gcc-4.1-20051216-src/gcc/ifcvt.c
--- gcc-4.1-20051216.orig/gcc/ifcvt.c	2005-11-09 22:34:31.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/ifcvt.c	2005-12-18 22:24:47.000000000 +0100
@@ -2026,6 +2026,16 @@
   if (MEM_P (op))
     return ! side_effects_p (XEXP (op, 0));
 
+  /* (TIGCC 20040925) Can't if-convert global register variables.
+                      -- Kevin Kofler */
+  if (GET_CODE (op) == REG)
+    {
+      int regno;
+      regno = REGNO (op);
+      if (regno < FIRST_PSEUDO_REGISTER && global_regs[regno])
+        return FALSE;
+    }
+
   if (side_effects_p (op))
     return FALSE;
 
@@ -3359,6 +3369,21 @@
 		 TEST range.  */
 	      if (for_each_rtx (&PATTERN (insn), find_memory, NULL))
 		return FALSE;
+
+	      /* (TIGCC 20040925) Can't if-convert global register variables.
+	                          -- Kevin Kofler */
+	      if (GET_CODE (PATTERN (insn)) == SET)
+            {
+              rtx dest;
+              dest = SET_DEST (PATTERN (insn));
+              if (GET_CODE (dest) == REG)
+                {
+                  int regno;
+                  regno = REGNO (dest);
+                  if (regno < FIRST_PSEUDO_REGISTER && global_regs[regno])
+                    return FALSE;
+                }
+            }
 	    }
 	  if (insn == end)
 	    break;
diff -Naur gcc-4.1-20051216.orig/gcc/langhooks-def.h gcc-4.1-20051216-src/gcc/langhooks-def.h
--- gcc-4.1-20051216.orig/gcc/langhooks-def.h	2005-11-19 00:40:29.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/langhooks-def.h	2005-12-19 01:07:11.000000000 +0100
@@ -107,6 +107,7 @@
 #define LANG_HOOKS_SAFE_FROM_P		lhd_safe_from_p
 #define LANG_HOOKS_FINISH_INCOMPLETE_DECL lhd_do_nothing_t
 #define LANG_HOOKS_STATICP		lhd_staticp
+#define LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES lhd_do_nothing_t
 #define LANG_HOOKS_DUP_LANG_SPECIFIC_DECL lhd_do_nothing_t
 #define LANG_HOOKS_SET_DECL_ASSEMBLER_NAME lhd_set_decl_assembler_name
 #define LANG_HOOKS_CAN_USE_BIT_FIELDS_P lhd_can_use_bit_fields_p
@@ -272,6 +273,7 @@
   LANG_HOOKS_EXPAND_CONSTANT, \
   LANG_HOOKS_EXPAND_EXPR, \
   LANG_HOOKS_EXPAND_DECL, \
+  LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES, \
   LANG_HOOKS_SAFE_FROM_P, \
   LANG_HOOKS_FINISH_INCOMPLETE_DECL, \
   LANG_HOOKS_MARK_ADDRESSABLE, \
diff -Naur gcc-4.1-20051216.orig/gcc/langhooks.h gcc-4.1-20051216-src/gcc/langhooks.h
--- gcc-4.1-20051216.orig/gcc/langhooks.h	2005-11-19 00:40:29.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/langhooks.h	2005-12-18 22:24:47.000000000 +0100
@@ -283,6 +283,10 @@
      1 if handled, 0 otherwise.  */
   int (*expand_decl) (tree);
 
+  /* Possibly apply default attributes to a function (represented by
+     a FUNCTION_DECL).  */
+  void (*insert_default_attributes) PARAMS ((tree));
+
   /* Hook called by safe_from_p for language-specific tree codes.  It is
      up to the language front-end to install a hook if it has any such
      codes that safe_from_p needs to know about.  Since same_from_p will
diff -Naur gcc-4.1-20051216.orig/gcc/loop.c gcc-4.1-20051216-src/gcc/loop.c
--- gcc-4.1-20051216.orig/gcc/loop.c	2005-12-16 13:14:15.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/loop.c	2005-12-18 22:24:47.000000000 +0100
@@ -1296,6 +1296,13 @@
 		      && REGNO_LAST_UID (regno) == INSN_UID (user)
 		      && regs->array[regno].set_in_loop == 1
 		      && GET_CODE (SET_SRC (set)) != ASM_OPERANDS
+		      /* (TIGCC 20050206) Patch by Ian Lance Taylor regarding using hard
+		                          register variables as an asm input
+		         See http://gcc.gnu.org/ml/gcc/2004-05/msg00678.html */
+		      && (regno >= FIRST_PSEUDO_REGISTER
+			  || asm_noperands (PATTERN (regs->array[regno]
+						     .single_usage))
+			  < 0)
 		      && ! side_effects_p (SET_SRC (set))
 		      && ! find_reg_note (p, REG_RETVAL, NULL_RTX)
 		      && (!SMALL_REGISTER_CLASSES
diff -Naur gcc-4.1-20051216.orig/gcc/machmode.def gcc-4.1-20051216-src/gcc/machmode.def
--- gcc-4.1-20051216.orig/gcc/machmode.def	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/machmode.def	2005-12-18 22:24:47.000000000 +0100
@@ -170,8 +170,8 @@
    These are the IEEE mappings.  They can be overridden with
    RESET_FLOAT_FORMAT or at runtime (in OVERRIDE_OPTIONS).  */
 
-FLOAT_MODE (SF, 4, ieee_single_format);
-FLOAT_MODE (DF, 8, ieee_double_format);
+FLOAT_MODE (SF, 4, 0);
+FLOAT_MODE (DF, 8, 0);
 
 /* Basic CC modes.
    FIXME define this only for targets that need it.  */
diff -Naur gcc-4.1-20051216.orig/gcc/optabs.c gcc-4.1-20051216-src/gcc/optabs.c
--- gcc-4.1-20051216.orig/gcc/optabs.c	2005-12-01 23:50:31.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/optabs.c	2005-12-18 22:24:47.000000000 +0100
@@ -1747,7 +1747,7 @@
   /* Look for a wider mode of the same class for which it appears we can do
      the operation.  */
 
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+  if (class == MODE_INT)
     {
       for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
 	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
@@ -2043,7 +2043,7 @@
 
   /* It can't be done in this mode.  Can we do it in a wider mode?  */
 
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+  if (class == MODE_INT)
     {
       for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
 	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
@@ -2231,6 +2231,7 @@
   return ret;
 }
 
+#if 0 /* (TIGCC 20050216) */
 /* Expand a floating point absolute value or negation operation via a
    logical operation on the sign bit.  */
 
@@ -2335,6 +2336,7 @@
 
   return target;
 }
+#endif /* 0 */
 
 /* Generate code to perform an operation specified by UNOPTAB
    on operand OP0, with result having machine-mode MODE.
@@ -2412,7 +2414,7 @@
 	goto try_libcall;
     }
 
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+  if (class == MODE_INT)
     for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
 	 wider_mode = GET_MODE_WIDER_MODE (wider_mode))
       {
@@ -2488,13 +2490,16 @@
 
   if (unoptab->code == NEG)
     {
+#if 0
       /* Try negating floating point values by flipping the sign bit.  */
+      /* (TIGCC 20050205) Don't. We have unsigned zero and infinity.  */
       if (class == MODE_FLOAT)
 	{
 	  temp = expand_absneg_bit (NEG, mode, op0, target);
 	  if (temp)
 	    return temp;
 	}
+#endif /* 0 */
 
       /* If there is no negation pattern, and we have no negative zero,
 	 try subtracting from zero.  */
@@ -2551,7 +2556,7 @@
 
   /* It can't be done in this mode.  Can we do it in a wider mode?  */
 
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+  if (class == MODE_INT)
     {
       for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
 	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
@@ -2640,13 +2645,16 @@
   if (temp != 0)
     return temp;
 
+#if 0
   /* For floating point modes, try clearing the sign bit.  */
+  /* (TIGCC 20050205) Don't. We have unsigned zero and infinity.  */
   if (GET_MODE_CLASS (mode) == MODE_FLOAT)
     {
       temp = expand_absneg_bit (ABS, mode, op0, target);
       if (temp)
 	return temp;
     }
+#endif /* 0 */
 
   /* If we have a MAX insn, we can do this as MAX (x, -x).  */
   if (smax_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing
@@ -2820,6 +2828,7 @@
 }
 
 
+#if 0
 /* A subroutine of expand_copysign, perform the entire copysign operation
    with integer bitmasks.  BITPOS is the position of the sign bit; OP0_IS_ABS
    is true if op0 is known to have its sign bit clear.  */
@@ -2971,6 +2980,7 @@
   return expand_copysign_bit (mode, op0, op1, target,
 			      fmt->signbit_rw, op0_is_abs);
 }
+#endif /* 0 */
 
 /* Generate an instruction whose insn-code is INSN_CODE,
    with two operands: an output TARGET and an input OP0.
@@ -4351,6 +4361,7 @@
 	  }
       }
 
+#if 0
   /* Unsigned integer, and no way to convert directly.
      Convert as signed, then conditionally adjust the result.  */
   if (unsignedp)
@@ -4455,6 +4466,7 @@
       emit_label (label);
       goto done;
     }
+#endif /* 0 */
 
   /* No hardware instruction available; call a library routine.  */
     {
@@ -4545,6 +4557,7 @@
 	  }
       }
 
+#if 0
   /* For an unsigned conversion, there is one more way to do it.
      If we have a signed conversion, we generate code that compares
      the real value to the largest representable positive number.  If if
@@ -4628,6 +4641,7 @@
 
 	  return;
 	}
+#endif /* 0 */
 
   /* We can't do it with an insn, so use a library call.  But first ensure
      that the mode of TO is at least as wide as SImode, since those are the
@@ -5231,6 +5245,9 @@
   /* Conversions.  */
   init_interclass_conv_libfuncs (sfloat_optab, "float",
 				 MODE_INT, MODE_FLOAT);
+  /* (TIGCC 20050208) Someone forgot this one... */
+  init_interclass_conv_libfuncs (ufloat_optab, "floatuns",
+				 MODE_INT, MODE_FLOAT);
   init_interclass_conv_libfuncs (sfix_optab, "fix",
 				 MODE_FLOAT, MODE_INT);
   init_interclass_conv_libfuncs (ufix_optab, "fixuns",
diff -Naur gcc-4.1-20051216.orig/gcc/opts.c gcc-4.1-20051216-src/gcc/opts.c
--- gcc-4.1-20051216.orig/gcc/opts.c	2005-12-06 12:28:18.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/opts.c	2005-12-18 22:24:47.000000000 +0100
@@ -570,7 +570,12 @@
 #endif
       flag_regmove = 1;
       flag_strict_aliasing = 1;
+#if 0 /* (TIGCC 20050213) Null pointer dereferences won't necessarily trigger
+         a trap. When reading, they definitely won't. When writing, they will
+         only when the variable being dereferenced is a scalar or a small
+         enough structure. */
       flag_delete_null_pointer_checks = 1;
+#endif
       flag_reorder_blocks = 1;
       flag_reorder_functions = 1;
       flag_tree_store_ccp = 1;
@@ -589,6 +594,10 @@
       flag_inline_functions = 1;
       flag_unswitch_loops = 1;
       flag_gcse_after_reload = 1;
+      /* (TIGCC 20050217) Halve maximum inline insns under -O3. Use -O4 to
+                          override this. */
+      if (optimize == 3)
+        set_param_value ("max-inline-insns-auto", 60);
     }
 
   if (optimize < 2 || optimize_size)
@@ -609,12 +618,17 @@
       flag_reorder_blocks_and_partition = 0;
     }
 
-  if (optimize_size)
+  /* (TIGCC 20050217) Do this at -O2 as well, as it improves both size and speed. */
+  if (optimize == 2 || optimize_size)
     {
       /* Inlining of very small functions usually reduces total size.  */
-      set_param_value ("max-inline-insns-single", 5);
       set_param_value ("max-inline-insns-auto", 5);
       flag_inline_functions = 1;
+    }
+  if (optimize_size)
+    {
+      /* Inlining of very small functions usually reduces total size.  */
+      set_param_value ("max-inline-insns-single", 5);
 
       /* We want to crossjump as much as possible.  */
       set_param_value ("min-crossjump-insns", 1);
@@ -645,6 +659,11 @@
   if (flag_pic && !flag_pie)
     flag_shlib = 1;
 
+  /* TIGCC Patch: Register d2 is used by the TIOS calling convention.
+     See "call-used-" further down in this file. */
+  if (TARGET_TIOS)
+    fix_register ("d2", 0, 1);
+
   if (flag_no_inline == 2)
     flag_no_inline = 0;
   else
@@ -922,6 +941,12 @@
       flag_profile_values_set = true;
       break;
 
+    case OPT_freg_relative_:
+      fix_register (arg, 1, 1);
+      target_flags |= MASK_REG_RELATIVE;
+      strcpy (TARGET_RELATION_REG, arg);
+      break;
+
     case OPT_fvisibility_:
       {
         if (!strcmp(arg, "default"))
diff -Naur gcc-4.1-20051216.orig/gcc/output.h gcc-4.1-20051216-src/gcc/output.h
--- gcc-4.1-20051216.orig/gcc/output.h	2005-10-26 09:03:30.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/output.h	2005-12-18 22:24:47.000000000 +0100
@@ -334,7 +334,7 @@
 #define assemble_aligned_integer(SIZE, VALUE) \
   assemble_integer (VALUE, SIZE, (SIZE) * BITS_PER_UNIT, 1)
 
-#ifdef REAL_VALUE_TYPE_SIZE
+#ifdef REAL_WIDTH /* (TIGCC 20050205) */
 /* Assemble the floating-point constant D into an object of size MODE.  */
 extern void assemble_real (REAL_VALUE_TYPE, enum machine_mode, unsigned);
 #endif
diff -Naur gcc-4.1-20051216.orig/gcc/postreload.c gcc-4.1-20051216-src/gcc/postreload.c
--- gcc-4.1-20051216.orig/gcc/postreload.c	2005-11-18 14:14:39.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/postreload.c	2005-12-18 22:24:50.000000000 +0100
@@ -1189,6 +1189,9 @@
        && TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (OUTMODE), \
 				 GET_MODE_BITSIZE (INMODE))))
 
+/* (TIGCC 20050213) Declare this target-dependent function. */
+int const_method (rtx);
+
 static void
 reload_cse_move2add (rtx first)
 {
@@ -1276,11 +1279,17 @@
 			   && narrow_mode != GET_MODE (reg);
 			   narrow_mode = GET_MODE_WIDER_MODE (narrow_mode))
 			{
-			  if (have_insn_for (STRICT_LOW_PART, narrow_mode)
+			  /* (TIGCC 20050213) Don't do this for QImode. Byte moves aren't
+			      any cheaper than word moves, they just kill chances to use a
+			      moveq. Also don't turn long moves which can be done using
+			      moveq into word moves. */
+			  if (narrow_mode != QImode
+			      && have_insn_for (STRICT_LOW_PART, narrow_mode)
 			      && ((reg_offset[regno]
 				   & ~GET_MODE_MASK (narrow_mode))
 				  == (INTVAL (src)
-				      & ~GET_MODE_MASK (narrow_mode))))
+				      & ~GET_MODE_MASK (narrow_mode)))
+			      && (GET_MODE (reg) != SImode || const_method (src)))
 			    {
 			      rtx narrow_reg = gen_rtx_REG (narrow_mode,
 							    REGNO (reg));
diff -Naur gcc-4.1-20051216.orig/gcc/print-rtl.c gcc-4.1-20051216-src/gcc/print-rtl.c
--- gcc-4.1-20051216.orig/gcc/print-rtl.c	2005-08-16 02:13:53.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/print-rtl.c	2005-12-18 22:24:50.000000000 +0100
@@ -586,6 +586,9 @@
 	{
 	  char s[60];
 
+	  REAL_VALUE_TO_STRING (*CONST_DOUBLE_REAL_VALUE (in_rtx), s);
+	  fprintf (outfile, " %s", s);
+#if 0
 	  real_to_decimal (s, CONST_DOUBLE_REAL_VALUE (in_rtx),
 			   sizeof (s), 0, 1);
 	  fprintf (outfile, " %s", s);
@@ -593,6 +596,7 @@
 	  real_to_hexadecimal (s, CONST_DOUBLE_REAL_VALUE (in_rtx),
 			       sizeof (s), 0, 1);
 	  fprintf (outfile, " [%s]", s);
+#endif /* 0 */
 	}
       break;
 #endif
diff -Naur gcc-4.1-20051216.orig/gcc/print-tree.c gcc-4.1-20051216-src/gcc/print-tree.c
--- gcc-4.1-20051216.orig/gcc/print-tree.c	2005-10-13 01:34:09.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/print-tree.c	2005-12-18 22:24:50.000000000 +0100
@@ -134,7 +134,7 @@
       else
 	{
 	  char string[60];
-	  real_to_decimal (string, &d, sizeof (string), 0, 1);
+	  REAL_VALUE_TO_STRING (d, string);
 	  fprintf (file, " %s", string);
 	}
     }
@@ -680,7 +680,7 @@
 	    else
 	      {
 		char string[64];
-		real_to_decimal (string, &d, sizeof (string), 0, 1);
+		REAL_VALUE_TO_STRING (d, string);
 		fprintf (file, " %s", string);
 	      }
 	  }
diff -Naur gcc-4.1-20051216.orig/gcc/real.c gcc-4.1-20051216-src/gcc/real.c
--- gcc-4.1-20051216.orig/gcc/real.c	2005-09-19 19:01:40.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/real.c	2005-12-18 22:24:50.000000000 +0100
@@ -72,6 +72,7 @@
    adjust the significand to match.  */
 
 
+#if 0
 /* Used to classify two numbers simultaneously.  */
 #define CLASS2(A, B)  ((A) << 2 | (B))
 
@@ -122,7 +123,9 @@
 static void times_pten (REAL_VALUE_TYPE *, int);
 
 static void round_for_format (const struct real_format *, REAL_VALUE_TYPE *);
+#endif /* 0 */
 
+#if 0
 /* Initialize R with a positive zero.  */
 
 static inline void
@@ -973,6 +976,614 @@
       gcc_unreachable ();
     }
 }
+#endif /* 0 */
+
+/* Add 1 unit in the last place to a positive SMAP II BCD float. */
+static void bcdpadd1ulp(smap_bcd_float *op)
+{
+  int i;
+  op->mantissa++; /* This will give a digit of 10 in some cases. */
+  for (i=0;i<60;i+=4) { /* for each digit except the first one */
+    int d=(op->mantissa>>i)&15;
+    if (d<10) /* if the digit is <10, we're done */
+      break;
+    op->mantissa += 6ull<<i; /* subtract 10 from the digit, add 1 to the next digit */
+  }
+  /* Now, we should have a carry only in one case: the mantissa was
+     9999999999999999. So now, we have A000000000000000, where A is 10 in a
+     single digit. We can safely truncate the last digit because it is 0 (so
+     there is no risk of double-rounding here). */
+  if (op->mantissa >= 0xA000000000000000ull) { /* if we have a carry */
+    gcc_assert (op->mantissa == 0xA000000000000000ull); /* sanity check */
+    op->mantissa = 0x1000000000000000ull; /* A -> 10, drop the last digit */
+    op->exponent++; /* adjust the exponent */
+    if (op->exponent > 0x4000+16383) /* exponent too large, overflow to +infinity */
+      *op = POSITIVE_INF;
+  }
+}
+
+/* Add 2 positive SMAP II BCD floats. */
+static smap_bcd_float bcdppadd(smap_bcd_float op0, smap_bcd_float op1)
+{
+  int lastdigit=0;
+
+  if (op0.exponent < op1.exponent) {
+    /* If op0 does not contribute to the result, avoid shift count overflow by
+       returning op1 immediately. */
+    if (op1.exponent-op0.exponent>16) return op1;
+    /* Adjust op0 exponent to fit op1. */
+    op0.mantissa >>= ((op1.exponent-op0.exponent-1)<<2);
+    lastdigit = (op0.mantissa&15); /* save the last digit of op0 */
+    op0.mantissa >>= 4; /* drop the last digit of op0 */
+    op0.exponent = op1.exponent; /* adjust the exponent of op0 */
+  } else if (op1.exponent < op0.exponent) {
+    /* If op1 does not contribute to the result, avoid shift count overflow by
+       returning op0 immediately. */
+    if (op0.exponent-op1.exponent>16) return op0;
+    /* Adjust op1 exponent to fit op0. */
+    op1.mantissa >>= ((op0.exponent-op1.exponent-1)<<2);
+    lastdigit = (op1.mantissa&15); /* save the last digit of op1 */
+    op1.mantissa >>= 4; /* drop the last digit of op1 */
+    op1.exponent = op0.exponent; /* adjust the exponent of op1 */
+  }
+
+  /* Now do the addition in the BCD-coded mantissa. */
+  {
+    int i,d,carry=0;
+    smap_bcd_float result={0,0};result.exponent=op0.exponent;
+    for (i=0;i<64;i+=4) { /* for each digit */
+      d = (op0.mantissa&15)+(op1.mantissa&15)+carry;
+      carry = (d>=10); /* handle carry */
+      if (carry) d -= 10;
+      /* We are done with this digit of the mantissa. */
+      op0.mantissa >>= 4;
+      op1.mantissa >>= 4;
+      /* Store it into the resulting mantissa. */
+      result.mantissa += ((unsigned long long)d)<<i;
+    }
+    if (carry) { /* The mantissa overflowed, so we need to adjust the exponent. */
+      lastdigit = (result.mantissa&15); /* save the last digit of result,
+                                           dropping the previously saved last
+                                           digit */
+      result.mantissa >>= 4; /* drop the last digit of result */
+      result.exponent++; /* adjust the exponent of result */
+      if (result.exponent > 0x4000+16383) /* exponent too large, overflow to */
+        return POSITIVE_INF;              /* +infinity */
+      /* prepend the first digit */
+      result.mantissa += ((unsigned long long)carry)<<60;
+    }
+    if (lastdigit>=5) /* now do the correct rounding */
+      bcdpadd1ulp(&result);
+    return result;
+  }
+}
+
+/* Subtract 2 positive SMAP II BCD floats. */
+static smap_bcd_float bcdppsub(smap_bcd_float op0, smap_bcd_float op1)
+{
+  unsigned long long lastdigits=0;
+
+  if (REAL_VALUES_LESS(op0,op1)) /* if op0<op1, subtract the other way round */
+    return REAL_VALUE_NEGATE(bcdppsub(op1,op0));
+  else if (REAL_VALUES_IDENTICAL(op0,op1)) /* if op0=op1, return unsigned 0 */
+    return UNSIGNED_ZERO;
+
+  /* Now, we can assume op0>op1. */
+  if (op1.exponent < op0.exponent) {
+    /* If op1 does not contribute to the result, avoid shift count overflow by
+       returning op0 immediately. */
+    if (op0.exponent-op1.exponent>16) return op0;
+    /* Adjust op1 exponent to fit op0.
+       Save all dropped digits, so we can round correctly. */
+    lastdigits = op1.mantissa << (64-((op0.exponent-op1.exponent)<<2));
+    if (op0.exponent-op1.exponent==16)
+      op1.mantissa = 0; /* special-cased because shifts by 64 aren't allowed */
+    else
+      op1.mantissa >>= ((op0.exponent-op1.exponent)<<2);
+    op1.exponent = op0.exponent; /* adjust the exponent of op1 */
+  }
+
+  /* Now do the subtraction in the BCD-coded mantissa. */
+  {
+    int i,d,carry=0;
+    smap_bcd_float result={0,0};result.exponent=op0.exponent;
+    for (i=0;i<64;i+=4) { /* for each digit */
+      d = (op0.mantissa&15)-((op1.mantissa&15)+carry);
+      carry = (d<0); /* handle carry */
+      if (carry) d += 10;
+      /* We are done with this digit of the mantissa. */
+      op0.mantissa >>= 4;
+      op1.mantissa >>= 4;
+      /* Store it into the resulting mantissa. */
+      result.mantissa += ((unsigned long long)d)<<i;
+    }
+    gcc_assert (!carry); /* Carry should be 0 here! */
+    /* Normalize and return the result (which is always positive here, since we
+       assumed op1>op0). Handle rounding and extra digits during normalization.
+       */
+    while ((result.mantissa<0x1000000000000000ull)
+           || ((result.mantissa==0x1000000000000000ull)
+              && ((lastdigits>0x5000000000000000ull)
+                 || ((lastdigits>0x500000000000000ull)
+                     && (result.exponent>0x4000-16383))))) {
+    /* while mantissa<1 */
+      int c = (result.mantissa==0x1000000000000000ull); /* used by the sanity
+                                                           check below */
+      result.exponent--; /* decrease exponent by 1 */
+      if (result.exponent<0x4000-16383) /* exponent too small, underflow to +0 */
+        return POSITIVE_ZERO;
+      result.mantissa <<= 4; /* left-shift mantissa */
+      carry = !!(lastdigits>>60);
+      result.mantissa -= (lastdigits>>60)+(carry*6); /* Subtract extra digit. If
+        there is a carry, add 10 to the digit, subtract 1 from the next digit.
+        This can give digits of 15 in some cases. */
+      for (i=4;i<64;i+=4) { /* for each digit except the last one */
+        int d=(result.mantissa>>i)&15;
+        if (d<10) /* if the digit is <10, we're done */
+          break;
+        result.mantissa -= 6ull<<i; /* add 10 to the digit, subtract 1 from the
+                                       next digit */
+        /* There should be no carry in the first digit except if the mantissa
+           was exactly 1. */
+        gcc_assert (c || result.mantissa<0xA000000000000000ull);
+      }
+      lastdigits <<= 4; /* We handled an extra digit. */
+    }
+    /* Now do the rounding. */
+    if (lastdigits>0x5000000000000000ull) {
+      int c = !result.mantissa; /* used by the sanity check below */
+      /* This corner case should have been handled above. */
+      gcc_assert (result.mantissa!=0x1000000000000000ull);
+      result.mantissa--; /* Subtract 1. This can give digits of 15 in some cases. */
+      for (i=0;i<64;i+=4) { /* for each digit */
+        int d=(result.mantissa>>i)&15;
+        if (d<10) /* if the digit is <10, we're done */
+          break;
+        result.mantissa -= 6ull<<i; /* add 10 to the digit, subtract 1 from the
+                                       next digit */
+        /* There should be no carry in the first digit except if the mantissa was
+           0 (which actually means 10^16 here). */
+        gcc_assert (c || result.mantissa<0xA000000000000000ull);
+      }
+    }
+    return result;
+  }
+}
+
+/* Add 2 SMAP II BCD floats. */
+static smap_bcd_float bcdadd(smap_bcd_float op0, smap_bcd_float op1)
+{
+  if (REAL_VALUE_ISNAN(op0) || REAL_VALUE_ISNAN(op1)) /* keep NAN */
+    return NAN;
+  else if (REAL_VALUE_ISINF(op0) && REAL_VALUE_ISINF(op1)) { /* both operands
+                                                                are infinity */
+    if (!REAL_VALUES_IDENTICAL(op0,op1)
+        || REAL_VALUES_IDENTICAL(op0,UNSIGNED_INF)) /* differing signs or both
+                                                       unsigned yield NAN */
+      return NAN;
+    else /* both positive or both negative */
+      return op0;
+  } else if (REAL_VALUE_ISINF(op0)) /* op0=inf, so op0+op1=inf+op1=inf=op0 */
+    return op0;
+  else if (REAL_VALUE_ISINF(op1)) /* op1=inf, so op0+op1=op0+inf=inf=op1 */
+    return op1;
+  else if (REAL_VALUE_ISZERO(op0) && REAL_VALUE_ISZERO(op1)) { /* both operands
+                                                                  are 0 */
+    if (REAL_VALUES_IDENTICAL(op0,op1)) /* both positive, both negative or both
+                                           unsigned */
+      return op0;
+    else /* differing signs yield unsigned zero */
+      return UNSIGNED_ZERO;
+  } else if (REAL_VALUE_ISZERO(op0)) /* op0=0, so op0+op1=0+op1=op1 */
+    return op1;
+  else if (REAL_VALUE_ISZERO(op1)) /* op1=0, so op0+op1=op0+0=op0 */
+    return op0;
+  else if (REAL_VALUE_ISPOSITIVE(op0) && REAL_VALUE_ISPOSITIVE(op1))
+    return bcdppadd(op0,op1);
+  else if (REAL_VALUE_ISPOSITIVE(op0)) /* and op1 negative */
+    return bcdppsub(op0,REAL_VALUE_NEGATE(op1));
+  else if (REAL_VALUE_ISPOSITIVE(op1)) /* and op0 negative */
+    return bcdppsub(op1,REAL_VALUE_NEGATE(op0));
+  else /* both negative */
+    return REAL_VALUE_NEGATE(bcdppadd(REAL_VALUE_NEGATE(op0),
+                                      REAL_VALUE_NEGATE(op1)));
+}
+
+/* Subtract 2 SMAP II BCD floats. */
+static smap_bcd_float bcdsub(smap_bcd_float op0, smap_bcd_float op1)
+{
+  return bcdadd(op0,REAL_VALUE_NEGATE(op1));
+}
+
+/* Multiply 2 positive SMAP II BCD floats. */
+static smap_bcd_float bcdppmul(smap_bcd_float op0, smap_bcd_float op1)
+{
+  /* Compute the result in 2 binary parts. The upper 16 decimal digits and the
+     lower ones. */
+  unsigned long long resulth=0, resultl=0;
+  int i,j,k,d0,d1,d32,exponent;
+  unsigned long long factor=1ull;
+  for (i=0;i<64;i+=4,factor*=10ull) { /* for each result digit <16 */
+    for (j=0;j<64;j+=4) { /* for each digit of op0 */
+      k = i-j; /* corresponding op1 digit */
+      if (k<0 || k>=64) continue; /* digit out of range */
+      d0 = (op0.mantissa>>j)&15; /* jth digit of op0 */
+      d1 = (op1.mantissa>>k)&15; /* kth digit of op0 */
+      resultl += (unsigned long long)(d0*d1)*factor;
+      while (resultl>=10000000000000000ull/*10^16*/) { /* carry into resulth */
+        resultl -= 10000000000000000ull/*10^16*/;
+        resulth++;
+      }
+    }
+  }
+  for (factor=1ull;i<128;i+=4,factor*=10ull) { /* for each result digit >=16 */
+    for (j=0;j<64;j+=4) { /* for each digit of op0 */
+      k = i-j; /* corresponding op1 digit */
+      if (k<0 || k>=64) continue; /* digit out of range */
+      d0 = (op0.mantissa>>j)&15; /* jth digit of op0 */
+      d1 = (op1.mantissa>>k)&15; /* kth digit of op0 */
+      resulth += (unsigned long long)(d0*d1)*factor;
+    }
+  }
+
+  /* resultl should always be <10^16 */
+  gcc_assert (resultl<10000000000000000ull);
+
+  /* Because of normalization, the result has either 31 or 32 digits. */
+  d32 = (resulth>=1000000000000000ull/*10^15*/
+         || (resulth==999999999999999ull/*10^15-1*/
+             && resultl>=9500000000000000ull/*9.5*10^15*/));
+  if (!d32) { /* if we have only 15 digits in resulth, take one from resultl */
+    resulth = resulth*10ull+resultl/1000000000000000ull/*10^15*/;
+    resultl = (resultl%1000000000000000ull/*10^15*/)*10ull;
+  }
+  if (resultl>=5000000000000000ull/*5*10^15*/) /* round resultl into resulth */
+    resulth++;
+
+  /* Now compute the exponent. */
+  exponent=op0.exponent+op1.exponent-0x4000+d32;
+  if (exponent>0x4000+16383) /* exponent too large, overflow to +infinity */
+    return POSITIVE_INF;
+  if (exponent<0x4000-16383) /* exponent too small, underflow to +0 */
+    return POSITIVE_ZERO;
+
+  /* Now convert resulth into a BCD mantissa. */
+  {
+    unsigned long long d;
+    smap_bcd_float result={0,0};result.exponent=exponent;
+    for (i=0;i<64;i+=4) { /* for each digit */
+      d = resulth%10ull; /* Extract the digit. */
+      resulth /= 10ull; /* We are done with this digit of the mantissa. */
+      result.mantissa += d<<i; /* Store it into the resulting mantissa. */
+    }
+    return result;
+  }
+}
+
+/* Multiply 2 SMAP II BCD floats. */
+static smap_bcd_float bcdmul(smap_bcd_float op0, smap_bcd_float op1)
+{
+  if (REAL_VALUE_ISNAN(op0) || REAL_VALUE_ISNAN(op1)
+      || (REAL_VALUE_ISINF(op0) && REAL_VALUE_ISZERO(op1))
+      || (REAL_VALUE_ISZERO(op0) && REAL_VALUE_ISINF(op1))) /* keep NAN,
+                                                               0*inf=NAN */
+    return NAN;
+  else if (REAL_VALUES_IDENTICAL(op0,UNSIGNED_INF)
+           || REAL_VALUES_IDENTICAL(op1,UNSIGNED_INF)) /* unsigned inf * non-0 =
+                                                          unsigned inf */
+    return UNSIGNED_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* +inf * +inf = +inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF))) /* -inf * -inf = +inf */
+    return POSITIVE_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* +inf * -inf = -inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF))) /* -inf * +inf = -inf */
+    return NEGATIVE_INF;
+  /* Now we can assume that at least 1 value is finite, and that we don't have
+     an unsigned infinity, a NAN or an inf*0 indeterminate form. */
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUE_ISPOSITIVE(op1)) /* +inf * +finite = +inf */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* +finite * +inf = +inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUE_ISNEGATIVE(op1)) /* -inf * -finite = +inf */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF))) /* -finite * -inf = +inf */
+    return POSITIVE_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUE_ISNEGATIVE(op1)) /* +inf * -finite = -inf */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* +finite * -inf = -inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUE_ISPOSITIVE(op1)) /* -inf * +finite = -inf */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF))) /* -finite * +inf = -inf */
+    return NEGATIVE_INF;
+  /* Now we can assume that both values are finite. */
+  else if (REAL_VALUES_IDENTICAL(op0,UNSIGNED_ZERO)
+           || REAL_VALUES_IDENTICAL(op1,UNSIGNED_ZERO)) /* unsigned 0 * finite =
+                                                           unsigned 0 */
+    return UNSIGNED_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO)) /* +0 * +0 = +0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO))) /* -0 * -0 = +0 */
+    return POSITIVE_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO)) /* +0 * -0 = -0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO))) /* -0 * +0 = -0 */
+    return NEGATIVE_ZERO;
+  /* Now we can assume that both values are finite, at least 1 value is non-0,
+     and that we don't have an unsigned 0. */
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUE_ISPOSITIVE(op1)) /* +0 * +finite = +0 */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO)) /* +finite * +0 = +0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUE_ISNEGATIVE(op1)) /* -0 * -finite = +0 */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO))) /* -finite * -0 = +0 */
+    return POSITIVE_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUE_ISNEGATIVE(op1)) /* +0 * -finite = -0 */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO)) /* +finite * -0 = -0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUE_ISPOSITIVE(op1)) /* -0 * +finite = -0 */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO))) /* -finite * +0 = -0 */
+    return NEGATIVE_ZERO;
+  /* Now we can assume that both values are finite and non-0. */
+  else if (REAL_VALUE_ISPOSITIVE(op0) && REAL_VALUE_ISPOSITIVE(op1))
+    return bcdppmul(op0,op1);
+  else if (REAL_VALUE_ISPOSITIVE(op0)) /* and op1 negative */
+    return REAL_VALUE_NEGATE(bcdppmul(op0,REAL_VALUE_NEGATE(op1)));
+  else if (REAL_VALUE_ISPOSITIVE(op1)) /* and op0 negative */
+    return REAL_VALUE_NEGATE(bcdppmul(REAL_VALUE_NEGATE(op0),op1));
+  else /* both negative */
+    return bcdppmul(REAL_VALUE_NEGATE(op0),REAL_VALUE_NEGATE(op1));
+}
+
+/* Divide 2 positive SMAP II BCD floats. Indicate if the computed result was exact. */
+static smap_bcd_float bcdppdiv(smap_bcd_float op0, smap_bcd_float op1, int *exactresult)
+{
+  /* The dividend is represented multiplied by 10^16, and in 2 binary parts. The
+     upper 64 bits and the lower ones. The divisor is represented in binary, in
+     2 parts to allow shifting. Compute the result mantissa in binary. */
+  unsigned long long dividendh, dividendl=0, divisorh, divisorl=0, resultm=0;
+  int i,d17,exponent;
+  unsigned long long factor=1ull;
+  /* Convert the mantissa of op0 to binary. */
+  for (i=0;i<64;i+=4,factor*=10ull) /* for each digit of op0 */
+    dividendl += (unsigned long long)((op0.mantissa>>i)&15)*factor;
+  /* Multiply the dividend with 10^16. */
+  dividendh = dividendl>>48; /* multiply first 16 bits with 2^16 */
+  dividendh *= 152587890625ull; /* and with 5^16 */
+  dividendl &= 0xFFFFFFFFFFFFull; /* remove them from dividendl */
+  dividendl *= 15625ull; /* multiply the remaining 48 bits with 5^6
+                            we still have to multiply them by 2^16*5^10 */
+  dividendh += (dividendl>>48)*9765625ull; /* multiply first 16 bits with 2^16*5^10 */
+  dividendl &= 0xFFFFFFFFFFFFull; /* remove them from dividendl */
+  dividendl *= 15625ull; /* multiply the remaining 48 bits with 5^6
+                            we still have to multiply them by 2^16*5^4 */
+  dividendh += (dividendl>>48)*625ull; /* multiply first 16 bits with 2^16*5^4 */
+  dividendl &= 0xFFFFFFFFFFFFull; /* remove them from dividendl */
+  dividendl *= 625ull; /* multiply the remaining 48 bits with 5^4
+                          we still have to multiply them by 2^16 */
+  dividendh += dividendl>>48; /* multiply first 16 bits with 2^16 */
+  dividendl <<= 16; /* multiply the remaining 48 bits with 2^16 */
+  /* Convert the mantissa of op1 to binary. */
+  for (i=0,factor=1ull;i<64;i+=4,factor*=10ull) /* for each digit of op1 */
+    divisorl += (unsigned long long)((op1.mantissa>>i)&15)*factor;
+  /* Multiply the divisor with 2^56. We know that, due to normalization, the
+     result is always <10^17, which is smaller than 2^57, so we don't have to go
+     through the full 128-bit division. */
+  divisorh = divisorl>>(64-56);
+  divisorl <<= 56;
+  /* Now do the 128-bit division. */
+  for (i=56;i>=0;i--) {
+    /* Shift the result to the left. */
+    resultm <<= 1;
+    /* Check if the divisor fits into the dividend. */
+    if (divisorh<dividendh || (divisorh==dividendh && divisorl<=dividendl)) {
+      /* Add 1 to the result. */
+      resultm++;
+      /* Subtract the divisor from the dividend. */
+      if (dividendl<divisorl) /* handle carry, use unsigned wraparound overflow */
+        dividendh--;
+      dividendl -= divisorl; /* now do the subtraction */
+      dividendh -= divisorh;
+    }
+    if (i) {
+      /* Shift the divisor to the right. */
+      divisorl = ((divisorh&1)<<63)+(divisorl>>1);
+      divisorh >>= 1;
+    }
+  }
+  /* dividendl now contains the remainder. It is always smaller than the
+     divisor, so it always fits into 64 bits. divisorl now contains the original
+     divisor. */
+
+  if (exactresult)
+    *exactresult = !dividendl; /* if there is a remainder, the result sure is
+                                  not exact, otherwise, let's assume it is for
+                                  a moment */
+
+  /* Because of normalization, the result has either 16 or 17 digits. */
+  d17 = (resultm>=10000000000000000ull/*10^16*/
+         || (resultm==9999999999999999ull/*10^16-1*/
+             && (dividendl<<1)>=divisorl) /* 2r>=d <=> r>=d/2 */);
+  if (d17) { /* if we have 17 digits in the result, drop one */
+    if (exactresult && (resultm%10ull)) /* if we are about to drop a non-0
+                                           digit, the result is not exact
+                                           anymore */
+      *exactresult = 0;
+    resultm = (resultm+5ull)/10ull; /* add 5 for correct rounding */
+  } else {
+    if ((dividendl<<1)>=divisorl /* r>=d/2 */) /* round remainder into result */
+      resultm++;
+  }
+
+  /* Now compute the exponent. */
+  exponent=op0.exponent-op1.exponent+0x4000-(!d17);
+  if (exactresult && (exponent>0x4000+16383 || exponent<0x4000-16383))
+    /* if we overflowed, the result is not exact anymore */
+    *exactresult = 0;
+  if (exponent>0x4000+16383) /* exponent too large, overflow to +infinity */
+    return POSITIVE_INF;
+  if (exponent<0x4000-16383) /* exponent too small, underflow to +0 */
+    return POSITIVE_ZERO;
+
+  /* Now convert resulth into a BCD mantissa. */
+  {
+    unsigned long long d;
+    smap_bcd_float result={0,0};result.exponent=exponent;
+    for (i=0;i<64;i+=4) { /* for each digit */
+      d = resultm%10ull; /* Extract the digit. */
+      resultm /= 10ull; /* We are done with this digit of the mantissa. */
+      result.mantissa += d<<i; /* Store it into the resulting mantissa. */
+    }
+    return result;
+  }
+}
+
+/* Divide 2 SMAP II BCD floats. Indicate if the computed result was exact. */
+static smap_bcd_float bcddiv(smap_bcd_float op0, smap_bcd_float op1, int *exactresult)
+{
+  if (exactresult) *exactresult=1; /* special cases are all exact */
+  if (REAL_VALUE_ISNAN(op0) || REAL_VALUE_ISNAN(op1)
+      || (REAL_VALUE_ISINF(op0) && REAL_VALUE_ISINF(op1))
+      || (REAL_VALUE_ISZERO(op0) && REAL_VALUE_ISZERO(op1))) /* keep NAN,
+                                                                0/0=inf/inf=NAN */
+    return NAN;
+  else if (REAL_VALUES_IDENTICAL(op0,UNSIGNED_INF)
+           || REAL_VALUES_IDENTICAL(op1,UNSIGNED_ZERO)) /* unsigned inf / finite
+                                          = non-0 / unsigned 0 = unsigned inf */
+    return UNSIGNED_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO)) /* +inf / +0 = +inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO))) /* -inf / -0 = +inf */
+    return POSITIVE_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO)) /* +inf / -0 = -inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO))) /* -inf / +0 = -inf */
+    return NEGATIVE_INF;
+  /* Now we can assume that at least 1 of op0 and 1/op1 is finite, and that we
+     don't have op0 = unsigned inf, op1 = unsigned 0, a NAN or an inf/inf or 0/0
+     indeterminate form. */
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUE_ISPOSITIVE(op1)) /* +inf / +non-0 = +inf */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO)) /* +finite / +0 = +inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUE_ISNEGATIVE(op1)) /* -inf / -non-0 = +inf */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO))) /* -finite / -0 = +inf */
+    return POSITIVE_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUE_ISNEGATIVE(op1)) /* +inf / -non-0 = -inf */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO)) /* +finite / -0 = -inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUE_ISPOSITIVE(op1)) /* -inf / +non-0 = -inf */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO))) /* -finite / +0 = -inf */
+    return NEGATIVE_INF;
+  /* Now we can assume that both of op0 and 1/op1 are finite. */
+  else if (REAL_VALUES_IDENTICAL(op0,UNSIGNED_ZERO)
+           || REAL_VALUES_IDENTICAL(op1,UNSIGNED_INF)) /* unsigned 0 / non-0 =
+                                           finite / unsigned inf = unsigned 0 */
+    return UNSIGNED_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* +0 / +inf = +0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF))) /* -0 / -inf = +0 */
+    return POSITIVE_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* +0 / -inf = -0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF))) /* -0 / +inf = -0 */
+    return NEGATIVE_ZERO;
+  /* Now we can assume that both of op0 and 1/op1 are finite, at least 1 of them
+     is non-0, and that neither of them is an unsigned 0. */
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUE_ISPOSITIVE(op1)) /* +0 / +non-0 = +0 */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* +finite / +inf = +0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUE_ISNEGATIVE(op1)) /* -0 / -non-0 = +0 */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF))) /* -finite / -inf = +0 */
+    return POSITIVE_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUE_ISNEGATIVE(op1)) /* +0 / -non-0 = -0 */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* +finite / -inf = -0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUE_ISPOSITIVE(op1)) /* -0 / +non-0 = -0 */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF))) /* -finite / +inf = -0 */
+    return NEGATIVE_ZERO;
+  /* Now we can assume that both values are finite and non-0. */
+  else if (REAL_VALUE_ISPOSITIVE(op0) && REAL_VALUE_ISPOSITIVE(op1))
+    return bcdppdiv(op0,op1,exactresult);
+  else if (REAL_VALUE_ISPOSITIVE(op0)) /* and op1 negative */
+    return REAL_VALUE_NEGATE(bcdppdiv(op0,REAL_VALUE_NEGATE(op1),exactresult));
+  else if (REAL_VALUE_ISPOSITIVE(op1)) /* and op0 negative */
+    return REAL_VALUE_NEGATE(bcdppdiv(REAL_VALUE_NEGATE(op0),op1,exactresult));
+  else /* both negative */
+    return bcdppdiv(REAL_VALUE_NEGATE(op0),REAL_VALUE_NEGATE(op1),exactresult);
+}
+
+/* Compute min of 2 SMAP II BCD floats. */
+static smap_bcd_float bcdmin(smap_bcd_float op0, smap_bcd_float op1)
+{
+  if (REAL_VALUE_ISNANUINF(op0) || REAL_VALUE_ISNANUINF(op1)) /* keep NAN,
+                    UNSIGNED_INF is neither smaller nor larger than the other */
+    return NAN;
+  else if (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+           || REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* keep -infinity */
+    return NEGATIVE_INF;
+  else if (REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)) /* all numbers are smaller
+                                                       than +infinity */
+    return op1;
+  else if (REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* all numbers are smaller
+                                                       than +infinity */
+    return op0;
+  /* Now, we can assume that all values are finite. */
+  else if (REAL_VALUES_LESS(op0,op1)) /* if op0<op1, return op0 */
+    return op0;
+  else /* if op0>=op1, return op1 */
+    return op1;
+}
+
+/* Compute max of 2 SMAP II BCD floats. */
+static smap_bcd_float bcdmax(smap_bcd_float op0, smap_bcd_float op1)
+{
+  if (REAL_VALUE_ISNANUINF(op0) || REAL_VALUE_ISNANUINF(op1)) /* keep NAN,
+                    UNSIGNED_INF is neither smaller nor larger than the other */
+    return NAN;
+  else if (REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+           || REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* keep +infinity */
+    return POSITIVE_INF;
+  else if (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)) /* all numbers are smaller
+                                                       than -infinity */
+    return op1;
+  else if (REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* all numbers are smaller
+                                                       than -infinity */
+    return op0;
+  /* Now, we can assume that all values are finite. */
+  else if (REAL_VALUES_LESS(op0,op1)) /* if op0<op1, return op1 */
+    return op1;
+  else /* if op0>=op1, return op0 */
+    return op0;
+}
 
 /* Perform the binary or unary operation described by CODE.
    For a unary operation, leave OP1 NULL.  This function returns
@@ -982,6 +1593,37 @@
 real_arithmetic (REAL_VALUE_TYPE *r, int icode, const REAL_VALUE_TYPE *op0,
 		 const REAL_VALUE_TYPE *op1)
 {
+  switch (icode)
+    {
+    case PLUS_EXPR:
+      *r = bcdadd (*op0, *op1);
+      return true;
+
+    case MINUS_EXPR:
+      *r = bcdsub (*op0, *op1);
+      return true;
+
+    case MULT_EXPR:
+      *r = bcdmul (*op0, *op1);
+      return true;
+
+    case RDIV_EXPR:
+      *r = bcddiv (*op0, *op1, NULL);
+      return true;
+
+    case MIN_EXPR:
+      *r = bcdmin (*op0, *op1);
+      return false;
+
+    case MAX_EXPR:
+      *r = bcdmax (*op0, *op1);
+      return false;
+
+    default:
+      gcc_unreachable ();
+    }
+
+#if 0
   enum tree_code code = icode;
 
   switch (code)
@@ -1033,9 +1675,11 @@
     default:
       gcc_unreachable ();
     }
+#endif /* 0 */
   return false;
 }
 
+#if 0
 /* Legacy.  Similar, but return the result directly.  */
 
 REAL_VALUE_TYPE
@@ -1046,6 +1690,7 @@
   real_arithmetic (&r, icode, op0, op1);
   return r;
 }
+#endif /* 0 */
 
 bool
 real_compare (int icode, const REAL_VALUE_TYPE *op0,
@@ -1056,39 +1701,40 @@
   switch (code)
     {
     case LT_EXPR:
-      return do_compare (op0, op1, 1) < 0;
+      return REAL_VALUES_LESS (*op0, *op1);
     case LE_EXPR:
-      return do_compare (op0, op1, 1) <= 0;
+      return !real_compare (UNGT_EXPR, op0, op1);
     case GT_EXPR:
-      return do_compare (op0, op1, -1) > 0;
+      return real_compare (LT_EXPR, op1, op0);
     case GE_EXPR:
-      return do_compare (op0, op1, -1) >= 0;
+      return !real_compare (UNLT_EXPR, op0, op1);
     case EQ_EXPR:
-      return do_compare (op0, op1, -1) == 0;
+      return REAL_VALUES_EQUAL (*op0, *op1);
     case NE_EXPR:
-      return do_compare (op0, op1, -1) != 0;
+      return !real_compare (EQ_EXPR, op0, op1);
     case UNORDERED_EXPR:
-      return op0->cl == rvc_nan || op1->cl == rvc_nan;
+      return REAL_VALUE_ISNANUINF (*op0) || REAL_VALUE_ISNANUINF (*op1);
     case ORDERED_EXPR:
-      return op0->cl != rvc_nan && op1->cl != rvc_nan;
+      return !real_compare (UNORDERED_EXPR, op0, op1);
     case UNLT_EXPR:
-      return do_compare (op0, op1, -1) < 0;
+      return real_compare (UNORDERED_EXPR, op0, op1) || real_compare (LT_EXPR, op0, op1);
     case UNLE_EXPR:
-      return do_compare (op0, op1, -1) <= 0;
+      return !real_compare (GT_EXPR, op0, op1);
     case UNGT_EXPR:
-      return do_compare (op0, op1, 1) > 0;
+      return real_compare (UNORDERED_EXPR, op0, op1) || real_compare (GT_EXPR, op0, op1);
     case UNGE_EXPR:
-      return do_compare (op0, op1, 1) >= 0;
+      return !real_compare (LT_EXPR, op0, op1);
     case UNEQ_EXPR:
-      return do_compare (op0, op1, 0) == 0;
+      return real_compare (UNORDERED_EXPR, op0, op1) || real_compare (EQ_EXPR, op0, op1);
     case LTGT_EXPR:
-      return do_compare (op0, op1, 0) != 0;
+      return !real_compare (UNEQ_EXPR, op0, op1);
 
     default:
       gcc_unreachable ();
     }
 }
 
+#if 0
 /* Return floor log2(R).  */
 
 int
@@ -1209,6 +1855,7 @@
 
   return true;
 }
+#endif /* 0 */
 
 /* Try to change R into its exact multiplicative inverse in machine
    mode MODE.  Return true if successful.  */
@@ -1216,6 +1863,13 @@
 bool
 exact_real_inverse (enum machine_mode mode, REAL_VALUE_TYPE *r)
 {
+  int exactresult=0;
+  smap_bcd_float one={0x4000,0x1000000000000000ull}, invr;
+
+  invr = bcddiv(one,*r,&exactresult);
+  if (exactresult) *r=invr;
+  return exactresult;
+#if 0
   const REAL_VALUE_TYPE *one = real_digit (1);
   REAL_VALUE_TYPE u;
   int i;
@@ -1245,8 +1899,10 @@
 
   *r = u;
   return true;
+#endif /* 0 */
 }
 
+#if 0
 /* Render R as an integer.  */
 
 HOST_WIDE_INT
@@ -1298,6 +1954,7 @@
       gcc_unreachable ();
     }
 }
+#endif /* 0 */
 
 /* Likewise, but to an integer pair, HI+LOW.  */
 
@@ -1305,6 +1962,59 @@
 real_to_integer2 (HOST_WIDE_INT *plow, HOST_WIDE_INT *phigh,
 		  const REAL_VALUE_TYPE *r)
 {
+  unsigned short exponent = (r->exponent & 0x7fff);
+  unsigned HOST_WIDE_INT low = 0, high = 0;
+  int e, i;
+  unsigned long long mantissa = r->mantissa;
+
+  /* Return 0 for transfinite, zero or |*r|<1 */
+  if (!REAL_VALUE_ISFINITE(*r) || REAL_VALUE_ISZERO(*r) || exponent < 0x4000) {
+    *plow = *phigh = 0;
+    return;
+  }
+
+  /* Compute the effective exponent */
+  e = (int)exponent - (0x4000+15);
+
+  /* Delete any digits following the decimal point right now */
+  if (e < 0) {
+    mantissa >>= ((-e)<<2);
+    e = 0;
+  } else if (e > 2*HOST_BITS_PER_WIDE_INT) {
+    /* We'll multiply by 10^(2*HBPWI)=5^(2*HBPWI)*2^(2*HBPWI). This will zero
+       out all digits. So avoid the long loop and return 0 right now. */
+    *plow = *phigh = 0;
+    return;
+  }
+
+  /* Convert the mantissa from BCD to binary */
+  for (i=60;i>=0;i-=4) {
+    /* Multiply by 10 using x*10=(x<<3)+(x<<1) */
+    high = (high<<3) + (low>>(HOST_BITS_PER_WIDE_INT-3)) /* (x<<3) */
+           + (high<<1) + (low>>(HOST_BITS_PER_WIDE_INT-1)) /* (x<<1) */
+           + ((low<<3) + (low<<1) < (low<<1)); /* (carry) */
+    low = (low<<3) + (low<<1);
+    low += (mantissa>>i)&15;
+  }
+
+  /* Multiply by 10^e */
+  for (i=0;i<e;i++) {
+    /* Multiply by 10 using x*10=(x<<3)+(x<<1) */
+    high = (high<<3) + (low>>(HOST_BITS_PER_WIDE_INT-3)) /* (x<<3) */
+           + (high<<1) + (low>>(HOST_BITS_PER_WIDE_INT-1)) /* (x<<1) */
+           + ((low<<3) + (low<<1) < (low<<1)); /* (carry) */
+    low = (low<<3) + (low<<1);
+  }
+
+  /* Negate the result if *r was negative */
+  if (r->exponent >= 0x8000) {
+	if (low == 0)
+	  high = -high;
+	else
+	  low = -low, high = ~high;
+  }
+
+#if 0
   REAL_VALUE_TYPE t;
   HOST_WIDE_INT low, high;
   int exp;
@@ -1370,11 +2080,13 @@
     default:
       gcc_unreachable ();
     }
+#endif /* 0 */
 
   *plow = low;
   *phigh = high;
 }
 
+#if 0
 /* A subroutine of real_to_decimal.  Compute the quotient and remainder
    of NUM / DEN.  Return the quotient and place the remainder in NUM.
    It is expected that NUM / DEN are close enough that the quotient is
@@ -1749,6 +2461,327 @@
 
   sprintf (p, "p%+d", exp);
 }
+#endif /* 0 */
+
+static void real_value_dtof (REAL_VALUE_TYPE *r, const char *string)
+{
+	const char *strpart = string;
+	unsigned char state = 0;
+	unsigned long long mpmul = 0x1000000000000000;
+	signed short expshift = -1;
+	unsigned short exp = 0;
+	unsigned short expmul = 1;
+	unsigned short expadd = 0;
+	int endrounding = -1;
+	r->mantissa = 0;
+	while (strpart && *strpart)
+	{
+		switch (state)
+		{
+			case 0:
+				if (*strpart == '.')
+				{
+					state = 1;
+					break;
+				}
+				else if (*strpart == '+')
+					expadd = 0;
+				else if (*strpart == '-')
+					expadd = 0x8000;
+				else if (((*strpart) >= '0' && (*strpart) <= '9') && ((r->mantissa) || (*strpart != '0')))
+					expshift++;
+				else if ((*strpart == 'i') || (*strpart == 'I'))
+				{
+					if (expadd == 0x8000)
+						*r = NEGATIVE_INF;
+					else
+						*r = POSITIVE_INF;
+					expadd = 0x3FFF;
+					strpart = 0;
+				}
+				else if ((*strpart == 'n') || (*strpart == 'N'))
+				{
+					*r = NAN;
+					expadd = 0x3FFF;
+					strpart = 0;
+				}
+			case 1:
+				if ((*strpart == 'e') || (*strpart == 'E'))
+					state = 2;
+				else if ((*strpart) >= '0' && (*strpart) <= '9')
+				{
+					if (mpmul)
+						r->mantissa |= (*strpart - '0') * mpmul;
+					else if (endrounding < 0)
+						endrounding = (*strpart >= '5');
+					if (r->mantissa)
+						mpmul /= 0x10;
+					else if (state)
+						expshift--;
+				}
+				break;
+			case 2:
+				if (*strpart == '+')
+					expmul = 1;
+				else if (*strpart == '-')
+					expmul = -1;
+				if ((*strpart) >= '0' && (*strpart) <= '9')
+				{
+					exp *= 10;
+					exp += (*strpart - '0');
+				}
+				break;
+		}
+		if (strpart)
+			strpart++;
+		else
+			break;
+	}
+	if (!(r->mantissa))
+		*r = ZERO;
+	else if (expadd != 0x3FFF)
+	{
+		r->exponent = exp * expmul + 0x4000 + expshift;
+		if (r->exponent>0x4000+16383) /* exponent too large, overflow to +infinity */
+			*r = POSITIVE_INF;
+		else if (r->exponent<0x4000-16383) /* exponent too small, underflow to +0 */
+			*r = POSITIVE_ZERO;
+		else if (endrounding > 0)
+			bcdpadd1ulp (r);
+		r->exponent += expadd;
+	}
+}
+
+typedef struct {
+  int ndigits;
+  unsigned char *digits;
+  long effexp;
+} arbprec_decimal;
+
+static void arbprec_pack (arbprec_decimal *r)
+{
+  unsigned char *p = r->digits;
+  if (r->ndigits) {
+    while (p < r->digits + r->ndigits && !*p) p++;
+    r->ndigits -= p - r->digits;
+    memmove (r->digits, p, r->ndigits);
+    if (r->ndigits) {
+      p = r->digits + r->ndigits - 1;
+      while (p > r->digits && !*p) {
+        p--;
+        r->effexp++;
+      }
+      r->ndigits = (p + 1) - r->digits;
+    }
+    r->digits = xrealloc (r->digits, r->ndigits);
+  }
+}
+
+static void arbprec_mul2 (arbprec_decimal *r)
+{
+  unsigned char *p;
+  unsigned char carry = 0;
+  r->ndigits++;
+  r->digits = xrealloc (r->digits, r->ndigits);
+  for (p = r->digits + r->ndigits - 1; p > r->digits; p--) {
+    unsigned char digit = (p[-1]<<1) + carry;
+    *p = digit % 10;
+    carry = digit / 10;
+  }
+  *p = carry;
+  arbprec_pack (r);
+}
+
+static void arbprec_div2 (arbprec_decimal *r)
+{
+  unsigned char *p;
+  unsigned char carry = 0;
+  r->ndigits++;
+  r->digits = xrealloc (r->digits, r->ndigits);
+  for (p = r->digits; p < r->digits + r->ndigits - 1; p++) {
+    unsigned char digit = (*p>>1) + carry;
+    carry = (*p&1)*5;
+    *p = digit;
+  }
+  *p = carry;
+  r->effexp--;
+  arbprec_pack (r);
+}
+
+static void arbprec_mul16 (arbprec_decimal *r)
+{
+  arbprec_mul2 (r);
+  arbprec_mul2 (r);
+  arbprec_mul2 (r);
+  arbprec_mul2 (r);
+}
+
+static void arbprec_div16 (arbprec_decimal *r)
+{
+  arbprec_div2 (r);
+  arbprec_div2 (r);
+  arbprec_div2 (r);
+  arbprec_div2 (r);
+}
+
+static void arbprec_add (arbprec_decimal *r1, arbprec_decimal *r2)
+{
+  if (!r2->ndigits)
+    return;
+  else if (!r1->ndigits) {
+    r1->digits = xrealloc (r1->digits, r2->ndigits);
+    memcpy (r1->digits, r2->digits, r2->ndigits);
+    r1->ndigits = r2->ndigits;
+    r1->effexp = r2->effexp;
+  } else {
+    if (r1->effexp > r2->effexp) {
+      long effexpdiff = r1->effexp - r2->effexp;
+      r1->digits = xrealloc (r1->digits, r1->ndigits + effexpdiff);
+      memset (r1->digits + r1->ndigits, 0, effexpdiff);
+      r1->ndigits += effexpdiff;
+      r1->effexp = r2->effexp;
+    } else if (r2->effexp > r1->effexp) {
+      long effexpdiff = r2->effexp - r1->effexp;
+      r2->digits = xrealloc (r2->digits, r2->ndigits + effexpdiff);
+      memset (r2->digits + r2->ndigits, 0, effexpdiff);
+      r2->ndigits += effexpdiff;
+      r2->effexp = r1->effexp;
+    }
+
+    {
+      int ndigits = MAX (r1->ndigits, r2->ndigits) + 1;
+      unsigned char *digits = xmalloc (ndigits);
+      unsigned char *p, *q1, *q2;
+      unsigned char carry = 0;
+      for (p = digits + ndigits - 1, q1 = r1->digits + r1->ndigits - 1,
+           q2 = r2->digits + r2->ndigits - 1; p > digits; p--, q1--, q2--) {
+        unsigned char digit = (q1>=r1->digits?*q1:0) + (q2>=r2->digits?*q2:0)
+                              + carry;
+        *p = digit % 10;
+        carry = digit / 10;
+      }
+      *p = carry;
+      free (r1->digits);
+      r1->digits = digits;
+      r1->ndigits = ndigits;
+      arbprec_pack (r1);
+      arbprec_pack (r2);
+    }
+  }
+}
+
+static void arbprec_add_n_times (arbprec_decimal *r1, arbprec_decimal *r2, int n)
+{
+  int i;
+  for (i = 0; i < n; i++) arbprec_add (r1, r2);
+}
+
+static void arbprec_to_bcd (arbprec_decimal *a, smap_bcd_float *r)
+{
+  if (a->ndigits) {
+    long exponent = a->effexp + a->ndigits - 1;
+    if (exponent>16383) /* exponent too large, overflow to +infinity */
+      *r = POSITIVE_INF;
+    else if (exponent<-16383) /* exponent too small, underflow to +0 */
+      *r = POSITIVE_ZERO;
+    else {
+      int i;
+      r->exponent = 0x4000 + exponent;
+      r->mantissa = 0;
+      for (i = 0; i < a->ndigits && i < 16; i++) {
+        r->mantissa = (r->mantissa << 4) + a->digits[i];
+      }
+      for (; i < 16; i++) {
+        r->mantissa <<= 4;
+      }
+      if (a->ndigits > 16 && a->digits[16] >= 5)
+        bcdpadd1ulp (r);
+    }
+  } else {
+    *r = UNSIGNED_ZERO;
+  }
+}
+
+static void real_value_htof (REAL_VALUE_TYPE *res, const char *string)
+{
+	arbprec_decimal r = {0, NULL, 0};
+	const char *strpart = string;
+	signed char state = -1;
+	arbprec_decimal rdiv = {1, NULL, 0};
+	unsigned int negative = 0;
+	unsigned short exp = 0;
+	unsigned short expsign = 1;
+	unsigned long exp2 = 1;
+	rdiv.digits = xmalloc (1);
+	*(rdiv.digits) = 1;
+	while (strpart && *strpart)
+	{
+		switch (state)
+		{
+			case -1:
+				if (*strpart == 'x' || *strpart == 'X')
+					state = 0;
+				else if (*strpart == '+')
+					negative = 0;
+				else if (*strpart == '-')
+					negative = 1;
+				break;
+			case 0:
+				if (*strpart == '.')
+				{
+					state = 1;
+					break;
+				}
+				else if ((*strpart >= '0' && *strpart <= '9') || (*strpart >= 'a' && *strpart <= 'f') || (*strpart >= 'A' && *strpart <= 'F'))
+					arbprec_mul16 (&r);
+			case 1:
+				if (state == 1)
+					arbprec_div16 (&rdiv);
+				if ((*strpart == 'p') || (*strpart == 'P'))
+					state = 2;
+				else if (*strpart >= '0' && *strpart <= '9')
+					arbprec_add_n_times (&r, &rdiv, (*strpart - '0'));
+				else if (*strpart >= 'a' && *strpart <= 'f')
+					arbprec_add_n_times (&r, &rdiv, (*strpart - 'a' + 0xA));
+				else if (*strpart >= 'A' && *strpart <= 'F')
+					arbprec_add_n_times (&r, &rdiv, (*strpart - 'A' + 0xA));
+				break;
+			case 2:
+				if (*strpart == '+')
+					expsign = 1;
+				else if (*strpart == '-')
+					expsign = -1;
+				if ((*strpart) >= '0' && (*strpart) <= '9')
+				{
+					exp *= 10;
+					exp += (*strpart - '0');
+				}
+				break;
+		}
+		strpart++;
+	}
+	free (rdiv.digits);
+	if (expsign == 1)
+	{
+		while (exp)
+		{
+			arbprec_mul2 (&r);
+			exp--;
+		}
+	}
+	else
+	{
+		while (exp)
+		{
+			arbprec_div2 (&r);
+			exp--;
+		}
+	}
+	arbprec_to_bcd (&r, res);
+	free (r.digits);
+	if (negative)
+		*res = REAL_VALUE_NEGATE (*res);
+}
 
 /* Initialize R from a decimal or hexadecimal string.  The string is
    assumed to have been syntax checked already.  */
@@ -1756,6 +2789,17 @@
 void
 real_from_string (REAL_VALUE_TYPE *r, const char *str)
 {
+  const char *p = str;
+
+  if (*p == '-' || *p == '+')
+    p++;
+
+  if (p[0] == '0' && (p[1] == 'x' || p[1] == 'X'))
+    real_value_htof (r, str);
+  else
+    real_value_dtof (r, str);
+
+#if 0
   int exp = 0;
   bool sign = false;
 
@@ -1941,6 +2985,7 @@
  overflow:
   get_inf (r, sign);
   return;
+#endif /* 0 */
 }
 
 /* Legacy.  Similar, but return the result directly.  */
@@ -1964,6 +3009,67 @@
 		   unsigned HOST_WIDE_INT low, HOST_WIDE_INT high,
 		   int unsigned_p)
 {
+  int i, j, e = -1, lastdigit = 0;
+  bool negative = high < 0 && !unsigned_p;
+  unsigned HOST_WIDE_INT uhigh = (unsigned HOST_WIDE_INT)high;
+  unsigned HOST_WIDE_INT ulow = low;
+  unsigned HOST_WIDE_INT remainderh, remainderl, divisorh, divisorl;
+  unsigned long long mantissa = 0;
+
+  if (negative) {
+    uhigh = ~uhigh;
+    if (!ulow) uhigh++; else ulow = -ulow;
+  }
+
+  /* Convert the integer to BCD */
+  while (uhigh || ulow) {
+    remainderh = uhigh; remainderl = ulow;
+    divisorl = uhigh = ulow = 0;
+    divisorh = (HOST_WIDE_INT)10<<(HOST_BITS_PER_WIDE_INT-4);
+    /* Divide the pair of HOST_WIDE_INTs by 10 */
+    for (j=2*HOST_BITS_PER_WIDE_INT-4;j>=0;j--) {
+      /* Shift the result to the left. */
+      uhigh = (uhigh<<1) + (ulow>>(HOST_BITS_PER_WIDE_INT-1));
+      ulow <<= 1;
+      /* Check if the divisor 10 fits into the dividend. */
+      if (divisorh<remainderh || (divisorh==remainderh && divisorl<=remainderl)) {
+        /* Add 1 to the result. */
+        ulow++;
+        if (!ulow) uhigh++; /* handle carry */
+        /* Subtract the divisor from the dividend. */
+        if (remainderl<divisorl) /* handle carry, use unsigned wraparound overflow */
+          remainderh--;
+        remainderl -= divisorl; /* now do the subtraction */
+        remainderh -= divisorh;
+      }
+      if (j) {
+        /* Shift the divisor to the right. */
+        divisorl = ((divisorh&1)<<(HOST_BITS_PER_WIDE_INT-1))+(divisorl>>1);
+        divisorh >>= 1;
+      }
+    }
+    e++;
+    lastdigit = (mantissa&15);
+    mantissa = (mantissa>>4) + ((unsigned long long)remainderl<<60);
+  }
+
+  if (e >= 0) {
+    /* We have a nonnegative exponent. Do the correct rounding for the last
+       digit. */
+
+    r->exponent = e+0x4000;
+    r->mantissa = mantissa;
+
+    if (lastdigit >= 5) bcdpadd1ulp(r);
+  } else {
+    /* We don't have any digit, so our number is actually zero. */
+    *r = UNSIGNED_ZERO;
+  }
+
+  /* Negate *r if the integer was negative */
+  if (negative) *r = REAL_VALUE_NEGATE (*r);
+
+#if 0
   if (low == 0 && high == 0)
     get_zero (r, 0);
   else
@@ -2001,8 +3107,10 @@
 
   if (mode != VOIDmode)
     real_convert (r, mode, r);
+#endif /* 0 */
 }
 
+#if 0
 /* Returns 10**2**N.  */
 
 static const REAL_VALUE_TYPE *
@@ -2490,6 +3598,7 @@
 
   return fmt->p * fmt->log2_b;
 }
+#endif /* 0 */
 
 /* Return a hash value for the given real value.  */
 /* ??? The "unsigned int" return value is intended to be hashval_t,
@@ -2498,6 +3607,12 @@
 unsigned int
 real_hash (const REAL_VALUE_TYPE *r)
 {
+  /* (TIGCC) Very naive hash for lack of something better. -- Kevin Kofler */
+  unsigned int h=r->exponent;
+  return h+(unsigned int)(r->mantissa >>
+                          ((sizeof(unsigned long long)-sizeof(unsigned int))*8));
+
+#if 0
   unsigned int h;
   size_t i;
 
@@ -2534,8 +3649,10 @@
       h ^= r->sig[i];
 
   return h;
+#endif /* 0 */
 }
 
+#if 0
 /* IEEE single-precision format.  */
 
 static void encode_ieee_single (const struct real_format *fmt,
@@ -4705,4 +5822,5 @@
 {
   r->sign = x->sign;
 }
+#endif /* 0 */
 
diff -Naur gcc-4.1-20051216.orig/gcc/real.h gcc-4.1-20051216-src/gcc/real.h
--- gcc-4.1-20051216.orig/gcc/real.h	2005-08-01 23:16:31.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/real.h	2005-12-18 22:24:50.000000000 +0100
@@ -22,6 +22,22 @@
 #ifndef GCC_REAL_H
 #define GCC_REAL_H
 
+/* (TIGCC) smapbcd.h need this, but gengtype needs it to be in this file. */
+/* (TIGCC) Hack to make gengtype shut up while still packing the structure. */
+#define exponent exponent __attribute__((packed))
+#define mantissa mantissa __attribute__((packed))
+__attribute__ ((packed))
+struct real_value GTY(())
+{
+	unsigned short exponent;
+	unsigned long long mantissa;
+};
+#undef exponent
+#undef mantissa
+
+#include <config/smapbcd.h>
+#define SMAP_BCD_FLOAT_FORMAT 5
+
 #include "machmode.h"
 
 /* An expanded form of the represented number.  */
@@ -40,19 +56,22 @@
 #define SIGSZ			(SIGNIFICAND_BITS / HOST_BITS_PER_LONG)
 #define SIG_MSB			((unsigned long)1 << (HOST_BITS_PER_LONG - 1))
 
+/*
 struct real_value GTY(())
 {
-  /* Use the same underlying type for all bit-fields, so as to make
+  ** Use the same underlying type for all bit-fields, so as to make
      sure they're packed together, otherwise REAL_VALUE_TYPE_SIZE will
-     be miscomputed.  */
-  unsigned int /* ENUM_BITFIELD (real_value_class) */ cl : 2;
+     be miscomputed.  **
+  unsigned int ** ENUM_BITFIELD (real_value_class) ** cl : 2;
   unsigned int sign : 1;
   unsigned int signalling : 1;
   unsigned int canonical : 1;
   unsigned int uexp : EXP_BITS;
   unsigned long sig[SIGSZ];
 };
-
+*/
+  
+#if 0
 #define REAL_EXP(REAL) \
   ((int)((REAL)->uexp ^ (unsigned int)(1 << (EXP_BITS - 1))) \
    - (1 << (EXP_BITS - 1)))
@@ -76,6 +95,9 @@
 /* Verify the guess.  */
 extern char test_real_width
   [sizeof(REAL_VALUE_TYPE) <= REAL_WIDTH*sizeof(HOST_WIDE_INT) ? 1 : -1];
+#endif /* 0 */
+
+#define REAL_WIDTH (11*8 + HOST_BITS_PER_WIDE_INT)/HOST_BITS_PER_WIDE_INT
 
 /* Calculate the format for CONST_DOUBLE.  We need as many slots as
    are necessary to overlay a REAL_VALUE_TYPE on them.  This could be
@@ -111,6 +133,7 @@
 #endif
 
 
+#if 0
 /* Describes the properties of the specific target format in use.  */
 struct real_format
 {
@@ -167,6 +190,7 @@
    case compile-time FP overflow may not model run-time overflow.  */
 #define REAL_MODE_FORMAT_COMPOSITE_P(MODE) \
 	((REAL_MODE_FORMAT(MODE))->pnan < (REAL_MODE_FORMAT (MODE))->p)
+#endif /* 0 */
 
 /* Declare functions in real.c.  */
 
@@ -177,6 +201,7 @@
 /* Compare reals by tree_code.  */
 extern bool real_compare (int, const REAL_VALUE_TYPE *, const REAL_VALUE_TYPE *);
 
+#if 0
 /* Determine whether a floating-point value X is infinite.  */
 extern bool real_isinf (const REAL_VALUE_TYPE *);
 
@@ -209,6 +234,7 @@
 
 /* Render R as an integer.  */
 extern HOST_WIDE_INT real_to_integer (const REAL_VALUE_TYPE *);
+#endif /* 0 */
 extern void real_to_integer2 (HOST_WIDE_INT *, HOST_WIDE_INT *,
 			      const REAL_VALUE_TYPE *);
 
@@ -219,6 +245,7 @@
 extern void real_from_integer (REAL_VALUE_TYPE *, enum machine_mode,
 			       unsigned HOST_WIDE_INT, HOST_WIDE_INT, int);
 
+#if 0
 extern long real_to_target_fmt (long *, const REAL_VALUE_TYPE *,
 				const struct real_format *);
 extern long real_to_target (long *, const REAL_VALUE_TYPE *, enum machine_mode);
@@ -235,10 +262,12 @@
 extern void real_maxval (REAL_VALUE_TYPE *, int, enum machine_mode);
 
 extern void real_2expN (REAL_VALUE_TYPE *, int);
+#endif /* 0 */
 
 extern unsigned int real_hash (const REAL_VALUE_TYPE *);
 
 
+#if 0
 /* Target formats defined in real.c.  */
 extern const struct real_format ieee_single_format;
 extern const struct real_format mips_single_format;
@@ -318,9 +347,11 @@
   real_arithmetic2 (ABS_EXPR, &(X), NULL)
 
 extern int significand_size (enum machine_mode);
+#endif /* 0 */
 
 extern REAL_VALUE_TYPE real_from_string2 (const char *, enum machine_mode);
 
+#if 0
 #define REAL_VALUE_ATOF(s, m) \
   real_from_string2 (s, m)
 
@@ -343,6 +374,7 @@
 extern void real_ldexp (REAL_VALUE_TYPE *, const REAL_VALUE_TYPE *, int);
 
 /* **** End of software floating point emulator interface macros **** */
+#endif /* 0 */
 
 /* Constant real values 0, 1, 2, 3, 10, -1, -2, 0.5 and 1/3.  */
 
@@ -355,8 +387,10 @@
 extern REAL_VALUE_TYPE dconstm2;
 extern REAL_VALUE_TYPE dconsthalf;
 extern REAL_VALUE_TYPE dconstthird;
+#if 0
 extern REAL_VALUE_TYPE dconstpi;
 extern REAL_VALUE_TYPE dconste;
+#endif /* 0 */
 
 /* Function to return a real value (not a tree node)
    from a given integer constant.  */
@@ -377,6 +411,7 @@
 /* In tree.c: wrap up a REAL_VALUE_TYPE in a tree node.  */
 extern tree build_real (tree, REAL_VALUE_TYPE);
 
+#if 0
 /* Calculate R as the square root of X in the given machine mode.  */
 extern bool real_sqrt (REAL_VALUE_TYPE *, enum machine_mode,
 		       const REAL_VALUE_TYPE *);
@@ -397,5 +432,6 @@
 
 /* Set the sign of R to the sign of X.  */
 extern void real_copysign (REAL_VALUE_TYPE *, const REAL_VALUE_TYPE *);
+#endif /* 0 */
 
 #endif /* ! GCC_REAL_H */
diff -Naur gcc-4.1-20051216.orig/gcc/rtlanal.c gcc-4.1-20051216-src/gcc/rtlanal.c
--- gcc-4.1-20051216.orig/gcc/rtlanal.c	2005-11-03 12:31:46.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/rtlanal.c	2005-12-19 01:11:06.000000000 +0100
@@ -3183,6 +3183,19 @@
   if (offset == 0 || nregs_xmode == nregs_ymode)
     return 0;
 
+  /* (TIGCC 20050324) Subregs of a 10-byte mode are special, hardcode them. */
+  if (GET_MODE_SIZE (xmode) == 10)
+  {
+     gcc_assert (nregs_xmode == 3);
+
+     if (offset < 4)
+       return 0;
+     else if (offset < 8)
+       return 1;
+     else
+       return 2;
+  }
+
   /* Size of ymode must not be greater than the size of xmode.  */
   mode_multiple = GET_MODE_SIZE (xmode) / GET_MODE_SIZE (ymode);
   gcc_assert (mode_multiple != 0);
@@ -3266,6 +3279,28 @@
 	  ? WORDS_BIG_ENDIAN : BYTES_BIG_ENDIAN))
     return true;
 
+  /* (TIGCC 20050324) Subregs of a 10-byte mode are special, hardcode them. */
+  if (GET_MODE_SIZE (xmode) == 10)
+  {
+     switch (GET_MODE_SIZE (ymode))
+     {
+       case 1:
+         return (offset == 3 || offset == 7 || offset == 9);
+
+       case 2:
+         return (offset == 2 || offset == 6 || offset == 8);
+
+       case 4:
+         return (offset == 0 || offset == 4);
+
+       case 8:
+         return !offset;
+
+       default:
+         return false;
+     }
+  }
+
   /* Lowpart subregs are otherwise valid.  */
   if (offset == subreg_lowpart_offset (ymode, xmode))
     return true;
diff -Naur gcc-4.1-20051216.orig/gcc/sdbout.c gcc-4.1-20051216-src/gcc/sdbout.c
--- gcc-4.1-20051216.orig/gcc/sdbout.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/sdbout.c	2005-12-18 22:24:50.000000000 +0100
@@ -1541,9 +1541,7 @@
 #ifdef SDB_OUTPUT_SOURCE_LINE
       SDB_OUTPUT_SOURCE_LINE (asm_out_file, line);
 #else
-      fprintf (asm_out_file, "\t.ln\t%d\n",
-	       ((sdb_begin_function_line > -1)
-		? line - sdb_begin_function_line : 1));
+      fprintf (asm_out_file, "\t.ln\t%d\n", line);
 #endif
     }
 }
diff -Naur gcc-4.1-20051216.orig/gcc/simplify-rtx.c gcc-4.1-20051216-src/gcc/simplify-rtx.c
--- gcc-4.1-20051216.orig/gcc/simplify-rtx.c	2005-11-16 18:15:23.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/simplify-rtx.c	2005-12-19 03:19:57.000000000 +0100
@@ -494,13 +494,14 @@
 	 both +0, (minus Y X) is the same as (minus X Y).  If the
 	 rounding mode is towards +infinity (or -infinity) then the two
 	 expressions will be rounded differently.  */
+      /* (TIGCC 20050210) This identity is valid for us thanks to unsigned 0. */
       if (GET_CODE (op) == MINUS
-	  && !HONOR_SIGNED_ZEROS (mode)
+	  /*&& !HONOR_SIGNED_ZEROS (mode)*/
 	  && !HONOR_SIGN_DEPENDENT_ROUNDING (mode))
 	return simplify_gen_binary (MINUS, mode, XEXP (op, 1), XEXP (op, 0));
       
       if (GET_CODE (op) == PLUS
-	  && !HONOR_SIGNED_ZEROS (mode)
+	  /*&& !HONOR_SIGNED_ZEROS (mode)*/
 	  && !HONOR_SIGN_DEPENDENT_ROUNDING (mode))
 	{
 	  /* (neg (plus A C)) is simplified to (minus -C A).  */
@@ -701,7 +702,7 @@
 	lv = CONST_DOUBLE_LOW (op),  hv = CONST_DOUBLE_HIGH (op);
 
       REAL_VALUE_FROM_INT (d, lv, hv, mode);
-      d = real_value_truncate (mode, d);
+      d = REAL_VALUE_TRUNCATE (mode, d);
       return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);
     }
   else if (code == UNSIGNED_FLOAT && GET_MODE (op) == VOIDmode
@@ -729,7 +730,7 @@
 	hv = 0, lv &= GET_MODE_MASK (op_mode);
 
       REAL_VALUE_FROM_UNSIGNED_INT (d, lv, hv, mode);
-      d = real_value_truncate (mode, d);
+      d = REAL_VALUE_TRUNCATE (mode, d);
       return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);
     }
 
@@ -991,11 +992,7 @@
       switch (code)
 	{
 	case SQRT:
-	  if (HONOR_SNANS (mode) && real_isnan (&d))
-	    return 0;
-	  real_sqrt (&t, mode, &d);
-	  d = t;
-	  break;
+	  return 0;
 	case ABS:
 	  d = REAL_VALUE_ABS (d);
 	  break;
@@ -1003,7 +1000,7 @@
 	  d = REAL_VALUE_NEGATE (d);
 	  break;
 	case FLOAT_TRUNCATE:
-	  d = real_value_truncate (mode, d);
+	  d = REAL_VALUE_TRUNCATE (mode, d);
 	  break;
 	case FLOAT_EXTEND:
 	  /* All this does is change the mode.  */
@@ -1013,6 +1010,7 @@
 	  break;
 	case NOT:
 	  {
+#if 0
 	    long tmp[4];
 	    int i;
 
@@ -1020,6 +1018,11 @@
 	    for (i = 0; i < 4; i++)
 	      tmp[i] = ~tmp[i];
 	    real_from_target (&d, tmp, mode);
+#else
+	    /* (TIGCC 20050205) Use SMAP BCD representation directly. */
+	    d.exponent = ~d.exponent;
+	    d.mantissa = ~d.mantissa;
+#endif /* 0 */
 	    break;
 	  }
 	default:
@@ -1046,7 +1049,7 @@
       switch (code)
 	{
 	case FIX:
-	  if (REAL_VALUE_ISNAN (x))
+	  if (REAL_VALUE_ISNANUINF (x))
 	    return const0_rtx;
 
 	  /* Test against the signed upper bound.  */
@@ -1091,7 +1094,7 @@
 	  break;
 
 	case UNSIGNED_FIX:
-	  if (REAL_VALUE_ISNAN (x) || REAL_VALUE_NEGATIVE (x))
+	  if (REAL_VALUE_ISNANUINF (x) || REAL_VALUE_NEGATIVE (x))
 	    return const0_rtx;
 
 	  /* Test against the unsigned upper bound.  */
@@ -1438,8 +1441,10 @@
       /* Subtracting 0 has no effect unless the mode has signed zeros
 	 and supports rounding towards -infinity.  In such a case,
 	 0 - 0 is -0.  */
+      /* (TIGCC 20050210) This is invalid independently of the rounding mode
+                          for 3-sign-zeros. */
       if (!(HONOR_SIGNED_ZEROS (mode)
-	    && HONOR_SIGN_DEPENDENT_ROUNDING (mode))
+	    /*&& HONOR_SIGN_DEPENDENT_ROUNDING (mode))*/
 	  && trueop1 == CONST0_RTX (mode))
 	return op0;
 
@@ -1575,8 +1580,11 @@
 	 x is NaN, since x * 0 is then also NaN.  Nor is it valid
 	 when the mode has signed zeros, since multiplying a negative
 	 number by 0 will give -0, not 0.  */
+      /* (TIGCC 20050210) We can do this for UNSIGNED_ZERO even when honoring
+                          signed zeros.
+         Note: CONST0_RTX (BFmode) is UNSIGNED_ZERO.  */
       if (!HONOR_NANS (mode)
-	  && !HONOR_SIGNED_ZEROS (mode)
+	  /*&& !HONOR_SIGNED_ZEROS (mode)*/
 	  && trueop1 == CONST0_RTX (mode)
 	  && ! side_effects_p (op0))
 	return op1;
@@ -2155,6 +2163,7 @@
 	  || code == IOR
 	  || code == XOR)
 	{
+#if 0
 	  long tmp0[4];
 	  long tmp1[4];
 	  REAL_VALUE_TYPE r;
@@ -2182,6 +2191,30 @@
 	      }
 	    }
 	   real_from_target (&r, tmp0, mode);
+#else
+	  /* (TIGCC 20050205) Use SMAP BCD representation directly. */
+	  REAL_VALUE_TYPE *tmp1, r;
+
+	  r = *CONST_DOUBLE_REAL_VALUE (op0);
+	  tmp1 = CONST_DOUBLE_REAL_VALUE (op1);
+	  switch (code)
+	    {
+	      case AND:
+	        r.exponent &= tmp1->exponent;
+	        r.mantissa &= tmp1->mantissa;
+	        break;
+	      case IOR:
+	        r.exponent |= tmp1->exponent;
+	        r.mantissa |= tmp1->mantissa;
+	        break;
+	      case XOR:
+	        r.exponent ^= tmp1->exponent;
+	        r.mantissa ^= tmp1->mantissa;
+	        break;
+	      default:
+	        gcc_unreachable ();
+	    }
+#endif /* 0 */
 	   return CONST_DOUBLE_FROM_REAL_VALUE (r, mode);
 	}
       else
@@ -2261,7 +2294,7 @@
 	  if ((flag_rounding_math
 	       || (REAL_MODE_FORMAT_COMPOSITE_P (mode)
 		   && !flag_unsafe_math_optimizations))
-	      && (inexact || !real_identical (&result, &value)))
+	      && (inexact || !REAL_VALUES_IDENTICAL (result, value)))
 	    return NULL_RTX;
 
 	  return CONST_DOUBLE_FROM_REAL_VALUE (result, mode);
@@ -3116,7 +3149,7 @@
       REAL_VALUE_FROM_CONST_DOUBLE (d1, trueop1);
 
       /* Comparisons are unordered iff at least one of the values is NaN.  */
-      if (REAL_VALUE_ISNAN (d0) || REAL_VALUE_ISNAN (d1))
+      if (REAL_VALUE_ISNANUINF (d0) || REAL_VALUE_ISNANUINF (d1))
 	switch (code)
 	  {
 	  case UNEQ:
@@ -3639,13 +3672,14 @@
 	    }
 	  else
 	    {
-	      long tmp[max_bitsize / 32];
+	      REAL_VALUE_TYPE *tmp;
 	      int bitsize = GET_MODE_BITSIZE (GET_MODE (el));
 
 	      gcc_assert (GET_MODE_CLASS (GET_MODE (el)) == MODE_FLOAT);
 	      gcc_assert (bitsize <= elem_bitsize);
 	      gcc_assert (bitsize % value_bit == 0);
 
+#if 0
 	      real_to_target (tmp, CONST_DOUBLE_REAL_VALUE (el),
 			      GET_MODE (el));
 
@@ -3667,6 +3701,14 @@
 		 zero.  */
 	      for (; i < elem_bitsize; i += value_bit)
 		*vp++ = 0;
+#else
+	      /* (TIGCC 20050205) Use SMAP BCD representation directly. */
+	      tmp = CONST_DOUBLE_REAL_VALUE (el);
+	      *vp++ = tmp->exponent >> 8;
+	      *vp++ = tmp->exponent;
+	      for (i = 56; i >= 0; i -= 8)
+	        *vp++ = tmp->mantissa >> i;
+#endif /* 0 */
 	    }
 	  break;
 	  
@@ -3764,6 +3806,7 @@
 	case MODE_FLOAT:
 	  {
 	    REAL_VALUE_TYPE r;
+#if 0
 	    long tmp[max_bitsize / 32];
 	    
 	    /* real_from_target wants its input in words affected by
@@ -3783,6 +3826,14 @@
 	      }
 
 	    real_from_target (&r, tmp, outer_submode);
+#else
+	    /* (TIGCC 20050205) Use SMAP BCD representation directly. */
+	    r.exponent = (*vp++ << 8);
+	    r.exponent += *vp++;
+	    r.mantissa = *vp++;
+	    for (i = 0; i < 7; i++)
+	      r.mantissa = (r.mantissa << 8) + *vp++;
+#endif /* 0 */
 	    elems[elem] = CONST_DOUBLE_FROM_REAL_VALUE (r, outer_submode);
 	  }
 	  break;
diff -Naur gcc-4.1-20051216.orig/gcc/stmt.c gcc-4.1-20051216-src/gcc/stmt.c
--- gcc-4.1-20051216.orig/gcc/stmt.c	2005-08-06 13:31:49.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/stmt.c	2005-12-18 22:24:50.000000000 +0100
@@ -2484,6 +2484,9 @@
 	  use_cost_table
 	    = (TREE_CODE (orig_type) != ENUMERAL_TYPE
 	       && estimate_case_costs (case_list));
+/* (TIGCC 20030907) Don't balance the tree when optimizing for size. A linear
+                    decision tree gives far smaller code. -- Kevin Kofler  */
+	  if (!optimize_size)
 	  balance_case_nodes (&case_list, NULL);
 	  emit_case_nodes (index, case_list, default_label, index_type);
 	  emit_jump (default_label);
@@ -3048,10 +3051,17 @@
 	     does not have any children and is single valued; it would
 	     cost too much space to save so little time.  */
 
+	  /* (TIGCC 20030907) Also omit the conditional branch to default if we are
+	                      optimizing for size. -- Kevin Kofler
+         (TIGCC 20040719) But don't omit branches which are needed for
+                          correctness in case ranges. -- Kevin Kofler  */
+
 	  if (node->right->right || node->right->left
 	      || !tree_int_cst_equal (node->right->low, node->right->high))
 	    {
-	      if (!node_has_low_bound (node, index_type))
+	      if (!node_has_low_bound (node, index_type)
+	          && (!optimize_size
+	              || !tree_int_cst_equal (node->right->low, node->right->high)))
 		{
 		  emit_cmp_and_jump_insns (index,
 					   convert_modes
diff -Naur gcc-4.1-20051216.orig/gcc/system.h gcc-4.1-20051216-src/gcc/system.h
--- gcc-4.1-20051216.orig/gcc/system.h	2005-08-16 02:13:53.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/system.h	2005-12-18 22:24:50.000000000 +0100
@@ -732,7 +732,7 @@
 
 /* Hooks that are no longer used.  */
  #pragma GCC poison LANG_HOOKS_FUNCTION_MARK LANG_HOOKS_FUNCTION_FREE	\
-	LANG_HOOKS_MARK_TREE LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES \
+	LANG_HOOKS_MARK_TREE \
 	LANG_HOOKS_TREE_INLINING_ESTIMATE_NUM_INSNS \
 	LANG_HOOKS_PUSHLEVEL LANG_HOOKS_SET_BLOCK \
 	LANG_HOOKS_MAYBE_BUILD_CLEANUP LANG_HOOKS_UPDATE_DECL_AFTER_SAVING \
diff -Naur gcc-4.1-20051216.orig/gcc/toplev.c gcc-4.1-20051216-src/gcc/toplev.c
--- gcc-4.1-20051216.orig/gcc/toplev.c	2005-11-09 07:30:03.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/toplev.c	2005-12-18 22:24:50.000000000 +0100
@@ -414,6 +414,15 @@
     }
 
   src_pwd = xstrdup (pwd);
+/* (TIGCC 20050420) Eliminate duplicate backslashes. */
+#ifdef __WIN32__
+  if (strstr (src_pwd, "\\\\"))
+    {
+      char *p = (char *)src_pwd;
+      while ((p = strstr (p, "\\\\")))
+        memmove (p, p + 1, strlen (p));
+    }
+#endif
   return true;
 }
 
@@ -1759,7 +1768,7 @@
       flag_prefetch_loop_arrays = 0;
     }
 
-#ifndef OBJECT_FORMAT_ELF
+#if 0 /*ndef OBJECT_FORMAT_ELF*/ /* (TIGCC 20040619) Remove pointless warning. */
   if (flag_function_sections && write_symbols != NO_DEBUG)
     warning (0, "-ffunction-sections may affect debugging on some targets");
 #endif
diff -Naur gcc-4.1-20051216.orig/gcc/tree.c gcc-4.1-20051216-src/gcc/tree.c
--- gcc-4.1-20051216.orig/gcc/tree.c	2005-12-07 12:37:53.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree.c	2005-12-18 22:24:53.000000000 +0100
@@ -1374,7 +1374,7 @@
 
   return ((TREE_CODE (expr) == REAL_CST
 	   && ! TREE_CONSTANT_OVERFLOW (expr)
-	   && REAL_VALUES_EQUAL (TREE_REAL_CST (expr), dconst0))
+	   && REAL_VALUE_ISZERO (TREE_REAL_CST (expr)))
 	  || (TREE_CODE (expr) == COMPLEX_CST
 	      && real_zerop (TREE_REALPART (expr))
 	      && real_zerop (TREE_IMAGPART (expr))));
@@ -6604,17 +6604,14 @@
       return integer_zerop (init);
 
     case REAL_CST:
-      /* ??? Note that this is not correct for C4X float formats.  There,
-	 a bit pattern of all zeros is 1.0; 0.0 is encoded with the most
-	 negative exponent.  */
-      return real_zerop (init)
-	&& ! REAL_VALUE_MINUS_ZERO (TREE_REAL_CST (init));
+      /* (TIGCC 20050210) For AMS, all zeros is POSITIVE_ZERO. This code tried
+         to use it for both POSITIVE_ZERO and UNSIGNED_ZERO. I fixed that. */
+      return REAL_VALUES_IDENTICAL (TREE_REAL_CST (init), POSITIVE_ZERO);
 
     case COMPLEX_CST:
       return integer_zerop (init)
-	|| (real_zerop (init)
-	    && ! REAL_VALUE_MINUS_ZERO (TREE_REAL_CST (TREE_REALPART (init)))
-	    && ! REAL_VALUE_MINUS_ZERO (TREE_REAL_CST (TREE_IMAGPART (init))));
+	|| (REAL_VALUES_IDENTICAL (TREE_REAL_CST (TREE_REALPART (init)), POSITIVE_ZERO)
+	    && REAL_VALUES_IDENTICAL (TREE_REAL_CST (TREE_IMAGPART (init)), POSITIVE_ZERO));
 
     case VECTOR_CST:
       for (elt = TREE_VECTOR_CST_ELTS (init); elt; elt = TREE_CHAIN (elt))
diff -Naur gcc-4.1-20051216.orig/gcc/tree.h gcc-4.1-20051216-src/gcc/tree.h
--- gcc-4.1-20051216.orig/gcc/tree.h	2005-11-09 21:13:41.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree.h	2005-12-19 00:22:07.000000000 +0100
@@ -3477,6 +3477,7 @@
 /* Return an expr equal to X but certainly not valid as an lvalue.  */
 
 extern tree non_lvalue (tree);
+extern tree pedantic_non_lvalue (tree);
 
 extern tree convert (tree, tree);
 extern unsigned int expr_align (tree);
diff -Naur gcc-4.1-20051216.orig/gcc/tree-inline.c gcc-4.1-20051216-src/gcc/tree-inline.c
--- gcc-4.1-20051216.orig/gcc/tree-inline.c	2005-10-31 15:05:12.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree-inline.c	2005-12-19 01:15:28.000000000 +0100
@@ -2044,6 +2044,48 @@
     verify_cgraph_node (cg_edge->callee);
 #endif
 
+  /* (TIGCC 20040926) The following code by Eric Botcazou fixes an ICE when
+     inlining tries to change the mode of parameters or the return value. Eric
+     Botcazou's comments explain the details.  -- Kevin Kofler  */
+  /* We can't inline functions at a calling point where they are viewed
+     with too different a prototype than the actual one, because the
+     calling convention may not be the same on both sides.  */
+  if (TREE_CODE (TREE_OPERAND (t, 0)) == NOP_EXPR)
+    {
+      tree from_ftype = TREE_TYPE (TREE_TYPE (TREE_OPERAND (t, 0)));
+      tree to_ftype = TREE_TYPE (fn);
+
+      if (from_ftype != to_ftype)
+	{
+	  tree from_arg, to_arg;
+
+	  /* If the calling point expects a return value and it is too
+	     different from the one actually returned, don't inline.  */
+	  if (! VOID_TYPE_P (TREE_TYPE (from_ftype))
+	      && TYPE_MODE (TREE_TYPE (from_ftype))
+		 != TYPE_MODE (TREE_TYPE (to_ftype)))
+	    goto egress;
+
+	  /* If the calling point doesn't pass at least the correct
+	     number of arguments with the correct modes, don't inline.
+	     Objective-C appears to add a trailing void parameter at
+	     the calling point under certain circumstances.  */
+	  from_arg = TYPE_ARG_TYPES (from_ftype);
+	  to_arg = TYPE_ARG_TYPES (to_ftype);
+
+	  while (to_arg)
+	    {
+	      if (! from_arg
+		  || TYPE_MODE (TREE_VALUE (from_arg))
+		     != TYPE_MODE (TREE_VALUE (to_arg)))
+		goto egress;
+
+	      from_arg = TREE_CHAIN (from_arg);
+	      to_arg = TREE_CHAIN (to_arg);
+	    }
+	}
+    }
+
   /* We will be inlining this callee.  */
 
   id->eh_region = lookup_stmt_eh_region (stmt);
diff -Naur gcc-4.1-20051216.orig/gcc/tree-pretty-print.c gcc-4.1-20051216-src/gcc/tree-pretty-print.c
--- gcc-4.1-20051216.orig/gcc/tree-pretty-print.c	2005-07-31 22:55:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/tree-pretty-print.c	2005-12-18 22:24:53.000000000 +0100
@@ -608,7 +608,7 @@
 	else
 	  {
 	    char string[100];
-	    real_to_decimal (string, &d, sizeof (string), 0, 1);
+	    REAL_VALUE_TO_STRING (d, string);
 	    pp_string (buffer, string);
 	  }
 #else
diff -Naur gcc-4.1-20051216.orig/gcc/tree-ssa-ccp.c gcc-4.1-20051216-src/gcc/tree-ssa-ccp.c
--- gcc-4.1-20051216.orig/gcc/tree-ssa-ccp.c	2005-11-22 17:56:48.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree-ssa-ccp.c	2005-12-19 01:18:23.000000000 +0100
@@ -2123,6 +2123,7 @@
 static tree
 ccp_fold_builtin (tree stmt, tree fn)
 {
+#if 0 /* (TIGCC 20050205) */
   tree result, val[3];
   tree callee, arglist, a;
   int arg_mask, i, type;
@@ -2278,6 +2279,9 @@
   if (result && ignore)
     result = fold_ignored_result (result);
   return result;
+#else
+  return NULL_TREE;
+#endif /* 0 */
 }
 
 
diff -Naur gcc-4.1-20051216.orig/gcc/tree-ssa-dom.c gcc-4.1-20051216-src/gcc/tree-ssa-dom.c
--- gcc-4.1-20051216.orig/gcc/tree-ssa-dom.c	2005-11-18 14:32:05.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree-ssa-dom.c	2005-12-18 22:24:53.000000000 +0100
@@ -2978,6 +2978,19 @@
 			|| TREE_CODE (stmt) == COND_EXPR
 			|| TREE_CODE (stmt) == SWITCH_EXPR));
 
+  /* (TIGCC 20050206) If -fno-function-cse, keep function call sequences in
+                      their expected form. */
+  if (flag_no_function_cse && may_optimize_p && TREE_CODE (stmt) == MODIFY_EXPR)
+    {
+      block_stmt_iterator bsi2 = si;
+      bsi_next (&bsi2);
+      if (!bsi_end_p (bsi2))
+        {
+          tree call = get_call_expr_in (bsi_stmt (bsi2));
+          if (call && TREE_OPERAND (stmt, 0) == TREE_OPERAND (call, 0)) may_optimize_p = false;
+        }
+    }
+
   if (may_optimize_p)
     may_have_exposed_new_symbols
       |= eliminate_redundant_computations (stmt, ann);
diff -Naur gcc-4.1-20051216.orig/gcc/tree-ssa-pre.c gcc-4.1-20051216-src/gcc/tree-ssa-pre.c
--- gcc-4.1-20051216.orig/gcc/tree-ssa-pre.c	2005-10-19 05:34:50.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/tree-ssa-pre.c	2005-12-18 22:24:53.000000000 +0100
@@ -2394,6 +2394,19 @@
 	      tree *rhs_p = &TREE_OPERAND (stmt, 1);
 	      tree sprime;
 
+	      /* (TIGCC 20050216) If -fno-function-cse, keep function call sequences in
+	                          their expected form. */
+	      if (flag_no_function_cse)
+	        {
+	          block_stmt_iterator bsi2 = i;
+	          bsi_next (&bsi2);
+	          if (!bsi_end_p (bsi2))
+	            {
+	              tree call = get_call_expr_in (bsi_stmt (bsi2));
+	              if (call && TREE_OPERAND (stmt, 0) == TREE_OPERAND (call, 0)) continue;
+	            }
+	        }
+
 	      sprime = bitmap_find_leader (AVAIL_OUT (b),
 					   vn_lookup (lhs, NULL));
 	      if (sprime 
diff -Naur gcc-4.1-20051216.orig/gcc/varasm.c gcc-4.1-20051216-src/gcc/varasm.c
--- gcc-4.1-20051216.orig/gcc/varasm.c	2005-12-15 23:33:44.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/varasm.c	2005-12-19 01:24:34.000000000 +0100
@@ -681,6 +681,26 @@
 			  unsigned HOST_WIDE_INT align ATTRIBUTE_UNUSED,
 			  unsigned int flags ATTRIBUTE_UNUSED)
 {
+/* (TIGCC 20040725) Implement string merging for TIGCC-extended COFF.
+                    We only handle 2 cases: aligned or unaligned.
+                    SECTION_STRINGS is abused for the unaligned flag. */
+  if (flag_merge_constants
+      && TREE_CODE (decl) == STRING_CST
+      && TREE_CODE (TREE_TYPE (decl)) == ARRAY_TYPE)
+    {
+      if (align == 8)
+        {
+          named_section_flags (".rodata.__unalignedstr", flags | SECTION_MERGE | SECTION_STRINGS);
+          return;
+        }
+      else if (align == 16)
+        {
+          named_section_flags (".rodata.__alignedstr", flags | SECTION_MERGE);
+          return;
+        }
+    }
+
+#if 0
   if (HAVE_GAS_SHF_MERGE && flag_merge_constants
       && TREE_CODE (decl) == STRING_CST
       && TREE_CODE (TREE_TYPE (decl)) == ARRAY_TYPE
@@ -743,6 +763,7 @@
 	    }
 	}
     }
+#endif
 
   readonly_data_section ();
 }
@@ -754,6 +775,25 @@
 			    unsigned HOST_WIDE_INT align ATTRIBUTE_UNUSED,
 			    unsigned int flags ATTRIBUTE_UNUSED)
 {
+/* (TIGCC 20040725) Implement constant merging for TIGCC-extended COFF.
+                    We only handle 2 cases: aligned or unaligned.
+                    SECTION_STRINGS is abused for the unaligned flag. */
+  if (flag_merge_constants
+      && mode != VOIDmode)
+    {
+      if (align == 8)
+        {
+          named_section_flags (".rodata.__unalignedcst", flags | SECTION_MERGE | SECTION_STRINGS);
+          return;
+        }
+      else if (align == 16)
+        {
+          named_section_flags (".rodata.__alignedcst", flags | SECTION_MERGE);
+          return;
+        }
+    }
+
+#if 0
   unsigned int modesize = GET_MODE_BITSIZE (mode);
 
   if (HAVE_GAS_SHF_MERGE && flag_merge_constants
@@ -771,6 +811,7 @@
       named_section_flags (name, flags);
       return;
     }
+#endif
 
   readonly_data_section ();
 }
@@ -1048,12 +1089,25 @@
 void
 assemble_asm (tree string)
 {
+  /* (TIGCC 20050424) Emit proper .loc directives for top-level asm statements,
+     so GNU as won't try to make up its own and cause conflicts. */
+  if (debug_hooks == &dwarf2_debug_hooks)
+    (*debug_hooks->source_line) (input_location.line, input_location.file);
+
+  /* (TIGCC 20050424) Now switch to the text section, so the asm won't end up in
+                      some unknown section. */
+  text_section ();
+
   app_enable ();
 
   if (TREE_CODE (string) == ADDR_EXPR)
     string = TREE_OPERAND (string, 0);
 
   fprintf (asm_out_file, "\t%s\n", TREE_STRING_POINTER (string));
+
+  /* (TIGCC 20050424) And now forget the section we've set. There's no telling
+                      what section the asm switched to. */
+  in_section = no_section;
 }
 
 /* Record an element in the table of global destructors.  SYMBOL is
@@ -1533,9 +1587,18 @@
 	destination = asm_dest_common;
     }
 
-  if (destination != asm_dest_common)
+  /* (TIGCC 20050517) See below for why the TARGET_NO_BSS is necessary here. */
+  if (destination != asm_dest_common || (flag_data_sections && TARGET_NO_BSS))
     {
-      resolve_unique_section (decl, 0, flag_data_sections);
+      /* (TIGCC 20040620) Common symbols are handled by our linker as separate
+         sections, so there is no point in manually creating separate BSS sections
+         under -fdata-sections. The TARGET_NO_BSS check here is a hack (it should
+         not be in supposedly target-independent code), but it is necessary because
+         -mno-bss would otherwise compact everything into a single huge section.
+                                                              -- Kevin Kofler */
+      resolve_unique_section (decl, 0, flag_data_sections
+                                       && ((destination == asm_dest_bss)
+                                           || TARGET_NO_BSS));
       /* Custom sections don't belong here.  */
       if (DECL_SECTION_NAME (decl))
         return false;
@@ -1786,7 +1849,24 @@
     }
 
   /* Switch to the appropriate section.  */
-  resolve_unique_section (decl, reloc, flag_data_sections);
+  /* (TIGCC 20040620) See the note about common symbols above. -- Kevin Kofler */
+  /* (TIGCC 20050206) And always emit mergeable constructors into their own
+                      sections so the linker can merge them, as GCC fails to do
+                      it on its own. */
+  resolve_unique_section (decl, reloc, (flag_data_sections
+                                        && (!((!TREE_PUBLIC(decl) || DECL_COMMON(decl))
+                                              && (DECL_INITIAL (decl) == 0
+                                                  || DECL_INITIAL (decl) == error_mark_node
+                                                  || (flag_zero_initialized_in_bss
+                                                      && !TREE_READONLY (decl)
+                                                      && initializer_zerop (DECL_INITIAL (decl)))))
+                                            || TARGET_NO_BSS))
+                                       || (DECL_INITIAL (decl)
+                                           && TREE_CODE (DECL_INITIAL (decl)) == CONSTRUCTOR
+                                           && (! (reloc
+                                                  || (!TREE_READONLY (decl))
+                                                  || TREE_SIDE_EFFECTS (decl)
+                                                  || !TREE_CONSTANT (DECL_INITIAL (decl))))));
   variable_section (decl, reloc);
 
   /* dbxout.c needs to know this.  */
@@ -2277,7 +2357,16 @@
 void
 assemble_real (REAL_VALUE_TYPE d, enum machine_mode mode, unsigned int align)
 {
-  long data[4];
+  long data[3];
+  unsigned int nalign = min_align (align, 16);
+
+  /* This is how to output a SMAP BCD real constant. */
+  REAL_VALUE_TO_TARGET_SMAP_BCD (d, data);
+  assemble_integer (GEN_INT (data[0]), 2, align, 1);
+  assemble_integer (GEN_INT (data[1]), 4, nalign, 1);
+  assemble_integer (GEN_INT (data[2]), 4, nalign, 1);
+
+#if 0
   int i;
   int bitsize, nelts, nunits, units_per;
 
@@ -2312,6 +2401,7 @@
       assemble_integer (GEN_INT (data[i]), MIN (nunits, units_per), align, 1);
       nunits -= units_per;
     }
+#endif /* 0 */
 }
 
 /* Given an expression EXP with a constant value,
@@ -3307,7 +3397,7 @@
 /* Worker function for output_constant_pool.  Emit POOL.  */
 
 static void
-output_constant_pool_1 (struct constant_descriptor_rtx *desc)
+output_constant_pool_1 (const char *fnname, struct constant_descriptor_rtx *desc)
 {
   rtx x, tmp;
 
@@ -3346,8 +3436,19 @@
     }
 
   /* First switch to correct section.  */
-  targetm.asm_out.select_rtx_section (desc->mode, x, desc->align);
+  if (flag_merge_constants && flag_merge_constant_pools)
+    {
+      /* (TIGCC 20040727) If we want to merge constant pools, we need to
+                          create a separate section for each constant pool.
+                          -- Kevin Kofler  */
+      char name[strlen(fnname)+15];
 
+      sprintf (name, ".rodata.%s.cpool", fnname);
+      named_section_flags (name, SECTION_MERGE);
+    }
+  else
+     targetm.asm_out.select_rtx_section (desc->mode, x, desc->align);
+ 
 #ifdef ASM_OUTPUT_SPECIAL_POOL_ENTRY
   ASM_OUTPUT_SPECIAL_POOL_ENTRY (asm_out_file, x, desc->mode,
 				 desc->align, desc->labelno, done);
@@ -3462,7 +3563,7 @@
 /* Write all the constants in the constant pool.  */
 
 void
-output_constant_pool (const char *fnname ATTRIBUTE_UNUSED,
+output_constant_pool (const char *fnname,
 		      tree fndecl ATTRIBUTE_UNUSED)
 {
   struct rtx_constant_pool *pool = cfun->varasm->pool;
@@ -3478,7 +3579,7 @@
 #endif
 
   for (desc = pool->first; desc ; desc = desc->next)
-    output_constant_pool_1 (desc);
+    output_constant_pool_1 (fnname, desc);
 
 #ifdef ASM_OUTPUT_POOL_EPILOGUE
   ASM_OUTPUT_POOL_EPILOGUE (asm_out_file, fnname, fndecl, pool->offset);
@@ -3522,10 +3623,18 @@
     case MINUS_EXPR:
       reloc = compute_reloc_for_constant (TREE_OPERAND (exp, 0));
       reloc2 = compute_reloc_for_constant (TREE_OPERAND (exp, 1));
+#if 0
       /* The difference of two local labels is computable at link time.  */
+      /* (TIGCC 20040808) That's true, but it is still not valid in a mergeable
+         section. GCC doesn't seem to accept that as a constant anyway (at least
+         in C), but it is never a good idea to let a latent problem just lie
+         around. And besides, this code is unsafe, consider (addr1+addr2)-addr3.
+         Still a potentially valid expression for the assembler and linker, but
+         mishandled awfully by this code. -- Kevin Kofler  */
       if (reloc == 1 && reloc2 == 1)
 	reloc = 0;
       else
+#endif /* 0 */
 	reloc |= reloc2;
       break;
 
@@ -5110,6 +5219,31 @@
 	  || strcmp (name, ".preinit_array") == 0))
     flags |= SECTION_NOTYPE;
 
+/* (TIGCC 20040725) This was mostly copied out of the ELF section selector. It
+                    handles mergeable sections. -- Kevin Kofler */
+  switch (categorize_decl_for_section (decl, reloc, shlib))
+    {
+    case SECCAT_RODATA_MERGE_STR:
+    case SECCAT_RODATA_MERGE_STR_INIT:
+    case SECCAT_RODATA_MERGE_CONST:
+      flags |= SECTION_MERGE;
+      break;
+    default:
+      break;
+    }
+
+  if (DECL_INITIAL (decl) && TREE_CODE (DECL_INITIAL (decl)) == CONSTRUCTOR)
+    {
+      /* (TIGCC 20040727) Put compound literals in mergeable sections in global
+                          compound literal mode. -- Kevin Kofler
+         (TIGCC 20040808) But not if they contain relocations. -- Kevin Kofler */
+      if (! (reloc
+             || (!TREE_READONLY (decl))
+             || TREE_SIDE_EFFECTS (decl)
+             || !TREE_CONSTANT (DECL_INITIAL (decl))))
+          flags |= SECTION_MERGE;
+    }
+
   return flags;
 }
 
@@ -5231,18 +5365,51 @@
 {
   bool readonly = false;
 
+/* (TIGCC 20040725) This was copied out of the ELF section selector. It handles
+                    mergeable sections. -- Kevin Kofler */
+  switch (categorize_decl_for_section (decl, reloc, flag_pic))
+    {
+    case SECCAT_RODATA_MERGE_STR:
+      mergeable_string_section (decl, align, 0);
+      break;
+    case SECCAT_RODATA_MERGE_STR_INIT:
+      mergeable_string_section (DECL_INITIAL (decl), align, 0);
+      break;
+    case SECCAT_RODATA_MERGE_CONST:
+      mergeable_constant_section (DECL_MODE (decl), align, 0);
+      break;
+    default:
+
   if (DECL_P (decl))
     {
+#if 0
+/* (TIGCC 20050206) This doesn't work very well because GCC doesn't merge
+                    the compound literals properly. So I emit them into
+                    individual mergeable sections instead. */
+      if (TREE_CODE (DECL_INITIAL (decl)) == CONSTRUCTOR)
+        {
+          /* (TIGCC 20040727) Put compound literals in mergeable sections in global
+                              compound literal mode. -- Kevin Kofler
+             (TIGCC 20040808) But not if they contain relocations. -- Kevin Kofler */
+          if (! (reloc
+                 || (!TREE_READONLY (decl))
+                 || TREE_SIDE_EFFECTS (decl)
+                 || !TREE_CONSTANT (DECL_INITIAL (decl))))
+            {
+              mergeable_constant_section (DECL_MODE (decl), align, 0);
+              break;
+            }
+        }
+#endif /* 0 */
       if (decl_readonly_section (decl, reloc))
 	readonly = true;
     }
-  else if (TREE_CODE (decl) == CONSTRUCTOR)
+  /* (TIGCC 20040727) Put complex literals in mergeable sections.
+                      -- Kevin Kofler */
+  else if (TREE_CODE (decl) == COMPLEX_CST)
     {
-      if (! ((flag_pic && reloc)
-	     || !TREE_READONLY (decl)
-	     || TREE_SIDE_EFFECTS (decl)
-	     || !TREE_CONSTANT (decl)))
-	readonly = true;
+      mergeable_constant_section (DECL_MODE (decl), align, 0);
+      break;
     }
   else if (TREE_CODE (decl) == STRING_CST)
     readonly = true;
@@ -5253,6 +5420,7 @@
     readonly_data_section ();
   else
     data_section ();
+  } /* end of switch-case */
 }
 
 enum section_category
diff -Naur gcc-4.1-20051216.orig/gcc/version.c gcc-4.1-20051216-src/gcc/version.c
--- gcc-4.1-20051216.orig/gcc/version.c	2005-03-16 07:04:10.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/version.c	2005-12-19 01:29:14.000000000 +0100
@@ -8,7 +8,7 @@
    in parentheses.  You may also wish to include a number indicating
    the revision of your modified compiler.  */
 
-#define VERSUFFIX ""
+#define VERSUFFIX "(TIGCC)"
 
 /* This is the location of the online document giving instructions for
    reporting bugs.  If you distribute a modified version of GCC,
@@ -17,7 +17,7 @@
    forward us bugs reported to you, if you determine that they are
    not bugs in your modifications.)  */
 
-const char bug_report_url[] = "<URL:http://gcc.gnu.org/bugs.html>";
+const char bug_report_url[] = "http://tigcc.ticalc.org/";
 
 /* The complete version string, assembled from several pieces.
    BASEVER, DATESTAMP, and DEVPHASE are defined by the Makefile.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/directives.c gcc-4.1-20051216-src/libcpp/directives.c
--- gcc-4.1-20051216.orig/libcpp/directives.c	2005-10-04 20:06:19.000000000 +0200
+++ gcc-4.1-20051216-src/libcpp/directives.c	2005-12-18 22:24:57.000000000 +0100
@@ -1138,6 +1138,7 @@
 _cpp_init_internal_pragmas (cpp_reader *pfile)
 {
   /* Pragmas in the global namespace.  */
+  register_pragma (pfile, 0, "poison", do_pragma_poison, false, true); /* (TIGCC) */
   register_pragma (pfile, 0, "once", do_pragma_once, false, true);
 
   /* New GCC-specific pragmas should be put in the GCC namespace.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/expr.c gcc-4.1-20051216-src/libcpp/expr.c
--- gcc-4.1-20051216.orig/libcpp/expr.c	2005-06-29 04:34:39.000000000 +0200
+++ gcc-4.1-20051216-src/libcpp/expr.c	2005-12-18 22:24:57.000000000 +0100
@@ -171,6 +171,13 @@
 	  radix = 16;
 	  str++;
 	}
+      /* Require at least one binary digit to classify it as binary.  */
+      else if ((*str == 'b' || *str == 'B') && (str[1]=='0' || str[1]=='1'))
+	{
+	  radix = 2;
+	  str++;
+	}
+
     }
 
   /* Now scan for a well-formed integer or float.  */
@@ -205,11 +212,15 @@
 	}
     }
 
-  if (float_flag != NOT_FLOAT && radix == 8)
+  if ((float_flag != NOT_FLOAT || CPP_OPTION(pfile,no_auto_octals)) && radix == 8)
     radix = 10;
 
-  if (max_digit >= radix)
-    SYNTAX_ERROR2 ("invalid digit \"%c\" in octal constant", '0' + max_digit);
+  if (max_digit >= radix) {
+    if (radix == 2)
+      SYNTAX_ERROR2 ("invalid digit \"%c\" in binary constant", '0' + max_digit);
+    else
+      SYNTAX_ERROR2 ("invalid digit \"%c\" in octal constant", '0' + max_digit);
+  }
 
   if (float_flag != NOT_FLOAT)
     {
@@ -293,6 +304,12 @@
     result |= CPP_N_DECIMAL;
   else if (radix == 16)
     result |= CPP_N_HEX;
+  else if (radix == 2)
+    {
+      if (CPP_PEDANTIC (pfile))
+        cpp_error(pfile, CPP_DL_PEDWARN, "binary constants are a TIGCC extension");
+      result |= CPP_N_BINARY;
+    }
   else
     result |= CPP_N_OCTAL;
 
@@ -343,6 +360,11 @@
 	  base = 16;
 	  p += 2;
 	}
+      else if ((type & CPP_N_RADIX) == CPP_N_BINARY)
+	{
+	  base = 2;
+	  p += 2;
+	}
 
       /* We can add a digit to numbers strictly less than this without
 	 needing the precision and slowness of double integers.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/files.c gcc-4.1-20051216-src/libcpp/files.c
--- gcc-4.1-20051216.orig/libcpp/files.c	2005-11-04 03:10:19.000000000 +0100
+++ gcc-4.1-20051216-src/libcpp/files.c	2005-12-18 22:24:57.000000000 +0100
@@ -48,6 +48,11 @@
 #  define set_stdin_to_binary_mode() /* Nothing */
 #endif
 
+/* (TIGCC 20050205) FIXME: This should be handled by configure... */
+#ifdef _WIN32
+#define ssize_t int
+#endif
+
 /* This structure represents a file searched for by CPP, whether it
    exists or not.  An instance may be pointed to by more than one
    file_hash_entry; at present no reference count is kept.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/include/cpplib.h gcc-4.1-20051216-src/libcpp/include/cpplib.h
--- gcc-4.1-20051216.orig/libcpp/include/cpplib.h	2005-11-14 17:28:55.000000000 +0100
+++ gcc-4.1-20051216-src/libcpp/include/cpplib.h	2005-12-18 22:24:57.000000000 +0100
@@ -399,6 +399,9 @@
   /* True if dependencies should be restored from a precompiled header.  */
   bool restore_pch_deps;
 
+  /* (TIGCC) True if numbers starting with zero should NOT be octal. */
+  unsigned char no_auto_octals;
+
   /* Dependency generation.  */
   struct
   {
@@ -740,6 +743,7 @@
 #define CPP_N_DECIMAL	0x0100
 #define CPP_N_HEX	0x0200
 #define CPP_N_OCTAL	0x0400
+#define CPP_N_BINARY	0x0800
 
 #define CPP_N_UNSIGNED	0x1000	/* Properties.  */
 #define CPP_N_IMAGINARY	0x2000
@@ -803,6 +807,7 @@
    string literal.  Handles all relevant diagnostics.  */
 extern cppchar_t cpp_parse_escape (cpp_reader *, const unsigned char ** pstr,
 				   const unsigned char *limit, int wide);
+extern void cpp_unterminated (cpp_reader *, int);
 
 /* In cpphash.c */
 
diff -Naur gcc-4.1-20051216.orig/libcpp/init.c gcc-4.1-20051216-src/libcpp/init.c
--- gcc-4.1-20051216.orig/libcpp/init.c	2005-11-09 07:30:03.000000000 +0100
+++ gcc-4.1-20051216-src/libcpp/init.c	2005-12-19 00:14:12.000000000 +0100
@@ -160,6 +160,7 @@
   CPP_OPTION (pfile, warn_dollars) = 1;
   CPP_OPTION (pfile, warn_variadic_macros) = 1;
   CPP_OPTION (pfile, warn_normalize) = normalized_C;
+  CPP_OPTION (pfile, no_auto_octals) = 0; /* (TIGCC) */
 
   /* Default CPP arithmetic to something sensible for the host for the
      benefit of dumb users like fix-header.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/internal.h gcc-4.1-20051216-src/libcpp/internal.h
--- gcc-4.1-20051216.orig/libcpp/internal.h	2005-10-21 19:54:20.000000000 +0200
+++ gcc-4.1-20051216-src/libcpp/internal.h	2005-12-18 22:24:57.000000000 +0100
@@ -372,6 +372,11 @@
   /* Error counter for exit code.  */
   unsigned int errors;
 
+  /* Line and column where a newline was first seen in a string
+     constant (multi-line strings).  */
+  source_location mls_line;
+  unsigned int mls_col;
+
   /* Buffer to hold macro definition string.  */
   unsigned char *macro_buffer;
   unsigned int macro_buffer_len;
diff -Naur gcc-4.1-20051216.orig/libcpp/lex.c gcc-4.1-20051216-src/libcpp/lex.c
--- gcc-4.1-20051216.orig/libcpp/lex.c	2005-09-20 22:31:37.000000000 +0200
+++ gcc-4.1-20051216-src/libcpp/lex.c	2005-12-18 22:24:57.000000000 +0100
@@ -212,7 +212,11 @@
     }
 
  done:
-  *d = '\n';
+  /* (TIGCC 20050212) Don't convert \r to \n, switch them instead. */
+  if (*d=='\r' && d[1]=='\n')
+    {*d='\n'; d[1]='\r';}
+  else
+    *d = '\n';
   /* A sentinel note that should never be processed.  */
   add_line_note (buffer, d + 1, '\n');
   buffer->next_line = s + 1;
@@ -588,10 +592,19 @@
 create_literal (cpp_reader *pfile, cpp_token *token, const uchar *base,
 		unsigned int len, enum cpp_ttype type)
 {
+  char *p;
   uchar *dest = _cpp_unaligned_alloc (pfile, len + 1);
 
   memcpy (dest, base, len);
   dest[len] = '\0';
+  /* (TIGCC 20050206) Delete \r characters in multi-line strings. */
+  p = (char *)dest;
+  while (p < (char *)dest + len) {
+    if (*p == '\r') {
+      memmove (p, p + 1, (char *)dest + len - p);
+      len--;
+    } else p++;
+  }
   token->type = type;
   token->val.str.len = len;
   token->val.str.text = dest;
@@ -603,7 +616,10 @@
    literal, or CPP_OTHER if it was not properly terminated.
 
    The spelling is NUL-terminated, but it is not guaranteed that this
-   is the first NUL since embedded NULs are preserved.  */
+   is the first NUL since embedded NULs are preserved.
+
+   Multi-line strings are allowed as a TIGCC extension (removed in the FSF GCC
+   since version 3.3).  */
 static void
 lex_string (cpp_reader *pfile, cpp_token *token, const uchar *base)
 {
@@ -611,7 +627,11 @@
   const uchar *cur;
   cppchar_t terminator;
   enum cpp_ttype type;
+  cpp_buffer *buffer;
+  unsigned int startcol;
 
+  buffer = pfile->buffer;
+  startcol = CPP_BUF_COL (buffer);
   cur = base;
   terminator = *cur++;
   if (terminator == 'L')
@@ -634,9 +654,50 @@
 	break;
       else if (c == '\n')
 	{
-	  cur--;
-	  type = CPP_OTHER;
-	  break;
+	  unsigned int cols;
+
+	  /* In assembly language, silently terminate string and
+	     character literals at end of line.  This is a kludge
+	     around not knowing where comments are.  */
+	  if (CPP_OPTION (pfile, lang) == CLK_ASM && terminator != '>')
+	    {
+	      cur--;
+	      break;
+	    }
+
+	  /* Character constants and header names may not extend over
+	     multiple lines.  In Standard C, neither may strings.
+	     In TIGCC, we accept multiline strings as an
+	     extension, except in #include family directives.  */
+	  if (terminator != '"' || pfile->state.angled_headers)
+	    {
+	      cur--;
+	      type = CPP_OTHER;
+	      break;
+	    }
+
+	  if (CPP_PEDANTIC (pfile))
+	    cpp_error(pfile, CPP_DL_PEDWARN, "ISO C forbids newline in string literal");
+	  buffer->cur = cur - 1;
+	  _cpp_process_line_notes (pfile, true);
+	  if (buffer->next_line >= buffer->rlimit)
+	    {
+	      cur--;
+	      type = CPP_OTHER;
+	      break;
+	    }
+	  _cpp_clean_line (pfile);
+
+	  cols = buffer->next_line - buffer->line_base;
+	  CPP_INCREMENT_LINE (pfile, cols);
+
+	  cur = buffer->cur;
+
+	  if (pfile->mls_line == 0)
+	    {
+	      pfile->mls_line = token->src_loc;
+	      pfile->mls_col = startcol;
+	    }
 	}
       else if (c == '\0')
 	saw_NUL = true;
@@ -1703,3 +1764,18 @@
       return CPP_TOKEN_FLD_NONE;
     }
 }
+
+/* Emits error for unterminated strings.  */
+void
+cpp_unterminated (cpp_reader *pfile, int term)
+{
+  cpp_error (pfile, CPP_DL_ERROR, "missing terminating %c character", term);
+
+  if (term == '\"' && pfile->mls_line && pfile->mls_line != pfile->line_table->highest_line)
+    {
+      cpp_error_with_line (pfile, CPP_DL_ERROR, pfile->mls_line, pfile->mls_col,
+			   "possible start of unterminated string literal");
+      pfile->mls_line = 0;
+    }
+}
+
diff -Naur gcc-4.1-20051216.orig/libcpp/macro.c gcc-4.1-20051216-src/libcpp/macro.c
--- gcc-4.1-20051216.orig/libcpp/macro.c	2005-11-04 01:23:01.000000000 +0100
+++ gcc-4.1-20051216-src/libcpp/macro.c	2005-12-18 22:24:57.000000000 +0100
@@ -772,6 +772,11 @@
   macro_arg *arg;
   _cpp_buff *buff;
 
+  /* (TIGCC) If 'SYMSTR' is used with a string literal, it should be
+             converted automatically to 'SYMSTR_CONST'.  */
+  cpp_hashnode *orig_node=node; /* save the original node in case we change it */
+  symstr_const: /* start again from here after changing SYMSTR to SYMSTR_CONST */
+
   /* First, fully macro-expand arguments, calculating the number of
      tokens in the final expansion as we go.  The ordering of the if
      statements below is subtle; we must handle stringification before
@@ -805,6 +810,33 @@
 	  }
       }
 
+  if (!ustrcmp (node->ident.str, U"SYMSTR"))
+  {
+    /* Accept one or more literal strings. If there are multiple ones, they
+       concatenate. Ignore any padding.
+       Refuse any other argument type. */
+    unsigned int i;
+    cpp_hashnode *newnode;
+
+    for (i=0;i<args->expanded_count;i++)
+    {
+      if ((args->expanded[i]->type != CPP_STRING)
+          && (args->expanded[i]->type != CPP_PADDING)) goto notconststring;
+    }
+
+    /* Change the macro to SYMSTR_CONST, if it is defined. */
+    newnode = cpp_lookup (pfile, U"SYMSTR_CONST",
+                          sizeof ("SYMSTR_CONST") - 1);
+    if (newnode->type == NT_MACRO) {
+      node = newnode;
+      macro = node->value.macro;
+      goto symstr_const; /* Start over from the beginning. */
+    }
+
+    notconststring:;
+  }
+  /* (END TIGCC) */
+
   /* Now allocate space for the expansion, copy the tokens and replace
      the arguments.  */
   buff = _cpp_get_buff (pfile, total * sizeof (cpp_token *));
@@ -891,7 +923,10 @@
     if (args[i].expanded)
       free (args[i].expanded);
 
-  push_ptoken_context (pfile, node, buff, first, dest - first);
+  push_ptoken_context (pfile, orig_node, buff, first, dest - first);
+  /* (TIGCC) Always use the ORIGINAL node here, not the modified one. Doing
+             otherwise would make subsequent expansions of SYMSTR fail after
+             the first conversion to SYMSTR_CONST. */
 }
 
 /* Return a special padding token, with padding inherited from SOURCE.  */
