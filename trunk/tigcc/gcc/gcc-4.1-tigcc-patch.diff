diff -Naur gcc-4.1-20051216.orig/config.guess gcc-4.1-20051216-src/config.guess
--- gcc-4.1-20051216.orig/config.guess	2005-11-24 13:49:42.000000000 +0100
+++ gcc-4.1-20051216-src/config.guess	2005-12-18 22:33:47.000000000 +0100
@@ -770,11 +770,11 @@
 	echo ${UNAME_MACHINE}-pc-cygwin
 	exit ;;
     i*:MINGW*:*)
-	echo ${UNAME_MACHINE}-pc-mingw32
+	echo i386-pc-mingw32
 	exit ;;
     i*:windows32*:*)
     	# uname -m includes "-pc" on this system.
-    	echo ${UNAME_MACHINE}-mingw32
+    	echo i386-pc-mingw32
 	exit ;;
     i*:PW*:*)
 	echo ${UNAME_MACHINE}-pc-pw32
diff -Naur gcc-4.1-20051216.orig/gcc/attribs.c gcc-4.1-20051216-src/gcc/attribs.c
--- gcc-4.1-20051216.orig/gcc/attribs.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/attribs.c	2005-12-18 22:24:27.000000000 +0100
@@ -131,7 +131,11 @@
    information, in the form of a bitwise OR of flags in enum attribute_flags
    from tree.h.  Depending on these flags, some attributes may be
    returned to be applied at a later stage (for example, to apply
-   a decl attribute to the declaration rather than to its type).  */
+   a decl attribute to the declaration rather than to its type).  If
+   ATTR_FLAG_BUILT_IN is not set and *NODE is a DECL, then also consider
+   whether there might be some default attributes to apply to this DECL;
+   if so, decl_attributes will be called recursively with those attributes
+   and ATTR_FLAG_BUILT_IN set.  */
 
 tree
 decl_attributes (tree *node, tree attributes, int flags)
@@ -144,6 +148,10 @@
 
   targetm.insert_attributes (*node, &attributes);
 
+  if (DECL_P (*node) && TREE_CODE (*node) == FUNCTION_DECL
+      && !(flags & (int) ATTR_FLAG_BUILT_IN))
+    (*lang_hooks.insert_default_attributes) (*node);
+
   for (a = attributes; a; a = TREE_CHAIN (a))
     {
       tree name = TREE_PURPOSE (a);
diff -Naur gcc-4.1-20051216.orig/gcc/builtin-attrs.def gcc-4.1-20051216-src/gcc/builtin-attrs.def
--- gcc-4.1-20051216.orig/gcc/builtin-attrs.def	2005-06-27 14:17:39.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/builtin-attrs.def	2005-12-18 22:24:27.000000000 +0100
@@ -169,6 +169,10 @@
 DEF_FORMAT_ATTRIBUTE(SCANF,1,1_2)
 DEF_FORMAT_ATTRIBUTE(SCANF,2,2_0)
 DEF_FORMAT_ATTRIBUTE(SCANF,2,2_3)
+DEF_FORMAT_ATTRIBUTE(SCANF,3,3_0)
+DEF_FORMAT_ATTRIBUTE(SCANF,3,3_4)
+DEF_FORMAT_ATTRIBUTE(SCANF,4,4_0)
+DEF_FORMAT_ATTRIBUTE(SCANF,4,4_5)
 DEF_FORMAT_ATTRIBUTE(STRFTIME,3,3_0)
 DEF_FORMAT_ATTRIBUTE(STRFMON,3,3_4)
 #undef DEF_FORMAT_ATTRIBUTE
@@ -181,3 +185,25 @@
 DEF_FORMAT_ARG_ATTRIBUTE(2)
 #undef DEF_FORMAT_ARG_ATTRIBUTE
 
+/* (TIGCC 20040219, 20050205) Default attributes. */
+#define DEF_FN_ATTR_IDENT(NAME, ATTRS, PREDICATE)	\
+  DEF_ATTR_IDENT (ATTR_ ## NAME, #NAME)	\
+  DEF_FN_ATTR (ATTR_ ## NAME, ATTRS, PREDICATE)
+#define DEF_C89_ATTR(NAME, ATTRS) DEF_FN_ATTR_IDENT (NAME, ATTRS, flag_hosted)
+DEF_C89_ATTR (printf, ATTR_FORMAT_PRINTF_1_2)
+DEF_C89_ATTR (fprintf, ATTR_FORMAT_PRINTF_2_3)
+DEF_C89_ATTR (sprintf, ATTR_FORMAT_PRINTF_2_3)
+DEF_C89_ATTR (scanf, ATTR_FORMAT_SCANF_1_2)
+DEF_C89_ATTR (fscanf, ATTR_FORMAT_SCANF_2_3)
+DEF_C89_ATTR (sscanf, ATTR_FORMAT_SCANF_2_3)
+DEF_C89_ATTR (vprintf, ATTR_FORMAT_PRINTF_1_0)
+DEF_C89_ATTR (vfprintf, ATTR_FORMAT_PRINTF_2_0)
+DEF_C89_ATTR (vsprintf, ATTR_FORMAT_PRINTF_2_0)
+DEF_C89_ATTR (vcbprintf, ATTR_FORMAT_PRINTF_3_0)
+DEF_C89_ATTR (cbprintf, ATTR_FORMAT_PRINTF_3_4)
+DEF_C89_ATTR (vcbscanf, ATTR_FORMAT_SCANF_4_0)
+DEF_C89_ATTR (cbscanf, ATTR_FORMAT_SCANF_4_5)
+DEF_C89_ATTR (vscanf, ATTR_FORMAT_SCANF_1_0)
+DEF_C89_ATTR (vfscanf, ATTR_FORMAT_SCANF_2_0)
+DEF_C89_ATTR (vsscanf, ATTR_FORMAT_SCANF_2_0)
+
diff -Naur gcc-4.1-20051216.orig/gcc/builtins.c gcc-4.1-20051216-src/gcc/builtins.c
--- gcc-4.1-20051216.orig/gcc/builtins.c	2005-12-01 03:32:58.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/builtins.c	2005-12-18 22:24:28.000000000 +0100
@@ -47,6 +47,7 @@
 #include "langhooks.h"
 #include "basic-block.h"
 #include "tree-mudflap.h"
+#include "ggc.h"
 
 #ifndef PAD_VARARGS_DOWN
 #define PAD_VARARGS_DOWN BYTES_BIG_ENDIAN
@@ -76,7 +77,9 @@
 static rtx c_readstr (const char *, enum machine_mode);
 static int target_char_cast (tree, char *);
 static rtx get_memory_rtx (tree, tree);
+#if 0
 static tree build_string_literal (int, const char *);
+#endif /* 0 */
 static int apply_args_size (void);
 static int apply_result_size (void);
 #if defined (HAVE_untyped_call) || defined (HAVE_untyped_return)
@@ -1177,7 +1180,13 @@
 	size += GET_MODE_SIZE (Pmode);
 
       for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
-	if (FUNCTION_ARG_REGNO_P (regno))
+	if (0 /*FUNCTION_ARG_REGNO_P (regno)*/)
+	/* (TIGCC) Do NOT use register passing for __builtin_apply since:
+	           1. It doesn't work: ALL registers are POSSIBLE registers for
+	                               function parameters, so this code uses up all
+	                               registers.
+	           2. It significantly increases code size.
+	           3. The default calling convention is stkparm anyway. */
 	  {
 	    mode = reg_raw_mode[regno];
 
@@ -1630,6 +1639,7 @@
 tree
 mathfn_built_in (tree type, enum built_in_function fn)
 {
+#if 0
   enum built_in_function fcode, fcodef, fcodel;
 
   switch (fn)
@@ -1724,9 +1734,11 @@
   else if (TYPE_MAIN_VARIANT (type) == long_double_type_node)
     return implicit_built_in_decls[fcodel];
   else
+#endif /* 0 */
     return 0;
 }
 
+#if 0
 /* If errno must be maintained, expand the RTL to check if the result,
    TARGET, of a built-in function call, EXP, is NaN, and if so set
    errno to EDOM.  */
@@ -2837,6 +2849,7 @@
     }
   return 0;
 }
+#endif /* 0 */
 
 /* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
    bytes from constant string DATA + OFFSET and return it as target
@@ -2930,6 +2943,7 @@
     }
 }
 
+#if 0
 /* Expand a call to the mempcpy builtin, with arguments in ARGLIST.
    Return 0 if we failed; the caller should emit a normal call,
    otherwise try to get the result in TARGET, if convenient (and in
@@ -3353,6 +3367,7 @@
     }
   return 0;
 }
+#endif /* 0 */
 
 /* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
    bytes from constant string DATA + OFFSET and return it as target
@@ -3500,6 +3515,7 @@
     }
 }
 
+#if 0
 /* Expand expression EXP, which is a call to the bzero builtin.  Return 0
    if we failed the caller should emit a normal call.  */
 
@@ -4031,6 +4047,7 @@
     }
   return 0;
 }
+#endif /* 0 */
 
 /* Expand a call to __builtin_saveregs, generating the result in TARGET,
    if that's convenient.  */
@@ -4584,6 +4601,7 @@
   return convert_to_mode (target_mode, target, 0);
 }
 
+#if 0
 /* If the string passed to fputs is a constant and is one character
    long, we attempt to transform this call into __builtin_fputc().  */
 
@@ -4600,6 +4618,7 @@
     }
   return 0;
 }
+#endif /* 0 */
 
 /* Expand a call to __builtin_expect.  We return our argument and emit a
    NOTE_INSN_EXPECTED_VALUE note.  This is the expansion of __builtin_expect in
@@ -4772,6 +4791,35 @@
   emit_barrier ();
 }
 
+/* (TIGCC 20050206) Implement ER_throw. */
+static void
+expand_builtin_ER_throw (tree arglist)
+{
+  tree arg;
+  char buffer[40];
+
+  if (!validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    {
+      error ("invalid argument list for ER_throw");
+      return;
+    }
+
+  arg = TREE_VALUE (arglist);
+
+  if (TREE_CODE (arg) != INTEGER_CST)
+    {
+      error ("argument to ER_throw must be a constant");
+      return;
+    }
+
+  sprintf (buffer, ".word _A_LINE+%d", (int) TREE_INT_CST_LOW (arg));
+
+  emit_insn (gen_rtx_ASM_INPUT (VOIDmode, ggc_strdup (buffer)));
+
+  emit_barrier ();
+}
+
+#if 0
 /* Expand a call to fabs, fabsf or fabsl with arguments ARGLIST.
    Return 0 if a normal call should be emitted rather than expanding
    the function inline.  If convenient, the result should be placed
@@ -5140,6 +5188,7 @@
 
   return 0;
 }
+#endif /* 0 */
 
 /* Expand a call to either the entry or exit function profiler.  */
 
@@ -5244,6 +5293,7 @@
   return tramp;
 }
 
+#if 0
 /* Expand a call to the built-in signbit, signbitf or signbitl function.
    Return NULL_RTX if a normal call should be emitted rather than expanding
    the function in-line.  EXP is the expression that is a call to the builtin
@@ -5579,6 +5629,7 @@
   expand_builtin_synchronize ();
   emit_move_insn (mem, val);
 }
+#endif /* 0 */
 
 /* Expand an expression EXP that calls a built-in function,
    with result going to TARGET if that's convenient
@@ -5638,6 +5689,7 @@
 
   switch (fcode)
     {
+#if 0
     case BUILT_IN_FABS:
     case BUILT_IN_FABSF:
     case BUILT_IN_FABSL:
@@ -5806,6 +5858,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
     case BUILT_IN_APPLY_ARGS:
       return expand_builtin_apply_args ();
@@ -5942,6 +5995,7 @@
 	return target;
       break;
 
+#if 0
     case BUILT_IN_STRLEN:
       target = expand_builtin_strlen (arglist, target, target_mode);
       if (target)
@@ -6015,6 +6069,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
     case BUILT_IN_MEMCPY:
       target = expand_builtin_memcpy (exp, target, mode);
@@ -6022,6 +6077,7 @@
 	return target;
       break;
 
+#if 0
     case BUILT_IN_MEMPCPY:
       target = expand_builtin_mempcpy (arglist, TREE_TYPE (exp), target, mode, /*endp=*/ 1);
       if (target)
@@ -6040,6 +6096,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
     case BUILT_IN_MEMSET:
       target = expand_builtin_memset (arglist, target, mode, exp);
@@ -6047,6 +6104,7 @@
 	return target;
       break;
 
+#if 0
     case BUILT_IN_BZERO:
       target = expand_builtin_bzero (exp);
       if (target)
@@ -6071,6 +6129,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
     case BUILT_IN_SETJMP:
       target = expand_builtin_setjmp (arglist, target);
@@ -6124,6 +6183,7 @@
       expand_builtin_trap ();
       return const0_rtx;
 
+#if 0
     case BUILT_IN_PRINTF:
       target = expand_builtin_printf (exp, target, mode, false);
       if (target)
@@ -6172,6 +6232,7 @@
       if (target)
 	return target;
       break;
+#endif /* 0 */
 
       /* Various hooks for the DWARF 2 __throw routine.  */
     case BUILT_IN_UNWIND_INIT:
@@ -6224,6 +6285,7 @@
     case BUILT_IN_ADJUST_TRAMPOLINE:
       return expand_builtin_adjust_trampoline (arglist);
 
+#if 0
     case BUILT_IN_FORK:
     case BUILT_IN_EXECL:
     case BUILT_IN_EXECV:
@@ -6459,6 +6521,7 @@
 enum built_in_function
 builtin_mathfn_code (tree t)
 {
+#if 0
   tree fndecl, arglist, parmlist;
   tree argtype, parmtype;
 
@@ -6513,13 +6576,16 @@
 	    return END_BUILTINS;
 	}
       else
+#endif /* 0 */
 	return END_BUILTINS;
+#if 0
 
       arglist = TREE_CHAIN (arglist);
     }
 
   /* Variable-length argument list.  */
   return DECL_FUNCTION_CODE (fndecl);
+#endif /* 0 */
 }
 
 /* Fold a call to __builtin_constant_p, if we know it will evaluate to a
@@ -6619,6 +6685,7 @@
 			type_to_class (TREE_TYPE (TREE_VALUE (arglist))));
 }
 
+#if 0
 /* Fold a call to __builtin_strlen.  */
 
 static tree
@@ -7320,6 +7387,7 @@
 
   return fold_trunc_transparent_mathfn (fndecl, arglist);
 }
+#endif /* 0 */
 
 /* Fold function call to builtin lround, lroundf or lroundl (or the
    corresponding long long versions) and other rounding functions.
@@ -7493,6 +7561,7 @@
   return NULL_TREE;
 }
 
+#if 0
 /* Return true if EXPR is the real constant contained in VALUE.  */
 
 static bool
@@ -7883,6 +7952,7 @@
 
   return 0;
 }
+#endif /* 0 */
 
 /* Fold function call to builtin memcpy.  Return
    NULL_TREE if no simplification can be made.  */
@@ -7911,6 +7981,7 @@
   return 0;
 }
 
+#if 0
 /* Fold function call to builtin mempcpy.  Return
    NULL_TREE if no simplification can be made.  */
 
@@ -8644,6 +8715,7 @@
   return fold_build1 (TRUTH_NOT_EXPR, type,
 		      fold_build2 (code, type, arg0, arg1));
 }
+#endif /* 0 */
 
 /* Used by constant folding to simplify calls to builtin functions.  EXP is
    the CALL_EXPR of a call to a builtin function.  IGNORE is true if the
@@ -8662,6 +8734,7 @@
   fcode = DECL_FUNCTION_CODE (fndecl);
   switch (fcode)
     {
+#if 0
     case BUILT_IN_FPUTS:
       return fold_builtin_fputs (arglist, ignore, false, NULL_TREE);
 
@@ -8712,6 +8785,7 @@
 
     case BUILT_IN_SPRINTF:
       return fold_builtin_sprintf (arglist, ignore);
+#endif /* 0 */
 
     case BUILT_IN_CONSTANT_P:
       {
@@ -8733,6 +8807,7 @@
     case BUILT_IN_CLASSIFY_TYPE:
       return fold_builtin_classify_type (arglist);
 
+#if 0
     case BUILT_IN_STRLEN:
       return fold_builtin_strlen (arglist);
 
@@ -8944,6 +9019,7 @@
     case BUILT_IN_MEMCPY:
       return fold_builtin_memcpy (fndecl, arglist);
 
+#if 0
     case BUILT_IN_MEMPCPY:
       return fold_builtin_mempcpy (arglist, type, /*endp=*/1);
 
@@ -9173,6 +9249,7 @@
     return false;
 }
 
+#if 0
 /* Simplify a call to the strstr builtin.
 
    Return 0 if no simplification was possible, otherwise return the
@@ -9711,6 +9788,7 @@
      hence there's no need to cast the result to integer_type_node.  */
   return build_function_call_expr (fn, arglist);
 }
+#endif /* 0 */
 
 /* Fold the new_arg's arguments (ARGLIST). Returns true if there was an error
    produced.  False otherwise.  This is done so that we don't output the error
@@ -9780,6 +9858,7 @@
 }
 
 
+#if 0
 /* Simplify a call to the sprintf builtin.
 
    Return 0 if no simplification was possible, otherwise return the
@@ -11062,3 +11141,5 @@
     }
   return true;
 }
+#endif /* 0 */
+
diff -Naur gcc-4.1-20051216.orig/gcc/builtins.c.orig gcc-4.1-20051216-src/gcc/builtins.c.orig
--- gcc-4.1-20051216.orig/gcc/builtins.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/builtins.c.orig	2005-12-01 03:32:58.000000000 +0100
@@ -0,0 +1,11064 @@
+/* Expand builtin functions.
+   Copyright (C) 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
+   2000, 2001, 2002, 2003, 2004, 2005 Free Software Foundation, Inc.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 2, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING.  If not, write to the Free
+Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA
+02110-1301, USA.  */
+
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "tm.h"
+#include "machmode.h"
+#include "real.h"
+#include "rtl.h"
+#include "tree.h"
+#include "tree-gimple.h"
+#include "flags.h"
+#include "regs.h"
+#include "hard-reg-set.h"
+#include "except.h"
+#include "function.h"
+#include "insn-config.h"
+#include "expr.h"
+#include "optabs.h"
+#include "libfuncs.h"
+#include "recog.h"
+#include "output.h"
+#include "typeclass.h"
+#include "toplev.h"
+#include "predict.h"
+#include "tm_p.h"
+#include "target.h"
+#include "langhooks.h"
+#include "basic-block.h"
+#include "tree-mudflap.h"
+
+#ifndef PAD_VARARGS_DOWN
+#define PAD_VARARGS_DOWN BYTES_BIG_ENDIAN
+#endif
+
+/* Define the names of the builtin function types and codes.  */
+const char *const built_in_class_names[4]
+  = {"NOT_BUILT_IN", "BUILT_IN_FRONTEND", "BUILT_IN_MD", "BUILT_IN_NORMAL"};
+
+#define DEF_BUILTIN(X, N, C, T, LT, B, F, NA, AT, IM, COND) #X,
+const char * built_in_names[(int) END_BUILTINS] =
+{
+#include "builtins.def"
+};
+#undef DEF_BUILTIN
+
+/* Setup an array of _DECL trees, make sure each element is
+   initialized to NULL_TREE.  */
+tree built_in_decls[(int) END_BUILTINS];
+/* Declarations used when constructing the builtin implicitly in the compiler.
+   It may be NULL_TREE when this is invalid (for instance runtime is not
+   required to implement the function call in all cases).  */
+tree implicit_built_in_decls[(int) END_BUILTINS];
+
+static int get_pointer_alignment (tree, unsigned int);
+static const char *c_getstr (tree);
+static rtx c_readstr (const char *, enum machine_mode);
+static int target_char_cast (tree, char *);
+static rtx get_memory_rtx (tree, tree);
+static tree build_string_literal (int, const char *);
+static int apply_args_size (void);
+static int apply_result_size (void);
+#if defined (HAVE_untyped_call) || defined (HAVE_untyped_return)
+static rtx result_vector (int, rtx);
+#endif
+static rtx expand_builtin_setjmp (tree, rtx);
+static void expand_builtin_update_setjmp_buf (rtx);
+static void expand_builtin_prefetch (tree);
+static rtx expand_builtin_apply_args (void);
+static rtx expand_builtin_apply_args_1 (void);
+static rtx expand_builtin_apply (rtx, rtx, rtx);
+static void expand_builtin_return (rtx);
+static enum type_class type_to_class (tree);
+static rtx expand_builtin_classify_type (tree);
+static void expand_errno_check (tree, rtx);
+static rtx expand_builtin_mathfn (tree, rtx, rtx);
+static rtx expand_builtin_mathfn_2 (tree, rtx, rtx);
+static rtx expand_builtin_mathfn_3 (tree, rtx, rtx);
+static rtx expand_builtin_int_roundingfn (tree, rtx, rtx);
+static rtx expand_builtin_args_info (tree);
+static rtx expand_builtin_next_arg (void);
+static rtx expand_builtin_va_start (tree);
+static rtx expand_builtin_va_end (tree);
+static rtx expand_builtin_va_copy (tree);
+static rtx expand_builtin_memcmp (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strcmp (tree, rtx, enum machine_mode);
+static rtx expand_builtin_strncmp (tree, rtx, enum machine_mode);
+static rtx builtin_memcpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+static rtx expand_builtin_strcat (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strncat (tree, rtx, enum machine_mode);
+static rtx expand_builtin_strspn (tree, rtx, enum machine_mode);
+static rtx expand_builtin_strcspn (tree, rtx, enum machine_mode);
+static rtx expand_builtin_memcpy (tree, rtx, enum machine_mode);
+static rtx expand_builtin_mempcpy (tree, tree, rtx, enum machine_mode, int);
+static rtx expand_builtin_memmove (tree, tree, rtx, enum machine_mode, tree);
+static rtx expand_builtin_bcopy (tree);
+static rtx expand_builtin_strcpy (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_stpcpy (tree, rtx, enum machine_mode);
+static rtx builtin_strncpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+static rtx expand_builtin_strncpy (tree, rtx, enum machine_mode);
+static rtx builtin_memset_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+static rtx builtin_memset_gen_str (void *, HOST_WIDE_INT, enum machine_mode);
+static rtx expand_builtin_memset (tree, rtx, enum machine_mode, tree);
+static rtx expand_builtin_bzero (tree);
+static rtx expand_builtin_strlen (tree, rtx, enum machine_mode);
+static rtx expand_builtin_strstr (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strpbrk (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strchr (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_strrchr (tree, tree, rtx, enum machine_mode);
+static rtx expand_builtin_alloca (tree, rtx);
+static rtx expand_builtin_unop (enum machine_mode, tree, rtx, rtx, optab);
+static rtx expand_builtin_frame_address (tree, tree);
+static rtx expand_builtin_fputs (tree, rtx, bool);
+static rtx expand_builtin_printf (tree, rtx, enum machine_mode, bool);
+static rtx expand_builtin_fprintf (tree, rtx, enum machine_mode, bool);
+static rtx expand_builtin_sprintf (tree, rtx, enum machine_mode);
+static tree stabilize_va_list (tree, int);
+static rtx expand_builtin_expect (tree, rtx);
+static tree fold_builtin_constant_p (tree);
+static tree fold_builtin_classify_type (tree);
+static tree fold_builtin_strlen (tree);
+static tree fold_builtin_inf (tree, int);
+static tree fold_builtin_nan (tree, tree, int);
+static int validate_arglist (tree, ...);
+static bool integer_valued_real_p (tree);
+static tree fold_trunc_transparent_mathfn (tree, tree);
+static bool readonly_data_expr (tree);
+static rtx expand_builtin_fabs (tree, rtx, rtx);
+static rtx expand_builtin_signbit (tree, rtx);
+static tree fold_builtin_cabs (tree, tree);
+static tree fold_builtin_sqrt (tree, tree);
+static tree fold_builtin_cbrt (tree, tree);
+static tree fold_builtin_pow (tree, tree, tree);
+static tree fold_builtin_powi (tree, tree, tree);
+static tree fold_builtin_sin (tree);
+static tree fold_builtin_cos (tree, tree, tree);
+static tree fold_builtin_tan (tree);
+static tree fold_builtin_atan (tree, tree);
+static tree fold_builtin_trunc (tree, tree);
+static tree fold_builtin_floor (tree, tree);
+static tree fold_builtin_ceil (tree, tree);
+static tree fold_builtin_round (tree, tree);
+static tree fold_builtin_int_roundingfn (tree, tree);
+static tree fold_builtin_bitop (tree, tree);
+static tree fold_builtin_memcpy (tree, tree);
+static tree fold_builtin_mempcpy (tree, tree, int);
+static tree fold_builtin_memmove (tree, tree);
+static tree fold_builtin_strchr (tree, tree);
+static tree fold_builtin_memcmp (tree);
+static tree fold_builtin_strcmp (tree);
+static tree fold_builtin_strncmp (tree);
+static tree fold_builtin_signbit (tree, tree);
+static tree fold_builtin_copysign (tree, tree, tree);
+static tree fold_builtin_isascii (tree);
+static tree fold_builtin_toascii (tree);
+static tree fold_builtin_isdigit (tree);
+static tree fold_builtin_fabs (tree, tree);
+static tree fold_builtin_abs (tree, tree);
+static tree fold_builtin_unordered_cmp (tree, tree, enum tree_code,
+					enum tree_code);
+static tree fold_builtin_1 (tree, tree, bool);
+
+static tree fold_builtin_strpbrk (tree, tree);
+static tree fold_builtin_strstr (tree, tree);
+static tree fold_builtin_strrchr (tree, tree);
+static tree fold_builtin_strcat (tree);
+static tree fold_builtin_strncat (tree);
+static tree fold_builtin_strspn (tree);
+static tree fold_builtin_strcspn (tree);
+static tree fold_builtin_sprintf (tree, int);
+
+static rtx expand_builtin_object_size (tree);
+static rtx expand_builtin_memory_chk (tree, rtx, enum machine_mode,
+				      enum built_in_function);
+static void maybe_emit_chk_warning (tree, enum built_in_function);
+static void maybe_emit_sprintf_chk_warning (tree, enum built_in_function);
+static tree fold_builtin_object_size (tree);
+static tree fold_builtin_strcat_chk (tree, tree);
+static tree fold_builtin_strncat_chk (tree, tree);
+static tree fold_builtin_sprintf_chk (tree, enum built_in_function);
+static tree fold_builtin_printf (tree, tree, bool, enum built_in_function);
+static tree fold_builtin_fprintf (tree, tree, bool, enum built_in_function);
+static bool init_target_chars (void);
+
+static unsigned HOST_WIDE_INT target_newline;
+static unsigned HOST_WIDE_INT target_percent;
+static unsigned HOST_WIDE_INT target_c;
+static unsigned HOST_WIDE_INT target_s;
+static char target_percent_c[3];
+static char target_percent_s[3];
+static char target_percent_s_newline[4];
+
+/* Return true if NODE should be considered for inline expansion regardless
+   of the optimization level.  This means whenever a function is invoked with
+   its "internal" name, which normally contains the prefix "__builtin".  */
+
+static bool called_as_built_in (tree node)
+{
+  const char *name = IDENTIFIER_POINTER (DECL_NAME (node));
+  if (strncmp (name, "__builtin_", 10) == 0)
+    return true;
+  if (strncmp (name, "__sync_", 7) == 0)
+    return true;
+  return false;
+}
+
+/* Return the alignment in bits of EXP, a pointer valued expression.
+   But don't return more than MAX_ALIGN no matter what.
+   The alignment returned is, by default, the alignment of the thing that
+   EXP points to.  If it is not a POINTER_TYPE, 0 is returned.
+
+   Otherwise, look at the expression to see if we can do better, i.e., if the
+   expression is actually pointing at an object whose alignment is tighter.  */
+
+static int
+get_pointer_alignment (tree exp, unsigned int max_align)
+{
+  unsigned int align, inner;
+
+  if (! POINTER_TYPE_P (TREE_TYPE (exp)))
+    return 0;
+
+  align = TYPE_ALIGN (TREE_TYPE (TREE_TYPE (exp)));
+  align = MIN (align, max_align);
+
+  while (1)
+    {
+      switch (TREE_CODE (exp))
+	{
+	case NOP_EXPR:
+	case CONVERT_EXPR:
+	case NON_LVALUE_EXPR:
+	  exp = TREE_OPERAND (exp, 0);
+	  if (! POINTER_TYPE_P (TREE_TYPE (exp)))
+	    return align;
+
+	  inner = TYPE_ALIGN (TREE_TYPE (TREE_TYPE (exp)));
+	  align = MIN (inner, max_align);
+	  break;
+
+	case PLUS_EXPR:
+	  /* If sum of pointer + int, restrict our maximum alignment to that
+	     imposed by the integer.  If not, we can't do any better than
+	     ALIGN.  */
+	  if (! host_integerp (TREE_OPERAND (exp, 1), 1))
+	    return align;
+
+	  while (((tree_low_cst (TREE_OPERAND (exp, 1), 1))
+		  & (max_align / BITS_PER_UNIT - 1))
+		 != 0)
+	    max_align >>= 1;
+
+	  exp = TREE_OPERAND (exp, 0);
+	  break;
+
+	case ADDR_EXPR:
+	  /* See what we are pointing at and look at its alignment.  */
+	  exp = TREE_OPERAND (exp, 0);
+	  if (TREE_CODE (exp) == FUNCTION_DECL)
+	    align = FUNCTION_BOUNDARY;
+	  else if (DECL_P (exp))
+	    align = DECL_ALIGN (exp);
+#ifdef CONSTANT_ALIGNMENT
+	  else if (CONSTANT_CLASS_P (exp))
+	    align = CONSTANT_ALIGNMENT (exp, align);
+#endif
+	  return MIN (align, max_align);
+
+	default:
+	  return align;
+	}
+    }
+}
+
+/* Compute the length of a C string.  TREE_STRING_LENGTH is not the right
+   way, because it could contain a zero byte in the middle.
+   TREE_STRING_LENGTH is the size of the character array, not the string.
+
+   ONLY_VALUE should be nonzero if the result is not going to be emitted
+   into the instruction stream and zero if it is going to be expanded.
+   E.g. with i++ ? "foo" : "bar", if ONLY_VALUE is nonzero, constant 3
+   is returned, otherwise NULL, since
+   len = c_strlen (src, 1); if (len) expand_expr (len, ...); would not
+   evaluate the side-effects.
+
+   The value returned is of type `ssizetype'.
+
+   Unfortunately, string_constant can't access the values of const char
+   arrays with initializers, so neither can we do so here.  */
+
+tree
+c_strlen (tree src, int only_value)
+{
+  tree offset_node;
+  HOST_WIDE_INT offset;
+  int max;
+  const char *ptr;
+
+  STRIP_NOPS (src);
+  if (TREE_CODE (src) == COND_EXPR
+      && (only_value || !TREE_SIDE_EFFECTS (TREE_OPERAND (src, 0))))
+    {
+      tree len1, len2;
+
+      len1 = c_strlen (TREE_OPERAND (src, 1), only_value);
+      len2 = c_strlen (TREE_OPERAND (src, 2), only_value);
+      if (tree_int_cst_equal (len1, len2))
+	return len1;
+    }
+
+  if (TREE_CODE (src) == COMPOUND_EXPR
+      && (only_value || !TREE_SIDE_EFFECTS (TREE_OPERAND (src, 0))))
+    return c_strlen (TREE_OPERAND (src, 1), only_value);
+
+  src = string_constant (src, &offset_node);
+  if (src == 0)
+    return 0;
+
+  max = TREE_STRING_LENGTH (src) - 1;
+  ptr = TREE_STRING_POINTER (src);
+
+  if (offset_node && TREE_CODE (offset_node) != INTEGER_CST)
+    {
+      /* If the string has an internal zero byte (e.g., "foo\0bar"), we can't
+	 compute the offset to the following null if we don't know where to
+	 start searching for it.  */
+      int i;
+
+      for (i = 0; i < max; i++)
+	if (ptr[i] == 0)
+	  return 0;
+
+      /* We don't know the starting offset, but we do know that the string
+	 has no internal zero bytes.  We can assume that the offset falls
+	 within the bounds of the string; otherwise, the programmer deserves
+	 what he gets.  Subtract the offset from the length of the string,
+	 and return that.  This would perhaps not be valid if we were dealing
+	 with named arrays in addition to literal string constants.  */
+
+      return size_diffop (size_int (max), offset_node);
+    }
+
+  /* We have a known offset into the string.  Start searching there for
+     a null character if we can represent it as a single HOST_WIDE_INT.  */
+  if (offset_node == 0)
+    offset = 0;
+  else if (! host_integerp (offset_node, 0))
+    offset = -1;
+  else
+    offset = tree_low_cst (offset_node, 0);
+
+  /* If the offset is known to be out of bounds, warn, and call strlen at
+     runtime.  */
+  if (offset < 0 || offset > max)
+    {
+      warning (0, "offset outside bounds of constant string");
+      return 0;
+    }
+
+  /* Use strlen to search for the first zero byte.  Since any strings
+     constructed with build_string will have nulls appended, we win even
+     if we get handed something like (char[4])"abcd".
+
+     Since OFFSET is our starting index into the string, no further
+     calculation is needed.  */
+  return ssize_int (strlen (ptr + offset));
+}
+
+/* Return a char pointer for a C string if it is a string constant
+   or sum of string constant and integer constant.  */
+
+static const char *
+c_getstr (tree src)
+{
+  tree offset_node;
+
+  src = string_constant (src, &offset_node);
+  if (src == 0)
+    return 0;
+
+  if (offset_node == 0)
+    return TREE_STRING_POINTER (src);
+  else if (!host_integerp (offset_node, 1)
+	   || compare_tree_int (offset_node, TREE_STRING_LENGTH (src) - 1) > 0)
+    return 0;
+
+  return TREE_STRING_POINTER (src) + tree_low_cst (offset_node, 1);
+}
+
+/* Return a CONST_INT or CONST_DOUBLE corresponding to target reading
+   GET_MODE_BITSIZE (MODE) bits from string constant STR.  */
+
+static rtx
+c_readstr (const char *str, enum machine_mode mode)
+{
+  HOST_WIDE_INT c[2];
+  HOST_WIDE_INT ch;
+  unsigned int i, j;
+
+  gcc_assert (GET_MODE_CLASS (mode) == MODE_INT);
+
+  c[0] = 0;
+  c[1] = 0;
+  ch = 1;
+  for (i = 0; i < GET_MODE_SIZE (mode); i++)
+    {
+      j = i;
+      if (WORDS_BIG_ENDIAN)
+	j = GET_MODE_SIZE (mode) - i - 1;
+      if (BYTES_BIG_ENDIAN != WORDS_BIG_ENDIAN
+	  && GET_MODE_SIZE (mode) > UNITS_PER_WORD)
+	j = j + UNITS_PER_WORD - 2 * (j % UNITS_PER_WORD) - 1;
+      j *= BITS_PER_UNIT;
+      gcc_assert (j <= 2 * HOST_BITS_PER_WIDE_INT);
+
+      if (ch)
+	ch = (unsigned char) str[i];
+      c[j / HOST_BITS_PER_WIDE_INT] |= ch << (j % HOST_BITS_PER_WIDE_INT);
+    }
+  return immed_double_const (c[0], c[1], mode);
+}
+
+/* Cast a target constant CST to target CHAR and if that value fits into
+   host char type, return zero and put that value into variable pointed to by
+   P.  */
+
+static int
+target_char_cast (tree cst, char *p)
+{
+  unsigned HOST_WIDE_INT val, hostval;
+
+  if (!host_integerp (cst, 1)
+      || CHAR_TYPE_SIZE > HOST_BITS_PER_WIDE_INT)
+    return 1;
+
+  val = tree_low_cst (cst, 1);
+  if (CHAR_TYPE_SIZE < HOST_BITS_PER_WIDE_INT)
+    val &= (((unsigned HOST_WIDE_INT) 1) << CHAR_TYPE_SIZE) - 1;
+
+  hostval = val;
+  if (HOST_BITS_PER_CHAR < HOST_BITS_PER_WIDE_INT)
+    hostval &= (((unsigned HOST_WIDE_INT) 1) << HOST_BITS_PER_CHAR) - 1;
+
+  if (val != hostval)
+    return 1;
+
+  *p = hostval;
+  return 0;
+}
+
+/* Similar to save_expr, but assumes that arbitrary code is not executed
+   in between the multiple evaluations.  In particular, we assume that a
+   non-addressable local variable will not be modified.  */
+
+static tree
+builtin_save_expr (tree exp)
+{
+  if (TREE_ADDRESSABLE (exp) == 0
+      && (TREE_CODE (exp) == PARM_DECL
+	  || (TREE_CODE (exp) == VAR_DECL && !TREE_STATIC (exp))))
+    return exp;
+
+  return save_expr (exp);
+}
+
+/* Given TEM, a pointer to a stack frame, follow the dynamic chain COUNT
+   times to get the address of either a higher stack frame, or a return
+   address located within it (depending on FNDECL_CODE).  */
+
+static rtx
+expand_builtin_return_addr (enum built_in_function fndecl_code, int count)
+{
+  int i;
+
+#ifdef INITIAL_FRAME_ADDRESS_RTX
+  rtx tem = INITIAL_FRAME_ADDRESS_RTX;
+#else
+  rtx tem;
+
+  /* For a zero count, we don't care what frame address we return, so frame
+     pointer elimination is OK, and using the soft frame pointer is OK.
+     For a non-zero count, we require a stable offset from the current frame
+     pointer to the previous one, so we must use the hard frame pointer, and
+     we must disable frame pointer elimination.  */
+  if (count == 0)
+    tem = frame_pointer_rtx;
+  else 
+    {
+      tem = hard_frame_pointer_rtx;
+
+      /* Tell reload not to eliminate the frame pointer.  */
+      current_function_accesses_prior_frames = 1;
+    }
+#endif
+
+  /* Some machines need special handling before we can access
+     arbitrary frames.  For example, on the sparc, we must first flush
+     all register windows to the stack.  */
+#ifdef SETUP_FRAME_ADDRESSES
+  if (count > 0)
+    SETUP_FRAME_ADDRESSES ();
+#endif
+
+  /* On the sparc, the return address is not in the frame, it is in a
+     register.  There is no way to access it off of the current frame
+     pointer, but it can be accessed off the previous frame pointer by
+     reading the value from the register window save area.  */
+#ifdef RETURN_ADDR_IN_PREVIOUS_FRAME
+  if (fndecl_code == BUILT_IN_RETURN_ADDRESS)
+    count--;
+#endif
+
+  /* Scan back COUNT frames to the specified frame.  */
+  for (i = 0; i < count; i++)
+    {
+      /* Assume the dynamic chain pointer is in the word that the
+	 frame address points to, unless otherwise specified.  */
+#ifdef DYNAMIC_CHAIN_ADDRESS
+      tem = DYNAMIC_CHAIN_ADDRESS (tem);
+#endif
+      tem = memory_address (Pmode, tem);
+      tem = gen_frame_mem (Pmode, tem);
+      tem = copy_to_reg (tem);
+    }
+
+  /* For __builtin_frame_address, return what we've got.  */
+  if (fndecl_code == BUILT_IN_FRAME_ADDRESS)
+    return tem;
+
+  /* For __builtin_return_address, Get the return address from that
+     frame.  */
+#ifdef RETURN_ADDR_RTX
+  tem = RETURN_ADDR_RTX (count, tem);
+#else
+  tem = memory_address (Pmode,
+			plus_constant (tem, GET_MODE_SIZE (Pmode)));
+  tem = gen_frame_mem (Pmode, tem);
+#endif
+  return tem;
+}
+
+/* Alias set used for setjmp buffer.  */
+static HOST_WIDE_INT setjmp_alias_set = -1;
+
+/* Construct the leading half of a __builtin_setjmp call.  Control will
+   return to RECEIVER_LABEL.  This is used directly by sjlj exception
+   handling code.  */
+
+void
+expand_builtin_setjmp_setup (rtx buf_addr, rtx receiver_label)
+{
+  enum machine_mode sa_mode = STACK_SAVEAREA_MODE (SAVE_NONLOCAL);
+  rtx stack_save;
+  rtx mem;
+
+  if (setjmp_alias_set == -1)
+    setjmp_alias_set = new_alias_set ();
+
+  buf_addr = convert_memory_address (Pmode, buf_addr);
+
+  buf_addr = force_reg (Pmode, force_operand (buf_addr, NULL_RTX));
+
+  /* We store the frame pointer and the address of receiver_label in
+     the buffer and use the rest of it for the stack save area, which
+     is machine-dependent.  */
+
+  mem = gen_rtx_MEM (Pmode, buf_addr);
+  set_mem_alias_set (mem, setjmp_alias_set);
+  emit_move_insn (mem, targetm.builtin_setjmp_frame_value ());
+
+  mem = gen_rtx_MEM (Pmode, plus_constant (buf_addr, GET_MODE_SIZE (Pmode))),
+  set_mem_alias_set (mem, setjmp_alias_set);
+
+  emit_move_insn (validize_mem (mem),
+		  force_reg (Pmode, gen_rtx_LABEL_REF (Pmode, receiver_label)));
+
+  stack_save = gen_rtx_MEM (sa_mode,
+			    plus_constant (buf_addr,
+					   2 * GET_MODE_SIZE (Pmode)));
+  set_mem_alias_set (stack_save, setjmp_alias_set);
+  emit_stack_save (SAVE_NONLOCAL, &stack_save, NULL_RTX);
+
+  /* If there is further processing to do, do it.  */
+#ifdef HAVE_builtin_setjmp_setup
+  if (HAVE_builtin_setjmp_setup)
+    emit_insn (gen_builtin_setjmp_setup (buf_addr));
+#endif
+
+  /* Tell optimize_save_area_alloca that extra work is going to
+     need to go on during alloca.  */
+  current_function_calls_setjmp = 1;
+
+  /* Set this so all the registers get saved in our frame; we need to be
+     able to copy the saved values for any registers from frames we unwind.  */
+  current_function_has_nonlocal_label = 1;
+}
+
+/* Construct the trailing part of a __builtin_setjmp call.
+   This is used directly by sjlj exception handling code.  */
+
+void
+expand_builtin_setjmp_receiver (rtx receiver_label ATTRIBUTE_UNUSED)
+{
+  /* Clobber the FP when we get here, so we have to make sure it's
+     marked as used by this function.  */
+  emit_insn (gen_rtx_USE (VOIDmode, hard_frame_pointer_rtx));
+
+  /* Mark the static chain as clobbered here so life information
+     doesn't get messed up for it.  */
+  emit_insn (gen_rtx_CLOBBER (VOIDmode, static_chain_rtx));
+
+  /* Now put in the code to restore the frame pointer, and argument
+     pointer, if needed.  */
+#ifdef HAVE_nonlocal_goto
+  if (! HAVE_nonlocal_goto)
+#endif
+    emit_move_insn (virtual_stack_vars_rtx, hard_frame_pointer_rtx);
+
+#if ARG_POINTER_REGNUM != HARD_FRAME_POINTER_REGNUM
+  if (fixed_regs[ARG_POINTER_REGNUM])
+    {
+#ifdef ELIMINABLE_REGS
+      size_t i;
+      static const struct elims {const int from, to;} elim_regs[] = ELIMINABLE_REGS;
+
+      for (i = 0; i < ARRAY_SIZE (elim_regs); i++)
+	if (elim_regs[i].from == ARG_POINTER_REGNUM
+	    && elim_regs[i].to == HARD_FRAME_POINTER_REGNUM)
+	  break;
+
+      if (i == ARRAY_SIZE (elim_regs))
+#endif
+	{
+	  /* Now restore our arg pointer from the address at which it
+	     was saved in our stack frame.  */
+	  emit_move_insn (virtual_incoming_args_rtx,
+			  copy_to_reg (get_arg_pointer_save_area (cfun)));
+	}
+    }
+#endif
+
+#ifdef HAVE_builtin_setjmp_receiver
+  if (HAVE_builtin_setjmp_receiver)
+    emit_insn (gen_builtin_setjmp_receiver (receiver_label));
+  else
+#endif
+#ifdef HAVE_nonlocal_goto_receiver
+    if (HAVE_nonlocal_goto_receiver)
+      emit_insn (gen_nonlocal_goto_receiver ());
+    else
+#endif
+      { /* Nothing */ }
+
+  /* @@@ This is a kludge.  Not all machine descriptions define a blockage
+     insn, but we must not allow the code we just generated to be reordered
+     by scheduling.  Specifically, the update of the frame pointer must
+     happen immediately, not later.  So emit an ASM_INPUT to act as blockage
+     insn.  */
+  emit_insn (gen_rtx_ASM_INPUT (VOIDmode, ""));
+}
+
+/* __builtin_setjmp is passed a pointer to an array of five words (not
+   all will be used on all machines).  It operates similarly to the C
+   library function of the same name, but is more efficient.  Much of
+   the code below (and for longjmp) is copied from the handling of
+   non-local gotos.
+
+   NOTE: This is intended for use by GNAT and the exception handling
+   scheme in the compiler and will only work in the method used by
+   them.  */
+
+static rtx
+expand_builtin_setjmp (tree arglist, rtx target)
+{
+  rtx buf_addr, next_lab, cont_lab;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  if (target == 0 || !REG_P (target)
+      || REGNO (target) < FIRST_PSEUDO_REGISTER)
+    target = gen_reg_rtx (TYPE_MODE (integer_type_node));
+
+  buf_addr = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);
+
+  next_lab = gen_label_rtx ();
+  cont_lab = gen_label_rtx ();
+
+  expand_builtin_setjmp_setup (buf_addr, next_lab);
+
+  /* Set TARGET to zero and branch to the continue label.  Use emit_jump to
+     ensure that pending stack adjustments are flushed.  */
+  emit_move_insn (target, const0_rtx);
+  emit_jump (cont_lab);
+
+  emit_label (next_lab);
+
+  expand_builtin_setjmp_receiver (next_lab);
+
+  /* Set TARGET to one.  */
+  emit_move_insn (target, const1_rtx);
+  emit_label (cont_lab);
+
+  /* Tell flow about the strange goings on.  Putting `next_lab' on
+     `nonlocal_goto_handler_labels' to indicates that function
+     calls may traverse the arc back to this label.  */
+
+  current_function_has_nonlocal_label = 1;
+  nonlocal_goto_handler_labels
+    = gen_rtx_EXPR_LIST (VOIDmode, next_lab, nonlocal_goto_handler_labels);
+
+  return target;
+}
+
+/* __builtin_longjmp is passed a pointer to an array of five words (not
+   all will be used on all machines).  It operates similarly to the C
+   library function of the same name, but is more efficient.  Much of
+   the code below is copied from the handling of non-local gotos.
+
+   NOTE: This is intended for use by GNAT and the exception handling
+   scheme in the compiler and will only work in the method used by
+   them.  */
+
+static void
+expand_builtin_longjmp (rtx buf_addr, rtx value)
+{
+  rtx fp, lab, stack, insn, last;
+  enum machine_mode sa_mode = STACK_SAVEAREA_MODE (SAVE_NONLOCAL);
+
+  if (setjmp_alias_set == -1)
+    setjmp_alias_set = new_alias_set ();
+
+  buf_addr = convert_memory_address (Pmode, buf_addr);
+
+  buf_addr = force_reg (Pmode, buf_addr);
+
+  /* We used to store value in static_chain_rtx, but that fails if pointers
+     are smaller than integers.  We instead require that the user must pass
+     a second argument of 1, because that is what builtin_setjmp will
+     return.  This also makes EH slightly more efficient, since we are no
+     longer copying around a value that we don't care about.  */
+  gcc_assert (value == const1_rtx);
+
+  last = get_last_insn ();
+#ifdef HAVE_builtin_longjmp
+  if (HAVE_builtin_longjmp)
+    emit_insn (gen_builtin_longjmp (buf_addr));
+  else
+#endif
+    {
+      fp = gen_rtx_MEM (Pmode, buf_addr);
+      lab = gen_rtx_MEM (Pmode, plus_constant (buf_addr,
+					       GET_MODE_SIZE (Pmode)));
+
+      stack = gen_rtx_MEM (sa_mode, plus_constant (buf_addr,
+						   2 * GET_MODE_SIZE (Pmode)));
+      set_mem_alias_set (fp, setjmp_alias_set);
+      set_mem_alias_set (lab, setjmp_alias_set);
+      set_mem_alias_set (stack, setjmp_alias_set);
+
+      /* Pick up FP, label, and SP from the block and jump.  This code is
+	 from expand_goto in stmt.c; see there for detailed comments.  */
+#if HAVE_nonlocal_goto
+      if (HAVE_nonlocal_goto)
+	/* We have to pass a value to the nonlocal_goto pattern that will
+	   get copied into the static_chain pointer, but it does not matter
+	   what that value is, because builtin_setjmp does not use it.  */
+	emit_insn (gen_nonlocal_goto (value, lab, stack, fp));
+      else
+#endif
+	{
+	  lab = copy_to_reg (lab);
+
+	  emit_insn (gen_rtx_CLOBBER (VOIDmode,
+				      gen_rtx_MEM (BLKmode,
+						   gen_rtx_SCRATCH (VOIDmode))));
+	  emit_insn (gen_rtx_CLOBBER (VOIDmode,
+				      gen_rtx_MEM (BLKmode,
+						   hard_frame_pointer_rtx)));
+
+	  emit_move_insn (hard_frame_pointer_rtx, fp);
+	  emit_stack_restore (SAVE_NONLOCAL, stack, NULL_RTX);
+
+	  emit_insn (gen_rtx_USE (VOIDmode, hard_frame_pointer_rtx));
+	  emit_insn (gen_rtx_USE (VOIDmode, stack_pointer_rtx));
+	  emit_indirect_jump (lab);
+	}
+    }
+
+  /* Search backwards and mark the jump insn as a non-local goto.
+     Note that this precludes the use of __builtin_longjmp to a
+     __builtin_setjmp target in the same function.  However, we've
+     already cautioned the user that these functions are for
+     internal exception handling use only.  */
+  for (insn = get_last_insn (); insn; insn = PREV_INSN (insn))
+    {
+      gcc_assert (insn != last);
+
+      if (JUMP_P (insn))
+	{
+	  REG_NOTES (insn) = alloc_EXPR_LIST (REG_NON_LOCAL_GOTO, const0_rtx,
+					      REG_NOTES (insn));
+	  break;
+	}
+      else if (CALL_P (insn))
+	break;
+    }
+}
+
+/* Expand a call to __builtin_nonlocal_goto.  We're passed the target label
+   and the address of the save area.  */
+
+static rtx
+expand_builtin_nonlocal_goto (tree arglist)
+{
+  tree t_label, t_save_area;
+  rtx r_label, r_save_area, r_fp, r_sp, insn;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  t_label = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  t_save_area = TREE_VALUE (arglist);
+
+  r_label = expand_expr (t_label, NULL_RTX, VOIDmode, 0);
+  r_label = convert_memory_address (Pmode, r_label);
+  r_save_area = expand_expr (t_save_area, NULL_RTX, VOIDmode, 0);
+  r_save_area = convert_memory_address (Pmode, r_save_area);
+  r_fp = gen_rtx_MEM (Pmode, r_save_area);
+  r_sp = gen_rtx_MEM (STACK_SAVEAREA_MODE (SAVE_NONLOCAL),
+		      plus_constant (r_save_area, GET_MODE_SIZE (Pmode)));
+
+  current_function_has_nonlocal_goto = 1;
+
+#if HAVE_nonlocal_goto
+  /* ??? We no longer need to pass the static chain value, afaik.  */
+  if (HAVE_nonlocal_goto)
+    emit_insn (gen_nonlocal_goto (const0_rtx, r_label, r_sp, r_fp));
+  else
+#endif
+    {
+      r_label = copy_to_reg (r_label);
+
+      emit_insn (gen_rtx_CLOBBER (VOIDmode,
+				  gen_rtx_MEM (BLKmode,
+					       gen_rtx_SCRATCH (VOIDmode))));
+
+      emit_insn (gen_rtx_CLOBBER (VOIDmode,
+				  gen_rtx_MEM (BLKmode,
+					       hard_frame_pointer_rtx)));
+
+      /* Restore frame pointer for containing function.
+	 This sets the actual hard register used for the frame pointer
+	 to the location of the function's incoming static chain info.
+	 The non-local goto handler will then adjust it to contain the
+	 proper value and reload the argument pointer, if needed.  */
+      emit_move_insn (hard_frame_pointer_rtx, r_fp);
+      emit_stack_restore (SAVE_NONLOCAL, r_sp, NULL_RTX);
+
+      /* USE of hard_frame_pointer_rtx added for consistency;
+	 not clear if really needed.  */
+      emit_insn (gen_rtx_USE (VOIDmode, hard_frame_pointer_rtx));
+      emit_insn (gen_rtx_USE (VOIDmode, stack_pointer_rtx));
+      emit_indirect_jump (r_label);
+    }
+
+  /* Search backwards to the jump insn and mark it as a
+     non-local goto.  */
+  for (insn = get_last_insn (); insn; insn = PREV_INSN (insn))
+    {
+      if (JUMP_P (insn))
+	{
+	  REG_NOTES (insn) = alloc_EXPR_LIST (REG_NON_LOCAL_GOTO,
+					      const0_rtx, REG_NOTES (insn));
+	  break;
+	}
+      else if (CALL_P (insn))
+	break;
+    }
+
+  return const0_rtx;
+}
+
+/* __builtin_update_setjmp_buf is passed a pointer to an array of five words
+   (not all will be used on all machines) that was passed to __builtin_setjmp.
+   It updates the stack pointer in that block to correspond to the current
+   stack pointer.  */
+
+static void
+expand_builtin_update_setjmp_buf (rtx buf_addr)
+{
+  enum machine_mode sa_mode = Pmode;
+  rtx stack_save;
+
+
+#ifdef HAVE_save_stack_nonlocal
+  if (HAVE_save_stack_nonlocal)
+    sa_mode = insn_data[(int) CODE_FOR_save_stack_nonlocal].operand[0].mode;
+#endif
+#ifdef STACK_SAVEAREA_MODE
+  sa_mode = STACK_SAVEAREA_MODE (SAVE_NONLOCAL);
+#endif
+
+  stack_save
+    = gen_rtx_MEM (sa_mode,
+		   memory_address
+		   (sa_mode,
+		    plus_constant (buf_addr, 2 * GET_MODE_SIZE (Pmode))));
+
+#ifdef HAVE_setjmp
+  if (HAVE_setjmp)
+    emit_insn (gen_setjmp ());
+#endif
+
+  emit_stack_save (SAVE_NONLOCAL, &stack_save, NULL_RTX);
+}
+
+/* Expand a call to __builtin_prefetch.  For a target that does not support
+   data prefetch, evaluate the memory address argument in case it has side
+   effects.  */
+
+static void
+expand_builtin_prefetch (tree arglist)
+{
+  tree arg0, arg1, arg2;
+  rtx op0, op1, op2;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, 0))
+    return;
+
+  arg0 = TREE_VALUE (arglist);
+  /* Arguments 1 and 2 are optional; argument 1 (read/write) defaults to
+     zero (read) and argument 2 (locality) defaults to 3 (high degree of
+     locality).  */
+  if (TREE_CHAIN (arglist))
+    {
+      arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+      if (TREE_CHAIN (TREE_CHAIN (arglist)))
+	arg2 = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      else
+	arg2 = build_int_cst (NULL_TREE, 3);
+    }
+  else
+    {
+      arg1 = integer_zero_node;
+      arg2 = build_int_cst (NULL_TREE, 3);
+    }
+
+  /* Argument 0 is an address.  */
+  op0 = expand_expr (arg0, NULL_RTX, Pmode, EXPAND_NORMAL);
+
+  /* Argument 1 (read/write flag) must be a compile-time constant int.  */
+  if (TREE_CODE (arg1) != INTEGER_CST)
+    {
+      error ("second argument to %<__builtin_prefetch%> must be a constant");
+      arg1 = integer_zero_node;
+    }
+  op1 = expand_expr (arg1, NULL_RTX, VOIDmode, 0);
+  /* Argument 1 must be either zero or one.  */
+  if (INTVAL (op1) != 0 && INTVAL (op1) != 1)
+    {
+      warning (0, "invalid second argument to %<__builtin_prefetch%>;"
+	       " using zero");
+      op1 = const0_rtx;
+    }
+
+  /* Argument 2 (locality) must be a compile-time constant int.  */
+  if (TREE_CODE (arg2) != INTEGER_CST)
+    {
+      error ("third argument to %<__builtin_prefetch%> must be a constant");
+      arg2 = integer_zero_node;
+    }
+  op2 = expand_expr (arg2, NULL_RTX, VOIDmode, 0);
+  /* Argument 2 must be 0, 1, 2, or 3.  */
+  if (INTVAL (op2) < 0 || INTVAL (op2) > 3)
+    {
+      warning (0, "invalid third argument to %<__builtin_prefetch%>; using zero");
+      op2 = const0_rtx;
+    }
+
+#ifdef HAVE_prefetch
+  if (HAVE_prefetch)
+    {
+      if ((! (*insn_data[(int) CODE_FOR_prefetch].operand[0].predicate)
+	     (op0,
+	      insn_data[(int) CODE_FOR_prefetch].operand[0].mode))
+	  || (GET_MODE (op0) != Pmode))
+	{
+	  op0 = convert_memory_address (Pmode, op0);
+	  op0 = force_reg (Pmode, op0);
+	}
+      emit_insn (gen_prefetch (op0, op1, op2));
+    }
+#endif
+
+  /* Don't do anything with direct references to volatile memory, but
+     generate code to handle other side effects.  */
+  if (!MEM_P (op0) && side_effects_p (op0))
+    emit_insn (op0);
+}
+
+/* Get a MEM rtx for expression EXP which is the address of an operand
+   to be used in a string instruction (cmpstrsi, movmemsi, ..).  LEN is
+   the maximum length of the block of memory that might be accessed or
+   NULL if unknown.  */
+
+static rtx
+get_memory_rtx (tree exp, tree len)
+{
+  rtx addr = expand_expr (exp, NULL_RTX, ptr_mode, EXPAND_NORMAL);
+  rtx mem = gen_rtx_MEM (BLKmode, memory_address (BLKmode, addr));
+
+  /* Get an expression we can use to find the attributes to assign to MEM.
+     If it is an ADDR_EXPR, use the operand.  Otherwise, dereference it if
+     we can.  First remove any nops.  */
+  while ((TREE_CODE (exp) == NOP_EXPR || TREE_CODE (exp) == CONVERT_EXPR
+	  || TREE_CODE (exp) == NON_LVALUE_EXPR)
+	 && POINTER_TYPE_P (TREE_TYPE (TREE_OPERAND (exp, 0))))
+    exp = TREE_OPERAND (exp, 0);
+
+  if (TREE_CODE (exp) == ADDR_EXPR)
+    exp = TREE_OPERAND (exp, 0);
+  else if (POINTER_TYPE_P (TREE_TYPE (exp)))
+    exp = build1 (INDIRECT_REF, TREE_TYPE (TREE_TYPE (exp)), exp);
+  else
+    exp = NULL;
+
+  /* Honor attributes derived from exp, except for the alias set
+     (as builtin stringops may alias with anything) and the size
+     (as stringops may access multiple array elements).  */
+  if (exp)
+    {
+      set_mem_attributes (mem, exp, 0);
+
+      /* Allow the string and memory builtins to overflow from one
+	 field into another, see http://gcc.gnu.org/PR23561.
+	 Thus avoid COMPONENT_REFs in MEM_EXPR unless we know the whole
+	 memory accessed by the string or memory builtin will fit
+	 within the field.  */
+      if (MEM_EXPR (mem) && TREE_CODE (MEM_EXPR (mem)) == COMPONENT_REF)
+	{
+	  tree mem_expr = MEM_EXPR (mem);
+	  HOST_WIDE_INT offset = -1, length = -1;
+	  tree inner = exp;
+
+	  while (TREE_CODE (inner) == ARRAY_REF
+		 || TREE_CODE (inner) == NOP_EXPR
+		 || TREE_CODE (inner) == CONVERT_EXPR
+		 || TREE_CODE (inner) == NON_LVALUE_EXPR
+		 || TREE_CODE (inner) == VIEW_CONVERT_EXPR
+		 || TREE_CODE (inner) == SAVE_EXPR)
+	    inner = TREE_OPERAND (inner, 0);
+
+	  gcc_assert (TREE_CODE (inner) == COMPONENT_REF);
+
+	  if (MEM_OFFSET (mem)
+	      && GET_CODE (MEM_OFFSET (mem)) == CONST_INT)
+	    offset = INTVAL (MEM_OFFSET (mem));
+
+	  if (offset >= 0 && len && host_integerp (len, 0))
+	    length = tree_low_cst (len, 0);
+
+	  while (TREE_CODE (inner) == COMPONENT_REF)
+	    {
+	      tree field = TREE_OPERAND (inner, 1);
+	      gcc_assert (! DECL_BIT_FIELD (field));
+	      gcc_assert (TREE_CODE (mem_expr) == COMPONENT_REF);
+	      gcc_assert (field == TREE_OPERAND (mem_expr, 1));
+
+	      if (length >= 0
+		  && TYPE_SIZE_UNIT (TREE_TYPE (inner))
+		  && host_integerp (TYPE_SIZE_UNIT (TREE_TYPE (inner)), 0))
+		{
+		  HOST_WIDE_INT size
+		    = tree_low_cst (TYPE_SIZE_UNIT (TREE_TYPE (inner)), 0);
+		  /* If we can prove the memory starting at XEXP (mem, 0)
+		     and ending at XEXP (mem, 0) + LENGTH will fit into
+		     this field, we can keep that COMPONENT_REF in MEM_EXPR.  */
+		  if (offset <= size
+		      && length <= size
+		      && offset + length <= size)
+		    break;
+		}
+
+	      if (offset >= 0
+		  && host_integerp (DECL_FIELD_OFFSET (field), 0))
+		offset += tree_low_cst (DECL_FIELD_OFFSET (field), 0)
+			  + tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 1)
+			    / BITS_PER_UNIT;
+	      else
+		{
+		  offset = -1;
+		  length = -1;
+		}
+
+	      mem_expr = TREE_OPERAND (mem_expr, 0);
+	      inner = TREE_OPERAND (inner, 0);
+	    }
+
+	  if (mem_expr == NULL)
+	    offset = -1;
+	  if (mem_expr != MEM_EXPR (mem))
+	    {
+	      set_mem_expr (mem, mem_expr);
+	      set_mem_offset (mem, offset >= 0 ? GEN_INT (offset) : NULL_RTX);
+	    }
+	}
+      set_mem_alias_set (mem, 0);
+      set_mem_size (mem, NULL_RTX);
+    }
+
+  return mem;
+}
+
+/* Built-in functions to perform an untyped call and return.  */
+
+/* For each register that may be used for calling a function, this
+   gives a mode used to copy the register's value.  VOIDmode indicates
+   the register is not used for calling a function.  If the machine
+   has register windows, this gives only the outbound registers.
+   INCOMING_REGNO gives the corresponding inbound register.  */
+static enum machine_mode apply_args_mode[FIRST_PSEUDO_REGISTER];
+
+/* For each register that may be used for returning values, this gives
+   a mode used to copy the register's value.  VOIDmode indicates the
+   register is not used for returning values.  If the machine has
+   register windows, this gives only the outbound registers.
+   INCOMING_REGNO gives the corresponding inbound register.  */
+static enum machine_mode apply_result_mode[FIRST_PSEUDO_REGISTER];
+
+/* For each register that may be used for calling a function, this
+   gives the offset of that register into the block returned by
+   __builtin_apply_args.  0 indicates that the register is not
+   used for calling a function.  */
+static int apply_args_reg_offset[FIRST_PSEUDO_REGISTER];
+
+/* Return the size required for the block returned by __builtin_apply_args,
+   and initialize apply_args_mode.  */
+
+static int
+apply_args_size (void)
+{
+  static int size = -1;
+  int align;
+  unsigned int regno;
+  enum machine_mode mode;
+
+  /* The values computed by this function never change.  */
+  if (size < 0)
+    {
+      /* The first value is the incoming arg-pointer.  */
+      size = GET_MODE_SIZE (Pmode);
+
+      /* The second value is the structure value address unless this is
+	 passed as an "invisible" first argument.  */
+      if (targetm.calls.struct_value_rtx (cfun ? TREE_TYPE (cfun->decl) : 0, 0))
+	size += GET_MODE_SIZE (Pmode);
+
+      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+	if (FUNCTION_ARG_REGNO_P (regno))
+	  {
+	    mode = reg_raw_mode[regno];
+
+	    gcc_assert (mode != VOIDmode);
+
+	    align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	    if (size % align != 0)
+	      size = CEIL (size, align) * align;
+	    apply_args_reg_offset[regno] = size;
+	    size += GET_MODE_SIZE (mode);
+	    apply_args_mode[regno] = mode;
+	  }
+	else
+	  {
+	    apply_args_mode[regno] = VOIDmode;
+	    apply_args_reg_offset[regno] = 0;
+	  }
+    }
+  return size;
+}
+
+/* Return the size required for the block returned by __builtin_apply,
+   and initialize apply_result_mode.  */
+
+static int
+apply_result_size (void)
+{
+  static int size = -1;
+  int align, regno;
+  enum machine_mode mode;
+
+  /* The values computed by this function never change.  */
+  if (size < 0)
+    {
+      size = 0;
+
+      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+	if (FUNCTION_VALUE_REGNO_P (regno))
+	  {
+	    mode = reg_raw_mode[regno];
+
+	    gcc_assert (mode != VOIDmode);
+
+	    align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	    if (size % align != 0)
+	      size = CEIL (size, align) * align;
+	    size += GET_MODE_SIZE (mode);
+	    apply_result_mode[regno] = mode;
+	  }
+	else
+	  apply_result_mode[regno] = VOIDmode;
+
+      /* Allow targets that use untyped_call and untyped_return to override
+	 the size so that machine-specific information can be stored here.  */
+#ifdef APPLY_RESULT_SIZE
+      size = APPLY_RESULT_SIZE;
+#endif
+    }
+  return size;
+}
+
+#if defined (HAVE_untyped_call) || defined (HAVE_untyped_return)
+/* Create a vector describing the result block RESULT.  If SAVEP is true,
+   the result block is used to save the values; otherwise it is used to
+   restore the values.  */
+
+static rtx
+result_vector (int savep, rtx result)
+{
+  int regno, size, align, nelts;
+  enum machine_mode mode;
+  rtx reg, mem;
+  rtx *savevec = alloca (FIRST_PSEUDO_REGISTER * sizeof (rtx));
+
+  size = nelts = 0;
+  for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+    if ((mode = apply_result_mode[regno]) != VOIDmode)
+      {
+	align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	if (size % align != 0)
+	  size = CEIL (size, align) * align;
+	reg = gen_rtx_REG (mode, savep ? regno : INCOMING_REGNO (regno));
+	mem = adjust_address (result, mode, size);
+	savevec[nelts++] = (savep
+			    ? gen_rtx_SET (VOIDmode, mem, reg)
+			    : gen_rtx_SET (VOIDmode, reg, mem));
+	size += GET_MODE_SIZE (mode);
+      }
+  return gen_rtx_PARALLEL (VOIDmode, gen_rtvec_v (nelts, savevec));
+}
+#endif /* HAVE_untyped_call or HAVE_untyped_return */
+
+/* Save the state required to perform an untyped call with the same
+   arguments as were passed to the current function.  */
+
+static rtx
+expand_builtin_apply_args_1 (void)
+{
+  rtx registers, tem;
+  int size, align, regno;
+  enum machine_mode mode;
+  rtx struct_incoming_value = targetm.calls.struct_value_rtx (cfun ? TREE_TYPE (cfun->decl) : 0, 1);
+
+  /* Create a block where the arg-pointer, structure value address,
+     and argument registers can be saved.  */
+  registers = assign_stack_local (BLKmode, apply_args_size (), -1);
+
+  /* Walk past the arg-pointer and structure value address.  */
+  size = GET_MODE_SIZE (Pmode);
+  if (targetm.calls.struct_value_rtx (cfun ? TREE_TYPE (cfun->decl) : 0, 0))
+    size += GET_MODE_SIZE (Pmode);
+
+  /* Save each register used in calling a function to the block.  */
+  for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+    if ((mode = apply_args_mode[regno]) != VOIDmode)
+      {
+	align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	if (size % align != 0)
+	  size = CEIL (size, align) * align;
+
+	tem = gen_rtx_REG (mode, INCOMING_REGNO (regno));
+
+	emit_move_insn (adjust_address (registers, mode, size), tem);
+	size += GET_MODE_SIZE (mode);
+      }
+
+  /* Save the arg pointer to the block.  */
+  tem = copy_to_reg (virtual_incoming_args_rtx);
+#ifdef STACK_GROWS_DOWNWARD
+  /* We need the pointer as the caller actually passed them to us, not
+     as we might have pretended they were passed.  Make sure it's a valid
+     operand, as emit_move_insn isn't expected to handle a PLUS.  */
+  tem
+    = force_operand (plus_constant (tem, current_function_pretend_args_size),
+		     NULL_RTX);
+#endif
+  emit_move_insn (adjust_address (registers, Pmode, 0), tem);
+
+  size = GET_MODE_SIZE (Pmode);
+
+  /* Save the structure value address unless this is passed as an
+     "invisible" first argument.  */
+  if (struct_incoming_value)
+    {
+      emit_move_insn (adjust_address (registers, Pmode, size),
+		      copy_to_reg (struct_incoming_value));
+      size += GET_MODE_SIZE (Pmode);
+    }
+
+  /* Return the address of the block.  */
+  return copy_addr_to_reg (XEXP (registers, 0));
+}
+
+/* __builtin_apply_args returns block of memory allocated on
+   the stack into which is stored the arg pointer, structure
+   value address, static chain, and all the registers that might
+   possibly be used in performing a function call.  The code is
+   moved to the start of the function so the incoming values are
+   saved.  */
+
+static rtx
+expand_builtin_apply_args (void)
+{
+  /* Don't do __builtin_apply_args more than once in a function.
+     Save the result of the first call and reuse it.  */
+  if (apply_args_value != 0)
+    return apply_args_value;
+  {
+    /* When this function is called, it means that registers must be
+       saved on entry to this function.  So we migrate the
+       call to the first insn of this function.  */
+    rtx temp;
+    rtx seq;
+
+    start_sequence ();
+    temp = expand_builtin_apply_args_1 ();
+    seq = get_insns ();
+    end_sequence ();
+
+    apply_args_value = temp;
+
+    /* Put the insns after the NOTE that starts the function.
+       If this is inside a start_sequence, make the outer-level insn
+       chain current, so the code is placed at the start of the
+       function.  */
+    push_topmost_sequence ();
+    emit_insn_before (seq, NEXT_INSN (entry_of_function ()));
+    pop_topmost_sequence ();
+    return temp;
+  }
+}
+
+/* Perform an untyped call and save the state required to perform an
+   untyped return of whatever value was returned by the given function.  */
+
+static rtx
+expand_builtin_apply (rtx function, rtx arguments, rtx argsize)
+{
+  int size, align, regno;
+  enum machine_mode mode;
+  rtx incoming_args, result, reg, dest, src, call_insn;
+  rtx old_stack_level = 0;
+  rtx call_fusage = 0;
+  rtx struct_value = targetm.calls.struct_value_rtx (cfun ? TREE_TYPE (cfun->decl) : 0, 0);
+
+  arguments = convert_memory_address (Pmode, arguments);
+
+  /* Create a block where the return registers can be saved.  */
+  result = assign_stack_local (BLKmode, apply_result_size (), -1);
+
+  /* Fetch the arg pointer from the ARGUMENTS block.  */
+  incoming_args = gen_reg_rtx (Pmode);
+  emit_move_insn (incoming_args, gen_rtx_MEM (Pmode, arguments));
+#ifndef STACK_GROWS_DOWNWARD
+  incoming_args = expand_simple_binop (Pmode, MINUS, incoming_args, argsize,
+				       incoming_args, 0, OPTAB_LIB_WIDEN);
+#endif
+
+  /* Push a new argument block and copy the arguments.  Do not allow
+     the (potential) memcpy call below to interfere with our stack
+     manipulations.  */
+  do_pending_stack_adjust ();
+  NO_DEFER_POP;
+
+  /* Save the stack with nonlocal if available.  */
+#ifdef HAVE_save_stack_nonlocal
+  if (HAVE_save_stack_nonlocal)
+    emit_stack_save (SAVE_NONLOCAL, &old_stack_level, NULL_RTX);
+  else
+#endif
+    emit_stack_save (SAVE_BLOCK, &old_stack_level, NULL_RTX);
+
+  /* Allocate a block of memory onto the stack and copy the memory
+     arguments to the outgoing arguments address.  */
+  allocate_dynamic_stack_space (argsize, 0, BITS_PER_UNIT);
+  dest = virtual_outgoing_args_rtx;
+#ifndef STACK_GROWS_DOWNWARD
+  if (GET_CODE (argsize) == CONST_INT)
+    dest = plus_constant (dest, -INTVAL (argsize));
+  else
+    dest = gen_rtx_PLUS (Pmode, dest, negate_rtx (Pmode, argsize));
+#endif
+  dest = gen_rtx_MEM (BLKmode, dest);
+  set_mem_align (dest, PARM_BOUNDARY);
+  src = gen_rtx_MEM (BLKmode, incoming_args);
+  set_mem_align (src, PARM_BOUNDARY);
+  emit_block_move (dest, src, argsize, BLOCK_OP_NORMAL);
+
+  /* Refer to the argument block.  */
+  apply_args_size ();
+  arguments = gen_rtx_MEM (BLKmode, arguments);
+  set_mem_align (arguments, PARM_BOUNDARY);
+
+  /* Walk past the arg-pointer and structure value address.  */
+  size = GET_MODE_SIZE (Pmode);
+  if (struct_value)
+    size += GET_MODE_SIZE (Pmode);
+
+  /* Restore each of the registers previously saved.  Make USE insns
+     for each of these registers for use in making the call.  */
+  for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+    if ((mode = apply_args_mode[regno]) != VOIDmode)
+      {
+	align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	if (size % align != 0)
+	  size = CEIL (size, align) * align;
+	reg = gen_rtx_REG (mode, regno);
+	emit_move_insn (reg, adjust_address (arguments, mode, size));
+	use_reg (&call_fusage, reg);
+	size += GET_MODE_SIZE (mode);
+      }
+
+  /* Restore the structure value address unless this is passed as an
+     "invisible" first argument.  */
+  size = GET_MODE_SIZE (Pmode);
+  if (struct_value)
+    {
+      rtx value = gen_reg_rtx (Pmode);
+      emit_move_insn (value, adjust_address (arguments, Pmode, size));
+      emit_move_insn (struct_value, value);
+      if (REG_P (struct_value))
+	use_reg (&call_fusage, struct_value);
+      size += GET_MODE_SIZE (Pmode);
+    }
+
+  /* All arguments and registers used for the call are set up by now!  */
+  function = prepare_call_address (function, NULL, &call_fusage, 0, 0);
+
+  /* Ensure address is valid.  SYMBOL_REF is already valid, so no need,
+     and we don't want to load it into a register as an optimization,
+     because prepare_call_address already did it if it should be done.  */
+  if (GET_CODE (function) != SYMBOL_REF)
+    function = memory_address (FUNCTION_MODE, function);
+
+  /* Generate the actual call instruction and save the return value.  */
+#ifdef HAVE_untyped_call
+  if (HAVE_untyped_call)
+    emit_call_insn (gen_untyped_call (gen_rtx_MEM (FUNCTION_MODE, function),
+				      result, result_vector (1, result)));
+  else
+#endif
+#ifdef HAVE_call_value
+  if (HAVE_call_value)
+    {
+      rtx valreg = 0;
+
+      /* Locate the unique return register.  It is not possible to
+	 express a call that sets more than one return register using
+	 call_value; use untyped_call for that.  In fact, untyped_call
+	 only needs to save the return registers in the given block.  */
+      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+	if ((mode = apply_result_mode[regno]) != VOIDmode)
+	  {
+	    gcc_assert (!valreg); /* HAVE_untyped_call required.  */
+
+	    valreg = gen_rtx_REG (mode, regno);
+	  }
+
+      emit_call_insn (GEN_CALL_VALUE (valreg,
+				      gen_rtx_MEM (FUNCTION_MODE, function),
+				      const0_rtx, NULL_RTX, const0_rtx));
+
+      emit_move_insn (adjust_address (result, GET_MODE (valreg), 0), valreg);
+    }
+  else
+#endif
+    gcc_unreachable ();
+
+  /* Find the CALL insn we just emitted, and attach the register usage
+     information.  */
+  call_insn = last_call_insn ();
+  add_function_usage_to (call_insn, call_fusage);
+
+  /* Restore the stack.  */
+#ifdef HAVE_save_stack_nonlocal
+  if (HAVE_save_stack_nonlocal)
+    emit_stack_restore (SAVE_NONLOCAL, old_stack_level, NULL_RTX);
+  else
+#endif
+    emit_stack_restore (SAVE_BLOCK, old_stack_level, NULL_RTX);
+
+  OK_DEFER_POP;
+
+  /* Return the address of the result block.  */
+  result = copy_addr_to_reg (XEXP (result, 0));
+  return convert_memory_address (ptr_mode, result);
+}
+
+/* Perform an untyped return.  */
+
+static void
+expand_builtin_return (rtx result)
+{
+  int size, align, regno;
+  enum machine_mode mode;
+  rtx reg;
+  rtx call_fusage = 0;
+
+  result = convert_memory_address (Pmode, result);
+
+  apply_result_size ();
+  result = gen_rtx_MEM (BLKmode, result);
+
+#ifdef HAVE_untyped_return
+  if (HAVE_untyped_return)
+    {
+      emit_jump_insn (gen_untyped_return (result, result_vector (0, result)));
+      emit_barrier ();
+      return;
+    }
+#endif
+
+  /* Restore the return value and note that each value is used.  */
+  size = 0;
+  for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)
+    if ((mode = apply_result_mode[regno]) != VOIDmode)
+      {
+	align = GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT;
+	if (size % align != 0)
+	  size = CEIL (size, align) * align;
+	reg = gen_rtx_REG (mode, INCOMING_REGNO (regno));
+	emit_move_insn (reg, adjust_address (result, mode, size));
+
+	push_to_sequence (call_fusage);
+	emit_insn (gen_rtx_USE (VOIDmode, reg));
+	call_fusage = get_insns ();
+	end_sequence ();
+	size += GET_MODE_SIZE (mode);
+      }
+
+  /* Put the USE insns before the return.  */
+  emit_insn (call_fusage);
+
+  /* Return whatever values was restored by jumping directly to the end
+     of the function.  */
+  expand_naked_return ();
+}
+
+/* Used by expand_builtin_classify_type and fold_builtin_classify_type.  */
+
+static enum type_class
+type_to_class (tree type)
+{
+  switch (TREE_CODE (type))
+    {
+    case VOID_TYPE:	   return void_type_class;
+    case INTEGER_TYPE:	   return integer_type_class;
+    case CHAR_TYPE:	   return char_type_class;
+    case ENUMERAL_TYPE:	   return enumeral_type_class;
+    case BOOLEAN_TYPE:	   return boolean_type_class;
+    case POINTER_TYPE:	   return pointer_type_class;
+    case REFERENCE_TYPE:   return reference_type_class;
+    case OFFSET_TYPE:	   return offset_type_class;
+    case REAL_TYPE:	   return real_type_class;
+    case COMPLEX_TYPE:	   return complex_type_class;
+    case FUNCTION_TYPE:	   return function_type_class;
+    case METHOD_TYPE:	   return method_type_class;
+    case RECORD_TYPE:	   return record_type_class;
+    case UNION_TYPE:
+    case QUAL_UNION_TYPE:  return union_type_class;
+    case ARRAY_TYPE:	   return (TYPE_STRING_FLAG (type)
+				   ? string_type_class : array_type_class);
+    case LANG_TYPE:	   return lang_type_class;
+    default:		   return no_type_class;
+    }
+}
+
+/* Expand a call to __builtin_classify_type with arguments found in
+   ARGLIST.  */
+
+static rtx
+expand_builtin_classify_type (tree arglist)
+{
+  if (arglist != 0)
+    return GEN_INT (type_to_class (TREE_TYPE (TREE_VALUE (arglist))));
+  return GEN_INT (no_type_class);
+}
+
+/* This helper macro, meant to be used in mathfn_built_in below,
+   determines which among a set of three builtin math functions is
+   appropriate for a given type mode.  The `F' and `L' cases are
+   automatically generated from the `double' case.  */
+#define CASE_MATHFN(BUILT_IN_MATHFN) \
+  case BUILT_IN_MATHFN: case BUILT_IN_MATHFN##F: case BUILT_IN_MATHFN##L: \
+  fcode = BUILT_IN_MATHFN; fcodef = BUILT_IN_MATHFN##F ; \
+  fcodel = BUILT_IN_MATHFN##L ; break;
+
+/* Return mathematic function equivalent to FN but operating directly
+   on TYPE, if available.  If we can't do the conversion, return zero.  */
+tree
+mathfn_built_in (tree type, enum built_in_function fn)
+{
+  enum built_in_function fcode, fcodef, fcodel;
+
+  switch (fn)
+    {
+      CASE_MATHFN (BUILT_IN_ACOS)
+      CASE_MATHFN (BUILT_IN_ACOSH)
+      CASE_MATHFN (BUILT_IN_ASIN)
+      CASE_MATHFN (BUILT_IN_ASINH)
+      CASE_MATHFN (BUILT_IN_ATAN)
+      CASE_MATHFN (BUILT_IN_ATAN2)
+      CASE_MATHFN (BUILT_IN_ATANH)
+      CASE_MATHFN (BUILT_IN_CBRT)
+      CASE_MATHFN (BUILT_IN_CEIL)
+      CASE_MATHFN (BUILT_IN_COPYSIGN)
+      CASE_MATHFN (BUILT_IN_COS)
+      CASE_MATHFN (BUILT_IN_COSH)
+      CASE_MATHFN (BUILT_IN_DREM)
+      CASE_MATHFN (BUILT_IN_ERF)
+      CASE_MATHFN (BUILT_IN_ERFC)
+      CASE_MATHFN (BUILT_IN_EXP)
+      CASE_MATHFN (BUILT_IN_EXP10)
+      CASE_MATHFN (BUILT_IN_EXP2)
+      CASE_MATHFN (BUILT_IN_EXPM1)
+      CASE_MATHFN (BUILT_IN_FABS)
+      CASE_MATHFN (BUILT_IN_FDIM)
+      CASE_MATHFN (BUILT_IN_FLOOR)
+      CASE_MATHFN (BUILT_IN_FMA)
+      CASE_MATHFN (BUILT_IN_FMAX)
+      CASE_MATHFN (BUILT_IN_FMIN)
+      CASE_MATHFN (BUILT_IN_FMOD)
+      CASE_MATHFN (BUILT_IN_FREXP)
+      CASE_MATHFN (BUILT_IN_GAMMA)
+      CASE_MATHFN (BUILT_IN_HUGE_VAL)
+      CASE_MATHFN (BUILT_IN_HYPOT)
+      CASE_MATHFN (BUILT_IN_ILOGB)
+      CASE_MATHFN (BUILT_IN_INF)
+      CASE_MATHFN (BUILT_IN_J0)
+      CASE_MATHFN (BUILT_IN_J1)
+      CASE_MATHFN (BUILT_IN_JN)
+      CASE_MATHFN (BUILT_IN_LCEIL)
+      CASE_MATHFN (BUILT_IN_LDEXP)
+      CASE_MATHFN (BUILT_IN_LFLOOR)
+      CASE_MATHFN (BUILT_IN_LGAMMA)
+      CASE_MATHFN (BUILT_IN_LLCEIL)
+      CASE_MATHFN (BUILT_IN_LLFLOOR)
+      CASE_MATHFN (BUILT_IN_LLRINT)
+      CASE_MATHFN (BUILT_IN_LLROUND)
+      CASE_MATHFN (BUILT_IN_LOG)
+      CASE_MATHFN (BUILT_IN_LOG10)
+      CASE_MATHFN (BUILT_IN_LOG1P)
+      CASE_MATHFN (BUILT_IN_LOG2)
+      CASE_MATHFN (BUILT_IN_LOGB)
+      CASE_MATHFN (BUILT_IN_LRINT)
+      CASE_MATHFN (BUILT_IN_LROUND)
+      CASE_MATHFN (BUILT_IN_MODF)
+      CASE_MATHFN (BUILT_IN_NAN)
+      CASE_MATHFN (BUILT_IN_NANS)
+      CASE_MATHFN (BUILT_IN_NEARBYINT)
+      CASE_MATHFN (BUILT_IN_NEXTAFTER)
+      CASE_MATHFN (BUILT_IN_NEXTTOWARD)
+      CASE_MATHFN (BUILT_IN_POW)
+      CASE_MATHFN (BUILT_IN_POWI)
+      CASE_MATHFN (BUILT_IN_POW10)
+      CASE_MATHFN (BUILT_IN_REMAINDER)
+      CASE_MATHFN (BUILT_IN_REMQUO)
+      CASE_MATHFN (BUILT_IN_RINT)
+      CASE_MATHFN (BUILT_IN_ROUND)
+      CASE_MATHFN (BUILT_IN_SCALB)
+      CASE_MATHFN (BUILT_IN_SCALBLN)
+      CASE_MATHFN (BUILT_IN_SCALBN)
+      CASE_MATHFN (BUILT_IN_SIGNIFICAND)
+      CASE_MATHFN (BUILT_IN_SIN)
+      CASE_MATHFN (BUILT_IN_SINCOS)
+      CASE_MATHFN (BUILT_IN_SINH)
+      CASE_MATHFN (BUILT_IN_SQRT)
+      CASE_MATHFN (BUILT_IN_TAN)
+      CASE_MATHFN (BUILT_IN_TANH)
+      CASE_MATHFN (BUILT_IN_TGAMMA)
+      CASE_MATHFN (BUILT_IN_TRUNC)
+      CASE_MATHFN (BUILT_IN_Y0)
+      CASE_MATHFN (BUILT_IN_Y1)
+      CASE_MATHFN (BUILT_IN_YN)
+
+      default:
+	return 0;
+      }
+
+  if (TYPE_MAIN_VARIANT (type) == double_type_node)
+    return implicit_built_in_decls[fcode];
+  else if (TYPE_MAIN_VARIANT (type) == float_type_node)
+    return implicit_built_in_decls[fcodef];
+  else if (TYPE_MAIN_VARIANT (type) == long_double_type_node)
+    return implicit_built_in_decls[fcodel];
+  else
+    return 0;
+}
+
+/* If errno must be maintained, expand the RTL to check if the result,
+   TARGET, of a built-in function call, EXP, is NaN, and if so set
+   errno to EDOM.  */
+
+static void
+expand_errno_check (tree exp, rtx target)
+{
+  rtx lab = gen_label_rtx ();
+
+  /* Test the result; if it is NaN, set errno=EDOM because
+     the argument was not in the domain.  */
+  emit_cmp_and_jump_insns (target, target, EQ, 0, GET_MODE (target),
+			   0, lab);
+
+#ifdef TARGET_EDOM
+  /* If this built-in doesn't throw an exception, set errno directly.  */
+  if (TREE_NOTHROW (TREE_OPERAND (TREE_OPERAND (exp, 0), 0)))
+    {
+#ifdef GEN_ERRNO_RTX
+      rtx errno_rtx = GEN_ERRNO_RTX;
+#else
+      rtx errno_rtx
+	  = gen_rtx_MEM (word_mode, gen_rtx_SYMBOL_REF (Pmode, "errno"));
+#endif
+      emit_move_insn (errno_rtx, GEN_INT (TARGET_EDOM));
+      emit_label (lab);
+      return;
+    }
+#endif
+
+  /* We can't set errno=EDOM directly; let the library call do it.
+     Pop the arguments right away in case the call gets deleted.  */
+  NO_DEFER_POP;
+  expand_call (exp, target, 0);
+  OK_DEFER_POP;
+  emit_label (lab);
+}
+
+
+/* Expand a call to one of the builtin math functions (sqrt, exp, or log).
+   Return 0 if a normal call should be emitted rather than expanding the
+   function in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing one of EXP's operands.  */
+
+static rtx
+expand_builtin_mathfn (tree exp, rtx target, rtx subtarget)
+{
+  optab builtin_optab;
+  rtx op0, insns, before_call;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  enum machine_mode mode;
+  bool errno_set = false;
+  tree arg, narg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+
+  switch (DECL_FUNCTION_CODE (fndecl))
+    {
+    case BUILT_IN_SQRT:
+    case BUILT_IN_SQRTF:
+    case BUILT_IN_SQRTL:
+      errno_set = ! tree_expr_nonnegative_p (arg);
+      builtin_optab = sqrt_optab;
+      break;
+    case BUILT_IN_EXP:
+    case BUILT_IN_EXPF:
+    case BUILT_IN_EXPL:
+      errno_set = true; builtin_optab = exp_optab; break;
+    case BUILT_IN_EXP10:
+    case BUILT_IN_EXP10F:
+    case BUILT_IN_EXP10L:
+    case BUILT_IN_POW10:
+    case BUILT_IN_POW10F:
+    case BUILT_IN_POW10L:
+      errno_set = true; builtin_optab = exp10_optab; break;
+    case BUILT_IN_EXP2:
+    case BUILT_IN_EXP2F:
+    case BUILT_IN_EXP2L:
+      errno_set = true; builtin_optab = exp2_optab; break;
+    case BUILT_IN_EXPM1:
+    case BUILT_IN_EXPM1F:
+    case BUILT_IN_EXPM1L:
+      errno_set = true; builtin_optab = expm1_optab; break;
+    case BUILT_IN_LOGB:
+    case BUILT_IN_LOGBF:
+    case BUILT_IN_LOGBL:
+      errno_set = true; builtin_optab = logb_optab; break;
+    case BUILT_IN_ILOGB:
+    case BUILT_IN_ILOGBF:
+    case BUILT_IN_ILOGBL:
+      errno_set = true; builtin_optab = ilogb_optab; break;
+    case BUILT_IN_LOG:
+    case BUILT_IN_LOGF:
+    case BUILT_IN_LOGL:
+      errno_set = true; builtin_optab = log_optab; break;
+    case BUILT_IN_LOG10:
+    case BUILT_IN_LOG10F:
+    case BUILT_IN_LOG10L:
+      errno_set = true; builtin_optab = log10_optab; break;
+    case BUILT_IN_LOG2:
+    case BUILT_IN_LOG2F:
+    case BUILT_IN_LOG2L:
+      errno_set = true; builtin_optab = log2_optab; break;
+    case BUILT_IN_LOG1P:
+    case BUILT_IN_LOG1PF:
+    case BUILT_IN_LOG1PL:
+      errno_set = true; builtin_optab = log1p_optab; break;
+    case BUILT_IN_ASIN:
+    case BUILT_IN_ASINF:
+    case BUILT_IN_ASINL:
+      builtin_optab = asin_optab; break;
+    case BUILT_IN_ACOS:
+    case BUILT_IN_ACOSF:
+    case BUILT_IN_ACOSL:
+      builtin_optab = acos_optab; break;
+    case BUILT_IN_TAN:
+    case BUILT_IN_TANF:
+    case BUILT_IN_TANL:
+      builtin_optab = tan_optab; break;
+    case BUILT_IN_ATAN:
+    case BUILT_IN_ATANF:
+    case BUILT_IN_ATANL:
+      builtin_optab = atan_optab; break;
+    case BUILT_IN_FLOOR:
+    case BUILT_IN_FLOORF:
+    case BUILT_IN_FLOORL:
+      builtin_optab = floor_optab; break;
+    case BUILT_IN_CEIL:
+    case BUILT_IN_CEILF:
+    case BUILT_IN_CEILL:
+      builtin_optab = ceil_optab; break;
+    case BUILT_IN_TRUNC:
+    case BUILT_IN_TRUNCF:
+    case BUILT_IN_TRUNCL:
+      builtin_optab = btrunc_optab; break;
+    case BUILT_IN_ROUND:
+    case BUILT_IN_ROUNDF:
+    case BUILT_IN_ROUNDL:
+      builtin_optab = round_optab; break;
+    case BUILT_IN_NEARBYINT:
+    case BUILT_IN_NEARBYINTF:
+    case BUILT_IN_NEARBYINTL:
+      builtin_optab = nearbyint_optab; break;
+    case BUILT_IN_RINT:
+    case BUILT_IN_RINTF:
+    case BUILT_IN_RINTL:
+      builtin_optab = rint_optab; break;
+    case BUILT_IN_LRINT:
+    case BUILT_IN_LRINTF:
+    case BUILT_IN_LRINTL:
+    case BUILT_IN_LLRINT:
+    case BUILT_IN_LLRINTF:
+    case BUILT_IN_LLRINTL:
+      builtin_optab = lrint_optab; break;
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Make a suitable register to place result in.  */
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  if (! flag_errno_math || ! HONOR_NANS (mode))
+    errno_set = false;
+
+  /* Before working hard, check whether the instruction is available.  */
+  if (builtin_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    {
+      target = gen_reg_rtx (mode);
+
+      /* Wrap the computation of the argument in a SAVE_EXPR, as we may
+	 need to expand the argument again.  This way, we will not perform
+	 side-effects more the once.  */
+      narg = builtin_save_expr (arg);
+      if (narg != arg)
+	{
+	  arg = narg;
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  exp = build_function_call_expr (fndecl, arglist);
+	}
+
+      op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+
+      start_sequence ();
+
+      /* Compute into TARGET.
+	 Set TARGET to wherever the result comes back.  */
+      target = expand_unop (mode, builtin_optab, op0, target, 0);
+
+      if (target != 0)
+	{
+	  if (errno_set)
+	    expand_errno_check (exp, target);
+
+	  /* Output the entire sequence.  */
+	  insns = get_insns ();
+	  end_sequence ();
+	  emit_insn (insns);
+	  return target;
+	}
+
+      /* If we were unable to expand via the builtin, stop the sequence
+	 (without outputting the insns) and call to the library function
+	 with the stabilized argument list.  */
+      end_sequence ();
+    }
+
+  before_call = get_last_insn ();
+
+  target = expand_call (exp, target, target == const0_rtx);
+
+  /* If this is a sqrt operation and we don't care about errno, try to
+     attach a REG_EQUAL note with a SQRT rtx to the emitted libcall.
+     This allows the semantics of the libcall to be visible to the RTL
+     optimizers.  */
+  if (builtin_optab == sqrt_optab && !errno_set)
+    {
+      /* Search backwards through the insns emitted by expand_call looking
+	 for the instruction with the REG_RETVAL note.  */
+      rtx last = get_last_insn ();
+      while (last != before_call)
+	{
+	  if (find_reg_note (last, REG_RETVAL, NULL))
+	    {
+	      rtx note = find_reg_note (last, REG_EQUAL, NULL);
+	      /* Check that the REQ_EQUAL note is an EXPR_LIST with
+		 two elements, i.e. symbol_ref(sqrt) and the operand.  */
+	      if (note
+		  && GET_CODE (note) == EXPR_LIST
+		  && GET_CODE (XEXP (note, 0)) == EXPR_LIST
+		  && XEXP (XEXP (note, 0), 1) != NULL_RTX
+		  && XEXP (XEXP (XEXP (note, 0), 1), 1) == NULL_RTX)
+		{
+		  rtx operand = XEXP (XEXP (XEXP (note, 0), 1), 0);
+		  /* Check operand is a register with expected mode.  */
+		  if (operand
+		      && REG_P (operand)
+		      && GET_MODE (operand) == mode)
+		    {
+		      /* Replace the REG_EQUAL note with a SQRT rtx.  */
+		      rtx equiv = gen_rtx_SQRT (mode, operand);
+		      set_unique_reg_note (last, REG_EQUAL, equiv);
+		    }
+		}
+	      break;
+	    }
+	  last = PREV_INSN (last);
+	}
+    }
+
+  return target;
+}
+
+/* Expand a call to the builtin binary math functions (pow and atan2).
+   Return 0 if a normal call should be emitted rather than expanding the
+   function in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing one of EXP's
+   operands.  */
+
+static rtx
+expand_builtin_mathfn_2 (tree exp, rtx target, rtx subtarget)
+{
+  optab builtin_optab;
+  rtx op0, op1, insns;
+  int op1_type = REAL_TYPE;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree arg0, arg1, temp, narg;
+  enum machine_mode mode;
+  bool errno_set = true;
+  bool stable = true;
+
+  if ((DECL_FUNCTION_CODE (fndecl) == BUILT_IN_LDEXP)
+      || (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_LDEXPF)
+      || (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_LDEXPL))
+    op1_type = INTEGER_TYPE;
+
+  if (!validate_arglist (arglist, REAL_TYPE, op1_type, VOID_TYPE))
+    return 0;
+
+  arg0 = TREE_VALUE (arglist);
+  arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  switch (DECL_FUNCTION_CODE (fndecl))
+    {
+    case BUILT_IN_POW:
+    case BUILT_IN_POWF:
+    case BUILT_IN_POWL:
+      builtin_optab = pow_optab; break;
+    case BUILT_IN_ATAN2:
+    case BUILT_IN_ATAN2F:
+    case BUILT_IN_ATAN2L:
+      builtin_optab = atan2_optab; break;
+    case BUILT_IN_LDEXP:
+    case BUILT_IN_LDEXPF:
+    case BUILT_IN_LDEXPL:
+      builtin_optab = ldexp_optab; break;
+    case BUILT_IN_FMOD:
+    case BUILT_IN_FMODF:
+    case BUILT_IN_FMODL:
+      builtin_optab = fmod_optab; break;
+    case BUILT_IN_DREM:
+    case BUILT_IN_DREMF:
+    case BUILT_IN_DREML:
+      builtin_optab = drem_optab; break;
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Make a suitable register to place result in.  */
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  /* Before working hard, check whether the instruction is available.  */
+  if (builtin_optab->handlers[(int) mode].insn_code == CODE_FOR_nothing)
+    return 0;
+
+  target = gen_reg_rtx (mode);
+
+  if (! flag_errno_math || ! HONOR_NANS (mode))
+    errno_set = false;
+
+  /* Always stabilize the argument list.  */
+  narg = builtin_save_expr (arg1);
+  if (narg != arg1)
+    {
+      arg1 = narg;
+      temp = build_tree_list (NULL_TREE, narg);
+      stable = false;
+    }
+  else
+    temp = TREE_CHAIN (arglist);
+
+  narg = builtin_save_expr (arg0);
+  if (narg != arg0)
+    {
+      arg0 = narg;
+      arglist = tree_cons (NULL_TREE, narg, temp);
+      stable = false;
+    }
+  else if (! stable)
+    arglist = tree_cons (NULL_TREE, arg0, temp);
+
+  if (! stable)
+    exp = build_function_call_expr (fndecl, arglist);
+
+  op0 = expand_expr (arg0, subtarget, VOIDmode, 0);
+  op1 = expand_expr (arg1, 0, VOIDmode, 0);
+
+  start_sequence ();
+
+  /* Compute into TARGET.
+     Set TARGET to wherever the result comes back.  */
+  target = expand_binop (mode, builtin_optab, op0, op1,
+			 target, 0, OPTAB_DIRECT);
+
+  /* If we were unable to expand via the builtin, stop the sequence
+     (without outputting the insns) and call to the library function
+     with the stabilized argument list.  */
+  if (target == 0)
+    {
+      end_sequence ();
+      return expand_call (exp, target, target == const0_rtx);
+    }
+
+  if (errno_set)
+    expand_errno_check (exp, target);
+
+  /* Output the entire sequence.  */
+  insns = get_insns ();
+  end_sequence ();
+  emit_insn (insns);
+
+  return target;
+}
+
+/* Expand a call to the builtin sin and cos math functions.
+   Return 0 if a normal call should be emitted rather than expanding the
+   function in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing one of EXP's
+   operands.  */
+
+static rtx
+expand_builtin_mathfn_3 (tree exp, rtx target, rtx subtarget)
+{
+  optab builtin_optab;
+  rtx op0, insns;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  enum machine_mode mode;
+  bool errno_set = false;
+  tree arg, narg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+
+  switch (DECL_FUNCTION_CODE (fndecl))
+    {
+    case BUILT_IN_SIN:
+    case BUILT_IN_SINF:
+    case BUILT_IN_SINL:
+    case BUILT_IN_COS:
+    case BUILT_IN_COSF:
+    case BUILT_IN_COSL:
+      builtin_optab = sincos_optab; break;
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Make a suitable register to place result in.  */
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  if (! flag_errno_math || ! HONOR_NANS (mode))
+    errno_set = false;
+
+  /* Check if sincos insn is available, otherwise fallback
+     to sin or cos insn.  */
+  if (builtin_optab->handlers[(int) mode].insn_code == CODE_FOR_nothing) {
+    switch (DECL_FUNCTION_CODE (fndecl))
+      {
+      case BUILT_IN_SIN:
+      case BUILT_IN_SINF:
+      case BUILT_IN_SINL:
+	builtin_optab = sin_optab; break;
+      case BUILT_IN_COS:
+      case BUILT_IN_COSF:
+      case BUILT_IN_COSL:
+	builtin_optab = cos_optab; break;
+      default:
+	gcc_unreachable ();
+      }
+  }
+
+  /* Before working hard, check whether the instruction is available.  */
+  if (builtin_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    {
+      target = gen_reg_rtx (mode);
+
+      /* Wrap the computation of the argument in a SAVE_EXPR, as we may
+	 need to expand the argument again.  This way, we will not perform
+	 side-effects more the once.  */
+      narg = save_expr (arg);
+      if (narg != arg)
+	{
+	  arg = narg;
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  exp = build_function_call_expr (fndecl, arglist);
+	}
+
+      op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+
+      start_sequence ();
+
+      /* Compute into TARGET.
+	 Set TARGET to wherever the result comes back.  */
+      if (builtin_optab == sincos_optab)
+	{
+	  int result;
+
+	  switch (DECL_FUNCTION_CODE (fndecl))
+	    {
+	    case BUILT_IN_SIN:
+	    case BUILT_IN_SINF:
+	    case BUILT_IN_SINL:
+	      result = expand_twoval_unop (builtin_optab, op0, 0, target, 0);
+	      break;
+	    case BUILT_IN_COS:
+	    case BUILT_IN_COSF:
+	    case BUILT_IN_COSL:
+	      result = expand_twoval_unop (builtin_optab, op0, target, 0, 0);
+	      break;
+	    default:
+	      gcc_unreachable ();
+	    }
+	  gcc_assert (result);
+	}
+      else
+	{
+	  target = expand_unop (mode, builtin_optab, op0, target, 0);
+	}
+
+      if (target != 0)
+	{
+	  if (errno_set)
+	    expand_errno_check (exp, target);
+
+	  /* Output the entire sequence.  */
+	  insns = get_insns ();
+	  end_sequence ();
+	  emit_insn (insns);
+	  return target;
+	}
+
+      /* If we were unable to expand via the builtin, stop the sequence
+	 (without outputting the insns) and call to the library function
+	 with the stabilized argument list.  */
+      end_sequence ();
+    }
+
+  target = expand_call (exp, target, target == const0_rtx);
+
+  return target;
+}
+
+/* Expand a call to one of the builtin rounding functions (lfloor).
+   If expanding via optab fails, lower expression to (int)(floor(x)).
+   EXP is the expression that is a call to the builtin function;
+   if convenient, the result should be placed in TARGET.  SUBTARGET may
+   be used as the target for computing one of EXP's operands.  */
+
+static rtx
+expand_builtin_int_roundingfn (tree exp, rtx target, rtx subtarget)
+{
+  optab builtin_optab;
+  rtx op0, insns, tmp;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  enum built_in_function fallback_fn;
+  tree fallback_fndecl;
+  enum machine_mode mode;
+  tree arg, narg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    gcc_unreachable ();
+
+  arg = TREE_VALUE (arglist);
+
+  switch (DECL_FUNCTION_CODE (fndecl))
+    {
+    case BUILT_IN_LCEIL:
+    case BUILT_IN_LCEILF:
+    case BUILT_IN_LCEILL:
+    case BUILT_IN_LLCEIL:
+    case BUILT_IN_LLCEILF:
+    case BUILT_IN_LLCEILL:
+      builtin_optab = lceil_optab;
+      fallback_fn = BUILT_IN_CEIL;
+      break;
+
+    case BUILT_IN_LFLOOR:
+    case BUILT_IN_LFLOORF:
+    case BUILT_IN_LFLOORL:
+    case BUILT_IN_LLFLOOR:
+    case BUILT_IN_LLFLOORF:
+    case BUILT_IN_LLFLOORL:
+      builtin_optab = lfloor_optab;
+      fallback_fn = BUILT_IN_FLOOR;
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  /* Make a suitable register to place result in.  */
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  /* Before working hard, check whether the instruction is available.  */
+  if (builtin_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    {
+      target = gen_reg_rtx (mode);
+
+      /* Wrap the computation of the argument in a SAVE_EXPR, as we may
+	 need to expand the argument again.  This way, we will not perform
+	 side-effects more the once.  */
+      narg = builtin_save_expr (arg);
+      if (narg != arg)
+	{
+	  arg = narg;
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  exp = build_function_call_expr (fndecl, arglist);
+	}
+
+      op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+
+      start_sequence ();
+
+      /* Compute into TARGET.
+	 Set TARGET to wherever the result comes back.  */
+      target = expand_unop (mode, builtin_optab, op0, target, 0);
+
+      if (target != 0)
+	{
+	  /* Output the entire sequence.  */
+	  insns = get_insns ();
+	  end_sequence ();
+	  emit_insn (insns);
+	  return target;
+	}
+
+      /* If we were unable to expand via the builtin, stop the sequence
+	 (without outputting the insns).  */
+      end_sequence ();
+    }
+
+  /* Fall back to floating point rounding optab.  */
+  fallback_fndecl = mathfn_built_in (TREE_TYPE (arg), fallback_fn);
+  /* We shouldn't get here on targets without TARGET_C99_FUNCTIONS.
+     ??? Perhaps convert (int)floorf(x) into (int)floor((double)x).  */
+  gcc_assert (fallback_fndecl != NULL_TREE);
+  exp = build_function_call_expr (fallback_fndecl, arglist);
+
+  tmp = expand_builtin_mathfn (exp, NULL_RTX, NULL_RTX);
+
+  /* Truncate the result of floating point optab to integer
+     via expand_fix ().  */
+  target = gen_reg_rtx (mode);
+  expand_fix (target, tmp, 0);
+
+  return target;
+}
+
+/* To evaluate powi(x,n), the floating point value x raised to the
+   constant integer exponent n, we use a hybrid algorithm that
+   combines the "window method" with look-up tables.  For an
+   introduction to exponentiation algorithms and "addition chains",
+   see section 4.6.3, "Evaluation of Powers" of Donald E. Knuth,
+   "Seminumerical Algorithms", Vol. 2, "The Art of Computer Programming",
+   3rd Edition, 1998, and Daniel M. Gordon, "A Survey of Fast Exponentiation
+   Methods", Journal of Algorithms, Vol. 27, pp. 129-146, 1998.  */
+
+/* Provide a default value for POWI_MAX_MULTS, the maximum number of
+   multiplications to inline before calling the system library's pow
+   function.  powi(x,n) requires at worst 2*bits(n)-2 multiplications,
+   so this default never requires calling pow, powf or powl.  */
+
+#ifndef POWI_MAX_MULTS
+#define POWI_MAX_MULTS  (2*HOST_BITS_PER_WIDE_INT-2)
+#endif
+
+/* The size of the "optimal power tree" lookup table.  All
+   exponents less than this value are simply looked up in the
+   powi_table below.  This threshold is also used to size the
+   cache of pseudo registers that hold intermediate results.  */
+#define POWI_TABLE_SIZE 256
+
+/* The size, in bits of the window, used in the "window method"
+   exponentiation algorithm.  This is equivalent to a radix of
+   (1<<POWI_WINDOW_SIZE) in the corresponding "m-ary method".  */
+#define POWI_WINDOW_SIZE 3
+
+/* The following table is an efficient representation of an
+   "optimal power tree".  For each value, i, the corresponding
+   value, j, in the table states than an optimal evaluation
+   sequence for calculating pow(x,i) can be found by evaluating
+   pow(x,j)*pow(x,i-j).  An optimal power tree for the first
+   100 integers is given in Knuth's "Seminumerical algorithms".  */
+
+static const unsigned char powi_table[POWI_TABLE_SIZE] =
+  {
+      0,   1,   1,   2,   2,   3,   3,   4,  /*   0 -   7 */
+      4,   6,   5,   6,   6,  10,   7,   9,  /*   8 -  15 */
+      8,  16,   9,  16,  10,  12,  11,  13,  /*  16 -  23 */
+     12,  17,  13,  18,  14,  24,  15,  26,  /*  24 -  31 */
+     16,  17,  17,  19,  18,  33,  19,  26,  /*  32 -  39 */
+     20,  25,  21,  40,  22,  27,  23,  44,  /*  40 -  47 */
+     24,  32,  25,  34,  26,  29,  27,  44,  /*  48 -  55 */
+     28,  31,  29,  34,  30,  60,  31,  36,  /*  56 -  63 */
+     32,  64,  33,  34,  34,  46,  35,  37,  /*  64 -  71 */
+     36,  65,  37,  50,  38,  48,  39,  69,  /*  72 -  79 */
+     40,  49,  41,  43,  42,  51,  43,  58,  /*  80 -  87 */
+     44,  64,  45,  47,  46,  59,  47,  76,  /*  88 -  95 */
+     48,  65,  49,  66,  50,  67,  51,  66,  /*  96 - 103 */
+     52,  70,  53,  74,  54, 104,  55,  74,  /* 104 - 111 */
+     56,  64,  57,  69,  58,  78,  59,  68,  /* 112 - 119 */
+     60,  61,  61,  80,  62,  75,  63,  68,  /* 120 - 127 */
+     64,  65,  65, 128,  66, 129,  67,  90,  /* 128 - 135 */
+     68,  73,  69, 131,  70,  94,  71,  88,  /* 136 - 143 */
+     72, 128,  73,  98,  74, 132,  75, 121,  /* 144 - 151 */
+     76, 102,  77, 124,  78, 132,  79, 106,  /* 152 - 159 */
+     80,  97,  81, 160,  82,  99,  83, 134,  /* 160 - 167 */
+     84,  86,  85,  95,  86, 160,  87, 100,  /* 168 - 175 */
+     88, 113,  89,  98,  90, 107,  91, 122,  /* 176 - 183 */
+     92, 111,  93, 102,  94, 126,  95, 150,  /* 184 - 191 */
+     96, 128,  97, 130,  98, 133,  99, 195,  /* 192 - 199 */
+    100, 128, 101, 123, 102, 164, 103, 138,  /* 200 - 207 */
+    104, 145, 105, 146, 106, 109, 107, 149,  /* 208 - 215 */
+    108, 200, 109, 146, 110, 170, 111, 157,  /* 216 - 223 */
+    112, 128, 113, 130, 114, 182, 115, 132,  /* 224 - 231 */
+    116, 200, 117, 132, 118, 158, 119, 206,  /* 232 - 239 */
+    120, 240, 121, 162, 122, 147, 123, 152,  /* 240 - 247 */
+    124, 166, 125, 214, 126, 138, 127, 153,  /* 248 - 255 */
+  };
+
+
+/* Return the number of multiplications required to calculate
+   powi(x,n) where n is less than POWI_TABLE_SIZE.  This is a
+   subroutine of powi_cost.  CACHE is an array indicating
+   which exponents have already been calculated.  */
+
+static int
+powi_lookup_cost (unsigned HOST_WIDE_INT n, bool *cache)
+{
+  /* If we've already calculated this exponent, then this evaluation
+     doesn't require any additional multiplications.  */
+  if (cache[n])
+    return 0;
+
+  cache[n] = true;
+  return powi_lookup_cost (n - powi_table[n], cache)
+	 + powi_lookup_cost (powi_table[n], cache) + 1;
+}
+
+/* Return the number of multiplications required to calculate
+   powi(x,n) for an arbitrary x, given the exponent N.  This
+   function needs to be kept in sync with expand_powi below.  */
+
+static int
+powi_cost (HOST_WIDE_INT n)
+{
+  bool cache[POWI_TABLE_SIZE];
+  unsigned HOST_WIDE_INT digit;
+  unsigned HOST_WIDE_INT val;
+  int result;
+
+  if (n == 0)
+    return 0;
+
+  /* Ignore the reciprocal when calculating the cost.  */
+  val = (n < 0) ? -n : n;
+
+  /* Initialize the exponent cache.  */
+  memset (cache, 0, POWI_TABLE_SIZE * sizeof (bool));
+  cache[1] = true;
+
+  result = 0;
+
+  while (val >= POWI_TABLE_SIZE)
+    {
+      if (val & 1)
+	{
+	  digit = val & ((1 << POWI_WINDOW_SIZE) - 1);
+	  result += powi_lookup_cost (digit, cache)
+		    + POWI_WINDOW_SIZE + 1;
+	  val >>= POWI_WINDOW_SIZE;
+	}
+      else
+	{
+	  val >>= 1;
+	  result++;
+	}
+    }
+
+  return result + powi_lookup_cost (val, cache);
+}
+
+/* Recursive subroutine of expand_powi.  This function takes the array,
+   CACHE, of already calculated exponents and an exponent N and returns
+   an RTX that corresponds to CACHE[1]**N, as calculated in mode MODE.  */
+
+static rtx
+expand_powi_1 (enum machine_mode mode, unsigned HOST_WIDE_INT n, rtx *cache)
+{
+  unsigned HOST_WIDE_INT digit;
+  rtx target, result;
+  rtx op0, op1;
+
+  if (n < POWI_TABLE_SIZE)
+    {
+      if (cache[n])
+        return cache[n];
+
+      target = gen_reg_rtx (mode);
+      cache[n] = target;
+
+      op0 = expand_powi_1 (mode, n - powi_table[n], cache);
+      op1 = expand_powi_1 (mode, powi_table[n], cache);
+    }
+  else if (n & 1)
+    {
+      target = gen_reg_rtx (mode);
+      digit = n & ((1 << POWI_WINDOW_SIZE) - 1);
+      op0 = expand_powi_1 (mode, n - digit, cache);
+      op1 = expand_powi_1 (mode, digit, cache);
+    }
+  else
+    {
+      target = gen_reg_rtx (mode);
+      op0 = expand_powi_1 (mode, n >> 1, cache);
+      op1 = op0;
+    }
+
+  result = expand_mult (mode, op0, op1, target, 0);
+  if (result != target)
+    emit_move_insn (target, result);
+  return target;
+}
+
+/* Expand the RTL to evaluate powi(x,n) in mode MODE.  X is the
+   floating point operand in mode MODE, and N is the exponent.  This
+   function needs to be kept in sync with powi_cost above.  */
+
+static rtx
+expand_powi (rtx x, enum machine_mode mode, HOST_WIDE_INT n)
+{
+  unsigned HOST_WIDE_INT val;
+  rtx cache[POWI_TABLE_SIZE];
+  rtx result;
+
+  if (n == 0)
+    return CONST1_RTX (mode);
+
+  val = (n < 0) ? -n : n;
+
+  memset (cache, 0, sizeof (cache));
+  cache[1] = x;
+
+  result = expand_powi_1 (mode, (n < 0) ? -n : n, cache);
+
+  /* If the original exponent was negative, reciprocate the result.  */
+  if (n < 0)
+    result = expand_binop (mode, sdiv_optab, CONST1_RTX (mode),
+			   result, NULL_RTX, 0, OPTAB_LIB_WIDEN);
+
+  return result;
+}
+
+/* Expand a call to the pow built-in mathematical function.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.  */
+
+static rtx
+expand_builtin_pow (tree exp, rtx target, rtx subtarget)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree arg0, arg1;
+
+  if (! validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg0 = TREE_VALUE (arglist);
+  arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  if (TREE_CODE (arg1) == REAL_CST
+      && ! TREE_CONSTANT_OVERFLOW (arg1))
+    {
+      REAL_VALUE_TYPE cint;
+      REAL_VALUE_TYPE c;
+      HOST_WIDE_INT n;
+
+      c = TREE_REAL_CST (arg1);
+      n = real_to_integer (&c);
+      real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);
+      if (real_identical (&c, &cint))
+	{
+	  /* If the exponent is -1, 0, 1 or 2, then expand_powi is exact.
+	     Otherwise, check the number of multiplications required.
+	     Note that pow never sets errno for an integer exponent.  */
+	  if ((n >= -1 && n <= 2)
+	      || (flag_unsafe_math_optimizations
+		  && ! optimize_size
+		  && powi_cost (n) <= POWI_MAX_MULTS))
+	    {
+	      enum machine_mode mode = TYPE_MODE (TREE_TYPE (exp));
+	      rtx op = expand_expr (arg0, subtarget, VOIDmode, 0);
+	      op = force_reg (mode, op);
+	      return expand_powi (op, mode, n);
+	    }
+	}
+    }
+
+  if (! flag_unsafe_math_optimizations)
+    return NULL_RTX;
+  return expand_builtin_mathfn_2 (exp, target, subtarget);
+}
+
+/* Expand a call to the powi built-in mathematical function.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.  */
+
+static rtx
+expand_builtin_powi (tree exp, rtx target, rtx subtarget)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree arg0, arg1;
+  rtx op0, op1;
+  enum machine_mode mode;
+  enum machine_mode mode2;
+
+  if (! validate_arglist (arglist, REAL_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg0 = TREE_VALUE (arglist);
+  arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+  mode = TYPE_MODE (TREE_TYPE (exp));
+
+  /* Handle constant power.  */
+
+  if (TREE_CODE (arg1) == INTEGER_CST
+      && ! TREE_CONSTANT_OVERFLOW (arg1))
+    {
+      HOST_WIDE_INT n = TREE_INT_CST_LOW (arg1);
+
+      /* If the exponent is -1, 0, 1 or 2, then expand_powi is exact.
+	 Otherwise, check the number of multiplications required.  */
+      if ((TREE_INT_CST_HIGH (arg1) == 0
+	   || TREE_INT_CST_HIGH (arg1) == -1)
+	  && ((n >= -1 && n <= 2)
+	      || (! optimize_size
+		  && powi_cost (n) <= POWI_MAX_MULTS)))
+	{
+	  op0 = expand_expr (arg0, subtarget, VOIDmode, 0);
+	  op0 = force_reg (mode, op0);
+	  return expand_powi (op0, mode, n);
+	}
+    }
+
+  /* Emit a libcall to libgcc.  */
+
+  /* Mode of the 2nd argument must match that of an int. */
+  mode2 = mode_for_size (INT_TYPE_SIZE, MODE_INT, 0);
+
+  if (target == NULL_RTX)
+    target = gen_reg_rtx (mode);
+
+  op0 = expand_expr (arg0, subtarget, mode, 0);
+  if (GET_MODE (op0) != mode)
+    op0 = convert_to_mode (mode, op0, 0);
+  op1 = expand_expr (arg1, 0, mode2, 0);
+  if (GET_MODE (op1) != mode2)
+    op1 = convert_to_mode (mode2, op1, 0);
+
+  target = emit_library_call_value (powi_optab->handlers[(int) mode].libfunc,
+				    target, LCT_CONST_MAKE_BLOCK, mode, 2,
+				    op0, mode, op1, mode2);
+
+  return target;
+}
+
+/* Expand expression EXP which is a call to the strlen builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise
+   try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strlen (tree arglist, rtx target,
+		       enum machine_mode target_mode)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      rtx pat;
+      tree len, src = TREE_VALUE (arglist);
+      rtx result, src_reg, char_rtx, before_strlen;
+      enum machine_mode insn_mode = target_mode, char_mode;
+      enum insn_code icode = CODE_FOR_nothing;
+      int align;
+
+      /* If the length can be computed at compile-time, return it.  */
+      len = c_strlen (src, 0);
+      if (len)
+	return expand_expr (len, target, target_mode, EXPAND_NORMAL);
+
+      /* If the length can be computed at compile-time and is constant
+	 integer, but there are side-effects in src, evaluate
+	 src for side-effects, then return len.
+	 E.g. x = strlen (i++ ? "xfoo" + 1 : "bar");
+	 can be optimized into: i++; x = 3;  */
+      len = c_strlen (src, 1);
+      if (len && TREE_CODE (len) == INTEGER_CST)
+	{
+	  expand_expr (src, const0_rtx, VOIDmode, EXPAND_NORMAL);
+	  return expand_expr (len, target, target_mode, EXPAND_NORMAL);
+	}
+
+      align = get_pointer_alignment (src, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+
+      /* If SRC is not a pointer type, don't do this operation inline.  */
+      if (align == 0)
+	return 0;
+
+      /* Bail out if we can't compute strlen in the right mode.  */
+      while (insn_mode != VOIDmode)
+	{
+	  icode = strlen_optab->handlers[(int) insn_mode].insn_code;
+	  if (icode != CODE_FOR_nothing)
+	    break;
+
+	  insn_mode = GET_MODE_WIDER_MODE (insn_mode);
+	}
+      if (insn_mode == VOIDmode)
+	return 0;
+
+      /* Make a place to write the result of the instruction.  */
+      result = target;
+      if (! (result != 0
+	     && REG_P (result)
+	     && GET_MODE (result) == insn_mode
+	     && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+	result = gen_reg_rtx (insn_mode);
+
+      /* Make a place to hold the source address.  We will not expand
+	 the actual source until we are sure that the expansion will
+	 not fail -- there are trees that cannot be expanded twice.  */
+      src_reg = gen_reg_rtx (Pmode);
+
+      /* Mark the beginning of the strlen sequence so we can emit the
+	 source operand later.  */
+      before_strlen = get_last_insn ();
+
+      char_rtx = const0_rtx;
+      char_mode = insn_data[(int) icode].operand[2].mode;
+      if (! (*insn_data[(int) icode].operand[2].predicate) (char_rtx,
+							    char_mode))
+	char_rtx = copy_to_mode_reg (char_mode, char_rtx);
+
+      pat = GEN_FCN (icode) (result, gen_rtx_MEM (BLKmode, src_reg),
+			     char_rtx, GEN_INT (align));
+      if (! pat)
+	return 0;
+      emit_insn (pat);
+
+      /* Now that we are assured of success, expand the source.  */
+      start_sequence ();
+      pat = expand_expr (src, src_reg, ptr_mode, EXPAND_NORMAL);
+      if (pat != src_reg)
+	emit_move_insn (src_reg, pat);
+      pat = get_insns ();
+      end_sequence ();
+
+      if (before_strlen)
+	emit_insn_after (pat, before_strlen);
+      else
+	emit_insn_before (pat, get_insns ());
+
+      /* Return the value in the proper mode for this function.  */
+      if (GET_MODE (result) == target_mode)
+	target = result;
+      else if (target != 0)
+	convert_move (target, result, 0);
+      else
+	target = convert_to_mode (target_mode, result, 0);
+
+      return target;
+    }
+}
+
+/* Expand a call to the strstr builtin.  Return 0 if we failed the
+   caller should emit a normal call, otherwise try to get the result
+   in TARGET, if convenient (and in mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_strstr (tree arglist, tree type, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strstr (arglist, type);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand a call to the strchr builtin.  Return 0 if we failed the
+   caller should emit a normal call, otherwise try to get the result
+   in TARGET, if convenient (and in mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_strchr (tree arglist, tree type, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strchr (arglist, type);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      /* FIXME: Should use strchrM optab so that ports can optimize this.  */
+    }
+  return 0;
+}
+
+/* Expand a call to the strrchr builtin.  Return 0 if we failed the
+   caller should emit a normal call, otherwise try to get the result
+   in TARGET, if convenient (and in mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_strrchr (tree arglist, tree type, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strrchr (arglist, type);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand a call to the strpbrk builtin.  Return 0 if we failed the
+   caller should emit a normal call, otherwise try to get the result
+   in TARGET, if convenient (and in mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_strpbrk (tree arglist, tree type, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strpbrk (arglist, type);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
+   bytes from constant string DATA + OFFSET and return it as target
+   constant.  */
+
+static rtx
+builtin_memcpy_read_str (void *data, HOST_WIDE_INT offset,
+			 enum machine_mode mode)
+{
+  const char *str = (const char *) data;
+
+  gcc_assert (offset >= 0
+	      && ((unsigned HOST_WIDE_INT) offset + GET_MODE_SIZE (mode)
+		  <= strlen (str) + 1));
+
+  return c_readstr (str + offset, mode);
+}
+
+/* Expand a call to the memcpy builtin, with arguments in ARGLIST.
+   Return 0 if we failed, the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient (and in
+   mode MODE if that's convenient).  */
+static rtx
+expand_builtin_memcpy (tree exp, rtx target, enum machine_mode mode)
+{
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      const char *src_str;
+      unsigned int src_align = get_pointer_alignment (src, BIGGEST_ALIGNMENT);
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+      rtx dest_mem, src_mem, dest_addr, len_rtx;
+      tree result = fold_builtin_memcpy (fndecl, arglist);
+
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      /* If DEST is not a pointer type, call the normal function.  */
+      if (dest_align == 0)
+	return 0;
+
+      /* If either SRC is not a pointer type, don't do this
+         operation in-line.  */
+      if (src_align == 0)
+	return 0;
+
+      dest_mem = get_memory_rtx (dest, len);
+      set_mem_align (dest_mem, dest_align);
+      len_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+      src_str = c_getstr (src);
+
+      /* If SRC is a string constant and block move would be done
+	 by pieces, we can avoid loading the string from memory
+	 and only stored the computed constants.  */
+      if (src_str
+	  && GET_CODE (len_rtx) == CONST_INT
+	  && (unsigned HOST_WIDE_INT) INTVAL (len_rtx) <= strlen (src_str) + 1
+	  && can_store_by_pieces (INTVAL (len_rtx), builtin_memcpy_read_str,
+				  (void *) src_str, dest_align))
+	{
+	  dest_mem = store_by_pieces (dest_mem, INTVAL (len_rtx),
+				      builtin_memcpy_read_str,
+				      (void *) src_str, dest_align, 0);
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      src_mem = get_memory_rtx (src, len);
+      set_mem_align (src_mem, src_align);
+
+      /* Copy word part most expediently.  */
+      dest_addr = emit_block_move (dest_mem, src_mem, len_rtx,
+				   CALL_EXPR_TAILCALL (exp)
+				   ? BLOCK_OP_TAILCALL : BLOCK_OP_NORMAL);
+
+      if (dest_addr == 0)
+	{
+	  dest_addr = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_addr = convert_memory_address (ptr_mode, dest_addr);
+	}
+      return dest_addr;
+    }
+}
+
+/* Expand a call to the mempcpy builtin, with arguments in ARGLIST.
+   Return 0 if we failed; the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient (and in
+   mode MODE if that's convenient).  If ENDP is 0 return the
+   destination pointer, if ENDP is 1 return the end pointer ala
+   mempcpy, and if ENDP is 2 return the end pointer minus one ala
+   stpcpy.  */
+
+static rtx
+expand_builtin_mempcpy (tree arglist, tree type, rtx target, enum machine_mode mode,
+			int endp)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  /* If return value is ignored, transform mempcpy into memcpy.  */
+  else if (target == const0_rtx)
+    {
+      tree fn = implicit_built_in_decls[BUILT_IN_MEMCPY];
+
+      if (!fn)
+	return 0;
+
+      return expand_expr (build_function_call_expr (fn, arglist),
+			  target, mode, EXPAND_NORMAL);
+    }
+  else
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      const char *src_str;
+      unsigned int src_align = get_pointer_alignment (src, BIGGEST_ALIGNMENT);
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+      rtx dest_mem, src_mem, len_rtx;
+      tree result = fold_builtin_mempcpy (arglist, type, endp);
+
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+      
+      /* If either SRC or DEST is not a pointer type, don't do this
+         operation in-line.  */
+      if (dest_align == 0 || src_align == 0)
+	return 0;
+
+      /* If LEN is not constant, call the normal function.  */
+      if (! host_integerp (len, 1))
+	return 0;
+
+      len_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+      src_str = c_getstr (src);
+
+      /* If SRC is a string constant and block move would be done
+	 by pieces, we can avoid loading the string from memory
+	 and only stored the computed constants.  */
+      if (src_str
+	  && GET_CODE (len_rtx) == CONST_INT
+	  && (unsigned HOST_WIDE_INT) INTVAL (len_rtx) <= strlen (src_str) + 1
+	  && can_store_by_pieces (INTVAL (len_rtx), builtin_memcpy_read_str,
+				  (void *) src_str, dest_align))
+	{
+	  dest_mem = get_memory_rtx (dest, len);
+	  set_mem_align (dest_mem, dest_align);
+	  dest_mem = store_by_pieces (dest_mem, INTVAL (len_rtx),
+				      builtin_memcpy_read_str,
+				      (void *) src_str, dest_align, endp);
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      if (GET_CODE (len_rtx) == CONST_INT
+	  && can_move_by_pieces (INTVAL (len_rtx),
+				 MIN (dest_align, src_align)))
+	{
+	  dest_mem = get_memory_rtx (dest, len);
+	  set_mem_align (dest_mem, dest_align);
+	  src_mem = get_memory_rtx (src, len);
+	  set_mem_align (src_mem, src_align);
+	  dest_mem = move_by_pieces (dest_mem, src_mem, INTVAL (len_rtx),
+				     MIN (dest_align, src_align), endp);
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      return 0;
+    }
+}
+
+/* Expand expression EXP, which is a call to the memmove builtin.  Return 0
+   if we failed; the caller should emit a normal call.  */
+
+static rtx
+expand_builtin_memmove (tree arglist, tree type, rtx target,
+			enum machine_mode mode, tree orig_exp)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+      unsigned int src_align = get_pointer_alignment (src, BIGGEST_ALIGNMENT);
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+      tree result = fold_builtin_memmove (arglist, type);
+
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      /* If DEST is not a pointer type, call the normal function.  */
+      if (dest_align == 0)
+	return 0;
+
+      /* If either SRC is not a pointer type, don't do this
+         operation in-line.  */
+      if (src_align == 0)
+	return 0;
+
+      /* If src is categorized for a readonly section we can use
+	 normal memcpy.  */
+      if (readonly_data_expr (src))
+        {
+	  tree fn = implicit_built_in_decls[BUILT_IN_MEMCPY];
+	  if (!fn)
+	    return 0;
+	  fn = build_function_call_expr (fn, arglist);
+	  if (TREE_CODE (fn) == CALL_EXPR)
+	    CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (orig_exp);
+	  return expand_expr (fn, target, mode, EXPAND_NORMAL);
+	}
+
+      /* If length is 1 and we can expand memcpy call inline,
+	 it is ok to use memcpy as well.  */
+      if (integer_onep (len))
+        {
+	  rtx ret = expand_builtin_mempcpy (arglist, type, target, mode,
+					    /*endp=*/0);
+	  if (ret)
+	    return ret;
+        }
+
+      /* Otherwise, call the normal function.  */
+      return 0;
+   }
+}
+
+/* Expand expression EXP, which is a call to the bcopy builtin.  Return 0
+   if we failed the caller should emit a normal call.  */
+
+static rtx
+expand_builtin_bcopy (tree exp)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree type = TREE_TYPE (exp);
+  tree src, dest, size, newarglist;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  src = TREE_VALUE (arglist);
+  dest = TREE_VALUE (TREE_CHAIN (arglist));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* New argument list transforming bcopy(ptr x, ptr y, int z) to
+     memmove(ptr y, ptr x, size_t z).   This is done this way
+     so that if it isn't expanded inline, we fallback to
+     calling bcopy instead of memmove.  */
+
+  newarglist = build_tree_list (NULL_TREE, fold_convert (sizetype, size));
+  newarglist = tree_cons (NULL_TREE, src, newarglist);
+  newarglist = tree_cons (NULL_TREE, dest, newarglist);
+
+  return expand_builtin_memmove (newarglist, type, const0_rtx, VOIDmode, exp);
+}
+
+#ifndef HAVE_movstr
+# define HAVE_movstr 0
+# define CODE_FOR_movstr CODE_FOR_nothing
+#endif
+
+/* Expand into a movstr instruction, if one is available.  Return 0 if
+   we failed, the caller should emit a normal call, otherwise try to
+   get the result in TARGET, if convenient.  If ENDP is 0 return the
+   destination pointer, if ENDP is 1 return the end pointer ala
+   mempcpy, and if ENDP is 2 return the end pointer minus one ala
+   stpcpy.  */
+
+static rtx
+expand_movstr (tree dest, tree src, rtx target, int endp)
+{
+  rtx end;
+  rtx dest_mem;
+  rtx src_mem;
+  rtx insn;
+  const struct insn_data * data;
+
+  if (!HAVE_movstr)
+    return 0;
+
+  dest_mem = get_memory_rtx (dest, NULL);
+  src_mem = get_memory_rtx (src, NULL);
+  if (!endp)
+    {
+      target = force_reg (Pmode, XEXP (dest_mem, 0));
+      dest_mem = replace_equiv_address (dest_mem, target);
+      end = gen_reg_rtx (Pmode);
+    }
+  else
+    {
+      if (target == 0 || target == const0_rtx)
+	{
+	  end = gen_reg_rtx (Pmode);
+	  if (target == 0)
+	    target = end;
+	}
+      else
+	end = target;
+    }
+
+  data = insn_data + CODE_FOR_movstr;
+
+  if (data->operand[0].mode != VOIDmode)
+    end = gen_lowpart (data->operand[0].mode, end);
+
+  insn = data->genfun (end, dest_mem, src_mem);
+
+  gcc_assert (insn);
+
+  emit_insn (insn);
+
+  /* movstr is supposed to set end to the address of the NUL
+     terminator.  If the caller requested a mempcpy-like return value,
+     adjust it.  */
+  if (endp == 1 && target != const0_rtx)
+    {
+      rtx tem = plus_constant (gen_lowpart (GET_MODE (target), end), 1);
+      emit_move_insn (target, force_operand (tem, NULL_RTX));
+    }
+
+  return target;
+}
+
+/* Expand expression EXP, which is a call to the strcpy builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient (and in mode MODE if that's
+   convenient).  */
+
+static rtx
+expand_builtin_strcpy (tree fndecl, tree arglist, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strcpy (fndecl, arglist, 0);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      return expand_movstr (TREE_VALUE (arglist),
+			    TREE_VALUE (TREE_CHAIN (arglist)),
+			    target, /*endp=*/0);
+    }
+  return 0;
+}
+
+/* Expand a call to the stpcpy builtin, with arguments in ARGLIST.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient (and in
+   mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_stpcpy (tree exp, rtx target, enum machine_mode mode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  /* If return value is ignored, transform stpcpy into strcpy.  */
+  if (target == const0_rtx)
+    {
+      tree fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+      if (!fn)
+	return 0;
+
+      return expand_expr (build_function_call_expr (fn, arglist),
+			  target, mode, EXPAND_NORMAL);
+    }
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dst, src, len, lenp1;
+      tree narglist;
+      rtx ret;
+
+      /* Ensure we get an actual string whose length can be evaluated at
+         compile-time, not an expression containing a string.  This is
+         because the latter will potentially produce pessimized code
+         when used to produce the return value.  */
+      src = TREE_VALUE (TREE_CHAIN (arglist));
+      if (! c_getstr (src) || ! (len = c_strlen (src, 0)))
+	return expand_movstr (TREE_VALUE (arglist),
+			      TREE_VALUE (TREE_CHAIN (arglist)),
+			      target, /*endp=*/2);
+
+      dst = TREE_VALUE (arglist);
+      lenp1 = size_binop (PLUS_EXPR, len, ssize_int (1));
+      narglist = build_tree_list (NULL_TREE, lenp1);
+      narglist = tree_cons (NULL_TREE, src, narglist);
+      narglist = tree_cons (NULL_TREE, dst, narglist);
+      ret = expand_builtin_mempcpy (narglist, TREE_TYPE (exp),
+				    target, mode, /*endp=*/2);
+
+      if (ret)
+	return ret;
+
+      if (TREE_CODE (len) == INTEGER_CST)
+	{
+	  rtx len_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+
+	  if (GET_CODE (len_rtx) == CONST_INT)
+	    {
+	      ret = expand_builtin_strcpy (get_callee_fndecl (exp), 
+					   arglist, target, mode);
+
+	      if (ret)
+		{
+		  if (! target)
+		    {
+		      if (mode != VOIDmode)
+			target = gen_reg_rtx (mode);
+		      else
+			target = gen_reg_rtx (GET_MODE (ret));
+		    }
+		  if (GET_MODE (target) != GET_MODE (ret))
+		    ret = gen_lowpart (GET_MODE (target), ret);
+
+		  ret = plus_constant (ret, INTVAL (len_rtx));
+		  ret = emit_move_insn (target, force_operand (ret, NULL_RTX));
+		  gcc_assert (ret);
+
+		  return target;
+		}
+	    }
+	}
+
+      return expand_movstr (TREE_VALUE (arglist),
+			    TREE_VALUE (TREE_CHAIN (arglist)),
+			    target, /*endp=*/2);
+    }
+}
+
+/* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
+   bytes from constant string DATA + OFFSET and return it as target
+   constant.  */
+
+static rtx
+builtin_strncpy_read_str (void *data, HOST_WIDE_INT offset,
+			  enum machine_mode mode)
+{
+  const char *str = (const char *) data;
+
+  if ((unsigned HOST_WIDE_INT) offset > strlen (str))
+    return const0_rtx;
+
+  return c_readstr (str + offset, mode);
+}
+
+/* Expand expression EXP, which is a call to the strncpy builtin.  Return 0
+   if we failed the caller should emit a normal call.  */
+
+static rtx
+expand_builtin_strncpy (tree exp, rtx target, enum machine_mode mode)
+{
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  if (validate_arglist (arglist,
+			POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree slen = c_strlen (TREE_VALUE (TREE_CHAIN (arglist)), 1);
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      tree result = fold_builtin_strncpy (fndecl, arglist, slen);
+      
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+
+      /* We must be passed a constant len and src parameter.  */
+      if (!host_integerp (len, 1) || !slen || !host_integerp (slen, 1))
+	return 0;
+
+      slen = size_binop (PLUS_EXPR, slen, ssize_int (1));
+
+      /* We're required to pad with trailing zeros if the requested
+         len is greater than strlen(s2)+1.  In that case try to
+	 use store_by_pieces, if it fails, punt.  */
+      if (tree_int_cst_lt (slen, len))
+	{
+	  tree dest = TREE_VALUE (arglist);
+	  unsigned int dest_align
+	    = get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+	  const char *p = c_getstr (TREE_VALUE (TREE_CHAIN (arglist)));
+	  rtx dest_mem;
+
+	  if (!p || dest_align == 0 || !host_integerp (len, 1)
+	      || !can_store_by_pieces (tree_low_cst (len, 1),
+				       builtin_strncpy_read_str,
+				       (void *) p, dest_align))
+	    return 0;
+
+	  dest_mem = get_memory_rtx (dest, len);
+	  store_by_pieces (dest_mem, tree_low_cst (len, 1),
+			   builtin_strncpy_read_str,
+			   (void *) p, dest_align, 0);
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+    }
+  return 0;
+}
+
+/* Callback routine for store_by_pieces.  Read GET_MODE_BITSIZE (MODE)
+   bytes from constant string DATA + OFFSET and return it as target
+   constant.  */
+
+static rtx
+builtin_memset_read_str (void *data, HOST_WIDE_INT offset ATTRIBUTE_UNUSED,
+			 enum machine_mode mode)
+{
+  const char *c = (const char *) data;
+  char *p = alloca (GET_MODE_SIZE (mode));
+
+  memset (p, *c, GET_MODE_SIZE (mode));
+
+  return c_readstr (p, mode);
+}
+
+/* Callback routine for store_by_pieces.  Return the RTL of a register
+   containing GET_MODE_SIZE (MODE) consecutive copies of the unsigned
+   char value given in the RTL register data.  For example, if mode is
+   4 bytes wide, return the RTL for 0x01010101*data.  */
+
+static rtx
+builtin_memset_gen_str (void *data, HOST_WIDE_INT offset ATTRIBUTE_UNUSED,
+			enum machine_mode mode)
+{
+  rtx target, coeff;
+  size_t size;
+  char *p;
+
+  size = GET_MODE_SIZE (mode);
+  if (size == 1)
+    return (rtx) data;
+
+  p = alloca (size);
+  memset (p, 1, size);
+  coeff = c_readstr (p, mode);
+
+  target = convert_to_mode (mode, (rtx) data, 1);
+  target = expand_mult (mode, target, coeff, NULL_RTX, 1);
+  return force_reg (mode, target);
+}
+
+/* Expand expression EXP, which is a call to the memset builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient (and in mode MODE if that's
+   convenient).  */
+
+static rtx
+expand_builtin_memset (tree arglist, rtx target, enum machine_mode mode,
+		       tree orig_exp)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, INTEGER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree val = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      char c;
+
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+      rtx dest_mem, dest_addr, len_rtx;
+
+      /* If DEST is not a pointer type, don't do this
+	 operation in-line.  */
+      if (dest_align == 0)
+	return 0;
+
+      /* If the LEN parameter is zero, return DEST.  */
+      if (integer_zerop (len))
+	{
+	  /* Evaluate and ignore VAL in case it has side-effects.  */
+	  expand_expr (val, const0_rtx, VOIDmode, EXPAND_NORMAL);
+	  return expand_expr (dest, target, mode, EXPAND_NORMAL);
+	}
+
+      len_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+      dest_mem = get_memory_rtx (dest, len);
+
+      if (TREE_CODE (val) != INTEGER_CST)
+	{
+	  rtx val_rtx;
+
+	  val = fold_build1 (CONVERT_EXPR, unsigned_char_type_node, val);
+	  val_rtx = expand_expr (val, NULL_RTX, VOIDmode, 0);
+
+	  /* Assume that we can memset by pieces if we can store the
+	   * the coefficients by pieces (in the required modes).
+	   * We can't pass builtin_memset_gen_str as that emits RTL.  */
+	  c = 1;
+	  if (host_integerp (len, 1)
+	      && !(optimize_size && tree_low_cst (len, 1) > 1)
+	      && can_store_by_pieces (tree_low_cst (len, 1),
+				      builtin_memset_read_str, &c, dest_align))
+	    {
+	      val_rtx = force_reg (TYPE_MODE (unsigned_char_type_node), 
+				   val_rtx);
+	      store_by_pieces (dest_mem, tree_low_cst (len, 1),
+			       builtin_memset_gen_str, val_rtx, dest_align, 0);
+	    }
+	  else if (!set_storage_via_setmem(dest_mem, len_rtx, val_rtx, 
+					   dest_align))
+	    return 0;
+
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      if (target_char_cast (val, &c))
+	return 0;
+
+      if (c)
+	{
+	  if (host_integerp (len, 1)
+	      && !(optimize_size && tree_low_cst (len, 1) > 1)
+	      && can_store_by_pieces (tree_low_cst (len, 1),
+				      builtin_memset_read_str, &c, dest_align))
+	    store_by_pieces (dest_mem, tree_low_cst (len, 1),
+			     builtin_memset_read_str, &c, dest_align, 0);
+	  else if (!set_storage_via_setmem (dest_mem, len_rtx, GEN_INT (c),
+					    dest_align))
+	    return 0;
+
+	  dest_mem = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_mem = convert_memory_address (ptr_mode, dest_mem);
+	  return dest_mem;
+	}
+
+      set_mem_align (dest_mem, dest_align);
+      dest_addr = clear_storage (dest_mem, len_rtx,
+				 CALL_EXPR_TAILCALL (orig_exp)
+				 ? BLOCK_OP_TAILCALL : BLOCK_OP_NORMAL);
+
+      if (dest_addr == 0)
+	{
+	  dest_addr = force_operand (XEXP (dest_mem, 0), NULL_RTX);
+	  dest_addr = convert_memory_address (ptr_mode, dest_addr);
+	}
+
+      return dest_addr;
+    }
+}
+
+/* Expand expression EXP, which is a call to the bzero builtin.  Return 0
+   if we failed the caller should emit a normal call.  */
+
+static rtx
+expand_builtin_bzero (tree exp)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree dest, size, newarglist;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  dest = TREE_VALUE (arglist);
+  size = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* New argument list transforming bzero(ptr x, int y) to
+     memset(ptr x, int 0, size_t y).   This is done this way
+     so that if it isn't expanded inline, we fallback to
+     calling bzero instead of memset.  */
+
+  newarglist = build_tree_list (NULL_TREE, fold_convert (sizetype, size));
+  newarglist = tree_cons (NULL_TREE, integer_zero_node, newarglist);
+  newarglist = tree_cons (NULL_TREE, dest, newarglist);
+
+  return expand_builtin_memset (newarglist, const0_rtx, VOIDmode, exp);
+}
+
+/* Expand expression EXP, which is a call to the memcmp built-in function.
+   ARGLIST is the argument list for this call.  Return 0 if we failed and the
+   caller should emit a normal call, otherwise try to get the result in
+   TARGET, if convenient (and in mode MODE, if that's convenient).  */
+
+static rtx
+expand_builtin_memcmp (tree exp ATTRIBUTE_UNUSED, tree arglist, rtx target,
+		       enum machine_mode mode)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree result = fold_builtin_memcmp (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+
+#if defined HAVE_cmpmemsi || defined HAVE_cmpstrnsi
+  {
+    tree arg1 = TREE_VALUE (arglist);
+    tree arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+    tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+    rtx arg1_rtx, arg2_rtx, arg3_rtx;
+    rtx result;
+    rtx insn;
+
+    int arg1_align
+      = get_pointer_alignment (arg1, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+    int arg2_align
+      = get_pointer_alignment (arg2, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+    enum machine_mode insn_mode;
+
+#ifdef HAVE_cmpmemsi
+    if (HAVE_cmpmemsi)
+      insn_mode = insn_data[(int) CODE_FOR_cmpmemsi].operand[0].mode;
+    else
+#endif
+#ifdef HAVE_cmpstrnsi
+    if (HAVE_cmpstrnsi)
+      insn_mode = insn_data[(int) CODE_FOR_cmpstrnsi].operand[0].mode;
+    else
+#endif
+      return 0;
+
+    /* If we don't have POINTER_TYPE, call the function.  */
+    if (arg1_align == 0 || arg2_align == 0)
+      return 0;
+
+    /* Make a place to write the result of the instruction.  */
+    result = target;
+    if (! (result != 0
+	   && REG_P (result) && GET_MODE (result) == insn_mode
+	   && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+      result = gen_reg_rtx (insn_mode);
+
+    arg1_rtx = get_memory_rtx (arg1, len);
+    arg2_rtx = get_memory_rtx (arg2, len);
+    arg3_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+
+    /* Set MEM_SIZE as appropriate.  */
+    if (GET_CODE (arg3_rtx) == CONST_INT)
+      {
+	set_mem_size (arg1_rtx, arg3_rtx);
+	set_mem_size (arg2_rtx, arg3_rtx);
+      }
+
+#ifdef HAVE_cmpmemsi
+    if (HAVE_cmpmemsi)
+      insn = gen_cmpmemsi (result, arg1_rtx, arg2_rtx, arg3_rtx,
+			   GEN_INT (MIN (arg1_align, arg2_align)));
+    else
+#endif
+#ifdef HAVE_cmpstrnsi
+    if (HAVE_cmpstrnsi)
+      insn = gen_cmpstrnsi (result, arg1_rtx, arg2_rtx, arg3_rtx,
+			    GEN_INT (MIN (arg1_align, arg2_align)));
+    else
+#endif
+      gcc_unreachable ();
+
+    if (insn)
+      emit_insn (insn);
+    else
+      emit_library_call_value (memcmp_libfunc, result, LCT_PURE_MAKE_BLOCK,
+			       TYPE_MODE (integer_type_node), 3,
+			       XEXP (arg1_rtx, 0), Pmode,
+			       XEXP (arg2_rtx, 0), Pmode,
+			       convert_to_mode (TYPE_MODE (sizetype), arg3_rtx,
+						TYPE_UNSIGNED (sizetype)),
+			       TYPE_MODE (sizetype));
+
+    /* Return the value in the proper mode for this function.  */
+    mode = TYPE_MODE (TREE_TYPE (exp));
+    if (GET_MODE (result) == mode)
+      return result;
+    else if (target != 0)
+      {
+	convert_move (target, result, 0);
+	return target;
+      }
+    else
+      return convert_to_mode (mode, result, 0);
+  }
+#endif
+
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strcmp builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strcmp (tree exp, rtx target, enum machine_mode mode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree result = fold_builtin_strcmp (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+
+#if defined HAVE_cmpstrsi || defined HAVE_cmpstrnsi
+  if (cmpstr_optab[SImode] != CODE_FOR_nothing
+      || cmpstrn_optab[SImode] != CODE_FOR_nothing)
+    {
+      rtx arg1_rtx, arg2_rtx;
+      rtx result, insn = NULL_RTX;
+      tree fndecl, fn;
+      
+      tree arg1 = TREE_VALUE (arglist);
+      tree arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+      int arg1_align
+	= get_pointer_alignment (arg1, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+      int arg2_align
+	= get_pointer_alignment (arg2, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+
+      /* If we don't have POINTER_TYPE, call the function.  */
+      if (arg1_align == 0 || arg2_align == 0)
+	return 0;
+
+      /* Stabilize the arguments in case gen_cmpstr(n)si fail.  */
+      arg1 = builtin_save_expr (arg1);
+      arg2 = builtin_save_expr (arg2);
+
+      arg1_rtx = get_memory_rtx (arg1, NULL);
+      arg2_rtx = get_memory_rtx (arg2, NULL);
+
+#ifdef HAVE_cmpstrsi
+      /* Try to call cmpstrsi.  */
+      if (HAVE_cmpstrsi)
+	{
+	  enum machine_mode insn_mode 
+	    = insn_data[(int) CODE_FOR_cmpstrsi].operand[0].mode;
+
+	  /* Make a place to write the result of the instruction.  */
+	  result = target;
+	  if (! (result != 0
+		 && REG_P (result) && GET_MODE (result) == insn_mode
+		 && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+	    result = gen_reg_rtx (insn_mode);
+
+	  insn = gen_cmpstrsi (result, arg1_rtx, arg2_rtx,
+			       GEN_INT (MIN (arg1_align, arg2_align)));
+	}
+#endif
+#if HAVE_cmpstrnsi 
+      /* Try to determine at least one length and call cmpstrnsi.  */
+      if (!insn && HAVE_cmpstrnsi) 
+	{
+	  tree len;
+	  rtx arg3_rtx;
+
+	  enum machine_mode insn_mode 
+	    = insn_data[(int) CODE_FOR_cmpstrnsi].operand[0].mode;
+	  tree len1 = c_strlen (arg1, 1);
+	  tree len2 = c_strlen (arg2, 1);
+
+	  if (len1)
+	    len1 = size_binop (PLUS_EXPR, ssize_int (1), len1);
+	  if (len2)
+	    len2 = size_binop (PLUS_EXPR, ssize_int (1), len2);
+
+	  /* If we don't have a constant length for the first, use the length
+	     of the second, if we know it.  We don't require a constant for
+	     this case; some cost analysis could be done if both are available
+	     but neither is constant.  For now, assume they're equally cheap,
+	     unless one has side effects.  If both strings have constant lengths,
+	     use the smaller.  */
+
+	  if (!len1)
+	    len = len2;
+	  else if (!len2)
+	    len = len1;
+	  else if (TREE_SIDE_EFFECTS (len1))
+	    len = len2;
+	  else if (TREE_SIDE_EFFECTS (len2))
+	    len = len1;
+	  else if (TREE_CODE (len1) != INTEGER_CST)
+	    len = len2;
+	  else if (TREE_CODE (len2) != INTEGER_CST)
+	    len = len1;
+	  else if (tree_int_cst_lt (len1, len2))
+	    len = len1;
+	  else
+	    len = len2;
+
+	  /* If both arguments have side effects, we cannot optimize.  */
+	  if (!len || TREE_SIDE_EFFECTS (len))
+	    return 0;
+
+	  /* Stabilize the arguments in case gen_cmpstrnsi fails.  */
+	  arg3_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+
+	  /* Make a place to write the result of the instruction.  */
+	  result = target;
+	  if (! (result != 0
+		 && REG_P (result) && GET_MODE (result) == insn_mode
+		 && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+	    result = gen_reg_rtx (insn_mode);
+
+	  insn = gen_cmpstrnsi (result, arg1_rtx, arg2_rtx, arg3_rtx,
+				GEN_INT (MIN (arg1_align, arg2_align)));
+	}
+#endif
+
+      if (insn)
+	{
+	  emit_insn (insn);
+
+	  /* Return the value in the proper mode for this function.  */
+	  mode = TYPE_MODE (TREE_TYPE (exp));
+	  if (GET_MODE (result) == mode)
+	    return result;
+	  if (target == 0)
+	    return convert_to_mode (mode, result, 0);
+	  convert_move (target, result, 0);
+	  return target;
+	}
+
+      /* Expand the library call ourselves using a stabilized argument
+	 list to avoid re-evaluating the function's arguments twice.  */
+      arglist = build_tree_list (NULL_TREE, arg2);
+      arglist = tree_cons (NULL_TREE, arg1, arglist);
+      fndecl = get_callee_fndecl (exp);
+      fn = build_function_call_expr (fndecl, arglist);
+      if (TREE_CODE (fn) == CALL_EXPR)
+	CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+      return expand_call (fn, target, target == const0_rtx);
+    }
+#endif
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strncmp builtin.  Return 0
+   if we failed the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strncmp (tree exp, rtx target, enum machine_mode mode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree result = fold_builtin_strncmp (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+
+  /* If c_strlen can determine an expression for one of the string
+     lengths, and it doesn't have side effects, then emit cmpstrnsi
+     using length MIN(strlen(string)+1, arg3).  */
+#ifdef HAVE_cmpstrnsi
+  if (HAVE_cmpstrnsi)
+  {
+    tree arg1 = TREE_VALUE (arglist);
+    tree arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+    tree arg3 = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+    tree len, len1, len2;
+    rtx arg1_rtx, arg2_rtx, arg3_rtx;
+    rtx result, insn;
+    tree fndecl, fn;
+
+    int arg1_align
+      = get_pointer_alignment (arg1, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+    int arg2_align
+      = get_pointer_alignment (arg2, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;
+    enum machine_mode insn_mode
+      = insn_data[(int) CODE_FOR_cmpstrnsi].operand[0].mode;
+
+    len1 = c_strlen (arg1, 1);
+    len2 = c_strlen (arg2, 1);
+
+    if (len1)
+      len1 = size_binop (PLUS_EXPR, ssize_int (1), len1);
+    if (len2)
+      len2 = size_binop (PLUS_EXPR, ssize_int (1), len2);
+
+    /* If we don't have a constant length for the first, use the length
+       of the second, if we know it.  We don't require a constant for
+       this case; some cost analysis could be done if both are available
+       but neither is constant.  For now, assume they're equally cheap,
+       unless one has side effects.  If both strings have constant lengths,
+       use the smaller.  */
+
+    if (!len1)
+      len = len2;
+    else if (!len2)
+      len = len1;
+    else if (TREE_SIDE_EFFECTS (len1))
+      len = len2;
+    else if (TREE_SIDE_EFFECTS (len2))
+      len = len1;
+    else if (TREE_CODE (len1) != INTEGER_CST)
+      len = len2;
+    else if (TREE_CODE (len2) != INTEGER_CST)
+      len = len1;
+    else if (tree_int_cst_lt (len1, len2))
+      len = len1;
+    else
+      len = len2;
+
+    /* If both arguments have side effects, we cannot optimize.  */
+    if (!len || TREE_SIDE_EFFECTS (len))
+      return 0;
+
+    /* The actual new length parameter is MIN(len,arg3).  */
+    len = fold_build2 (MIN_EXPR, TREE_TYPE (len), len,
+		       fold_convert (TREE_TYPE (len), arg3));
+
+    /* If we don't have POINTER_TYPE, call the function.  */
+    if (arg1_align == 0 || arg2_align == 0)
+      return 0;
+
+    /* Make a place to write the result of the instruction.  */
+    result = target;
+    if (! (result != 0
+	   && REG_P (result) && GET_MODE (result) == insn_mode
+	   && REGNO (result) >= FIRST_PSEUDO_REGISTER))
+      result = gen_reg_rtx (insn_mode);
+
+    /* Stabilize the arguments in case gen_cmpstrnsi fails.  */
+    arg1 = builtin_save_expr (arg1);
+    arg2 = builtin_save_expr (arg2);
+    len = builtin_save_expr (len);
+
+    arg1_rtx = get_memory_rtx (arg1, len);
+    arg2_rtx = get_memory_rtx (arg2, len);
+    arg3_rtx = expand_expr (len, NULL_RTX, VOIDmode, 0);
+    insn = gen_cmpstrnsi (result, arg1_rtx, arg2_rtx, arg3_rtx,
+			  GEN_INT (MIN (arg1_align, arg2_align)));
+    if (insn)
+      {
+	emit_insn (insn);
+
+	/* Return the value in the proper mode for this function.  */
+	mode = TYPE_MODE (TREE_TYPE (exp));
+	if (GET_MODE (result) == mode)
+	  return result;
+	if (target == 0)
+	  return convert_to_mode (mode, result, 0);
+	convert_move (target, result, 0);
+	return target;
+      }
+
+    /* Expand the library call ourselves using a stabilized argument
+       list to avoid re-evaluating the function's arguments twice.  */
+    arglist = build_tree_list (NULL_TREE, len);
+    arglist = tree_cons (NULL_TREE, arg2, arglist);
+    arglist = tree_cons (NULL_TREE, arg1, arglist);
+    fndecl = get_callee_fndecl (exp);
+    fn = build_function_call_expr (fndecl, arglist);
+    if (TREE_CODE (fn) == CALL_EXPR)
+      CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+    return expand_call (fn, target, target == const0_rtx);
+  }
+#endif
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strcat builtin.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strcat (tree fndecl, tree arglist, rtx target, enum machine_mode mode)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dst = TREE_VALUE (arglist),
+      src = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p = c_getstr (src);
+
+      /* If the string length is zero, return the dst parameter.  */
+      if (p && *p == '\0')	  
+	return expand_expr (dst, target, mode, EXPAND_NORMAL);
+      
+      if (!optimize_size)
+	{
+	  /* See if we can store by pieces into (dst + strlen(dst)).  */
+	  tree newsrc, newdst,
+	    strlen_fn = implicit_built_in_decls[BUILT_IN_STRLEN];
+	  rtx insns;
+
+	  /* Stabilize the argument list.  */
+	  newsrc = builtin_save_expr (src);
+	  if (newsrc != src)
+	    arglist = build_tree_list (NULL_TREE, newsrc);
+	  else 
+	    arglist = TREE_CHAIN (arglist); /* Reusing arglist if safe.  */
+
+	  dst = builtin_save_expr (dst);
+
+	  start_sequence ();
+
+	  /* Create strlen (dst).  */
+	  newdst =
+	    build_function_call_expr (strlen_fn,
+				      build_tree_list (NULL_TREE, dst));
+	  /* Create (dst + (cast) strlen (dst)).  */
+	  newdst = fold_convert (TREE_TYPE (dst), newdst);
+	  newdst = fold_build2 (PLUS_EXPR, TREE_TYPE (dst), dst, newdst);
+
+	  newdst = builtin_save_expr (newdst);
+	  arglist = tree_cons (NULL_TREE, newdst, arglist);
+
+	  if (!expand_builtin_strcpy (fndecl, arglist, target, mode))
+	    {
+	      end_sequence (); /* Stop sequence.  */
+	      return 0;
+	    }
+	  
+	  /* Output the entire sequence.  */
+	  insns = get_insns ();
+	  end_sequence ();
+	  emit_insn (insns);
+	  
+	  return expand_expr (dst, target, mode, EXPAND_NORMAL);
+	}
+
+      return 0;
+    }
+}
+
+/* Expand expression EXP, which is a call to the strncat builtin.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strncat (tree arglist, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist,
+			POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strncat (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strspn builtin.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strspn (tree arglist, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strspn (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand expression EXP, which is a call to the strcspn builtin.
+   Return 0 if we failed the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_strcspn (tree arglist, rtx target, enum machine_mode mode)
+{
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_strcspn (arglist);
+      if (result)
+	return expand_expr (result, target, mode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand a call to __builtin_saveregs, generating the result in TARGET,
+   if that's convenient.  */
+
+rtx
+expand_builtin_saveregs (void)
+{
+  rtx val, seq;
+
+  /* Don't do __builtin_saveregs more than once in a function.
+     Save the result of the first call and reuse it.  */
+  if (saveregs_value != 0)
+    return saveregs_value;
+
+  /* When this function is called, it means that registers must be
+     saved on entry to this function.  So we migrate the call to the
+     first insn of this function.  */
+
+  start_sequence ();
+
+  /* Do whatever the machine needs done in this case.  */
+  val = targetm.calls.expand_builtin_saveregs ();
+
+  seq = get_insns ();
+  end_sequence ();
+
+  saveregs_value = val;
+
+  /* Put the insns after the NOTE that starts the function.  If this
+     is inside a start_sequence, make the outer-level insn chain current, so
+     the code is placed at the start of the function.  */
+  push_topmost_sequence ();
+  emit_insn_after (seq, entry_of_function ());
+  pop_topmost_sequence ();
+
+  return val;
+}
+
+/* __builtin_args_info (N) returns word N of the arg space info
+   for the current function.  The number and meanings of words
+   is controlled by the definition of CUMULATIVE_ARGS.  */
+
+static rtx
+expand_builtin_args_info (tree arglist)
+{
+  int nwords = sizeof (CUMULATIVE_ARGS) / sizeof (int);
+  int *word_ptr = (int *) &current_function_args_info;
+
+  gcc_assert (sizeof (CUMULATIVE_ARGS) % sizeof (int) == 0);
+
+  if (arglist != 0)
+    {
+      if (!host_integerp (TREE_VALUE (arglist), 0))
+	error ("argument of %<__builtin_args_info%> must be constant");
+      else
+	{
+	  HOST_WIDE_INT wordnum = tree_low_cst (TREE_VALUE (arglist), 0);
+
+	  if (wordnum < 0 || wordnum >= nwords)
+	    error ("argument of %<__builtin_args_info%> out of range");
+	  else
+	    return GEN_INT (word_ptr[wordnum]);
+	}
+    }
+  else
+    error ("missing argument in %<__builtin_args_info%>");
+
+  return const0_rtx;
+}
+
+/* Expand a call to __builtin_next_arg.  */
+
+static rtx
+expand_builtin_next_arg (void)
+{
+  /* Checking arguments is already done in fold_builtin_next_arg
+     that must be called before this function.  */
+  return expand_binop (Pmode, add_optab,
+		       current_function_internal_arg_pointer,
+		       current_function_arg_offset_rtx,
+		       NULL_RTX, 0, OPTAB_LIB_WIDEN);
+}
+
+/* Make it easier for the backends by protecting the valist argument
+   from multiple evaluations.  */
+
+static tree
+stabilize_va_list (tree valist, int needs_lvalue)
+{
+  if (TREE_CODE (va_list_type_node) == ARRAY_TYPE)
+    {
+      if (TREE_SIDE_EFFECTS (valist))
+	valist = save_expr (valist);
+
+      /* For this case, the backends will be expecting a pointer to
+	 TREE_TYPE (va_list_type_node), but it's possible we've
+	 actually been given an array (an actual va_list_type_node).
+	 So fix it.  */
+      if (TREE_CODE (TREE_TYPE (valist)) == ARRAY_TYPE)
+	{
+	  tree p1 = build_pointer_type (TREE_TYPE (va_list_type_node));
+	  valist = build_fold_addr_expr_with_type (valist, p1);
+	}
+    }
+  else
+    {
+      tree pt;
+
+      if (! needs_lvalue)
+	{
+	  if (! TREE_SIDE_EFFECTS (valist))
+	    return valist;
+
+	  pt = build_pointer_type (va_list_type_node);
+	  valist = fold_build1 (ADDR_EXPR, pt, valist);
+	  TREE_SIDE_EFFECTS (valist) = 1;
+	}
+
+      if (TREE_SIDE_EFFECTS (valist))
+	valist = save_expr (valist);
+      valist = build_fold_indirect_ref (valist);
+    }
+
+  return valist;
+}
+
+/* The "standard" definition of va_list is void*.  */
+
+tree
+std_build_builtin_va_list (void)
+{
+  return ptr_type_node;
+}
+
+/* The "standard" implementation of va_start: just assign `nextarg' to
+   the variable.  */
+
+void
+std_expand_builtin_va_start (tree valist, rtx nextarg)
+{
+  tree t;
+
+  t = build2 (MODIFY_EXPR, TREE_TYPE (valist), valist,
+	      make_tree (ptr_type_node, nextarg));
+  TREE_SIDE_EFFECTS (t) = 1;
+
+  expand_expr (t, const0_rtx, VOIDmode, EXPAND_NORMAL);
+}
+
+/* Expand ARGLIST, from a call to __builtin_va_start.  */
+
+static rtx
+expand_builtin_va_start (tree arglist)
+{
+  rtx nextarg;
+  tree chain, valist;
+
+  chain = TREE_CHAIN (arglist);
+
+  if (!chain)
+    {
+      error ("too few arguments to function %<va_start%>");
+      return const0_rtx;
+    }
+
+  if (fold_builtin_next_arg (chain))
+    return const0_rtx;
+
+  nextarg = expand_builtin_next_arg ();
+  valist = stabilize_va_list (TREE_VALUE (arglist), 1);
+
+#ifdef EXPAND_BUILTIN_VA_START
+  EXPAND_BUILTIN_VA_START (valist, nextarg);
+#else
+  std_expand_builtin_va_start (valist, nextarg);
+#endif
+
+  return const0_rtx;
+}
+
+/* The "standard" implementation of va_arg: read the value from the
+   current (padded) address and increment by the (padded) size.  */
+
+tree
+std_gimplify_va_arg_expr (tree valist, tree type, tree *pre_p, tree *post_p)
+{
+  tree addr, t, type_size, rounded_size, valist_tmp;
+  unsigned HOST_WIDE_INT align, boundary;
+  bool indirect;
+
+#ifdef ARGS_GROW_DOWNWARD
+  /* All of the alignment and movement below is for args-grow-up machines.
+     As of 2004, there are only 3 ARGS_GROW_DOWNWARD targets, and they all
+     implement their own specialized gimplify_va_arg_expr routines.  */
+  gcc_unreachable ();
+#endif
+
+  indirect = pass_by_reference (NULL, TYPE_MODE (type), type, false);
+  if (indirect)
+    type = build_pointer_type (type);
+
+  align = PARM_BOUNDARY / BITS_PER_UNIT;
+  boundary = FUNCTION_ARG_BOUNDARY (TYPE_MODE (type), type) / BITS_PER_UNIT;
+
+  /* Hoist the valist value into a temporary for the moment.  */
+  valist_tmp = get_initialized_tmp_var (valist, pre_p, NULL);
+
+  /* va_list pointer is aligned to PARM_BOUNDARY.  If argument actually
+     requires greater alignment, we must perform dynamic alignment.  */
+  if (boundary > align)
+    {
+      t = fold_convert (TREE_TYPE (valist), size_int (boundary - 1));
+      t = build2 (MODIFY_EXPR, TREE_TYPE (valist), valist_tmp,
+		  build2 (PLUS_EXPR, TREE_TYPE (valist), valist_tmp, t));
+      gimplify_and_add (t, pre_p);
+
+      t = fold_convert (TREE_TYPE (valist), size_int (-boundary));
+      t = build2 (MODIFY_EXPR, TREE_TYPE (valist), valist_tmp,
+		  build2 (BIT_AND_EXPR, TREE_TYPE (valist), valist_tmp, t));
+      gimplify_and_add (t, pre_p);
+    }
+  else
+    boundary = align;
+
+  /* If the actual alignment is less than the alignment of the type,
+     adjust the type accordingly so that we don't assume strict alignment
+     when deferencing the pointer.  */
+  boundary *= BITS_PER_UNIT;
+  if (boundary < TYPE_ALIGN (type))
+    {
+      type = build_variant_type_copy (type);
+      TYPE_ALIGN (type) = boundary;
+    }
+
+  /* Compute the rounded size of the type.  */
+  type_size = size_in_bytes (type);
+  rounded_size = round_up (type_size, align);
+
+  /* Reduce rounded_size so it's sharable with the postqueue.  */
+  gimplify_expr (&rounded_size, pre_p, post_p, is_gimple_val, fb_rvalue);
+
+  /* Get AP.  */
+  addr = valist_tmp;
+  if (PAD_VARARGS_DOWN && !integer_zerop (rounded_size))
+    {
+      /* Small args are padded downward.  */
+      t = fold_build2 (GT_EXPR, sizetype, rounded_size, size_int (align));
+      t = fold_build3 (COND_EXPR, sizetype, t, size_zero_node,
+		       size_binop (MINUS_EXPR, rounded_size, type_size));
+      t = fold_convert (TREE_TYPE (addr), t);
+      addr = fold_build2 (PLUS_EXPR, TREE_TYPE (addr), addr, t);
+    }
+
+  /* Compute new value for AP.  */
+  t = fold_convert (TREE_TYPE (valist), rounded_size);
+  t = build2 (PLUS_EXPR, TREE_TYPE (valist), valist_tmp, t);
+  t = build2 (MODIFY_EXPR, TREE_TYPE (valist), valist, t);
+  gimplify_and_add (t, pre_p);
+
+  addr = fold_convert (build_pointer_type (type), addr);
+
+  if (indirect)
+    addr = build_va_arg_indirect_ref (addr);
+
+  return build_va_arg_indirect_ref (addr);
+}
+
+/* Build an indirect-ref expression over the given TREE, which represents a
+   piece of a va_arg() expansion.  */
+tree
+build_va_arg_indirect_ref (tree addr)
+{
+  addr = build_fold_indirect_ref (addr);
+
+  if (flag_mudflap) /* Don't instrument va_arg INDIRECT_REF.  */
+    mf_mark (addr);
+
+  return addr;
+}
+
+/* Return a dummy expression of type TYPE in order to keep going after an
+   error.  */
+
+static tree
+dummy_object (tree type)
+{
+  tree t = convert (build_pointer_type (type), null_pointer_node);
+  return build1 (INDIRECT_REF, type, t);
+}
+
+/* Gimplify __builtin_va_arg, aka VA_ARG_EXPR, which is not really a
+   builtin function, but a very special sort of operator.  */
+
+enum gimplify_status
+gimplify_va_arg_expr (tree *expr_p, tree *pre_p, tree *post_p)
+{
+  tree promoted_type, want_va_type, have_va_type;
+  tree valist = TREE_OPERAND (*expr_p, 0);
+  tree type = TREE_TYPE (*expr_p);
+  tree t;
+
+  /* Verify that valist is of the proper type.  */
+  want_va_type = va_list_type_node;
+  have_va_type = TREE_TYPE (valist);
+
+  if (have_va_type == error_mark_node)
+    return GS_ERROR;
+
+  if (TREE_CODE (want_va_type) == ARRAY_TYPE)
+    {
+      /* If va_list is an array type, the argument may have decayed
+	 to a pointer type, e.g. by being passed to another function.
+         In that case, unwrap both types so that we can compare the
+	 underlying records.  */
+      if (TREE_CODE (have_va_type) == ARRAY_TYPE
+	  || POINTER_TYPE_P (have_va_type))
+	{
+	  want_va_type = TREE_TYPE (want_va_type);
+	  have_va_type = TREE_TYPE (have_va_type);
+	}
+    }
+
+  if (TYPE_MAIN_VARIANT (want_va_type) != TYPE_MAIN_VARIANT (have_va_type))
+    {
+      error ("first argument to %<va_arg%> not of type %<va_list%>");
+      return GS_ERROR;
+    }
+
+  /* Generate a diagnostic for requesting data of a type that cannot
+     be passed through `...' due to type promotion at the call site.  */
+  else if ((promoted_type = lang_hooks.types.type_promotes_to (type))
+	   != type)
+    {
+      static bool gave_help;
+
+      /* Unfortunately, this is merely undefined, rather than a constraint
+	 violation, so we cannot make this an error.  If this call is never
+	 executed, the program is still strictly conforming.  */
+      warning (0, "%qT is promoted to %qT when passed through %<...%>",
+	       type, promoted_type);
+      if (! gave_help)
+	{
+	  gave_help = true;
+	  warning (0, "(so you should pass %qT not %qT to %<va_arg%>)",
+		   promoted_type, type);
+	}
+
+      /* We can, however, treat "undefined" any way we please.
+	 Call abort to encourage the user to fix the program.  */
+      inform ("if this code is reached, the program will abort");
+      t = build_function_call_expr (implicit_built_in_decls[BUILT_IN_TRAP],
+				    NULL);
+      append_to_statement_list (t, pre_p);
+
+      /* This is dead code, but go ahead and finish so that the
+	 mode of the result comes out right.  */
+      *expr_p = dummy_object (type);
+      return GS_ALL_DONE;
+    }
+  else
+    {
+      /* Make it easier for the backends by protecting the valist argument
+         from multiple evaluations.  */
+      if (TREE_CODE (va_list_type_node) == ARRAY_TYPE)
+	{
+	  /* For this case, the backends will be expecting a pointer to
+	     TREE_TYPE (va_list_type_node), but it's possible we've
+	     actually been given an array (an actual va_list_type_node).
+	     So fix it.  */
+	  if (TREE_CODE (TREE_TYPE (valist)) == ARRAY_TYPE)
+	    {
+	      tree p1 = build_pointer_type (TREE_TYPE (va_list_type_node));
+	      valist = build_fold_addr_expr_with_type (valist, p1);
+	    }
+	  gimplify_expr (&valist, pre_p, post_p, is_gimple_val, fb_rvalue);
+	}
+      else
+	gimplify_expr (&valist, pre_p, post_p, is_gimple_min_lval, fb_lvalue);
+
+      if (!targetm.gimplify_va_arg_expr)
+	/* FIXME:Once most targets are converted we should merely
+	   assert this is non-null.  */
+	return GS_ALL_DONE;
+
+      *expr_p = targetm.gimplify_va_arg_expr (valist, type, pre_p, post_p);
+      return GS_OK;
+    }
+}
+
+/* Expand ARGLIST, from a call to __builtin_va_end.  */
+
+static rtx
+expand_builtin_va_end (tree arglist)
+{
+  tree valist = TREE_VALUE (arglist);
+
+  /* Evaluate for side effects, if needed.  I hate macros that don't
+     do that.  */
+  if (TREE_SIDE_EFFECTS (valist))
+    expand_expr (valist, const0_rtx, VOIDmode, EXPAND_NORMAL);
+
+  return const0_rtx;
+}
+
+/* Expand ARGLIST, from a call to __builtin_va_copy.  We do this as a
+   builtin rather than just as an assignment in stdarg.h because of the
+   nastiness of array-type va_list types.  */
+
+static rtx
+expand_builtin_va_copy (tree arglist)
+{
+  tree dst, src, t;
+
+  dst = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+
+  dst = stabilize_va_list (dst, 1);
+  src = stabilize_va_list (src, 0);
+
+  if (TREE_CODE (va_list_type_node) != ARRAY_TYPE)
+    {
+      t = build2 (MODIFY_EXPR, va_list_type_node, dst, src);
+      TREE_SIDE_EFFECTS (t) = 1;
+      expand_expr (t, const0_rtx, VOIDmode, EXPAND_NORMAL);
+    }
+  else
+    {
+      rtx dstb, srcb, size;
+
+      /* Evaluate to pointers.  */
+      dstb = expand_expr (dst, NULL_RTX, Pmode, EXPAND_NORMAL);
+      srcb = expand_expr (src, NULL_RTX, Pmode, EXPAND_NORMAL);
+      size = expand_expr (TYPE_SIZE_UNIT (va_list_type_node), NULL_RTX,
+			  VOIDmode, EXPAND_NORMAL);
+
+      dstb = convert_memory_address (Pmode, dstb);
+      srcb = convert_memory_address (Pmode, srcb);
+
+      /* "Dereference" to BLKmode memories.  */
+      dstb = gen_rtx_MEM (BLKmode, dstb);
+      set_mem_alias_set (dstb, get_alias_set (TREE_TYPE (TREE_TYPE (dst))));
+      set_mem_align (dstb, TYPE_ALIGN (va_list_type_node));
+      srcb = gen_rtx_MEM (BLKmode, srcb);
+      set_mem_alias_set (srcb, get_alias_set (TREE_TYPE (TREE_TYPE (src))));
+      set_mem_align (srcb, TYPE_ALIGN (va_list_type_node));
+
+      /* Copy.  */
+      emit_block_move (dstb, srcb, size, BLOCK_OP_NORMAL);
+    }
+
+  return const0_rtx;
+}
+
+/* Expand a call to one of the builtin functions __builtin_frame_address or
+   __builtin_return_address.  */
+
+static rtx
+expand_builtin_frame_address (tree fndecl, tree arglist)
+{
+  /* The argument must be a nonnegative integer constant.
+     It counts the number of frames to scan up the stack.
+     The value is the return address saved in that frame.  */
+  if (arglist == 0)
+    /* Warning about missing arg was already issued.  */
+    return const0_rtx;
+  else if (! host_integerp (TREE_VALUE (arglist), 1))
+    {
+      if (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_FRAME_ADDRESS)
+	error ("invalid argument to %<__builtin_frame_address%>");
+      else
+	error ("invalid argument to %<__builtin_return_address%>");
+      return const0_rtx;
+    }
+  else
+    {
+      rtx tem
+	= expand_builtin_return_addr (DECL_FUNCTION_CODE (fndecl),
+				      tree_low_cst (TREE_VALUE (arglist), 1));
+
+      /* Some ports cannot access arbitrary stack frames.  */
+      if (tem == NULL)
+	{
+	  if (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_FRAME_ADDRESS)
+	    warning (0, "unsupported argument to %<__builtin_frame_address%>");
+	  else
+	    warning (0, "unsupported argument to %<__builtin_return_address%>");
+	  return const0_rtx;
+	}
+
+      /* For __builtin_frame_address, return what we've got.  */
+      if (DECL_FUNCTION_CODE (fndecl) == BUILT_IN_FRAME_ADDRESS)
+	return tem;
+
+      if (!REG_P (tem)
+	  && ! CONSTANT_P (tem))
+	tem = copy_to_mode_reg (Pmode, tem);
+      return tem;
+    }
+}
+
+/* Expand a call to the alloca builtin, with arguments ARGLIST.  Return 0 if
+   we failed and the caller should emit a normal call, otherwise try to get
+   the result in TARGET, if convenient.  */
+
+static rtx
+expand_builtin_alloca (tree arglist, rtx target)
+{
+  rtx op0;
+  rtx result;
+
+  /* In -fmudflap-instrumented code, alloca() and __builtin_alloca()
+     should always expand to function calls.  These can be intercepted
+     in libmudflap.  */
+  if (flag_mudflap)
+    return 0;
+
+  if (!validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Compute the argument.  */
+  op0 = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);
+
+  /* Allocate the desired space.  */
+  result = allocate_dynamic_stack_space (op0, target, BITS_PER_UNIT);
+  result = convert_memory_address (ptr_mode, result);
+
+  return result;
+}
+
+/* Expand a call to a unary builtin.  The arguments are in ARGLIST.
+   Return 0 if a normal call should be emitted rather than expanding the
+   function in-line.  If convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing one of EXP's operands.  */
+
+static rtx
+expand_builtin_unop (enum machine_mode target_mode, tree arglist, rtx target,
+		     rtx subtarget, optab op_optab)
+{
+  rtx op0;
+  if (!validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Compute the argument.  */
+  op0 = expand_expr (TREE_VALUE (arglist), subtarget, VOIDmode, 0);
+  /* Compute op, into TARGET if possible.
+     Set TARGET to wherever the result comes back.  */
+  target = expand_unop (TYPE_MODE (TREE_TYPE (TREE_VALUE (arglist))),
+			op_optab, op0, target, 1);
+  gcc_assert (target);
+
+  return convert_to_mode (target_mode, target, 0);
+}
+
+/* If the string passed to fputs is a constant and is one character
+   long, we attempt to transform this call into __builtin_fputc().  */
+
+static rtx
+expand_builtin_fputs (tree arglist, rtx target, bool unlocked)
+{
+  /* Verify the arguments in the original call.  */
+  if (validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    {
+      tree result = fold_builtin_fputs (arglist, (target == const0_rtx),
+					unlocked, NULL_TREE);
+      if (result)
+	return expand_expr (result, target, VOIDmode, EXPAND_NORMAL);
+    }
+  return 0;
+}
+
+/* Expand a call to __builtin_expect.  We return our argument and emit a
+   NOTE_INSN_EXPECTED_VALUE note.  This is the expansion of __builtin_expect in
+   a non-jump context.  */
+
+static rtx
+expand_builtin_expect (tree arglist, rtx target)
+{
+  tree exp, c;
+  rtx note, rtx_c;
+
+  if (arglist == NULL_TREE
+      || TREE_CHAIN (arglist) == NULL_TREE)
+    return const0_rtx;
+  exp = TREE_VALUE (arglist);
+  c = TREE_VALUE (TREE_CHAIN (arglist));
+
+  if (TREE_CODE (c) != INTEGER_CST)
+    {
+      error ("second argument to %<__builtin_expect%> must be a constant");
+      c = integer_zero_node;
+    }
+
+  target = expand_expr (exp, target, VOIDmode, EXPAND_NORMAL);
+
+  /* Don't bother with expected value notes for integral constants.  */
+  if (flag_guess_branch_prob && GET_CODE (target) != CONST_INT)
+    {
+      /* We do need to force this into a register so that we can be
+	 moderately sure to be able to correctly interpret the branch
+	 condition later.  */
+      target = force_reg (GET_MODE (target), target);
+
+      rtx_c = expand_expr (c, NULL_RTX, GET_MODE (target), EXPAND_NORMAL);
+
+      note = emit_note (NOTE_INSN_EXPECTED_VALUE);
+      NOTE_EXPECTED_VALUE (note) = gen_rtx_EQ (VOIDmode, target, rtx_c);
+    }
+
+  return target;
+}
+
+/* Like expand_builtin_expect, except do this in a jump context.  This is
+   called from do_jump if the conditional is a __builtin_expect.  Return either
+   a list of insns to emit the jump or NULL if we cannot optimize
+   __builtin_expect.  We need to optimize this at jump time so that machines
+   like the PowerPC don't turn the test into a SCC operation, and then jump
+   based on the test being 0/1.  */
+
+rtx
+expand_builtin_expect_jump (tree exp, rtx if_false_label, rtx if_true_label)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree arg0 = TREE_VALUE (arglist);
+  tree arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+  rtx ret = NULL_RTX;
+
+  /* Only handle __builtin_expect (test, 0) and
+     __builtin_expect (test, 1).  */
+  if (TREE_CODE (TREE_TYPE (arg1)) == INTEGER_TYPE
+      && (integer_zerop (arg1) || integer_onep (arg1)))
+    {
+      rtx insn, drop_through_label, temp;
+
+      /* Expand the jump insns.  */
+      start_sequence ();
+      do_jump (arg0, if_false_label, if_true_label);
+      ret = get_insns ();
+
+      drop_through_label = get_last_insn ();
+      if (drop_through_label && NOTE_P (drop_through_label))
+	drop_through_label = prev_nonnote_insn (drop_through_label);
+      if (drop_through_label && !LABEL_P (drop_through_label))
+	drop_through_label = NULL_RTX;
+      end_sequence ();
+
+      if (! if_true_label)
+	if_true_label = drop_through_label;
+      if (! if_false_label)
+	if_false_label = drop_through_label;
+
+      /* Go through and add the expect's to each of the conditional jumps.  */
+      insn = ret;
+      while (insn != NULL_RTX)
+	{
+	  rtx next = NEXT_INSN (insn);
+
+	  if (JUMP_P (insn) && any_condjump_p (insn))
+	    {
+	      rtx ifelse = SET_SRC (pc_set (insn));
+	      rtx then_dest = XEXP (ifelse, 1);
+	      rtx else_dest = XEXP (ifelse, 2);
+	      int taken = -1;
+
+	      /* First check if we recognize any of the labels.  */
+	      if (GET_CODE (then_dest) == LABEL_REF
+		  && XEXP (then_dest, 0) == if_true_label)
+		taken = 1;
+	      else if (GET_CODE (then_dest) == LABEL_REF
+		       && XEXP (then_dest, 0) == if_false_label)
+		taken = 0;
+	      else if (GET_CODE (else_dest) == LABEL_REF
+		       && XEXP (else_dest, 0) == if_false_label)
+		taken = 1;
+	      else if (GET_CODE (else_dest) == LABEL_REF
+		       && XEXP (else_dest, 0) == if_true_label)
+		taken = 0;
+	      /* Otherwise check where we drop through.  */
+	      else if (else_dest == pc_rtx)
+		{
+		  if (next && NOTE_P (next))
+		    next = next_nonnote_insn (next);
+
+		  if (next && JUMP_P (next)
+		      && any_uncondjump_p (next))
+		    temp = XEXP (SET_SRC (pc_set (next)), 0);
+		  else
+		    temp = next;
+
+		  /* TEMP is either a CODE_LABEL, NULL_RTX or something
+		     else that can't possibly match either target label.  */
+		  if (temp == if_false_label)
+		    taken = 1;
+		  else if (temp == if_true_label)
+		    taken = 0;
+		}
+	      else if (then_dest == pc_rtx)
+		{
+		  if (next && NOTE_P (next))
+		    next = next_nonnote_insn (next);
+
+		  if (next && JUMP_P (next)
+		      && any_uncondjump_p (next))
+		    temp = XEXP (SET_SRC (pc_set (next)), 0);
+		  else
+		    temp = next;
+
+		  if (temp == if_false_label)
+		    taken = 0;
+		  else if (temp == if_true_label)
+		    taken = 1;
+		}
+
+	      if (taken != -1)
+		{
+		  /* If the test is expected to fail, reverse the
+		     probabilities.  */
+		  if (integer_zerop (arg1))
+		    taken = 1 - taken;
+	          predict_insn_def (insn, PRED_BUILTIN_EXPECT, taken);
+		}
+	    }
+
+	  insn = next;
+	}
+    }
+
+  return ret;
+}
+
+void
+expand_builtin_trap (void)
+{
+#ifdef HAVE_trap
+  if (HAVE_trap)
+    emit_insn (gen_trap ());
+  else
+#endif
+    emit_library_call (abort_libfunc, LCT_NORETURN, VOIDmode, 0);
+  emit_barrier ();
+}
+
+/* Expand a call to fabs, fabsf or fabsl with arguments ARGLIST.
+   Return 0 if a normal call should be emitted rather than expanding
+   the function inline.  If convenient, the result should be placed
+   in TARGET.  SUBTARGET may be used as the target for computing
+   the operand.  */
+
+static rtx
+expand_builtin_fabs (tree arglist, rtx target, rtx subtarget)
+{
+  enum machine_mode mode;
+  tree arg;
+  rtx op0;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  mode = TYPE_MODE (TREE_TYPE (arg));
+  op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+  return expand_abs (mode, op0, target, 0, safe_from_p (target, arg, 1));
+}
+
+/* Expand a call to copysign, copysignf, or copysignl with arguments ARGLIST.
+   Return NULL is a normal call should be emitted rather than expanding the
+   function inline.  If convenient, the result should be placed in TARGET.
+   SUBTARGET may be used as the target for computing the operand.  */
+
+static rtx
+expand_builtin_copysign (tree arglist, rtx target, rtx subtarget)
+{
+  rtx op0, op1;
+  tree arg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  op0 = expand_expr (arg, subtarget, VOIDmode, 0);
+
+  arg = TREE_VALUE (TREE_CHAIN (arglist));
+  op1 = expand_expr (arg, NULL, VOIDmode, 0);
+
+  return expand_copysign (op0, op1, target);
+}
+
+/* Create a new constant string literal and return a char* pointer to it.
+   The STRING_CST value is the LEN characters at STR.  */
+static tree
+build_string_literal (int len, const char *str)
+{
+  tree t, elem, index, type;
+
+  t = build_string (len, str);
+  elem = build_type_variant (char_type_node, 1, 0);
+  index = build_index_type (build_int_cst (NULL_TREE, len - 1));
+  type = build_array_type (elem, index);
+  TREE_TYPE (t) = type;
+  TREE_CONSTANT (t) = 1;
+  TREE_INVARIANT (t) = 1;
+  TREE_READONLY (t) = 1;
+  TREE_STATIC (t) = 1;
+
+  type = build_pointer_type (type);
+  t = build1 (ADDR_EXPR, type, t);
+
+  type = build_pointer_type (elem);
+  t = build1 (NOP_EXPR, type, t);
+  return t;
+}
+
+/* Expand EXP, a call to printf or printf_unlocked.
+   Return 0 if a normal call should be emitted rather than transforming
+   the function inline.  If convenient, the result should be placed in
+   TARGET with mode MODE.  UNLOCKED indicates this is a printf_unlocked
+   call.  */
+static rtx
+expand_builtin_printf (tree exp, rtx target, enum machine_mode mode,
+		       bool unlocked)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  /* If we're using an unlocked function, assume the other unlocked
+     functions exist explicitly.  */
+  tree const fn_putchar = unlocked ? built_in_decls[BUILT_IN_PUTCHAR_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_PUTCHAR];
+  tree const fn_puts = unlocked ? built_in_decls[BUILT_IN_PUTS_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_PUTS];
+  const char *fmt_str;
+  tree fn, fmt, arg;
+
+  /* If the return value is used, don't do the transformation.  */
+  if (target != const0_rtx)
+    return 0;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return 0;
+
+  if (!init_target_chars())
+    return 0;
+  
+  /* If the format specifier was "%s\n", call __builtin_puts(arg).  */
+  if (strcmp (fmt_str, target_percent_s_newline) == 0)
+    {
+      if (! arglist
+          || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	  || TREE_CHAIN (arglist))
+	return 0;
+      fn = fn_puts;
+    }
+  /* If the format specifier was "%c", call __builtin_putchar(arg).  */
+  else if (strcmp (fmt_str, target_percent_c) == 0)
+    {
+      if (! arglist
+	  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != INTEGER_TYPE
+	  || TREE_CHAIN (arglist))
+	return 0;
+      fn = fn_putchar;
+    }
+  else
+    {
+      /* We can't handle anything else with % args or %% ... yet.  */
+      if (strchr (fmt_str, target_percent))
+        return 0;
+
+      if (arglist)
+	return 0;
+
+      /* If the format specifier was "", printf does nothing.  */
+      if (fmt_str[0] == '\0')
+	return const0_rtx;
+      /* If the format specifier has length of 1, call putchar.  */
+      if (fmt_str[1] == '\0')
+	{
+	  /* Given printf("c"), (where c is any one character,)
+	     convert "c"[0] to an int and pass that to the replacement
+	     function.  */
+	  arg = build_int_cst (NULL_TREE, fmt_str[0]);
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  fn = fn_putchar;
+	}
+      else
+	{
+	  /* If the format specifier was "string\n", call puts("string").  */
+	  size_t len = strlen (fmt_str);
+	  if ((unsigned char)fmt_str[len - 1] == target_newline)
+	    {
+	      /* Create a NUL-terminated string that's one char shorter
+		 than the original, stripping off the trailing '\n'.  */
+	      char *newstr = alloca (len);
+	      memcpy (newstr, fmt_str, len - 1);
+	      newstr[len - 1] = 0;
+
+	      arg = build_string_literal (len, newstr);
+	      arglist = build_tree_list (NULL_TREE, arg);
+	      fn = fn_puts;
+	    }
+	  else
+	    /* We'd like to arrange to call fputs(string,stdout) here,
+	       but we need stdout and don't have a way to get it yet.  */
+	    return 0;
+	}
+    }
+
+  if (!fn)
+    return 0;
+  fn = build_function_call_expr (fn, arglist);
+  if (TREE_CODE (fn) == CALL_EXPR)
+    CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+  return expand_expr (fn, target, mode, EXPAND_NORMAL);
+}
+
+/* Expand EXP, a call to fprintf or fprintf_unlocked.
+   Return 0 if a normal call should be emitted rather than transforming
+   the function inline.  If convenient, the result should be placed in
+   TARGET with mode MODE.  UNLOCKED indicates this is a fprintf_unlocked
+   call.  */
+static rtx
+expand_builtin_fprintf (tree exp, rtx target, enum machine_mode mode,
+		        bool unlocked)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  /* If we're using an unlocked function, assume the other unlocked
+     functions exist explicitly.  */
+  tree const fn_fputc = unlocked ? built_in_decls[BUILT_IN_FPUTC_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_FPUTC];
+  tree const fn_fputs = unlocked ? built_in_decls[BUILT_IN_FPUTS_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_FPUTS];
+  const char *fmt_str;
+  tree fn, fmt, fp, arg;
+
+  /* If the return value is used, don't do the transformation.  */
+  if (target != const0_rtx)
+    return 0;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  fp = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fp)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return 0;
+
+  if (!init_target_chars())
+    return 0;
+  
+  /* If the format specifier was "%s", call __builtin_fputs(arg,fp).  */
+  if (strcmp (fmt_str, target_percent_s) == 0)
+    {
+      if (! arglist
+          || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	  || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, arg, arglist);
+      fn = fn_fputs;
+    }
+  /* If the format specifier was "%c", call __builtin_fputc(arg,fp).  */
+  else if (strcmp (fmt_str, target_percent_c) == 0)
+    {
+      if (! arglist
+	  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != INTEGER_TYPE
+	  || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, arg, arglist);
+      fn = fn_fputc;
+    }
+  else
+    {
+      /* We can't handle anything else with % args or %% ... yet.  */
+      if (strchr (fmt_str, target_percent))
+        return 0;
+
+      if (arglist)
+	return 0;
+
+      /* If the format specifier was "", fprintf does nothing.  */
+      if (fmt_str[0] == '\0')
+	{
+	  /* Evaluate and ignore FILE* argument for side-effects.  */
+	  expand_expr (fp, const0_rtx, VOIDmode, EXPAND_NORMAL);
+	  return const0_rtx;
+	}
+
+      /* When "string" doesn't contain %, replace all cases of
+	 fprintf(stream,string) with fputs(string,stream).  The fputs
+	 builtin will take care of special cases like length == 1.  */
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, fmt, arglist);
+      fn = fn_fputs;
+    }
+
+  if (!fn)
+    return 0;
+  fn = build_function_call_expr (fn, arglist);
+  if (TREE_CODE (fn) == CALL_EXPR)
+    CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+  return expand_expr (fn, target, mode, EXPAND_NORMAL);
+}
+
+/* Expand a call to sprintf with argument list ARGLIST.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   inline.  If convenient, the result should be placed in TARGET with
+   mode MODE.  */
+
+static rtx
+expand_builtin_sprintf (tree arglist, rtx target, enum machine_mode mode)
+{
+  tree orig_arglist, dest, fmt;
+  const char *fmt_str;
+
+  orig_arglist = arglist;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  dest = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (dest)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return 0;
+
+  if (!init_target_chars())
+    return 0;
+
+  /* If the format doesn't contain % args or %%, use strcpy.  */
+  if (strchr (fmt_str, target_percent) == 0)
+    {
+      tree fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+      tree exp;
+
+      if (arglist || ! fn)
+	return 0;
+      expand_expr (build_function_call_expr (fn, orig_arglist),
+		   const0_rtx, VOIDmode, EXPAND_NORMAL);
+      if (target == const0_rtx)
+	return const0_rtx;
+      exp = build_int_cst (NULL_TREE, strlen (fmt_str));
+      return expand_expr (exp, target, mode, EXPAND_NORMAL);
+    }
+  /* If the format is "%s", use strcpy if the result isn't used.  */
+  else if (strcmp (fmt_str, target_percent_s) == 0)
+    {
+      tree fn, arg, len;
+      fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+
+      if (! fn)
+	return 0;
+
+      if (! arglist || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      if (! POINTER_TYPE_P (TREE_TYPE (arg)))
+	return 0;
+
+      if (target != const0_rtx)
+	{
+	  len = c_strlen (arg, 1);
+	  if (! len || TREE_CODE (len) != INTEGER_CST)
+	    return 0;
+	}
+      else
+	len = NULL_TREE;
+
+      arglist = build_tree_list (NULL_TREE, arg);
+      arglist = tree_cons (NULL_TREE, dest, arglist);
+      expand_expr (build_function_call_expr (fn, arglist),
+		   const0_rtx, VOIDmode, EXPAND_NORMAL);
+
+      if (target == const0_rtx)
+	return const0_rtx;
+      return expand_expr (len, target, mode, EXPAND_NORMAL);
+    }
+
+  return 0;
+}
+
+/* Expand a call to either the entry or exit function profiler.  */
+
+static rtx
+expand_builtin_profile_func (bool exitp)
+{
+  rtx this, which;
+
+  this = DECL_RTL (current_function_decl);
+  gcc_assert (MEM_P (this));
+  this = XEXP (this, 0);
+
+  if (exitp)
+    which = profile_function_exit_libfunc;
+  else
+    which = profile_function_entry_libfunc;
+
+  emit_library_call (which, LCT_NORMAL, VOIDmode, 2, this, Pmode,
+		     expand_builtin_return_addr (BUILT_IN_RETURN_ADDRESS,
+						 0),
+		     Pmode);
+
+  return const0_rtx;
+}
+
+/* Given a trampoline address, make sure it satisfies TRAMPOLINE_ALIGNMENT.  */
+
+static rtx
+round_trampoline_addr (rtx tramp)
+{
+  rtx temp, addend, mask;
+
+  /* If we don't need too much alignment, we'll have been guaranteed
+     proper alignment by get_trampoline_type.  */
+  if (TRAMPOLINE_ALIGNMENT <= STACK_BOUNDARY)
+    return tramp;
+
+  /* Round address up to desired boundary.  */
+  temp = gen_reg_rtx (Pmode);
+  addend = GEN_INT (TRAMPOLINE_ALIGNMENT / BITS_PER_UNIT - 1);
+  mask = GEN_INT (-TRAMPOLINE_ALIGNMENT / BITS_PER_UNIT);
+
+  temp  = expand_simple_binop (Pmode, PLUS, tramp, addend,
+			       temp, 0, OPTAB_LIB_WIDEN);
+  tramp = expand_simple_binop (Pmode, AND, temp, mask,
+			       temp, 0, OPTAB_LIB_WIDEN);
+
+  return tramp;
+}
+
+static rtx
+expand_builtin_init_trampoline (tree arglist)
+{
+  tree t_tramp, t_func, t_chain;
+  rtx r_tramp, r_func, r_chain;
+#ifdef TRAMPOLINE_TEMPLATE
+  rtx blktramp;
+#endif
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE,
+			 POINTER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  t_tramp = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  t_func = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  t_chain = TREE_VALUE (arglist);
+
+  r_tramp = expand_expr (t_tramp, NULL_RTX, VOIDmode, 0);
+  r_func = expand_expr (t_func, NULL_RTX, VOIDmode, 0);
+  r_chain = expand_expr (t_chain, NULL_RTX, VOIDmode, 0);
+
+  /* Generate insns to initialize the trampoline.  */
+  r_tramp = round_trampoline_addr (r_tramp);
+#ifdef TRAMPOLINE_TEMPLATE
+  blktramp = gen_rtx_MEM (BLKmode, r_tramp);
+  set_mem_align (blktramp, TRAMPOLINE_ALIGNMENT);
+  emit_block_move (blktramp, assemble_trampoline_template (),
+		   GEN_INT (TRAMPOLINE_SIZE), BLOCK_OP_NORMAL);
+#endif
+  trampolines_created = 1;
+  INITIALIZE_TRAMPOLINE (r_tramp, r_func, r_chain);
+
+  return const0_rtx;
+}
+
+static rtx
+expand_builtin_adjust_trampoline (tree arglist)
+{
+  rtx tramp;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return NULL_RTX;
+
+  tramp = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);
+  tramp = round_trampoline_addr (tramp);
+#ifdef TRAMPOLINE_ADJUST_ADDRESS
+  TRAMPOLINE_ADJUST_ADDRESS (tramp);
+#endif
+
+  return tramp;
+}
+
+/* Expand a call to the built-in signbit, signbitf or signbitl function.
+   Return NULL_RTX if a normal call should be emitted rather than expanding
+   the function in-line.  EXP is the expression that is a call to the builtin
+   function; if convenient, the result should be placed in TARGET.  */
+
+static rtx
+expand_builtin_signbit (tree exp, rtx target)
+{
+  const struct real_format *fmt;
+  enum machine_mode fmode, imode, rmode;
+  HOST_WIDE_INT hi, lo;
+  tree arg, arglist;
+  int word, bitpos;
+  rtx temp;
+
+  arglist = TREE_OPERAND (exp, 1);
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  fmode = TYPE_MODE (TREE_TYPE (arg));
+  rmode = TYPE_MODE (TREE_TYPE (exp));
+  fmt = REAL_MODE_FORMAT (fmode);
+
+  /* For floating point formats without a sign bit, implement signbit
+     as "ARG < 0.0".  */
+  bitpos = fmt->signbit_ro;
+  if (bitpos < 0)
+  {
+    /* But we can't do this if the format supports signed zero.  */
+    if (fmt->has_signed_zero && HONOR_SIGNED_ZEROS (fmode))
+      return 0;
+
+    arg = fold_build2 (LT_EXPR, TREE_TYPE (exp), arg,
+		       build_real (TREE_TYPE (arg), dconst0));
+    return expand_expr (arg, target, VOIDmode, EXPAND_NORMAL);
+  }
+
+  temp = expand_expr (arg, NULL_RTX, VOIDmode, 0);
+  if (GET_MODE_SIZE (fmode) <= UNITS_PER_WORD)
+    {
+      imode = int_mode_for_mode (fmode);
+      if (imode == BLKmode)
+	return 0;
+      temp = gen_lowpart (imode, temp);
+    }
+  else
+    {
+      imode = word_mode;
+      /* Handle targets with different FP word orders.  */
+      if (FLOAT_WORDS_BIG_ENDIAN)
+        word = (GET_MODE_BITSIZE (fmode) - bitpos) / BITS_PER_WORD;
+      else
+        word = bitpos / BITS_PER_WORD;
+      temp = operand_subword_force (temp, word, fmode);
+      bitpos = bitpos % BITS_PER_WORD;
+    }
+
+  /* Force the intermediate word_mode (or narrower) result into a
+     register.  This avoids attempting to create paradoxical SUBREGs
+     of floating point modes below.  */
+  temp = force_reg (imode, temp);
+
+  /* If the bitpos is within the "result mode" lowpart, the operation
+     can be implement with a single bitwise AND.  Otherwise, we need
+     a right shift and an AND.  */
+
+  if (bitpos < GET_MODE_BITSIZE (rmode))
+    {
+      if (bitpos < HOST_BITS_PER_WIDE_INT)
+	{
+	  hi = 0;
+	  lo = (HOST_WIDE_INT) 1 << bitpos;
+	}
+      else
+	{
+	  hi = (HOST_WIDE_INT) 1 << (bitpos - HOST_BITS_PER_WIDE_INT);
+	  lo = 0;
+	}
+
+      if (imode != rmode)
+	temp = gen_lowpart (rmode, temp);
+      temp = expand_binop (rmode, and_optab, temp,
+			   immed_double_const (lo, hi, rmode),
+			   NULL_RTX, 1, OPTAB_LIB_WIDEN);
+    }
+  else
+    {
+      /* Perform a logical right shift to place the signbit in the least
+         significant bit, then truncate the result to the desired mode
+	 and mask just this bit.  */
+      temp = expand_shift (RSHIFT_EXPR, imode, temp,
+			   build_int_cst (NULL_TREE, bitpos), NULL_RTX, 1);
+      temp = gen_lowpart (rmode, temp);
+      temp = expand_binop (rmode, and_optab, temp, const1_rtx,
+			   NULL_RTX, 1, OPTAB_LIB_WIDEN);
+    }
+
+  return temp;
+}
+
+/* Expand fork or exec calls.  TARGET is the desired target of the
+   call.  ARGLIST is the list of arguments of the call.  FN is the
+   identificator of the actual function.  IGNORE is nonzero if the
+   value is to be ignored.  */
+
+static rtx
+expand_builtin_fork_or_exec (tree fn, tree arglist, rtx target, int ignore)
+{
+  tree id, decl;
+  tree call;
+
+  /* If we are not profiling, just call the function.  */
+  if (!profile_arc_flag)
+    return NULL_RTX;
+
+  /* Otherwise call the wrapper.  This should be equivalent for the rest of
+     compiler, so the code does not diverge, and the wrapper may run the
+     code necessary for keeping the profiling sane.  */
+
+  switch (DECL_FUNCTION_CODE (fn))
+    {
+    case BUILT_IN_FORK:
+      id = get_identifier ("__gcov_fork");
+      break;
+
+    case BUILT_IN_EXECL:
+      id = get_identifier ("__gcov_execl");
+      break;
+
+    case BUILT_IN_EXECV:
+      id = get_identifier ("__gcov_execv");
+      break;
+
+    case BUILT_IN_EXECLP:
+      id = get_identifier ("__gcov_execlp");
+      break;
+
+    case BUILT_IN_EXECLE:
+      id = get_identifier ("__gcov_execle");
+      break;
+
+    case BUILT_IN_EXECVP:
+      id = get_identifier ("__gcov_execvp");
+      break;
+
+    case BUILT_IN_EXECVE:
+      id = get_identifier ("__gcov_execve");
+      break;
+
+    default:
+      gcc_unreachable ();
+    }
+
+  decl = build_decl (FUNCTION_DECL, id, TREE_TYPE (fn));
+  DECL_EXTERNAL (decl) = 1;
+  TREE_PUBLIC (decl) = 1;
+  DECL_ARTIFICIAL (decl) = 1;
+  TREE_NOTHROW (decl) = 1;
+  call = build_function_call_expr (decl, arglist);
+
+  return expand_call (call, target, ignore);
+}
+
+
+/* Reconstitute a mode for a __sync intrinsic operation.  Since the type of
+   the pointer in these functions is void*, the tree optimizers may remove
+   casts.  The mode computed in expand_builtin isn't reliable either, due
+   to __sync_bool_compare_and_swap.
+
+   FCODE_DIFF should be fcode - base, where base is the FOO_1 code for the
+   group of builtins.  This gives us log2 of the mode size.  */
+
+static inline enum machine_mode
+get_builtin_sync_mode (int fcode_diff)
+{
+  /* The size is not negotiable, so ask not to get BLKmode in return
+     if the target indicates that a smaller size would be better.  */
+  return mode_for_size (BITS_PER_UNIT << fcode_diff, MODE_INT, 0);
+}
+
+/* Expand the __sync_xxx_and_fetch and __sync_fetch_and_xxx intrinsics.
+   ARGLIST is the operands list to the function.  CODE is the rtx code 
+   that corresponds to the arithmetic or logical operation from the name;
+   an exception here is that NOT actually means NAND.  TARGET is an optional
+   place for us to store the results; AFTER is true if this is the
+   fetch_and_xxx form.  IGNORE is true if we don't actually care about
+   the result of the operation at all.  */
+
+static rtx
+expand_builtin_sync_operation (enum machine_mode mode, tree arglist,
+			       enum rtx_code code, bool after,
+			       rtx target, bool ignore)
+{
+  rtx addr, val, mem;
+
+  /* Expand the operands.  */
+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_SUM);
+
+  arglist = TREE_CHAIN (arglist);
+  val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);
+
+  /* Note that we explicitly do not want any alias information for this
+     memory, so that we kill all other live memories.  Otherwise we don't
+     satisfy the full barrier semantics of the intrinsic.  */
+  mem = validize_mem (gen_rtx_MEM (mode, addr));
+  MEM_VOLATILE_P (mem) = 1;
+
+  if (ignore)
+    return expand_sync_operation (mem, val, code);
+  else
+    return expand_sync_fetch_operation (mem, val, code, after, target);
+}
+
+/* Expand the __sync_val_compare_and_swap and __sync_bool_compare_and_swap
+   intrinsics.  ARGLIST is the operands list to the function.  IS_BOOL is
+   true if this is the boolean form.  TARGET is a place for us to store the
+   results; this is NOT optional if IS_BOOL is true.  */
+
+static rtx
+expand_builtin_compare_and_swap (enum machine_mode mode, tree arglist,
+				 bool is_bool, rtx target)
+{
+  rtx addr, old_val, new_val, mem;
+
+  /* Expand the operands.  */
+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_SUM);
+
+  arglist = TREE_CHAIN (arglist);
+  old_val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);
+
+  arglist = TREE_CHAIN (arglist);
+  new_val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);
+
+  /* Note that we explicitly do not want any alias information for this
+     memory, so that we kill all other live memories.  Otherwise we don't
+     satisfy the full barrier semantics of the intrinsic.  */
+  mem = validize_mem (gen_rtx_MEM (mode, addr));
+  MEM_VOLATILE_P (mem) = 1;
+
+  if (is_bool)
+    return expand_bool_compare_and_swap (mem, old_val, new_val, target);
+  else
+    return expand_val_compare_and_swap (mem, old_val, new_val, target);
+}
+
+/* Expand the __sync_lock_test_and_set intrinsic.  Note that the most
+   general form is actually an atomic exchange, and some targets only
+   support a reduced form with the second argument being a constant 1.
+   ARGLIST is the operands list to the function; TARGET is an optional
+   place for us to store the results.  */
+
+static rtx
+expand_builtin_lock_test_and_set (enum machine_mode mode, tree arglist,
+				  rtx target)
+{
+  rtx addr, val, mem;
+
+  /* Expand the operands.  */
+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_NORMAL);
+
+  arglist = TREE_CHAIN (arglist);
+  val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);
+
+  /* Note that we explicitly do not want any alias information for this
+     memory, so that we kill all other live memories.  Otherwise we don't
+     satisfy the barrier semantics of the intrinsic.  */
+  mem = validize_mem (gen_rtx_MEM (mode, addr));
+  MEM_VOLATILE_P (mem) = 1;
+
+  return expand_sync_lock_test_and_set (mem, val, target);
+}
+
+/* Expand the __sync_synchronize intrinsic.  */
+
+static void
+expand_builtin_synchronize (void)
+{
+  tree x;
+
+#ifdef HAVE_memory_barrier
+  if (HAVE_memory_barrier)
+    {
+      emit_insn (gen_memory_barrier ());
+      return;
+    }
+#endif
+
+  /* If no explicit memory barrier instruction is available, create an
+     empty asm stmt with a memory clobber.  */
+  x = build4 (ASM_EXPR, void_type_node, build_string (0, ""), NULL, NULL,
+	      tree_cons (NULL, build_string (6, "memory"), NULL));
+  ASM_VOLATILE_P (x) = 1;
+  expand_asm_expr (x);
+}
+
+/* Expand the __sync_lock_release intrinsic.  ARGLIST is the operands list
+   to the function.  */
+
+static void
+expand_builtin_lock_release (enum machine_mode mode, tree arglist)
+{
+  enum insn_code icode;
+  rtx addr, mem, insn;
+  rtx val = const0_rtx;
+
+  /* Expand the operands.  */
+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_NORMAL);
+
+  /* Note that we explicitly do not want any alias information for this
+     memory, so that we kill all other live memories.  Otherwise we don't
+     satisfy the barrier semantics of the intrinsic.  */
+  mem = validize_mem (gen_rtx_MEM (mode, addr));
+  MEM_VOLATILE_P (mem) = 1;
+
+  /* If there is an explicit operation in the md file, use it.  */
+  icode = sync_lock_release[mode];
+  if (icode != CODE_FOR_nothing)
+    {
+      if (!insn_data[icode].operand[1].predicate (val, mode))
+	val = force_reg (mode, val);
+
+      insn = GEN_FCN (icode) (mem, val);
+      if (insn)
+	{
+	  emit_insn (insn);
+	  return;
+	}
+    }
+
+  /* Otherwise we can implement this operation by emitting a barrier
+     followed by a store of zero.  */
+  expand_builtin_synchronize ();
+  emit_move_insn (mem, val);
+}
+
+/* Expand an expression EXP that calls a built-in function,
+   with result going to TARGET if that's convenient
+   (and in mode MODE if that's convenient).
+   SUBTARGET may be used as the target for computing one of EXP's operands.
+   IGNORE is nonzero if the value is to be ignored.  */
+
+rtx
+expand_builtin (tree exp, rtx target, rtx subtarget, enum machine_mode mode,
+		int ignore)
+{
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  enum built_in_function fcode = DECL_FUNCTION_CODE (fndecl);
+  enum machine_mode target_mode = TYPE_MODE (TREE_TYPE (exp));
+
+  if (DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_MD)
+    return targetm.expand_builtin (exp, target, subtarget, mode, ignore);
+
+  /* When not optimizing, generate calls to library functions for a certain
+     set of builtins.  */
+  if (!optimize
+      && !called_as_built_in (fndecl)
+      && DECL_ASSEMBLER_NAME_SET_P (fndecl)
+      && fcode != BUILT_IN_ALLOCA)
+    return expand_call (exp, target, ignore);
+
+  /* The built-in function expanders test for target == const0_rtx
+     to determine whether the function's result will be ignored.  */
+  if (ignore)
+    target = const0_rtx;
+
+  /* If the result of a pure or const built-in function is ignored, and
+     none of its arguments are volatile, we can avoid expanding the
+     built-in call and just evaluate the arguments for side-effects.  */
+  if (target == const0_rtx
+      && (DECL_IS_PURE (fndecl) || TREE_READONLY (fndecl)))
+    {
+      bool volatilep = false;
+      tree arg;
+
+      for (arg = arglist; arg; arg = TREE_CHAIN (arg))
+	if (TREE_THIS_VOLATILE (TREE_VALUE (arg)))
+	  {
+	    volatilep = true;
+	    break;
+	  }
+
+      if (! volatilep)
+	{
+	  for (arg = arglist; arg; arg = TREE_CHAIN (arg))
+	    expand_expr (TREE_VALUE (arg), const0_rtx,
+			 VOIDmode, EXPAND_NORMAL);
+	  return const0_rtx;
+	}
+    }
+
+  switch (fcode)
+    {
+    case BUILT_IN_FABS:
+    case BUILT_IN_FABSF:
+    case BUILT_IN_FABSL:
+      target = expand_builtin_fabs (arglist, target, subtarget);
+      if (target)
+        return target;
+      break;
+
+    case BUILT_IN_COPYSIGN:
+    case BUILT_IN_COPYSIGNF:
+    case BUILT_IN_COPYSIGNL:
+      target = expand_builtin_copysign (arglist, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+      /* Just do a normal library call if we were unable to fold
+	 the values.  */
+    case BUILT_IN_CABS:
+    case BUILT_IN_CABSF:
+    case BUILT_IN_CABSL:
+      break;
+
+    case BUILT_IN_EXP:
+    case BUILT_IN_EXPF:
+    case BUILT_IN_EXPL:
+    case BUILT_IN_EXP10:
+    case BUILT_IN_EXP10F:
+    case BUILT_IN_EXP10L:
+    case BUILT_IN_POW10:
+    case BUILT_IN_POW10F:
+    case BUILT_IN_POW10L:
+    case BUILT_IN_EXP2:
+    case BUILT_IN_EXP2F:
+    case BUILT_IN_EXP2L:
+    case BUILT_IN_EXPM1:
+    case BUILT_IN_EXPM1F:
+    case BUILT_IN_EXPM1L:
+    case BUILT_IN_LOGB:
+    case BUILT_IN_LOGBF:
+    case BUILT_IN_LOGBL:
+    case BUILT_IN_ILOGB:
+    case BUILT_IN_ILOGBF:
+    case BUILT_IN_ILOGBL:
+    case BUILT_IN_LOG:
+    case BUILT_IN_LOGF:
+    case BUILT_IN_LOGL:
+    case BUILT_IN_LOG10:
+    case BUILT_IN_LOG10F:
+    case BUILT_IN_LOG10L:
+    case BUILT_IN_LOG2:
+    case BUILT_IN_LOG2F:
+    case BUILT_IN_LOG2L:
+    case BUILT_IN_LOG1P:
+    case BUILT_IN_LOG1PF:
+    case BUILT_IN_LOG1PL:
+    case BUILT_IN_TAN:
+    case BUILT_IN_TANF:
+    case BUILT_IN_TANL:
+    case BUILT_IN_ASIN:
+    case BUILT_IN_ASINF:
+    case BUILT_IN_ASINL:
+    case BUILT_IN_ACOS:
+    case BUILT_IN_ACOSF:
+    case BUILT_IN_ACOSL:
+    case BUILT_IN_ATAN:
+    case BUILT_IN_ATANF:
+    case BUILT_IN_ATANL:
+      /* Treat these like sqrt only if unsafe math optimizations are allowed,
+	 because of possible accuracy problems.  */
+      if (! flag_unsafe_math_optimizations)
+	break;
+    case BUILT_IN_SQRT:
+    case BUILT_IN_SQRTF:
+    case BUILT_IN_SQRTL:
+    case BUILT_IN_FLOOR:
+    case BUILT_IN_FLOORF:
+    case BUILT_IN_FLOORL:
+    case BUILT_IN_CEIL:
+    case BUILT_IN_CEILF:
+    case BUILT_IN_CEILL:
+    case BUILT_IN_TRUNC:
+    case BUILT_IN_TRUNCF:
+    case BUILT_IN_TRUNCL:
+    case BUILT_IN_ROUND:
+    case BUILT_IN_ROUNDF:
+    case BUILT_IN_ROUNDL:
+    case BUILT_IN_NEARBYINT:
+    case BUILT_IN_NEARBYINTF:
+    case BUILT_IN_NEARBYINTL:
+    case BUILT_IN_RINT:
+    case BUILT_IN_RINTF:
+    case BUILT_IN_RINTL:
+    case BUILT_IN_LRINT:
+    case BUILT_IN_LRINTF:
+    case BUILT_IN_LRINTL:
+    case BUILT_IN_LLRINT:
+    case BUILT_IN_LLRINTF:
+    case BUILT_IN_LLRINTL:
+      target = expand_builtin_mathfn (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_LCEIL:
+    case BUILT_IN_LCEILF:
+    case BUILT_IN_LCEILL:
+    case BUILT_IN_LLCEIL:
+    case BUILT_IN_LLCEILF:
+    case BUILT_IN_LLCEILL:
+    case BUILT_IN_LFLOOR:
+    case BUILT_IN_LFLOORF:
+    case BUILT_IN_LFLOORL:
+    case BUILT_IN_LLFLOOR:
+    case BUILT_IN_LLFLOORF:
+    case BUILT_IN_LLFLOORL:
+      target = expand_builtin_int_roundingfn (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_POW:
+    case BUILT_IN_POWF:
+    case BUILT_IN_POWL:
+      target = expand_builtin_pow (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_POWI:
+    case BUILT_IN_POWIF:
+    case BUILT_IN_POWIL:
+      target = expand_builtin_powi (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_ATAN2:
+    case BUILT_IN_ATAN2F:
+    case BUILT_IN_ATAN2L:
+    case BUILT_IN_LDEXP:
+    case BUILT_IN_LDEXPF:
+    case BUILT_IN_LDEXPL:
+    case BUILT_IN_FMOD:
+    case BUILT_IN_FMODF:
+    case BUILT_IN_FMODL:
+    case BUILT_IN_DREM:
+    case BUILT_IN_DREMF:
+    case BUILT_IN_DREML:
+      if (! flag_unsafe_math_optimizations)
+	break;
+      target = expand_builtin_mathfn_2 (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SIN:
+    case BUILT_IN_SINF:
+    case BUILT_IN_SINL:
+    case BUILT_IN_COS:
+    case BUILT_IN_COSF:
+    case BUILT_IN_COSL:
+      if (! flag_unsafe_math_optimizations)
+	break;
+      target = expand_builtin_mathfn_3 (exp, target, subtarget);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_APPLY_ARGS:
+      return expand_builtin_apply_args ();
+
+      /* __builtin_apply (FUNCTION, ARGUMENTS, ARGSIZE) invokes
+	 FUNCTION with a copy of the parameters described by
+	 ARGUMENTS, and ARGSIZE.  It returns a block of memory
+	 allocated on the stack into which is stored all the registers
+	 that might possibly be used for returning the result of a
+	 function.  ARGUMENTS is the value returned by
+	 __builtin_apply_args.  ARGSIZE is the number of bytes of
+	 arguments that must be copied.  ??? How should this value be
+	 computed?  We'll also need a safe worst case value for varargs
+	 functions.  */
+    case BUILT_IN_APPLY:
+      if (!validate_arglist (arglist, POINTER_TYPE,
+			     POINTER_TYPE, INTEGER_TYPE, VOID_TYPE)
+	  && !validate_arglist (arglist, REFERENCE_TYPE,
+				POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+	return const0_rtx;
+      else
+	{
+	  int i;
+	  tree t;
+	  rtx ops[3];
+
+	  for (t = arglist, i = 0; t; t = TREE_CHAIN (t), i++)
+	    ops[i] = expand_expr (TREE_VALUE (t), NULL_RTX, VOIDmode, 0);
+
+	  return expand_builtin_apply (ops[0], ops[1], ops[2]);
+	}
+
+      /* __builtin_return (RESULT) causes the function to return the
+	 value described by RESULT.  RESULT is address of the block of
+	 memory returned by __builtin_apply.  */
+    case BUILT_IN_RETURN:
+      if (validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+	expand_builtin_return (expand_expr (TREE_VALUE (arglist),
+					    NULL_RTX, VOIDmode, 0));
+      return const0_rtx;
+
+    case BUILT_IN_SAVEREGS:
+      return expand_builtin_saveregs ();
+
+    case BUILT_IN_ARGS_INFO:
+      return expand_builtin_args_info (arglist);
+
+      /* Return the address of the first anonymous stack arg.  */
+    case BUILT_IN_NEXT_ARG:
+      if (fold_builtin_next_arg (arglist))
+        return const0_rtx;
+      return expand_builtin_next_arg ();
+
+    case BUILT_IN_CLASSIFY_TYPE:
+      return expand_builtin_classify_type (arglist);
+
+    case BUILT_IN_CONSTANT_P:
+      return const0_rtx;
+
+    case BUILT_IN_FRAME_ADDRESS:
+    case BUILT_IN_RETURN_ADDRESS:
+      return expand_builtin_frame_address (fndecl, arglist);
+
+    /* Returns the address of the area where the structure is returned.
+       0 otherwise.  */
+    case BUILT_IN_AGGREGATE_INCOMING_ADDRESS:
+      if (arglist != 0
+	  || ! AGGREGATE_TYPE_P (TREE_TYPE (TREE_TYPE (current_function_decl)))
+	  || !MEM_P (DECL_RTL (DECL_RESULT (current_function_decl))))
+	return const0_rtx;
+      else
+	return XEXP (DECL_RTL (DECL_RESULT (current_function_decl)), 0);
+
+    case BUILT_IN_ALLOCA:
+      target = expand_builtin_alloca (arglist, target);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STACK_SAVE:
+      return expand_stack_save ();
+
+    case BUILT_IN_STACK_RESTORE:
+      expand_stack_restore (TREE_VALUE (arglist));
+      return const0_rtx;
+
+    case BUILT_IN_FFS:
+    case BUILT_IN_FFSL:
+    case BUILT_IN_FFSLL:
+    case BUILT_IN_FFSIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, ffs_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_CLZ:
+    case BUILT_IN_CLZL:
+    case BUILT_IN_CLZLL:
+    case BUILT_IN_CLZIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, clz_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_CTZ:
+    case BUILT_IN_CTZL:
+    case BUILT_IN_CTZLL:
+    case BUILT_IN_CTZIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, ctz_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_POPCOUNT:
+    case BUILT_IN_POPCOUNTL:
+    case BUILT_IN_POPCOUNTLL:
+    case BUILT_IN_POPCOUNTIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, popcount_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_PARITY:
+    case BUILT_IN_PARITYL:
+    case BUILT_IN_PARITYLL:
+    case BUILT_IN_PARITYIMAX:
+      target = expand_builtin_unop (target_mode, arglist, target,
+				    subtarget, parity_optab);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRLEN:
+      target = expand_builtin_strlen (arglist, target, target_mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCPY:
+      target = expand_builtin_strcpy (fndecl, arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRNCPY:
+      target = expand_builtin_strncpy (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STPCPY:
+      target = expand_builtin_stpcpy (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCAT:
+      target = expand_builtin_strcat (fndecl, arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRNCAT:
+      target = expand_builtin_strncat (arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRSPN:
+      target = expand_builtin_strspn (arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCSPN:
+      target = expand_builtin_strcspn (arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRSTR:
+      target = expand_builtin_strstr (arglist, TREE_TYPE (exp), target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRPBRK:
+      target = expand_builtin_strpbrk (arglist, TREE_TYPE (exp), target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_INDEX:
+    case BUILT_IN_STRCHR:
+      target = expand_builtin_strchr (arglist, TREE_TYPE (exp), target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_RINDEX:
+    case BUILT_IN_STRRCHR:
+      target = expand_builtin_strrchr (arglist, TREE_TYPE (exp), target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_MEMCPY:
+      target = expand_builtin_memcpy (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_MEMPCPY:
+      target = expand_builtin_mempcpy (arglist, TREE_TYPE (exp), target, mode, /*endp=*/ 1);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_MEMMOVE:
+      target = expand_builtin_memmove (arglist, TREE_TYPE (exp), target,
+				       mode, exp);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_BCOPY:
+      target = expand_builtin_bcopy (exp);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_MEMSET:
+      target = expand_builtin_memset (arglist, target, mode, exp);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_BZERO:
+      target = expand_builtin_bzero (exp);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCMP:
+      target = expand_builtin_strcmp (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRNCMP:
+      target = expand_builtin_strncmp (exp, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_BCMP:
+    case BUILT_IN_MEMCMP:
+      target = expand_builtin_memcmp (exp, arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SETJMP:
+      target = expand_builtin_setjmp (arglist, target);
+      if (target)
+	return target;
+      break;
+
+      /* __builtin_longjmp is passed a pointer to an array of five words.
+	 It's similar to the C library longjmp function but works with
+	 __builtin_setjmp above.  */
+    case BUILT_IN_LONGJMP:
+      if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+	break;
+      else
+	{
+	  rtx buf_addr = expand_expr (TREE_VALUE (arglist), subtarget,
+				      VOIDmode, 0);
+	  rtx value = expand_expr (TREE_VALUE (TREE_CHAIN (arglist)),
+				   NULL_RTX, VOIDmode, 0);
+
+	  if (value != const1_rtx)
+	    {
+	      error ("%<__builtin_longjmp%> second argument must be 1");
+	      return const0_rtx;
+	    }
+
+	  expand_builtin_longjmp (buf_addr, value);
+	  return const0_rtx;
+	}
+
+    case BUILT_IN_NONLOCAL_GOTO:
+      target = expand_builtin_nonlocal_goto (arglist);
+      if (target)
+	return target;
+      break;
+
+      /* This updates the setjmp buffer that is its argument with the value
+	 of the current stack pointer.  */
+    case BUILT_IN_UPDATE_SETJMP_BUF:
+      if (validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+	{
+	  rtx buf_addr
+	    = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);
+
+	  expand_builtin_update_setjmp_buf (buf_addr);
+	  return const0_rtx;
+	}
+      break;
+
+    case BUILT_IN_TRAP:
+      expand_builtin_trap ();
+      return const0_rtx;
+
+    case BUILT_IN_PRINTF:
+      target = expand_builtin_printf (exp, target, mode, false);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_PRINTF_UNLOCKED:
+      target = expand_builtin_printf (exp, target, mode, true);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FPUTS:
+      target = expand_builtin_fputs (arglist, target, false);
+      if (target)
+	return target;
+      break;
+    case BUILT_IN_FPUTS_UNLOCKED:
+      target = expand_builtin_fputs (arglist, target, true);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FPRINTF:
+      target = expand_builtin_fprintf (exp, target, mode, false);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FPRINTF_UNLOCKED:
+      target = expand_builtin_fprintf (exp, target, mode, true);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SPRINTF:
+      target = expand_builtin_sprintf (arglist, target, mode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SIGNBIT:
+    case BUILT_IN_SIGNBITF:
+    case BUILT_IN_SIGNBITL:
+      target = expand_builtin_signbit (exp, target);
+      if (target)
+	return target;
+      break;
+
+      /* Various hooks for the DWARF 2 __throw routine.  */
+    case BUILT_IN_UNWIND_INIT:
+      expand_builtin_unwind_init ();
+      return const0_rtx;
+    case BUILT_IN_DWARF_CFA:
+      return virtual_cfa_rtx;
+#ifdef DWARF2_UNWIND_INFO
+    case BUILT_IN_DWARF_SP_COLUMN:
+      return expand_builtin_dwarf_sp_column ();
+    case BUILT_IN_INIT_DWARF_REG_SIZES:
+      expand_builtin_init_dwarf_reg_sizes (TREE_VALUE (arglist));
+      return const0_rtx;
+#endif
+    case BUILT_IN_FROB_RETURN_ADDR:
+      return expand_builtin_frob_return_addr (TREE_VALUE (arglist));
+    case BUILT_IN_EXTRACT_RETURN_ADDR:
+      return expand_builtin_extract_return_addr (TREE_VALUE (arglist));
+    case BUILT_IN_EH_RETURN:
+      expand_builtin_eh_return (TREE_VALUE (arglist),
+				TREE_VALUE (TREE_CHAIN (arglist)));
+      return const0_rtx;
+#ifdef EH_RETURN_DATA_REGNO
+    case BUILT_IN_EH_RETURN_DATA_REGNO:
+      return expand_builtin_eh_return_data_regno (arglist);
+#endif
+    case BUILT_IN_EXTEND_POINTER:
+      return expand_builtin_extend_pointer (TREE_VALUE (arglist));
+
+    case BUILT_IN_VA_START:
+    case BUILT_IN_STDARG_START:
+      return expand_builtin_va_start (arglist);
+    case BUILT_IN_VA_END:
+      return expand_builtin_va_end (arglist);
+    case BUILT_IN_VA_COPY:
+      return expand_builtin_va_copy (arglist);
+    case BUILT_IN_EXPECT:
+      return expand_builtin_expect (arglist, target);
+    case BUILT_IN_PREFETCH:
+      expand_builtin_prefetch (arglist);
+      return const0_rtx;
+
+    case BUILT_IN_PROFILE_FUNC_ENTER:
+      return expand_builtin_profile_func (false);
+    case BUILT_IN_PROFILE_FUNC_EXIT:
+      return expand_builtin_profile_func (true);
+
+    case BUILT_IN_INIT_TRAMPOLINE:
+      return expand_builtin_init_trampoline (arglist);
+    case BUILT_IN_ADJUST_TRAMPOLINE:
+      return expand_builtin_adjust_trampoline (arglist);
+
+    case BUILT_IN_FORK:
+    case BUILT_IN_EXECL:
+    case BUILT_IN_EXECV:
+    case BUILT_IN_EXECLP:
+    case BUILT_IN_EXECLE:
+    case BUILT_IN_EXECVP:
+    case BUILT_IN_EXECVE:
+      target = expand_builtin_fork_or_exec (fndecl, arglist, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_ADD_1:
+    case BUILT_IN_FETCH_AND_ADD_2:
+    case BUILT_IN_FETCH_AND_ADD_4:
+    case BUILT_IN_FETCH_AND_ADD_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_ADD_1);
+      target = expand_builtin_sync_operation (mode, arglist, PLUS,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_SUB_1:
+    case BUILT_IN_FETCH_AND_SUB_2:
+    case BUILT_IN_FETCH_AND_SUB_4:
+    case BUILT_IN_FETCH_AND_SUB_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_SUB_1);
+      target = expand_builtin_sync_operation (mode, arglist, MINUS,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_OR_1:
+    case BUILT_IN_FETCH_AND_OR_2:
+    case BUILT_IN_FETCH_AND_OR_4:
+    case BUILT_IN_FETCH_AND_OR_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_OR_1);
+      target = expand_builtin_sync_operation (mode, arglist, IOR,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_AND_1:
+    case BUILT_IN_FETCH_AND_AND_2:
+    case BUILT_IN_FETCH_AND_AND_4:
+    case BUILT_IN_FETCH_AND_AND_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_AND_1);
+      target = expand_builtin_sync_operation (mode, arglist, AND,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_XOR_1:
+    case BUILT_IN_FETCH_AND_XOR_2:
+    case BUILT_IN_FETCH_AND_XOR_4:
+    case BUILT_IN_FETCH_AND_XOR_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_XOR_1);
+      target = expand_builtin_sync_operation (mode, arglist, XOR,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_FETCH_AND_NAND_1:
+    case BUILT_IN_FETCH_AND_NAND_2:
+    case BUILT_IN_FETCH_AND_NAND_4:
+    case BUILT_IN_FETCH_AND_NAND_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_FETCH_AND_NAND_1);
+      target = expand_builtin_sync_operation (mode, arglist, NOT,
+					      false, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_ADD_AND_FETCH_1:
+    case BUILT_IN_ADD_AND_FETCH_2:
+    case BUILT_IN_ADD_AND_FETCH_4:
+    case BUILT_IN_ADD_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_ADD_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, PLUS,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_SUB_AND_FETCH_1:
+    case BUILT_IN_SUB_AND_FETCH_2:
+    case BUILT_IN_SUB_AND_FETCH_4:
+    case BUILT_IN_SUB_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_SUB_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, MINUS,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_OR_AND_FETCH_1:
+    case BUILT_IN_OR_AND_FETCH_2:
+    case BUILT_IN_OR_AND_FETCH_4:
+    case BUILT_IN_OR_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_OR_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, IOR,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_AND_AND_FETCH_1:
+    case BUILT_IN_AND_AND_FETCH_2:
+    case BUILT_IN_AND_AND_FETCH_4:
+    case BUILT_IN_AND_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_AND_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, AND,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_XOR_AND_FETCH_1:
+    case BUILT_IN_XOR_AND_FETCH_2:
+    case BUILT_IN_XOR_AND_FETCH_4:
+    case BUILT_IN_XOR_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_XOR_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, XOR,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_NAND_AND_FETCH_1:
+    case BUILT_IN_NAND_AND_FETCH_2:
+    case BUILT_IN_NAND_AND_FETCH_4:
+    case BUILT_IN_NAND_AND_FETCH_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_NAND_AND_FETCH_1);
+      target = expand_builtin_sync_operation (mode, arglist, NOT,
+					      true, target, ignore);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_1:
+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_2:
+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_4:
+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_8:
+      if (mode == VOIDmode)
+	mode = TYPE_MODE (boolean_type_node);
+      if (!target || !register_operand (target, mode))
+	target = gen_reg_rtx (mode);
+
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_BOOL_COMPARE_AND_SWAP_1);
+      target = expand_builtin_compare_and_swap (mode, arglist, true, target);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_VAL_COMPARE_AND_SWAP_1:
+    case BUILT_IN_VAL_COMPARE_AND_SWAP_2:
+    case BUILT_IN_VAL_COMPARE_AND_SWAP_4:
+    case BUILT_IN_VAL_COMPARE_AND_SWAP_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_VAL_COMPARE_AND_SWAP_1);
+      target = expand_builtin_compare_and_swap (mode, arglist, false, target);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_LOCK_TEST_AND_SET_1:
+    case BUILT_IN_LOCK_TEST_AND_SET_2:
+    case BUILT_IN_LOCK_TEST_AND_SET_4:
+    case BUILT_IN_LOCK_TEST_AND_SET_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_LOCK_TEST_AND_SET_1);
+      target = expand_builtin_lock_test_and_set (mode, arglist, target);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_LOCK_RELEASE_1:
+    case BUILT_IN_LOCK_RELEASE_2:
+    case BUILT_IN_LOCK_RELEASE_4:
+    case BUILT_IN_LOCK_RELEASE_8:
+      mode = get_builtin_sync_mode (fcode - BUILT_IN_LOCK_RELEASE_1);
+      expand_builtin_lock_release (mode, arglist);
+      return const0_rtx;
+
+    case BUILT_IN_SYNCHRONIZE:
+      expand_builtin_synchronize ();
+      return const0_rtx;
+
+    case BUILT_IN_OBJECT_SIZE:
+      return expand_builtin_object_size (exp);
+
+    case BUILT_IN_MEMCPY_CHK:
+    case BUILT_IN_MEMPCPY_CHK:
+    case BUILT_IN_MEMMOVE_CHK:
+    case BUILT_IN_MEMSET_CHK:
+      target = expand_builtin_memory_chk (exp, target, mode, fcode);
+      if (target)
+	return target;
+      break;
+
+    case BUILT_IN_STRCPY_CHK:
+    case BUILT_IN_STPCPY_CHK:
+    case BUILT_IN_STRNCPY_CHK:
+    case BUILT_IN_STRCAT_CHK:
+    case BUILT_IN_SNPRINTF_CHK:
+    case BUILT_IN_VSNPRINTF_CHK:
+      maybe_emit_chk_warning (exp, fcode);
+      break;
+
+    case BUILT_IN_SPRINTF_CHK:
+    case BUILT_IN_VSPRINTF_CHK:
+      maybe_emit_sprintf_chk_warning (exp, fcode);
+      break;
+
+    default:	/* just do library call, if unknown builtin */
+      break;
+    }
+
+  /* The switch statement above can drop through to cause the function
+     to be called normally.  */
+  return expand_call (exp, target, ignore);
+}
+
+/* Determine whether a tree node represents a call to a built-in
+   function.  If the tree T is a call to a built-in function with
+   the right number of arguments of the appropriate types, return
+   the DECL_FUNCTION_CODE of the call, e.g. BUILT_IN_SQRT.
+   Otherwise the return value is END_BUILTINS.  */
+
+enum built_in_function
+builtin_mathfn_code (tree t)
+{
+  tree fndecl, arglist, parmlist;
+  tree argtype, parmtype;
+
+  if (TREE_CODE (t) != CALL_EXPR
+      || TREE_CODE (TREE_OPERAND (t, 0)) != ADDR_EXPR)
+    return END_BUILTINS;
+
+  fndecl = get_callee_fndecl (t);
+  if (fndecl == NULL_TREE
+      || TREE_CODE (fndecl) != FUNCTION_DECL
+      || ! DECL_BUILT_IN (fndecl)
+      || DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_MD)
+    return END_BUILTINS;
+
+  arglist = TREE_OPERAND (t, 1);
+  parmlist = TYPE_ARG_TYPES (TREE_TYPE (fndecl));
+  for (; parmlist; parmlist = TREE_CHAIN (parmlist))
+    {
+      /* If a function doesn't take a variable number of arguments,
+	 the last element in the list will have type `void'.  */
+      parmtype = TREE_VALUE (parmlist);
+      if (VOID_TYPE_P (parmtype))
+	{
+	  if (arglist)
+	    return END_BUILTINS;
+	  return DECL_FUNCTION_CODE (fndecl);
+	}
+
+      if (! arglist)
+	return END_BUILTINS;
+
+      argtype = TREE_TYPE (TREE_VALUE (arglist));
+
+      if (SCALAR_FLOAT_TYPE_P (parmtype))
+	{
+	  if (! SCALAR_FLOAT_TYPE_P (argtype))
+	    return END_BUILTINS;
+	}
+      else if (COMPLEX_FLOAT_TYPE_P (parmtype))
+	{
+	  if (! COMPLEX_FLOAT_TYPE_P (argtype))
+	    return END_BUILTINS;
+	}
+      else if (POINTER_TYPE_P (parmtype))
+	{
+	  if (! POINTER_TYPE_P (argtype))
+	    return END_BUILTINS;
+	}
+      else if (INTEGRAL_TYPE_P (parmtype))
+	{
+	  if (! INTEGRAL_TYPE_P (argtype))
+	    return END_BUILTINS;
+	}
+      else
+	return END_BUILTINS;
+
+      arglist = TREE_CHAIN (arglist);
+    }
+
+  /* Variable-length argument list.  */
+  return DECL_FUNCTION_CODE (fndecl);
+}
+
+/* Fold a call to __builtin_constant_p, if we know it will evaluate to a
+   constant.  ARGLIST is the argument list of the call.  */
+
+static tree
+fold_builtin_constant_p (tree arglist)
+{
+  if (arglist == 0)
+    return 0;
+
+  arglist = TREE_VALUE (arglist);
+
+  /* We return 1 for a numeric type that's known to be a constant
+     value at compile-time or for an aggregate type that's a
+     literal constant.  */
+  STRIP_NOPS (arglist);
+
+  /* If we know this is a constant, emit the constant of one.  */
+  if (CONSTANT_CLASS_P (arglist)
+      || (TREE_CODE (arglist) == CONSTRUCTOR
+	  && TREE_CONSTANT (arglist)))
+    return integer_one_node;
+  if (TREE_CODE (arglist) == ADDR_EXPR)
+    {
+       tree op = TREE_OPERAND (arglist, 0);
+       if (TREE_CODE (op) == STRING_CST
+	   || (TREE_CODE (op) == ARRAY_REF
+	       && integer_zerop (TREE_OPERAND (op, 1))
+	       && TREE_CODE (TREE_OPERAND (op, 0)) == STRING_CST))
+	 return integer_one_node;
+    }
+
+  /* If this expression has side effects, show we don't know it to be a
+     constant.  Likewise if it's a pointer or aggregate type since in
+     those case we only want literals, since those are only optimized
+     when generating RTL, not later.
+     And finally, if we are compiling an initializer, not code, we
+     need to return a definite result now; there's not going to be any
+     more optimization done.  */
+  if (TREE_SIDE_EFFECTS (arglist)
+      || AGGREGATE_TYPE_P (TREE_TYPE (arglist))
+      || POINTER_TYPE_P (TREE_TYPE (arglist))
+      || cfun == 0)
+    return integer_zero_node;
+
+  return 0;
+}
+
+/* Fold a call to __builtin_expect, if we expect that a comparison against
+   the argument will fold to a constant.  In practice, this means a true
+   constant or the address of a non-weak symbol.  ARGLIST is the argument
+   list of the call.  */
+
+static tree
+fold_builtin_expect (tree arglist)
+{
+  tree arg, inner;
+
+  if (arglist == 0)
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+
+  /* If the argument isn't invariant, then there's nothing we can do.  */
+  if (!TREE_INVARIANT (arg))
+    return 0;
+
+  /* If we're looking at an address of a weak decl, then do not fold.  */
+  inner = arg;
+  STRIP_NOPS (inner);
+  if (TREE_CODE (inner) == ADDR_EXPR)
+    {
+      do
+	{
+	  inner = TREE_OPERAND (inner, 0);
+	}
+      while (TREE_CODE (inner) == COMPONENT_REF
+	     || TREE_CODE (inner) == ARRAY_REF);
+      if (DECL_P (inner) && DECL_WEAK (inner))
+	return 0;
+    }
+
+  /* Otherwise, ARG already has the proper type for the return value.  */
+  return arg;
+}
+
+/* Fold a call to __builtin_classify_type.  */
+
+static tree
+fold_builtin_classify_type (tree arglist)
+{
+  if (arglist == 0)
+    return build_int_cst (NULL_TREE, no_type_class);
+
+  return build_int_cst (NULL_TREE,
+			type_to_class (TREE_TYPE (TREE_VALUE (arglist))));
+}
+
+/* Fold a call to __builtin_strlen.  */
+
+static tree
+fold_builtin_strlen (tree arglist)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return NULL_TREE;
+  else
+    {
+      tree len = c_strlen (TREE_VALUE (arglist), 0);
+
+      if (len)
+	{
+	  /* Convert from the internal "sizetype" type to "size_t".  */
+	  if (size_type_node)
+	    len = fold_convert (size_type_node, len);
+	  return len;
+	}
+
+      return NULL_TREE;
+    }
+}
+
+/* Fold a call to __builtin_inf or __builtin_huge_val.  */
+
+static tree
+fold_builtin_inf (tree type, int warn)
+{
+  REAL_VALUE_TYPE real;
+
+  /* __builtin_inff is intended to be usable to define INFINITY on all
+     targets.  If an infinity is not available, INFINITY expands "to a
+     positive constant of type float that overflows at translation
+     time", footnote "In this case, using INFINITY will violate the
+     constraint in 6.4.4 and thus require a diagnostic." (C99 7.12#4).
+     Thus we pedwarn to ensure this constraint violation is
+     diagnosed.  */
+  if (!MODE_HAS_INFINITIES (TYPE_MODE (type)) && warn)
+    pedwarn ("target format does not support infinity");
+
+  real_inf (&real);
+  return build_real (type, real);
+}
+
+/* Fold a call to __builtin_nan or __builtin_nans.  */
+
+static tree
+fold_builtin_nan (tree arglist, tree type, int quiet)
+{
+  REAL_VALUE_TYPE real;
+  const char *str;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  str = c_getstr (TREE_VALUE (arglist));
+  if (!str)
+    return 0;
+
+  if (!real_nan (&real, str, quiet, TYPE_MODE (type)))
+    return 0;
+
+  return build_real (type, real);
+}
+
+/* Return true if the floating point expression T has an integer value.
+   We also allow +Inf, -Inf and NaN to be considered integer values.  */
+
+static bool
+integer_valued_real_p (tree t)
+{
+  switch (TREE_CODE (t))
+    {
+    case FLOAT_EXPR:
+      return true;
+
+    case ABS_EXPR:
+    case SAVE_EXPR:
+    case NON_LVALUE_EXPR:
+      return integer_valued_real_p (TREE_OPERAND (t, 0));
+
+    case COMPOUND_EXPR:
+    case MODIFY_EXPR:
+    case BIND_EXPR:
+      return integer_valued_real_p (TREE_OPERAND (t, 1));
+
+    case PLUS_EXPR:
+    case MINUS_EXPR:
+    case MULT_EXPR:
+    case MIN_EXPR:
+    case MAX_EXPR:
+      return integer_valued_real_p (TREE_OPERAND (t, 0))
+	     && integer_valued_real_p (TREE_OPERAND (t, 1));
+
+    case COND_EXPR:
+      return integer_valued_real_p (TREE_OPERAND (t, 1))
+	     && integer_valued_real_p (TREE_OPERAND (t, 2));
+
+    case REAL_CST:
+      if (! TREE_CONSTANT_OVERFLOW (t))
+      {
+        REAL_VALUE_TYPE c, cint;
+
+	c = TREE_REAL_CST (t);
+	real_trunc (&cint, TYPE_MODE (TREE_TYPE (t)), &c);
+	return real_identical (&c, &cint);
+      }
+      break;
+
+    case NOP_EXPR:
+      {
+	tree type = TREE_TYPE (TREE_OPERAND (t, 0));
+	if (TREE_CODE (type) == INTEGER_TYPE)
+	  return true;
+	if (TREE_CODE (type) == REAL_TYPE)
+	  return integer_valued_real_p (TREE_OPERAND (t, 0));
+	break;
+      }
+
+    case CALL_EXPR:
+      switch (builtin_mathfn_code (t))
+	{
+	case BUILT_IN_CEIL:
+	case BUILT_IN_CEILF:
+	case BUILT_IN_CEILL:
+	case BUILT_IN_FLOOR:
+	case BUILT_IN_FLOORF:
+	case BUILT_IN_FLOORL:
+	case BUILT_IN_NEARBYINT:
+	case BUILT_IN_NEARBYINTF:
+	case BUILT_IN_NEARBYINTL:
+	case BUILT_IN_RINT:
+	case BUILT_IN_RINTF:
+	case BUILT_IN_RINTL:
+	case BUILT_IN_ROUND:
+	case BUILT_IN_ROUNDF:
+	case BUILT_IN_ROUNDL:
+	case BUILT_IN_TRUNC:
+	case BUILT_IN_TRUNCF:
+	case BUILT_IN_TRUNCL:
+	  return true;
+
+	default:
+	  break;
+	}
+      break;
+
+    default:
+      break;
+    }
+  return false;
+}
+
+/* EXP is assumed to be builtin call where truncation can be propagated
+   across (for instance floor((double)f) == (double)floorf (f).
+   Do the transformation.  */
+
+static tree
+fold_trunc_transparent_mathfn (tree fndecl, tree arglist)
+{
+  enum built_in_function fcode = DECL_FUNCTION_CODE (fndecl);
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  /* Integer rounding functions are idempotent.  */
+  if (fcode == builtin_mathfn_code (arg))
+    return arg;
+
+  /* If argument is already integer valued, and we don't need to worry
+     about setting errno, there's no need to perform rounding.  */
+  if (! flag_errno_math && integer_valued_real_p (arg))
+    return arg;
+
+  if (optimize)
+    {
+      tree arg0 = strip_float_extensions (arg);
+      tree ftype = TREE_TYPE (TREE_TYPE (fndecl));
+      tree newtype = TREE_TYPE (arg0);
+      tree decl;
+
+      if (TYPE_PRECISION (newtype) < TYPE_PRECISION (ftype)
+	  && (decl = mathfn_built_in (newtype, fcode)))
+	{
+	  arglist =
+	    build_tree_list (NULL_TREE, fold_convert (newtype, arg0));
+	  return fold_convert (ftype,
+			       build_function_call_expr (decl, arglist));
+	}
+    }
+  return 0;
+}
+
+/* EXP is assumed to be builtin call which can narrow the FP type of
+   the argument, for instance lround((double)f) -> lroundf (f).  */
+
+static tree
+fold_fixed_mathfn (tree fndecl, tree arglist)
+{
+  enum built_in_function fcode = DECL_FUNCTION_CODE (fndecl);
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+
+  /* If argument is already integer valued, and we don't need to worry
+     about setting errno, there's no need to perform rounding.  */
+  if (! flag_errno_math && integer_valued_real_p (arg))
+    return fold_build1 (FIX_TRUNC_EXPR, TREE_TYPE (TREE_TYPE (fndecl)), arg);
+
+  if (optimize)
+    {
+      tree ftype = TREE_TYPE (arg);
+      tree arg0 = strip_float_extensions (arg);
+      tree newtype = TREE_TYPE (arg0);
+      tree decl;
+
+      if (TYPE_PRECISION (newtype) < TYPE_PRECISION (ftype)
+	  && (decl = mathfn_built_in (newtype, fcode)))
+	{
+	  arglist =
+	    build_tree_list (NULL_TREE, fold_convert (newtype, arg0));
+	  return build_function_call_expr (decl, arglist);
+	}
+    }
+  return 0;
+}
+
+/* Fold function call to builtin cabs, cabsf or cabsl.  ARGLIST
+   is the argument list and TYPE is the return type.  Return
+   NULL_TREE if no if no simplification can be made.  */
+
+static tree
+fold_builtin_cabs (tree arglist, tree type)
+{
+  tree arg;
+
+  if (!arglist || TREE_CHAIN (arglist))
+    return NULL_TREE;
+
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (arg)) != COMPLEX_TYPE
+      || TREE_CODE (TREE_TYPE (TREE_TYPE (arg))) != REAL_TYPE)
+    return NULL_TREE;
+
+  /* Evaluate cabs of a constant at compile-time.  */
+  if (flag_unsafe_math_optimizations
+      && TREE_CODE (arg) == COMPLEX_CST
+      && TREE_CODE (TREE_REALPART (arg)) == REAL_CST
+      && TREE_CODE (TREE_IMAGPART (arg)) == REAL_CST
+      && ! TREE_CONSTANT_OVERFLOW (TREE_REALPART (arg))
+      && ! TREE_CONSTANT_OVERFLOW (TREE_IMAGPART (arg)))
+    {
+      REAL_VALUE_TYPE r, i;
+
+      r = TREE_REAL_CST (TREE_REALPART (arg));
+      i = TREE_REAL_CST (TREE_IMAGPART (arg));
+
+      real_arithmetic (&r, MULT_EXPR, &r, &r);
+      real_arithmetic (&i, MULT_EXPR, &i, &i);
+      real_arithmetic (&r, PLUS_EXPR, &r, &i);
+      if (real_sqrt (&r, TYPE_MODE (type), &r)
+	  || ! flag_trapping_math)
+	return build_real (type, r);
+    }
+
+  /* If either part is zero, cabs is fabs of the other.  */
+  if (TREE_CODE (arg) == COMPLEX_EXPR
+      && real_zerop (TREE_OPERAND (arg, 0)))
+    return fold_build1 (ABS_EXPR, type, TREE_OPERAND (arg, 1));
+  if (TREE_CODE (arg) == COMPLEX_EXPR
+      && real_zerop (TREE_OPERAND (arg, 1)))
+    return fold_build1 (ABS_EXPR, type, TREE_OPERAND (arg, 0));
+
+  /* Don't do this when optimizing for size.  */
+  if (flag_unsafe_math_optimizations
+      && optimize && !optimize_size)
+    {
+      tree sqrtfn = mathfn_built_in (type, BUILT_IN_SQRT);
+
+      if (sqrtfn != NULL_TREE)
+	{
+	  tree rpart, ipart, result, arglist;
+
+	  arg = builtin_save_expr (arg);
+
+	  rpart = fold_build1 (REALPART_EXPR, type, arg);
+	  ipart = fold_build1 (IMAGPART_EXPR, type, arg);
+
+	  rpart = builtin_save_expr (rpart);
+	  ipart = builtin_save_expr (ipart);
+
+	  result = fold_build2 (PLUS_EXPR, type,
+				fold_build2 (MULT_EXPR, type,
+					     rpart, rpart),
+				fold_build2 (MULT_EXPR, type,
+					     ipart, ipart));
+
+	  arglist = build_tree_list (NULL_TREE, result);
+	  return build_function_call_expr (sqrtfn, arglist);
+	}
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold a builtin function call to sqrt, sqrtf, or sqrtl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_sqrt (tree arglist, tree type)
+{
+
+  enum built_in_function fcode;
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize sqrt of constant value.  */
+  if (TREE_CODE (arg) == REAL_CST
+      && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE r, x;
+
+      x = TREE_REAL_CST (arg);
+      if (real_sqrt (&r, TYPE_MODE (type), &x)
+	  || (!flag_trapping_math && !flag_errno_math))
+	return build_real (type, r);
+    }
+
+  /* Optimize sqrt(expN(x)) = expN(x*0.5).  */
+  fcode = builtin_mathfn_code (arg);
+  if (flag_unsafe_math_optimizations && BUILTIN_EXPONENT_P (fcode))
+    {
+      tree expfn = TREE_OPERAND (TREE_OPERAND (arg, 0), 0);
+      arg = fold_build2 (MULT_EXPR, type,
+			 TREE_VALUE (TREE_OPERAND (arg, 1)),
+			 build_real (type, dconsthalf));
+      arglist = build_tree_list (NULL_TREE, arg);
+      return build_function_call_expr (expfn, arglist);
+    }
+
+  /* Optimize sqrt(Nroot(x)) -> pow(x,1/(2*N)).  */
+  if (flag_unsafe_math_optimizations && BUILTIN_ROOT_P (fcode))
+    {
+      tree powfn = mathfn_built_in (type, BUILT_IN_POW);
+
+      if (powfn)
+	{
+	  tree arg0 = TREE_VALUE (TREE_OPERAND (arg, 1));
+	  tree tree_root;
+	  /* The inner root was either sqrt or cbrt.  */
+	  REAL_VALUE_TYPE dconstroot =
+	    BUILTIN_SQRT_P (fcode) ? dconsthalf : dconstthird;
+
+	  /* Adjust for the outer root.  */
+	  SET_REAL_EXP (&dconstroot, REAL_EXP (&dconstroot) - 1);
+	  dconstroot = real_value_truncate (TYPE_MODE (type), dconstroot);
+	  tree_root = build_real (type, dconstroot);
+	  arglist = tree_cons (NULL_TREE, arg0,
+			       build_tree_list (NULL_TREE, tree_root));
+	  return build_function_call_expr (powfn, arglist);
+	}
+    }
+
+  /* Optimize sqrt(pow(x,y)) = pow(|x|,y*0.5).  */
+  if (flag_unsafe_math_optimizations
+      && (fcode == BUILT_IN_POW
+	  || fcode == BUILT_IN_POWF
+	  || fcode == BUILT_IN_POWL))
+    {
+      tree powfn = TREE_OPERAND (TREE_OPERAND (arg, 0), 0);
+      tree arg0 = TREE_VALUE (TREE_OPERAND (arg, 1));
+      tree arg1 = TREE_VALUE (TREE_CHAIN (TREE_OPERAND (arg, 1)));
+      tree narg1;
+      if (!tree_expr_nonnegative_p (arg0))
+	arg0 = build1 (ABS_EXPR, type, arg0);
+      narg1 = fold_build2 (MULT_EXPR, type, arg1,
+			   build_real (type, dconsthalf));
+      arglist = tree_cons (NULL_TREE, arg0,
+			   build_tree_list (NULL_TREE, narg1));
+      return build_function_call_expr (powfn, arglist);
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold a builtin function call to cbrt, cbrtf, or cbrtl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_cbrt (tree arglist, tree type)
+{
+  tree arg = TREE_VALUE (arglist);
+  const enum built_in_function fcode = builtin_mathfn_code (arg);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize cbrt of constant value.  */
+  if (real_zerop (arg) || real_onep (arg) || real_minus_onep (arg))
+    return arg;
+
+  if (flag_unsafe_math_optimizations)
+    {
+      /* Optimize cbrt(expN(x)) -> expN(x/3).  */
+      if (BUILTIN_EXPONENT_P (fcode))
+        {
+	  tree expfn = TREE_OPERAND (TREE_OPERAND (arg, 0), 0);
+	  const REAL_VALUE_TYPE third_trunc =
+	    real_value_truncate (TYPE_MODE (type), dconstthird);
+	  arg = fold_build2 (MULT_EXPR, type,
+			     TREE_VALUE (TREE_OPERAND (arg, 1)),
+			     build_real (type, third_trunc));
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  return build_function_call_expr (expfn, arglist);
+	}
+
+      /* Optimize cbrt(sqrt(x)) -> pow(x,1/6).  */
+      if (BUILTIN_SQRT_P (fcode))
+        {
+	  tree powfn = mathfn_built_in (type, BUILT_IN_POW);
+
+	  if (powfn)
+	    {
+	      tree arg0 = TREE_VALUE (TREE_OPERAND (arg, 1));
+	      tree tree_root;
+	      REAL_VALUE_TYPE dconstroot = dconstthird;
+
+	      SET_REAL_EXP (&dconstroot, REAL_EXP (&dconstroot) - 1);
+	      dconstroot = real_value_truncate (TYPE_MODE (type), dconstroot);
+	      tree_root = build_real (type, dconstroot);
+	      arglist = tree_cons (NULL_TREE, arg0,
+				   build_tree_list (NULL_TREE, tree_root));
+	      return build_function_call_expr (powfn, arglist);
+	    }
+	}
+
+      /* Optimize cbrt(cbrt(x)) -> pow(x,1/9) iff x is nonnegative.  */
+      if (BUILTIN_CBRT_P (fcode))
+        {
+	  tree arg0 = TREE_VALUE (TREE_OPERAND (arg, 1));
+	  if (tree_expr_nonnegative_p (arg0))
+	    {
+	      tree powfn = mathfn_built_in (type, BUILT_IN_POW);
+
+	      if (powfn)
+	        {
+		  tree tree_root;
+		  REAL_VALUE_TYPE dconstroot;
+	      
+		  real_arithmetic (&dconstroot, MULT_EXPR, &dconstthird, &dconstthird);
+		  dconstroot = real_value_truncate (TYPE_MODE (type), dconstroot);
+		  tree_root = build_real (type, dconstroot);
+		  arglist = tree_cons (NULL_TREE, arg0,
+				       build_tree_list (NULL_TREE, tree_root));
+		  return build_function_call_expr (powfn, arglist);
+		}
+	    }
+	}
+      
+      /* Optimize cbrt(pow(x,y)) -> pow(x,y/3) iff x is nonnegative.  */
+      if (fcode == BUILT_IN_POW || fcode == BUILT_IN_POWF
+	  || fcode == BUILT_IN_POWL)
+        {
+	  tree arg00 = TREE_VALUE (TREE_OPERAND (arg, 1));
+	  tree arg01 = TREE_VALUE (TREE_CHAIN (TREE_OPERAND (arg, 1)));
+	  if (tree_expr_nonnegative_p (arg00))
+	    {
+	      tree powfn = TREE_OPERAND (TREE_OPERAND (arg, 0), 0);
+	      const REAL_VALUE_TYPE dconstroot
+		= real_value_truncate (TYPE_MODE (type), dconstthird);
+	      tree narg01 = fold_build2 (MULT_EXPR, type, arg01,
+					 build_real (type, dconstroot));
+	      arglist = tree_cons (NULL_TREE, arg00,
+				   build_tree_list (NULL_TREE, narg01));
+	      return build_function_call_expr (powfn, arglist);
+	    }
+	}
+    }
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin sin, sinf, or sinl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_sin (tree arglist)
+{
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize sin (0.0) = 0.0.  */
+  if (real_zerop (arg))
+    return arg;
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin cos, cosf, or cosl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_cos (tree arglist, tree type, tree fndecl)
+{
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize cos (0.0) = 1.0.  */
+  if (real_zerop (arg))
+    return build_real (type, dconst1);
+
+  /* Optimize cos(-x) into cos (x).  */
+  if (TREE_CODE (arg) == NEGATE_EXPR)
+    {
+      tree args = build_tree_list (NULL_TREE,
+				   TREE_OPERAND (arg, 0));
+      return build_function_call_expr (fndecl, args);
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin tan, tanf, or tanl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_tan (tree arglist)
+{
+  enum built_in_function fcode;
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize tan(0.0) = 0.0.  */
+  if (real_zerop (arg))
+    return arg;
+
+  /* Optimize tan(atan(x)) = x.  */
+  fcode = builtin_mathfn_code (arg);
+  if (flag_unsafe_math_optimizations
+      && (fcode == BUILT_IN_ATAN
+	  || fcode == BUILT_IN_ATANF
+	  || fcode == BUILT_IN_ATANL))
+    return TREE_VALUE (TREE_OPERAND (arg, 1));
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin atan, atanf, or atanl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_atan (tree arglist, tree type)
+{
+
+  tree arg = TREE_VALUE (arglist);
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize atan(0.0) = 0.0.  */
+  if (real_zerop (arg))
+    return arg;
+
+  /* Optimize atan(1.0) = pi/4.  */
+  if (real_onep (arg))
+    {
+      REAL_VALUE_TYPE cst;
+
+      real_convert (&cst, TYPE_MODE (type), &dconstpi);
+      SET_REAL_EXP (&cst, REAL_EXP (&cst) - 2);
+      return build_real (type, cst);
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin trunc, truncf or truncl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_trunc (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize trunc of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE r, x;
+      tree type = TREE_TYPE (TREE_TYPE (fndecl));
+
+      x = TREE_REAL_CST (arg);
+      real_trunc (&r, TYPE_MODE (type), &x);
+      return build_real (type, r);
+    }
+
+  return fold_trunc_transparent_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin floor, floorf or floorl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_floor (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize floor of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE x;
+
+      x = TREE_REAL_CST (arg);
+      if (! REAL_VALUE_ISNAN (x) || ! flag_errno_math)
+	{
+	  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+	  REAL_VALUE_TYPE r;
+
+	  real_floor (&r, TYPE_MODE (type), &x);
+	  return build_real (type, r);
+	}
+    }
+
+  return fold_trunc_transparent_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin ceil, ceilf or ceill.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_ceil (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize ceil of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE x;
+
+      x = TREE_REAL_CST (arg);
+      if (! REAL_VALUE_ISNAN (x) || ! flag_errno_math)
+	{
+	  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+	  REAL_VALUE_TYPE r;
+
+	  real_ceil (&r, TYPE_MODE (type), &x);
+	  return build_real (type, r);
+	}
+    }
+
+  return fold_trunc_transparent_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin round, roundf or roundl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_round (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize round of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE x;
+
+      x = TREE_REAL_CST (arg);
+      if (! REAL_VALUE_ISNAN (x) || ! flag_errno_math)
+	{
+	  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+	  REAL_VALUE_TYPE r;
+
+	  real_round (&r, TYPE_MODE (type), &x);
+	  return build_real (type, r);
+	}
+    }
+
+  return fold_trunc_transparent_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin lround, lroundf or lroundl (or the
+   corresponding long long versions) and other rounding functions.
+   Return NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_int_roundingfn (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  /* Optimize lround of constant value.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == REAL_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      const REAL_VALUE_TYPE x = TREE_REAL_CST (arg);
+
+      if (! REAL_VALUE_ISNAN (x) && ! REAL_VALUE_ISINF (x))
+	{
+	  tree itype = TREE_TYPE (TREE_TYPE (fndecl));
+	  tree ftype = TREE_TYPE (arg), result;
+	  HOST_WIDE_INT hi, lo;
+	  REAL_VALUE_TYPE r;
+
+	  switch (DECL_FUNCTION_CODE (fndecl))
+	    {
+	    case BUILT_IN_LFLOOR:
+	    case BUILT_IN_LFLOORF:
+	    case BUILT_IN_LFLOORL:
+	    case BUILT_IN_LLFLOOR:
+	    case BUILT_IN_LLFLOORF:
+	    case BUILT_IN_LLFLOORL:
+	      real_floor (&r, TYPE_MODE (ftype), &x);
+	      break;
+
+	    case BUILT_IN_LCEIL:
+	    case BUILT_IN_LCEILF:
+	    case BUILT_IN_LCEILL:
+	    case BUILT_IN_LLCEIL:
+	    case BUILT_IN_LLCEILF:
+	    case BUILT_IN_LLCEILL:
+	      real_ceil (&r, TYPE_MODE (ftype), &x);
+	      break;
+
+	    case BUILT_IN_LROUND:
+	    case BUILT_IN_LROUNDF:
+	    case BUILT_IN_LROUNDL:
+	    case BUILT_IN_LLROUND:
+	    case BUILT_IN_LLROUNDF:
+	    case BUILT_IN_LLROUNDL:
+	      real_round (&r, TYPE_MODE (ftype), &x);
+	      break;
+
+	    default:
+	      gcc_unreachable ();
+	    }
+
+	  REAL_VALUE_TO_INT (&lo, &hi, r);
+	  result = build_int_cst_wide (NULL_TREE, lo, hi);
+	  if (int_fits_type_p (result, itype))
+	    return fold_convert (itype, result);
+	}
+    }
+
+  return fold_fixed_mathfn (fndecl, arglist);
+}
+
+/* Fold function call to builtin ffs, clz, ctz, popcount and parity
+   and their long and long long variants (i.e. ffsl and ffsll).
+   Return NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_bitop (tree fndecl, tree arglist)
+{
+  tree arg;
+
+  if (! validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize for constant argument.  */
+  arg = TREE_VALUE (arglist);
+  if (TREE_CODE (arg) == INTEGER_CST && ! TREE_CONSTANT_OVERFLOW (arg))
+    {
+      HOST_WIDE_INT hi, width, result;
+      unsigned HOST_WIDE_INT lo;
+      tree type;
+
+      type = TREE_TYPE (arg);
+      width = TYPE_PRECISION (type);
+      lo = TREE_INT_CST_LOW (arg);
+
+      /* Clear all the bits that are beyond the type's precision.  */
+      if (width > HOST_BITS_PER_WIDE_INT)
+	{
+	  hi = TREE_INT_CST_HIGH (arg);
+	  if (width < 2 * HOST_BITS_PER_WIDE_INT)
+	    hi &= ~((HOST_WIDE_INT) (-1) >> (width - HOST_BITS_PER_WIDE_INT));
+	}
+      else
+	{
+	  hi = 0;
+	  if (width < HOST_BITS_PER_WIDE_INT)
+	    lo &= ~((unsigned HOST_WIDE_INT) (-1) << width);
+	}
+
+      switch (DECL_FUNCTION_CODE (fndecl))
+	{
+	case BUILT_IN_FFS:
+	case BUILT_IN_FFSL:
+	case BUILT_IN_FFSLL:
+	  if (lo != 0)
+	    result = exact_log2 (lo & -lo) + 1;
+	  else if (hi != 0)
+	    result = HOST_BITS_PER_WIDE_INT + exact_log2 (hi & -hi) + 1;
+	  else
+	    result = 0;
+	  break;
+
+	case BUILT_IN_CLZ:
+	case BUILT_IN_CLZL:
+	case BUILT_IN_CLZLL:
+	  if (hi != 0)
+	    result = width - floor_log2 (hi) - 1 - HOST_BITS_PER_WIDE_INT;
+	  else if (lo != 0)
+	    result = width - floor_log2 (lo) - 1;
+	  else if (! CLZ_DEFINED_VALUE_AT_ZERO (TYPE_MODE (type), result))
+	    result = width;
+	  break;
+
+	case BUILT_IN_CTZ:
+	case BUILT_IN_CTZL:
+	case BUILT_IN_CTZLL:
+	  if (lo != 0)
+	    result = exact_log2 (lo & -lo);
+	  else if (hi != 0)
+	    result = HOST_BITS_PER_WIDE_INT + exact_log2 (hi & -hi);
+	  else if (! CTZ_DEFINED_VALUE_AT_ZERO (TYPE_MODE (type), result))
+	    result = width;
+	  break;
+
+	case BUILT_IN_POPCOUNT:
+	case BUILT_IN_POPCOUNTL:
+	case BUILT_IN_POPCOUNTLL:
+	  result = 0;
+	  while (lo)
+	    result++, lo &= lo - 1;
+	  while (hi)
+	    result++, hi &= hi - 1;
+	  break;
+
+	case BUILT_IN_PARITY:
+	case BUILT_IN_PARITYL:
+	case BUILT_IN_PARITYLL:
+	  result = 0;
+	  while (lo)
+	    result++, lo &= lo - 1;
+	  while (hi)
+	    result++, hi &= hi - 1;
+	  result &= 1;
+	  break;
+
+	default:
+	  gcc_unreachable ();
+	}
+
+      return build_int_cst (TREE_TYPE (TREE_TYPE (fndecl)), result);
+    }
+
+  return NULL_TREE;
+}
+
+/* Return true if EXPR is the real constant contained in VALUE.  */
+
+static bool
+real_dconstp (tree expr, const REAL_VALUE_TYPE *value)
+{
+  STRIP_NOPS (expr);
+
+  return ((TREE_CODE (expr) == REAL_CST
+           && ! TREE_CONSTANT_OVERFLOW (expr)
+           && REAL_VALUES_EQUAL (TREE_REAL_CST (expr), *value))
+          || (TREE_CODE (expr) == COMPLEX_CST
+              && real_dconstp (TREE_REALPART (expr), value)
+              && real_zerop (TREE_IMAGPART (expr))));
+}
+
+/* A subroutine of fold_builtin to fold the various logarithmic
+   functions.  EXP is the CALL_EXPR of a call to a builtin logN
+   function.  VALUE is the base of the logN function.  */
+
+static tree
+fold_builtin_logarithm (tree fndecl, tree arglist,
+			const REAL_VALUE_TYPE *value)
+{
+  if (validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    {
+      tree type = TREE_TYPE (TREE_TYPE (fndecl));
+      tree arg = TREE_VALUE (arglist);
+      const enum built_in_function fcode = builtin_mathfn_code (arg);
+
+      /* Optimize logN(1.0) = 0.0.  */
+      if (real_onep (arg))
+	return build_real (type, dconst0);
+
+      /* Optimize logN(N) = 1.0.  If N can't be truncated to MODE
+         exactly, then only do this if flag_unsafe_math_optimizations.  */
+      if (exact_real_truncate (TYPE_MODE (type), value)
+	  || flag_unsafe_math_optimizations)
+        {
+	  const REAL_VALUE_TYPE value_truncate =
+	    real_value_truncate (TYPE_MODE (type), *value);
+	  if (real_dconstp (arg, &value_truncate))
+	    return build_real (type, dconst1);
+	}
+
+      /* Special case, optimize logN(expN(x)) = x.  */
+      if (flag_unsafe_math_optimizations
+	  && ((value == &dconste
+	       && (fcode == BUILT_IN_EXP
+		   || fcode == BUILT_IN_EXPF
+		   || fcode == BUILT_IN_EXPL))
+	      || (value == &dconst2
+		  && (fcode == BUILT_IN_EXP2
+		      || fcode == BUILT_IN_EXP2F
+		      || fcode == BUILT_IN_EXP2L))
+	      || (value == &dconst10 && (BUILTIN_EXP10_P (fcode)))))
+	return fold_convert (type, TREE_VALUE (TREE_OPERAND (arg, 1)));
+
+      /* Optimize logN(func()) for various exponential functions.  We
+         want to determine the value "x" and the power "exponent" in
+         order to transform logN(x**exponent) into exponent*logN(x).  */
+      if (flag_unsafe_math_optimizations)
+        {
+	  tree exponent = 0, x = 0;
+
+	  switch (fcode)
+	  {
+	  case BUILT_IN_EXP:
+	  case BUILT_IN_EXPF:
+	  case BUILT_IN_EXPL:
+	    /* Prepare to do logN(exp(exponent) -> exponent*logN(e).  */
+	    x = build_real (type,
+			    real_value_truncate (TYPE_MODE (type), dconste));
+	    exponent = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    break;
+	  case BUILT_IN_EXP2:
+	  case BUILT_IN_EXP2F:
+	  case BUILT_IN_EXP2L:
+	    /* Prepare to do logN(exp2(exponent) -> exponent*logN(2).  */
+	    x = build_real (type, dconst2);
+	    exponent = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    break;
+	  case BUILT_IN_EXP10:
+	  case BUILT_IN_EXP10F:
+	  case BUILT_IN_EXP10L:
+	  case BUILT_IN_POW10:
+	  case BUILT_IN_POW10F:
+	  case BUILT_IN_POW10L:
+	    /* Prepare to do logN(exp10(exponent) -> exponent*logN(10).  */
+	    x = build_real (type, dconst10);
+	    exponent = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    break;
+	  case BUILT_IN_SQRT:
+	  case BUILT_IN_SQRTF:
+	  case BUILT_IN_SQRTL:
+	    /* Prepare to do logN(sqrt(x) -> 0.5*logN(x).  */
+	    x = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    exponent = build_real (type, dconsthalf);
+	    break;
+	  case BUILT_IN_CBRT:
+	  case BUILT_IN_CBRTF:
+	  case BUILT_IN_CBRTL:
+	    /* Prepare to do logN(cbrt(x) -> (1/3)*logN(x).  */
+	    x = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    exponent = build_real (type, real_value_truncate (TYPE_MODE (type),
+							      dconstthird));
+	    break;
+	  case BUILT_IN_POW:
+	  case BUILT_IN_POWF:
+	  case BUILT_IN_POWL:
+	    /* Prepare to do logN(pow(x,exponent) -> exponent*logN(x).  */
+	    x = TREE_VALUE (TREE_OPERAND (arg, 1));
+	    exponent = TREE_VALUE (TREE_CHAIN (TREE_OPERAND (arg, 1)));
+	    break;
+	  default:
+	    break;
+	  }
+
+	  /* Now perform the optimization.  */
+	  if (x && exponent)
+	    {
+	      tree logfn;
+	      arglist = build_tree_list (NULL_TREE, x);
+	      logfn = build_function_call_expr (fndecl, arglist);
+	      return fold_build2 (MULT_EXPR, type, exponent, logfn);
+	    }
+	}
+    }
+
+  return 0;
+}
+
+/* Fold a builtin function call to pow, powf, or powl.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_pow (tree fndecl, tree arglist, tree type)
+{
+  tree arg0 = TREE_VALUE (arglist);
+  tree arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  if (!validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize pow(1.0,y) = 1.0.  */
+  if (real_onep (arg0))
+    return omit_one_operand (type, build_real (type, dconst1), arg1);
+
+  if (TREE_CODE (arg1) == REAL_CST
+      && ! TREE_CONSTANT_OVERFLOW (arg1))
+    {
+      REAL_VALUE_TYPE cint;
+      REAL_VALUE_TYPE c;
+      HOST_WIDE_INT n;
+
+      c = TREE_REAL_CST (arg1);
+
+      /* Optimize pow(x,0.0) = 1.0.  */
+      if (REAL_VALUES_EQUAL (c, dconst0))
+	return omit_one_operand (type, build_real (type, dconst1),
+				 arg0);
+
+      /* Optimize pow(x,1.0) = x.  */
+      if (REAL_VALUES_EQUAL (c, dconst1))
+	return arg0;
+
+      /* Optimize pow(x,-1.0) = 1.0/x.  */
+      if (REAL_VALUES_EQUAL (c, dconstm1))
+	return fold_build2 (RDIV_EXPR, type,
+			    build_real (type, dconst1), arg0);
+
+      /* Optimize pow(x,0.5) = sqrt(x).  */
+      if (flag_unsafe_math_optimizations
+	  && REAL_VALUES_EQUAL (c, dconsthalf))
+	{
+	  tree sqrtfn = mathfn_built_in (type, BUILT_IN_SQRT);
+
+	  if (sqrtfn != NULL_TREE)
+	    {
+	      tree arglist = build_tree_list (NULL_TREE, arg0);
+	      return build_function_call_expr (sqrtfn, arglist);
+	    }
+	}
+
+      /* Check for an integer exponent.  */
+      n = real_to_integer (&c);
+      real_from_integer (&cint, VOIDmode, n, n < 0 ? -1 : 0, 0);
+      if (real_identical (&c, &cint))
+	{
+	  /* Attempt to evaluate pow at compile-time.  */
+	  if (TREE_CODE (arg0) == REAL_CST
+	      && ! TREE_CONSTANT_OVERFLOW (arg0))
+	    {
+	      REAL_VALUE_TYPE x;
+	      bool inexact;
+
+	      x = TREE_REAL_CST (arg0);
+	      inexact = real_powi (&x, TYPE_MODE (type), &x, n);
+	      if (flag_unsafe_math_optimizations || !inexact)
+		return build_real (type, x);
+	    }
+
+	  /* Strip sign ops from even integer powers.  */
+	  if ((n & 1) == 0 && flag_unsafe_math_optimizations)
+	    {
+	      tree narg0 = fold_strip_sign_ops (arg0);
+	      if (narg0)
+		{
+		  arglist = build_tree_list (NULL_TREE, arg1);
+		  arglist = tree_cons (NULL_TREE, narg0, arglist);
+		  return build_function_call_expr (fndecl, arglist);
+		}
+	    }
+	}
+    }
+
+  if (flag_unsafe_math_optimizations)
+    {
+      const enum built_in_function fcode = builtin_mathfn_code (arg0);
+
+      /* Optimize pow(expN(x),y) = expN(x*y).  */
+      if (BUILTIN_EXPONENT_P (fcode))
+        {
+	  tree expfn = TREE_OPERAND (TREE_OPERAND (arg0, 0), 0);
+	  tree arg = TREE_VALUE (TREE_OPERAND (arg0, 1));
+	  arg = fold_build2 (MULT_EXPR, type, arg, arg1);
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  return build_function_call_expr (expfn, arglist);
+	}
+
+      /* Optimize pow(sqrt(x),y) = pow(x,y*0.5).  */
+      if (BUILTIN_SQRT_P (fcode))
+        {
+	  tree narg0 = TREE_VALUE (TREE_OPERAND (arg0, 1));
+	  tree narg1 = fold_build2 (MULT_EXPR, type, arg1,
+				    build_real (type, dconsthalf));
+
+	  arglist = tree_cons (NULL_TREE, narg0,
+			       build_tree_list (NULL_TREE, narg1));
+	  return build_function_call_expr (fndecl, arglist);
+	}
+
+      /* Optimize pow(cbrt(x),y) = pow(x,y/3) iff x is nonnegative.  */
+      if (BUILTIN_CBRT_P (fcode))
+        {
+	  tree arg = TREE_VALUE (TREE_OPERAND (arg0, 1));
+	  if (tree_expr_nonnegative_p (arg))
+	    {
+	      const REAL_VALUE_TYPE dconstroot
+		= real_value_truncate (TYPE_MODE (type), dconstthird);
+	      tree narg1 = fold_build2 (MULT_EXPR, type, arg1,
+					build_real (type, dconstroot));
+	      arglist = tree_cons (NULL_TREE, arg,
+				   build_tree_list (NULL_TREE, narg1));
+	      return build_function_call_expr (fndecl, arglist);
+	    }
+	}
+      
+      /* Optimize pow(pow(x,y),z) = pow(x,y*z).  */
+      if (fcode == BUILT_IN_POW || fcode == BUILT_IN_POWF
+	   || fcode == BUILT_IN_POWL)
+        {
+	  tree arg00 = TREE_VALUE (TREE_OPERAND (arg0, 1));
+	  tree arg01 = TREE_VALUE (TREE_CHAIN (TREE_OPERAND (arg0, 1)));
+	  tree narg1 = fold_build2 (MULT_EXPR, type, arg01, arg1);
+	  arglist = tree_cons (NULL_TREE, arg00,
+			       build_tree_list (NULL_TREE, narg1));
+	  return build_function_call_expr (fndecl, arglist);
+	}
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold a builtin function call to powi, powif, or powil.  Return
+   NULL_TREE if no simplification can be made.  */
+static tree
+fold_builtin_powi (tree fndecl ATTRIBUTE_UNUSED, tree arglist, tree type)
+{
+  tree arg0 = TREE_VALUE (arglist);
+  tree arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  if (!validate_arglist (arglist, REAL_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  /* Optimize pow(1.0,y) = 1.0.  */
+  if (real_onep (arg0))
+    return omit_one_operand (type, build_real (type, dconst1), arg1);
+
+  if (host_integerp (arg1, 0))
+    {
+      HOST_WIDE_INT c = TREE_INT_CST_LOW (arg1);
+
+      /* Evaluate powi at compile-time.  */
+      if (TREE_CODE (arg0) == REAL_CST
+	  && ! TREE_CONSTANT_OVERFLOW (arg0))
+	{
+	  REAL_VALUE_TYPE x;
+	  x = TREE_REAL_CST (arg0);
+	  real_powi (&x, TYPE_MODE (type), &x, c);
+	  return build_real (type, x);
+	}
+
+      /* Optimize pow(x,0) = 1.0.  */
+      if (c == 0)
+	return omit_one_operand (type, build_real (type, dconst1),
+				 arg0);
+
+      /* Optimize pow(x,1) = x.  */
+      if (c == 1)
+	return arg0;
+
+      /* Optimize pow(x,-1) = 1.0/x.  */
+      if (c == -1)
+	return fold_build2 (RDIV_EXPR, type,
+			   build_real (type, dconst1), arg0);
+    }
+
+  return NULL_TREE;
+}
+
+/* A subroutine of fold_builtin to fold the various exponent
+   functions.  EXP is the CALL_EXPR of a call to a builtin function.
+   VALUE is the value which will be raised to a power.  */
+
+static tree
+fold_builtin_exponent (tree fndecl, tree arglist,
+		       const REAL_VALUE_TYPE *value)
+{
+  if (validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    {
+      tree type = TREE_TYPE (TREE_TYPE (fndecl));
+      tree arg = TREE_VALUE (arglist);
+
+      /* Optimize exp*(0.0) = 1.0.  */
+      if (real_zerop (arg))
+	return build_real (type, dconst1);
+
+      /* Optimize expN(1.0) = N.  */
+      if (real_onep (arg))
+        {
+	  REAL_VALUE_TYPE cst;
+
+	  real_convert (&cst, TYPE_MODE (type), value);
+	  return build_real (type, cst);
+	}
+
+      /* Attempt to evaluate expN(integer) at compile-time.  */
+      if (flag_unsafe_math_optimizations
+	  && TREE_CODE (arg) == REAL_CST
+	  && ! TREE_CONSTANT_OVERFLOW (arg))
+        {
+	  REAL_VALUE_TYPE cint;
+	  REAL_VALUE_TYPE c;
+	  HOST_WIDE_INT n;
+
+	  c = TREE_REAL_CST (arg);
+	  n = real_to_integer (&c);
+	  real_from_integer (&cint, VOIDmode, n,
+			     n < 0 ? -1 : 0, 0);
+	  if (real_identical (&c, &cint))
+	    {
+	      REAL_VALUE_TYPE x;
+
+	      real_powi (&x, TYPE_MODE (type), value, n);
+	      return build_real (type, x);
+	    }
+	}
+
+      /* Optimize expN(logN(x)) = x.  */
+      if (flag_unsafe_math_optimizations)
+        {
+	  const enum built_in_function fcode = builtin_mathfn_code (arg);
+
+	  if ((value == &dconste
+	       && (fcode == BUILT_IN_LOG
+		   || fcode == BUILT_IN_LOGF
+		   || fcode == BUILT_IN_LOGL))
+	      || (value == &dconst2
+		  && (fcode == BUILT_IN_LOG2
+		      || fcode == BUILT_IN_LOG2F
+		      || fcode == BUILT_IN_LOG2L))
+	      || (value == &dconst10
+		  && (fcode == BUILT_IN_LOG10
+		      || fcode == BUILT_IN_LOG10F
+		      || fcode == BUILT_IN_LOG10L)))
+	    return fold_convert (type, TREE_VALUE (TREE_OPERAND (arg, 1)));
+	}
+    }
+
+  return 0;
+}
+
+/* Fold function call to builtin memcpy.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_memcpy (tree fndecl, tree arglist)
+{
+  tree dest, src, len;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return DEST.  */
+  if (integer_zerop (len))
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, src);
+
+  /* If SRC and DEST are the same (and not volatile), return DEST.  */
+  if (operand_equal_p (src, dest, 0))
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, len);
+
+  return 0;
+}
+
+/* Fold function call to builtin mempcpy.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_mempcpy (tree arglist, tree type, int endp)
+{
+  if (validate_arglist (arglist,
+			POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      tree dest = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+      /* If the LEN parameter is zero, return DEST.  */
+      if (integer_zerop (len))
+	return omit_one_operand (type, dest, src);
+
+      /* If SRC and DEST are the same (and not volatile), return DEST+LEN.  */
+      if (operand_equal_p (src, dest, 0))
+        {
+	  if (endp == 0)
+	    return omit_one_operand (type, dest, len);
+
+	  if (endp == 2)
+	    len = fold_build2 (MINUS_EXPR, TREE_TYPE (len), len,
+			       ssize_int (1));
+      
+	  len = fold_convert (TREE_TYPE (dest), len);
+	  len = fold_build2 (PLUS_EXPR, TREE_TYPE (dest), dest, len);
+	  return fold_convert (type, len);
+	}
+    }
+  return 0;
+}
+
+/* Fold function call to builtin memmove.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_memmove (tree arglist, tree type)
+{
+  tree dest, src, len;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return DEST.  */
+  if (integer_zerop (len))
+    return omit_one_operand (type, dest, src);
+
+  /* If SRC and DEST are the same (and not volatile), return DEST.  */
+  if (operand_equal_p (src, dest, 0))
+    return omit_one_operand (type, dest, len);
+
+  return 0;
+}
+
+/* Fold function call to builtin strcpy.  If LEN is not NULL, it represents
+   the length of the string to be copied.  Return NULL_TREE if no
+   simplification can be made.  */
+
+tree
+fold_builtin_strcpy (tree fndecl, tree arglist, tree len)
+{
+  tree dest, src, fn;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* If SRC and DEST are the same (and not volatile), return DEST.  */
+  if (operand_equal_p (src, dest, 0))
+    return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), dest);
+
+  if (optimize_size)
+    return 0;
+
+  fn = implicit_built_in_decls[BUILT_IN_MEMCPY];
+  if (!fn)
+    return 0;
+
+  if (!len)
+    {
+      len = c_strlen (src, 1);
+      if (! len || TREE_SIDE_EFFECTS (len))
+	return 0;
+    }
+
+  len = size_binop (PLUS_EXPR, len, ssize_int (1));
+  arglist = build_tree_list (NULL_TREE, len);
+  arglist = tree_cons (NULL_TREE, src, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)),
+		       build_function_call_expr (fn, arglist));
+}
+
+/* Fold function call to builtin strncpy.  If SLEN is not NULL, it represents
+   the length of the source string.  Return NULL_TREE if no simplification
+   can be made.  */
+
+tree
+fold_builtin_strncpy (tree fndecl, tree arglist, tree slen)
+{
+  tree dest, src, len, fn;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return DEST.  */
+  if (integer_zerop (len))
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, src);
+
+  /* We can't compare slen with len as constants below if len is not a
+     constant.  */
+  if (len == 0 || TREE_CODE (len) != INTEGER_CST)
+    return 0;
+
+  if (!slen)
+    slen = c_strlen (src, 1);
+
+  /* Now, we must be passed a constant src ptr parameter.  */
+  if (slen == 0 || TREE_CODE (slen) != INTEGER_CST)
+    return 0;
+
+  slen = size_binop (PLUS_EXPR, slen, ssize_int (1));
+
+  /* We do not support simplification of this case, though we do
+     support it when expanding trees into RTL.  */
+  /* FIXME: generate a call to __builtin_memset.  */
+  if (tree_int_cst_lt (slen, len))
+    return 0;
+
+  /* OK transform into builtin memcpy.  */
+  fn = implicit_built_in_decls[BUILT_IN_MEMCPY];
+  if (!fn)
+    return 0;
+  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)),
+		       build_function_call_expr (fn, arglist));
+}
+
+/* Fold function call to builtin memcmp.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_memcmp (tree arglist)
+{
+  tree arg1, arg2, len;
+  const char *p1, *p2;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg1 = TREE_VALUE (arglist);
+  arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return zero.  */
+  if (integer_zerop (len))
+    return omit_two_operands (integer_type_node, integer_zero_node,
+			      arg1, arg2);
+
+  /* If ARG1 and ARG2 are the same (and not volatile), return zero.  */
+  if (operand_equal_p (arg1, arg2, 0))
+    return omit_one_operand (integer_type_node, integer_zero_node, len);
+
+  p1 = c_getstr (arg1);
+  p2 = c_getstr (arg2);
+
+  /* If all arguments are constant, and the value of len is not greater
+     than the lengths of arg1 and arg2, evaluate at compile-time.  */
+  if (host_integerp (len, 1) && p1 && p2
+      && compare_tree_int (len, strlen (p1) + 1) <= 0
+      && compare_tree_int (len, strlen (p2) + 1) <= 0)
+    {
+      const int r = memcmp (p1, p2, tree_low_cst (len, 1));
+
+      if (r > 0)
+	return integer_one_node;
+      else if (r < 0)
+	return integer_minus_one_node;
+      else
+	return integer_zero_node;
+    }
+
+  /* If len parameter is one, return an expression corresponding to
+     (*(const unsigned char*)arg1 - (const unsigned char*)arg2).  */
+  if (host_integerp (len, 1) && tree_low_cst (len, 1) == 1)
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      tree ind1 = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg1)));
+      tree ind2 = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg2)));
+      return fold_build2 (MINUS_EXPR, integer_type_node, ind1, ind2);
+    }
+
+  return 0;
+}
+
+/* Fold function call to builtin strcmp.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_strcmp (tree arglist)
+{
+  tree arg1, arg2;
+  const char *p1, *p2;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg1 = TREE_VALUE (arglist);
+  arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* If ARG1 and ARG2 are the same (and not volatile), return zero.  */
+  if (operand_equal_p (arg1, arg2, 0))
+    return integer_zero_node;
+
+  p1 = c_getstr (arg1);
+  p2 = c_getstr (arg2);
+
+  if (p1 && p2)
+    {
+      const int i = strcmp (p1, p2);
+      if (i < 0)
+	return integer_minus_one_node;
+      else if (i > 0)
+	return integer_one_node;
+      else
+	return integer_zero_node;
+    }
+
+  /* If the second arg is "", return *(const unsigned char*)arg1.  */
+  if (p2 && *p2 == '\0')
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      return fold_convert (integer_type_node,
+			   build1 (INDIRECT_REF, cst_uchar_node,
+				   fold_convert (cst_uchar_ptr_node,
+						 arg1)));
+    }
+
+  /* If the first arg is "", return -*(const unsigned char*)arg2.  */
+  if (p1 && *p1 == '\0')
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      tree temp = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg2)));
+      return fold_build1 (NEGATE_EXPR, integer_type_node, temp);
+    }
+
+  return 0;
+}
+
+/* Fold function call to builtin strncmp.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_strncmp (tree arglist)
+{
+  tree arg1, arg2, len;
+  const char *p1, *p2;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg1 = TREE_VALUE (arglist);
+  arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If the LEN parameter is zero, return zero.  */
+  if (integer_zerop (len))
+    return omit_two_operands (integer_type_node, integer_zero_node,
+			      arg1, arg2);
+
+  /* If ARG1 and ARG2 are the same (and not volatile), return zero.  */
+  if (operand_equal_p (arg1, arg2, 0))
+    return omit_one_operand (integer_type_node, integer_zero_node, len);
+
+  p1 = c_getstr (arg1);
+  p2 = c_getstr (arg2);
+
+  if (host_integerp (len, 1) && p1 && p2)
+    {
+      const int i = strncmp (p1, p2, tree_low_cst (len, 1));
+      if (i > 0)
+	return integer_one_node;
+      else if (i < 0)
+	return integer_minus_one_node;
+      else
+	return integer_zero_node;
+    }
+
+  /* If the second arg is "", and the length is greater than zero,
+     return *(const unsigned char*)arg1.  */
+  if (p2 && *p2 == '\0'
+      && TREE_CODE (len) == INTEGER_CST
+      && tree_int_cst_sgn (len) == 1)
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      return fold_convert (integer_type_node,
+			   build1 (INDIRECT_REF, cst_uchar_node,
+				   fold_convert (cst_uchar_ptr_node,
+						 arg1)));
+    }
+
+  /* If the first arg is "", and the length is greater than zero,
+     return -*(const unsigned char*)arg2.  */
+  if (p1 && *p1 == '\0'
+      && TREE_CODE (len) == INTEGER_CST
+      && tree_int_cst_sgn (len) == 1)
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      tree temp = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg2)));
+      return fold_build1 (NEGATE_EXPR, integer_type_node, temp);
+    }
+
+  /* If len parameter is one, return an expression corresponding to
+     (*(const unsigned char*)arg1 - (const unsigned char*)arg2).  */
+  if (host_integerp (len, 1) && tree_low_cst (len, 1) == 1)
+    {
+      tree cst_uchar_node = build_type_variant (unsigned_char_type_node, 1, 0);
+      tree cst_uchar_ptr_node
+	= build_pointer_type_for_mode (cst_uchar_node, ptr_mode, true);
+
+      tree ind1 = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg1)));
+      tree ind2 = fold_convert (integer_type_node,
+				build1 (INDIRECT_REF, cst_uchar_node,
+					fold_convert (cst_uchar_ptr_node,
+						      arg2)));
+      return fold_build2 (MINUS_EXPR, integer_type_node, ind1, ind2);
+    }
+
+  return 0;
+}
+
+/* Fold function call to builtin signbit, signbitf or signbitl.  Return
+   NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_signbit (tree fndecl, tree arglist)
+{
+  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+  tree arg, temp;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  arg = TREE_VALUE (arglist);
+
+  /* If ARG is a compile-time constant, determine the result.  */
+  if (TREE_CODE (arg) == REAL_CST
+      && !TREE_CONSTANT_OVERFLOW (arg))
+    {
+      REAL_VALUE_TYPE c;
+
+      c = TREE_REAL_CST (arg);
+      temp = REAL_VALUE_NEGATIVE (c) ? integer_one_node : integer_zero_node;
+      return fold_convert (type, temp);
+    }
+
+  /* If ARG is non-negative, the result is always zero.  */
+  if (tree_expr_nonnegative_p (arg))
+    return omit_one_operand (type, integer_zero_node, arg);
+
+  /* If ARG's format doesn't have signed zeros, return "arg < 0.0".  */
+  if (!HONOR_SIGNED_ZEROS (TYPE_MODE (TREE_TYPE (arg))))
+    return fold_build2 (LT_EXPR, type, arg,
+			build_real (TREE_TYPE (arg), dconst0));
+
+  return NULL_TREE;
+}
+
+/* Fold function call to builtin copysign, copysignf or copysignl.
+   Return NULL_TREE if no simplification can be made.  */
+
+static tree
+fold_builtin_copysign (tree fndecl, tree arglist, tree type)
+{
+  tree arg1, arg2, tem;
+
+  if (!validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    return NULL_TREE;
+
+  arg1 = TREE_VALUE (arglist);
+  arg2 = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* copysign(X,X) is X.  */
+  if (operand_equal_p (arg1, arg2, 0))
+    return fold_convert (type, arg1);
+
+  /* If ARG1 and ARG2 are compile-time constants, determine the result.  */
+  if (TREE_CODE (arg1) == REAL_CST
+      && TREE_CODE (arg2) == REAL_CST
+      && !TREE_CONSTANT_OVERFLOW (arg1)
+      && !TREE_CONSTANT_OVERFLOW (arg2))
+    {
+      REAL_VALUE_TYPE c1, c2;
+
+      c1 = TREE_REAL_CST (arg1);
+      c2 = TREE_REAL_CST (arg2);
+      real_copysign (&c1, &c2);
+      return build_real (type, c1);
+      c1.sign = c2.sign;
+    }
+
+  /* copysign(X, Y) is fabs(X) when Y is always non-negative.
+     Remember to evaluate Y for side-effects.  */
+  if (tree_expr_nonnegative_p (arg2))
+    return omit_one_operand (type,
+			     fold_build1 (ABS_EXPR, type, arg1),
+			     arg2);
+
+  /* Strip sign changing operations for the first argument.  */
+  tem = fold_strip_sign_ops (arg1);
+  if (tem)
+    {
+      arglist = tree_cons (NULL_TREE, tem, TREE_CHAIN (arglist));
+      return build_function_call_expr (fndecl, arglist);
+    }
+
+  return NULL_TREE;
+}
+
+/* Fold a call to builtin isascii.  */
+
+static tree
+fold_builtin_isascii (tree arglist)
+{
+  if (! validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      /* Transform isascii(c) -> ((c & ~0x7f) == 0).  */
+      tree arg = TREE_VALUE (arglist);
+
+      arg = build2 (BIT_AND_EXPR, integer_type_node, arg,
+		    build_int_cst (NULL_TREE,
+				   ~ (unsigned HOST_WIDE_INT) 0x7f));
+      arg = fold_build2 (EQ_EXPR, integer_type_node,
+			 arg, integer_zero_node);
+
+      if (in_gimple_form && !TREE_CONSTANT (arg))
+        return NULL_TREE;
+      else
+        return arg;
+    }
+}
+
+/* Fold a call to builtin toascii.  */
+
+static tree
+fold_builtin_toascii (tree arglist)
+{
+  if (! validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      /* Transform toascii(c) -> (c & 0x7f).  */
+      tree arg = TREE_VALUE (arglist);
+
+      return fold_build2 (BIT_AND_EXPR, integer_type_node, arg,
+			  build_int_cst (NULL_TREE, 0x7f));
+    }
+}
+
+/* Fold a call to builtin isdigit.  */
+
+static tree
+fold_builtin_isdigit (tree arglist)
+{
+  if (! validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      /* Transform isdigit(c) -> (unsigned)(c) - '0' <= 9.  */
+      /* According to the C standard, isdigit is unaffected by locale.
+	 However, it definitely is affected by the target character set.  */
+      tree arg;
+      unsigned HOST_WIDE_INT target_digit0
+	= lang_hooks.to_target_charset ('0');
+
+      if (target_digit0 == 0)
+	return NULL_TREE;
+
+      arg = fold_convert (unsigned_type_node, TREE_VALUE (arglist));
+      arg = build2 (MINUS_EXPR, unsigned_type_node, arg,
+		    build_int_cst (unsigned_type_node, target_digit0));
+      arg = fold_build2 (LE_EXPR, integer_type_node, arg,
+			 build_int_cst (unsigned_type_node, 9));
+      if (in_gimple_form && !TREE_CONSTANT (arg))
+        return NULL_TREE;
+      else
+        return arg;
+    }
+}
+
+/* Fold a call to fabs, fabsf or fabsl.  */
+
+static tree
+fold_builtin_fabs (tree arglist, tree type)
+{
+  tree arg;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  arg = fold_convert (type, arg);
+  if (TREE_CODE (arg) == REAL_CST)
+    return fold_abs_const (arg, type);
+  return fold_build1 (ABS_EXPR, type, arg);
+}
+
+/* Fold a call to abs, labs, llabs or imaxabs.  */
+
+static tree
+fold_builtin_abs (tree arglist, tree type)
+{
+  tree arg;
+
+  if (!validate_arglist (arglist, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  arg = TREE_VALUE (arglist);
+  arg = fold_convert (type, arg);
+  if (TREE_CODE (arg) == INTEGER_CST)
+    return fold_abs_const (arg, type);
+  return fold_build1 (ABS_EXPR, type, arg);
+}
+
+/* Fold a call to __builtin_isnan(), __builtin_isinf, __builtin_finite.
+   EXP is the CALL_EXPR for the call.  */
+
+static tree
+fold_builtin_classify (tree fndecl, tree arglist, int builtin_index)
+{
+  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+  tree arg;
+  REAL_VALUE_TYPE r;
+
+  if (!validate_arglist (arglist, REAL_TYPE, VOID_TYPE))
+    {
+      /* Check that we have exactly one argument.  */
+      if (arglist == 0)
+	{
+	  error ("too few arguments to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+      else if (TREE_CHAIN (arglist) != 0)
+	{
+	  error ("too many arguments to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+      else
+	{
+	  error ("non-floating-point argument to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+    }
+
+  arg = TREE_VALUE (arglist);
+  switch (builtin_index)
+    {
+    case BUILT_IN_ISINF:
+      if (!MODE_HAS_INFINITIES (TYPE_MODE (TREE_TYPE (arg))))
+        return omit_one_operand (type, integer_zero_node, arg);
+
+      if (TREE_CODE (arg) == REAL_CST)
+	{
+	  r = TREE_REAL_CST (arg);
+	  if (real_isinf (&r))
+	    return real_compare (GT_EXPR, &r, &dconst0)
+		   ? integer_one_node : integer_minus_one_node;
+	  else
+	    return integer_zero_node;
+	}
+
+      return NULL_TREE;
+
+    case BUILT_IN_FINITE:
+      if (!MODE_HAS_NANS (TYPE_MODE (TREE_TYPE (arg)))
+          && !MODE_HAS_INFINITIES (TYPE_MODE (TREE_TYPE (arg))))
+        return omit_one_operand (type, integer_zero_node, arg);
+
+      if (TREE_CODE (arg) == REAL_CST)
+	{
+	  r = TREE_REAL_CST (arg);
+	  return real_isinf (&r) || real_isnan (&r)
+		 ? integer_zero_node : integer_one_node;
+	}
+
+      return NULL_TREE;
+
+    case BUILT_IN_ISNAN:
+      if (!MODE_HAS_NANS (TYPE_MODE (TREE_TYPE (arg))))
+        return omit_one_operand (type, integer_zero_node, arg);
+
+      if (TREE_CODE (arg) == REAL_CST)
+	{
+	  r = TREE_REAL_CST (arg);
+	  return real_isnan (&r) ? integer_one_node : integer_zero_node;
+	}
+
+      arg = builtin_save_expr (arg);
+      return fold_build2 (UNORDERED_EXPR, type, arg, arg);
+
+    default:
+      gcc_unreachable ();
+    }
+}
+
+/* Fold a call to an unordered comparison function such as
+   __builtin_isgreater().  FNDECL is the FUNCTION_DECL for the function
+   being called and ARGLIST is the argument list for the call.
+   UNORDERED_CODE and ORDERED_CODE are comparison codes that give
+   the opposite of the desired result.  UNORDERED_CODE is used
+   for modes that can hold NaNs and ORDERED_CODE is used for
+   the rest.  */
+
+static tree
+fold_builtin_unordered_cmp (tree fndecl, tree arglist,
+			    enum tree_code unordered_code,
+			    enum tree_code ordered_code)
+{
+  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+  enum tree_code code;
+  tree arg0, arg1;
+  tree type0, type1;
+  enum tree_code code0, code1;
+  tree cmp_type = NULL_TREE;
+
+  if (!validate_arglist (arglist, REAL_TYPE, REAL_TYPE, VOID_TYPE))
+    {
+      /* Check that we have exactly two arguments.  */
+      if (arglist == 0 || TREE_CHAIN (arglist) == 0)
+	{
+	  error ("too few arguments to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+      else if (TREE_CHAIN (TREE_CHAIN (arglist)) != 0)
+	{
+	  error ("too many arguments to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+	  return error_mark_node;
+	}
+    }
+
+  arg0 = TREE_VALUE (arglist);
+  arg1 = TREE_VALUE (TREE_CHAIN (arglist));
+  
+  type0 = TREE_TYPE (arg0);
+  type1 = TREE_TYPE (arg1);
+  
+  code0 = TREE_CODE (type0);
+  code1 = TREE_CODE (type1);
+  
+  if (code0 == REAL_TYPE && code1 == REAL_TYPE)
+    /* Choose the wider of two real types.  */
+    cmp_type = TYPE_PRECISION (type0) >= TYPE_PRECISION (type1)
+      ? type0 : type1;
+  else if (code0 == REAL_TYPE && code1 == INTEGER_TYPE)
+    cmp_type = type0;
+  else if (code0 == INTEGER_TYPE && code1 == REAL_TYPE)
+    cmp_type = type1;
+  else
+    {
+      error ("non-floating-point argument to function %qs",
+		 IDENTIFIER_POINTER (DECL_NAME (fndecl)));
+      return error_mark_node;
+    }
+  
+  arg0 = fold_convert (cmp_type, arg0);
+  arg1 = fold_convert (cmp_type, arg1);
+
+  if (unordered_code == UNORDERED_EXPR)
+    {
+      if (!MODE_HAS_NANS (TYPE_MODE (TREE_TYPE (arg0))))
+	return omit_two_operands (type, integer_zero_node, arg0, arg1);
+      return fold_build2 (UNORDERED_EXPR, type, arg0, arg1);
+    }
+
+  code = MODE_HAS_NANS (TYPE_MODE (TREE_TYPE (arg0))) ? unordered_code
+						      : ordered_code;
+  return fold_build1 (TRUTH_NOT_EXPR, type,
+		      fold_build2 (code, type, arg0, arg1));
+}
+
+/* Used by constant folding to simplify calls to builtin functions.  EXP is
+   the CALL_EXPR of a call to a builtin function.  IGNORE is true if the
+   result of the function call is ignored.  This function returns NULL_TREE
+   if no simplification was possible.  */
+
+static tree
+fold_builtin_1 (tree fndecl, tree arglist, bool ignore)
+{
+  tree type = TREE_TYPE (TREE_TYPE (fndecl));
+  enum built_in_function fcode;
+
+  if (DECL_BUILT_IN_CLASS (fndecl) == BUILT_IN_MD)
+    return targetm.fold_builtin (fndecl, arglist, ignore);
+
+  fcode = DECL_FUNCTION_CODE (fndecl);
+  switch (fcode)
+    {
+    case BUILT_IN_FPUTS:
+      return fold_builtin_fputs (arglist, ignore, false, NULL_TREE);
+
+    case BUILT_IN_FPUTS_UNLOCKED:
+      return fold_builtin_fputs (arglist, ignore, true, NULL_TREE);
+
+    case BUILT_IN_STRSTR:
+      return fold_builtin_strstr (arglist, type);
+
+    case BUILT_IN_STRCAT:
+      return fold_builtin_strcat (arglist);
+
+    case BUILT_IN_STRNCAT:
+      return fold_builtin_strncat (arglist);
+
+    case BUILT_IN_STRSPN:
+      return fold_builtin_strspn (arglist);
+
+    case BUILT_IN_STRCSPN:
+      return fold_builtin_strcspn (arglist);
+
+    case BUILT_IN_STRCHR:
+    case BUILT_IN_INDEX:
+      return fold_builtin_strchr (arglist, type);
+
+    case BUILT_IN_STRRCHR:
+    case BUILT_IN_RINDEX:
+      return fold_builtin_strrchr (arglist, type);
+
+    case BUILT_IN_STRCPY:
+      return fold_builtin_strcpy (fndecl, arglist, NULL_TREE);
+
+    case BUILT_IN_STRNCPY:
+      return fold_builtin_strncpy (fndecl, arglist, NULL_TREE);
+
+    case BUILT_IN_STRCMP:
+      return fold_builtin_strcmp (arglist);
+
+    case BUILT_IN_STRNCMP:
+      return fold_builtin_strncmp (arglist);
+
+    case BUILT_IN_STRPBRK:
+      return fold_builtin_strpbrk (arglist, type);
+
+    case BUILT_IN_BCMP:
+    case BUILT_IN_MEMCMP:
+      return fold_builtin_memcmp (arglist);
+
+    case BUILT_IN_SPRINTF:
+      return fold_builtin_sprintf (arglist, ignore);
+
+    case BUILT_IN_CONSTANT_P:
+      {
+	tree val;
+
+	val = fold_builtin_constant_p (arglist);
+	/* Gimplification will pull the CALL_EXPR for the builtin out of
+	   an if condition.  When not optimizing, we'll not CSE it back.
+	   To avoid link error types of regressions, return false now.  */
+	if (!val && !optimize)
+	  val = integer_zero_node;
+
+	return val;
+      }
+
+    case BUILT_IN_EXPECT:
+      return fold_builtin_expect (arglist);
+
+    case BUILT_IN_CLASSIFY_TYPE:
+      return fold_builtin_classify_type (arglist);
+
+    case BUILT_IN_STRLEN:
+      return fold_builtin_strlen (arglist);
+
+    case BUILT_IN_FABS:
+    case BUILT_IN_FABSF:
+    case BUILT_IN_FABSL:
+      return fold_builtin_fabs (arglist, type);
+
+    case BUILT_IN_ABS:
+    case BUILT_IN_LABS:
+    case BUILT_IN_LLABS:
+    case BUILT_IN_IMAXABS:
+      return fold_builtin_abs (arglist, type);
+
+    case BUILT_IN_CONJ:
+    case BUILT_IN_CONJF:
+    case BUILT_IN_CONJL:
+      if (validate_arglist (arglist, COMPLEX_TYPE, VOID_TYPE))
+	return fold_build1 (CONJ_EXPR, type, TREE_VALUE (arglist));
+      break;
+
+    case BUILT_IN_CREAL:
+    case BUILT_IN_CREALF:
+    case BUILT_IN_CREALL:
+      if (validate_arglist (arglist, COMPLEX_TYPE, VOID_TYPE))
+        return non_lvalue (fold_build1 (REALPART_EXPR, type,
+					TREE_VALUE (arglist)));
+      break;
+
+    case BUILT_IN_CIMAG:
+    case BUILT_IN_CIMAGF:
+    case BUILT_IN_CIMAGL:
+      if (validate_arglist (arglist, COMPLEX_TYPE, VOID_TYPE))
+        return non_lvalue (fold_build1 (IMAGPART_EXPR, type,
+					TREE_VALUE (arglist)));
+      break;
+
+    case BUILT_IN_CABS:
+    case BUILT_IN_CABSF:
+    case BUILT_IN_CABSL:
+      return fold_builtin_cabs (arglist, type);
+
+    case BUILT_IN_SQRT:
+    case BUILT_IN_SQRTF:
+    case BUILT_IN_SQRTL:
+      return fold_builtin_sqrt (arglist, type);
+
+    case BUILT_IN_CBRT:
+    case BUILT_IN_CBRTF:
+    case BUILT_IN_CBRTL:
+      return fold_builtin_cbrt (arglist, type);
+
+    case BUILT_IN_SIN:
+    case BUILT_IN_SINF:
+    case BUILT_IN_SINL:
+      return fold_builtin_sin (arglist);
+
+    case BUILT_IN_COS:
+    case BUILT_IN_COSF:
+    case BUILT_IN_COSL:
+      return fold_builtin_cos (arglist, type, fndecl);
+
+    case BUILT_IN_EXP:
+    case BUILT_IN_EXPF:
+    case BUILT_IN_EXPL:
+      return fold_builtin_exponent (fndecl, arglist, &dconste);
+
+    case BUILT_IN_EXP2:
+    case BUILT_IN_EXP2F:
+    case BUILT_IN_EXP2L:
+      return fold_builtin_exponent (fndecl, arglist, &dconst2);
+
+    case BUILT_IN_EXP10:
+    case BUILT_IN_EXP10F:
+    case BUILT_IN_EXP10L:
+    case BUILT_IN_POW10:
+    case BUILT_IN_POW10F:
+    case BUILT_IN_POW10L:
+      return fold_builtin_exponent (fndecl, arglist, &dconst10);
+
+    case BUILT_IN_LOG:
+    case BUILT_IN_LOGF:
+    case BUILT_IN_LOGL:
+      return fold_builtin_logarithm (fndecl, arglist, &dconste);
+
+    case BUILT_IN_LOG2:
+    case BUILT_IN_LOG2F:
+    case BUILT_IN_LOG2L:
+      return fold_builtin_logarithm (fndecl, arglist, &dconst2);
+
+    case BUILT_IN_LOG10:
+    case BUILT_IN_LOG10F:
+    case BUILT_IN_LOG10L:
+      return fold_builtin_logarithm (fndecl, arglist, &dconst10);
+
+    case BUILT_IN_TAN:
+    case BUILT_IN_TANF:
+    case BUILT_IN_TANL:
+      return fold_builtin_tan (arglist);
+
+    case BUILT_IN_ATAN:
+    case BUILT_IN_ATANF:
+    case BUILT_IN_ATANL:
+      return fold_builtin_atan (arglist, type);
+
+    case BUILT_IN_POW:
+    case BUILT_IN_POWF:
+    case BUILT_IN_POWL:
+      return fold_builtin_pow (fndecl, arglist, type);
+
+    case BUILT_IN_POWI:
+    case BUILT_IN_POWIF:
+    case BUILT_IN_POWIL:
+      return fold_builtin_powi (fndecl, arglist, type);
+
+    case BUILT_IN_INF:
+    case BUILT_IN_INFF:
+    case BUILT_IN_INFL:
+      return fold_builtin_inf (type, true);
+
+    case BUILT_IN_HUGE_VAL:
+    case BUILT_IN_HUGE_VALF:
+    case BUILT_IN_HUGE_VALL:
+      return fold_builtin_inf (type, false);
+
+    case BUILT_IN_NAN:
+    case BUILT_IN_NANF:
+    case BUILT_IN_NANL:
+      return fold_builtin_nan (arglist, type, true);
+
+    case BUILT_IN_NANS:
+    case BUILT_IN_NANSF:
+    case BUILT_IN_NANSL:
+      return fold_builtin_nan (arglist, type, false);
+
+    case BUILT_IN_FLOOR:
+    case BUILT_IN_FLOORF:
+    case BUILT_IN_FLOORL:
+      return fold_builtin_floor (fndecl, arglist);
+
+    case BUILT_IN_CEIL:
+    case BUILT_IN_CEILF:
+    case BUILT_IN_CEILL:
+      return fold_builtin_ceil (fndecl, arglist);
+
+    case BUILT_IN_TRUNC:
+    case BUILT_IN_TRUNCF:
+    case BUILT_IN_TRUNCL:
+      return fold_builtin_trunc (fndecl, arglist);
+
+    case BUILT_IN_ROUND:
+    case BUILT_IN_ROUNDF:
+    case BUILT_IN_ROUNDL:
+      return fold_builtin_round (fndecl, arglist);
+
+    case BUILT_IN_NEARBYINT:
+    case BUILT_IN_NEARBYINTF:
+    case BUILT_IN_NEARBYINTL:
+    case BUILT_IN_RINT:
+    case BUILT_IN_RINTF:
+    case BUILT_IN_RINTL:
+      return fold_trunc_transparent_mathfn (fndecl, arglist);
+
+    case BUILT_IN_LCEIL:
+    case BUILT_IN_LCEILF:
+    case BUILT_IN_LCEILL:
+    case BUILT_IN_LLCEIL:
+    case BUILT_IN_LLCEILF:
+    case BUILT_IN_LLCEILL:
+    case BUILT_IN_LFLOOR:
+    case BUILT_IN_LFLOORF:
+    case BUILT_IN_LFLOORL:
+    case BUILT_IN_LLFLOOR:
+    case BUILT_IN_LLFLOORF:
+    case BUILT_IN_LLFLOORL:
+    case BUILT_IN_LROUND:
+    case BUILT_IN_LROUNDF:
+    case BUILT_IN_LROUNDL:
+    case BUILT_IN_LLROUND:
+    case BUILT_IN_LLROUNDF:
+    case BUILT_IN_LLROUNDL:
+      return fold_builtin_int_roundingfn (fndecl, arglist);
+
+    case BUILT_IN_LRINT:
+    case BUILT_IN_LRINTF:
+    case BUILT_IN_LRINTL:
+    case BUILT_IN_LLRINT:
+    case BUILT_IN_LLRINTF:
+    case BUILT_IN_LLRINTL:
+      return fold_fixed_mathfn (fndecl, arglist);
+
+    case BUILT_IN_FFS:
+    case BUILT_IN_FFSL:
+    case BUILT_IN_FFSLL:
+    case BUILT_IN_CLZ:
+    case BUILT_IN_CLZL:
+    case BUILT_IN_CLZLL:
+    case BUILT_IN_CTZ:
+    case BUILT_IN_CTZL:
+    case BUILT_IN_CTZLL:
+    case BUILT_IN_POPCOUNT:
+    case BUILT_IN_POPCOUNTL:
+    case BUILT_IN_POPCOUNTLL:
+    case BUILT_IN_PARITY:
+    case BUILT_IN_PARITYL:
+    case BUILT_IN_PARITYLL:
+      return fold_builtin_bitop (fndecl, arglist);
+
+    case BUILT_IN_MEMCPY:
+      return fold_builtin_memcpy (fndecl, arglist);
+
+    case BUILT_IN_MEMPCPY:
+      return fold_builtin_mempcpy (arglist, type, /*endp=*/1);
+
+    case BUILT_IN_MEMMOVE:
+      return fold_builtin_memmove (arglist, type);
+
+    case BUILT_IN_SIGNBIT:
+    case BUILT_IN_SIGNBITF:
+    case BUILT_IN_SIGNBITL:
+      return fold_builtin_signbit (fndecl, arglist);
+
+    case BUILT_IN_ISASCII:
+      return fold_builtin_isascii (arglist);
+
+    case BUILT_IN_TOASCII:
+      return fold_builtin_toascii (arglist);
+
+    case BUILT_IN_ISDIGIT:
+      return fold_builtin_isdigit (arglist);
+
+    case BUILT_IN_COPYSIGN:
+    case BUILT_IN_COPYSIGNF:
+    case BUILT_IN_COPYSIGNL:
+      return fold_builtin_copysign (fndecl, arglist, type);
+
+    case BUILT_IN_FINITE:
+    case BUILT_IN_FINITEF:
+    case BUILT_IN_FINITEL:
+      return fold_builtin_classify (fndecl, arglist, BUILT_IN_FINITE);
+
+    case BUILT_IN_ISINF:
+    case BUILT_IN_ISINFF:
+    case BUILT_IN_ISINFL:
+      return fold_builtin_classify (fndecl, arglist, BUILT_IN_ISINF);
+
+    case BUILT_IN_ISNAN:
+    case BUILT_IN_ISNANF:
+    case BUILT_IN_ISNANL:
+      return fold_builtin_classify (fndecl, arglist, BUILT_IN_ISNAN);
+
+    case BUILT_IN_ISGREATER:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNLE_EXPR, LE_EXPR);
+    case BUILT_IN_ISGREATEREQUAL:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNLT_EXPR, LT_EXPR);
+    case BUILT_IN_ISLESS:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNGE_EXPR, GE_EXPR);
+    case BUILT_IN_ISLESSEQUAL:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNGT_EXPR, GT_EXPR);
+    case BUILT_IN_ISLESSGREATER:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNEQ_EXPR, EQ_EXPR);
+    case BUILT_IN_ISUNORDERED:
+      return fold_builtin_unordered_cmp (fndecl, arglist, UNORDERED_EXPR,
+					 NOP_EXPR);
+
+      /* We do the folding for va_start in the expander.  */
+    case BUILT_IN_VA_START:
+      break;
+
+    case BUILT_IN_OBJECT_SIZE:
+      return fold_builtin_object_size (arglist);
+    case BUILT_IN_MEMCPY_CHK:
+    case BUILT_IN_MEMPCPY_CHK:
+    case BUILT_IN_MEMMOVE_CHK:
+    case BUILT_IN_MEMSET_CHK:
+      return fold_builtin_memory_chk (fndecl, arglist, NULL_TREE, ignore,
+				      DECL_FUNCTION_CODE (fndecl));
+    case BUILT_IN_STRCPY_CHK:
+    case BUILT_IN_STPCPY_CHK:
+      return fold_builtin_stxcpy_chk (fndecl, arglist, NULL_TREE, ignore,
+				      DECL_FUNCTION_CODE (fndecl));
+    case BUILT_IN_STRNCPY_CHK:
+      return fold_builtin_strncpy_chk (arglist, NULL_TREE);
+    case BUILT_IN_STRCAT_CHK:
+      return fold_builtin_strcat_chk (fndecl, arglist);
+    case BUILT_IN_STRNCAT_CHK:
+      return fold_builtin_strncat_chk (fndecl, arglist);
+    case BUILT_IN_SPRINTF_CHK:
+    case BUILT_IN_VSPRINTF_CHK:
+      return fold_builtin_sprintf_chk (arglist, DECL_FUNCTION_CODE (fndecl));
+    case BUILT_IN_SNPRINTF_CHK:
+    case BUILT_IN_VSNPRINTF_CHK:
+      return fold_builtin_snprintf_chk (arglist, NULL_TREE,
+					DECL_FUNCTION_CODE (fndecl));
+
+    case BUILT_IN_PRINTF:
+    case BUILT_IN_PRINTF_UNLOCKED:
+    case BUILT_IN_VPRINTF:
+    case BUILT_IN_PRINTF_CHK:
+    case BUILT_IN_VPRINTF_CHK:
+      return fold_builtin_printf (fndecl, arglist, ignore,
+				  DECL_FUNCTION_CODE (fndecl));
+
+    case BUILT_IN_FPRINTF:
+    case BUILT_IN_FPRINTF_UNLOCKED:
+    case BUILT_IN_VFPRINTF:
+    case BUILT_IN_FPRINTF_CHK:
+    case BUILT_IN_VFPRINTF_CHK:
+      return fold_builtin_fprintf (fndecl, arglist, ignore,
+				   DECL_FUNCTION_CODE (fndecl));
+
+    default:
+      break;
+    }
+
+  return 0;
+}
+
+/* A wrapper function for builtin folding that prevents warnings for
+   "statement without effect" and the like, caused by removing the
+   call node earlier than the warning is generated.  */
+
+tree
+fold_builtin (tree fndecl, tree arglist, bool ignore)
+{
+  tree exp = fold_builtin_1 (fndecl, arglist, ignore);
+  if (exp)
+    {
+      exp = build1 (NOP_EXPR, TREE_TYPE (exp), exp);
+      TREE_NO_WARNING (exp) = 1;
+    }
+
+  return exp;
+}
+
+/* Conveniently construct a function call expression.  */
+
+tree
+build_function_call_expr (tree fn, tree arglist)
+{
+  tree call_expr;
+
+  call_expr = build1 (ADDR_EXPR, build_pointer_type (TREE_TYPE (fn)), fn);
+  return fold_build3 (CALL_EXPR, TREE_TYPE (TREE_TYPE (fn)),
+		      call_expr, arglist, NULL_TREE);
+}
+
+/* This function validates the types of a function call argument list
+   represented as a tree chain of parameters against a specified list
+   of tree_codes.  If the last specifier is a 0, that represents an
+   ellipses, otherwise the last specifier must be a VOID_TYPE.  */
+
+static int
+validate_arglist (tree arglist, ...)
+{
+  enum tree_code code;
+  int res = 0;
+  va_list ap;
+
+  va_start (ap, arglist);
+
+  do
+    {
+      code = va_arg (ap, enum tree_code);
+      switch (code)
+	{
+	case 0:
+	  /* This signifies an ellipses, any further arguments are all ok.  */
+	  res = 1;
+	  goto end;
+	case VOID_TYPE:
+	  /* This signifies an endlink, if no arguments remain, return
+	     true, otherwise return false.  */
+	  res = arglist == 0;
+	  goto end;
+	default:
+	  /* If no parameters remain or the parameter's code does not
+	     match the specified code, return false.  Otherwise continue
+	     checking any remaining arguments.  */
+	  if (arglist == 0)
+	    goto end;
+	  if (code == POINTER_TYPE)
+	    {
+	      if (! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist))))
+		goto end;
+	    }
+	  else if (code != TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))))
+	    goto end;
+	  break;
+	}
+      arglist = TREE_CHAIN (arglist);
+    }
+  while (1);
+
+  /* We need gotos here since we can only have one VA_CLOSE in a
+     function.  */
+ end: ;
+  va_end (ap);
+
+  return res;
+}
+
+/* Default target-specific builtin expander that does nothing.  */
+
+rtx
+default_expand_builtin (tree exp ATTRIBUTE_UNUSED,
+			rtx target ATTRIBUTE_UNUSED,
+			rtx subtarget ATTRIBUTE_UNUSED,
+			enum machine_mode mode ATTRIBUTE_UNUSED,
+			int ignore ATTRIBUTE_UNUSED)
+{
+  return NULL_RTX;
+}
+
+/* Returns true is EXP represents data that would potentially reside
+   in a readonly section.  */
+
+static bool
+readonly_data_expr (tree exp)
+{
+  STRIP_NOPS (exp);
+
+  if (TREE_CODE (exp) != ADDR_EXPR)
+    return false;
+
+  exp = get_base_address (TREE_OPERAND (exp, 0));
+  if (!exp)
+    return false;
+
+  /* Make sure we call decl_readonly_section only for trees it
+     can handle (since it returns true for everything it doesn't
+     understand).  */
+  if (TREE_CODE (exp) == STRING_CST
+      || TREE_CODE (exp) == CONSTRUCTOR
+      || (TREE_CODE (exp) == VAR_DECL && TREE_STATIC (exp)))
+    return decl_readonly_section (exp, 0);
+  else
+    return false;
+}
+
+/* Simplify a call to the strstr builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strstr (tree arglist, tree type)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      tree fn;
+      const char *p1, *p2;
+
+      p2 = c_getstr (s2);
+      if (p2 == NULL)
+	return 0;
+
+      p1 = c_getstr (s1);
+      if (p1 != NULL)
+	{
+	  const char *r = strstr (p1, p2);
+	  tree tem;
+
+	  if (r == NULL)
+	    return build_int_cst (TREE_TYPE (s1), 0);
+
+	  /* Return an offset into the constant string argument.  */
+	  tem = fold_build2 (PLUS_EXPR, TREE_TYPE (s1),
+			     s1, build_int_cst (TREE_TYPE (s1), r - p1));
+	  return fold_convert (type, tem);
+	}
+
+      /* The argument is const char *, and the result is char *, so we need
+	 a type conversion here to avoid a warning.  */
+      if (p2[0] == '\0')
+	return fold_convert (type, s1);
+
+      if (p2[1] != '\0')
+	return 0;
+
+      fn = implicit_built_in_decls[BUILT_IN_STRCHR];
+      if (!fn)
+	return 0;
+
+      /* New argument list transforming strstr(s1, s2) to
+	 strchr(s1, s2[0]).  */
+      arglist = build_tree_list (NULL_TREE,
+				 build_int_cst (NULL_TREE, p2[0]));
+      arglist = tree_cons (NULL_TREE, s1, arglist);
+      return build_function_call_expr (fn, arglist);
+    }
+}
+
+/* Simplify a call to the strchr builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strchr (tree arglist, tree type)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p1;
+
+      if (TREE_CODE (s2) != INTEGER_CST)
+	return 0;
+
+      p1 = c_getstr (s1);
+      if (p1 != NULL)
+	{
+	  char c;
+	  const char *r;
+	  tree tem;
+
+	  if (target_char_cast (s2, &c))
+	    return 0;
+
+	  r = strchr (p1, c);
+
+	  if (r == NULL)
+	    return build_int_cst (TREE_TYPE (s1), 0);
+
+	  /* Return an offset into the constant string argument.  */
+	  tem = fold_build2 (PLUS_EXPR, TREE_TYPE (s1),
+			     s1, build_int_cst (TREE_TYPE (s1), r - p1));
+	  return fold_convert (type, tem);
+	}
+      return 0;
+    }
+}
+
+/* Simplify a call to the strrchr builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strrchr (tree arglist, tree type)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      tree fn;
+      const char *p1;
+
+      if (TREE_CODE (s2) != INTEGER_CST)
+	return 0;
+
+      p1 = c_getstr (s1);
+      if (p1 != NULL)
+	{
+	  char c;
+	  const char *r;
+	  tree tem;
+
+	  if (target_char_cast (s2, &c))
+	    return 0;
+
+	  r = strrchr (p1, c);
+
+	  if (r == NULL)
+	    return build_int_cst (TREE_TYPE (s1), 0);
+
+	  /* Return an offset into the constant string argument.  */
+	  tem = fold_build2 (PLUS_EXPR, TREE_TYPE (s1),
+			     s1, build_int_cst (TREE_TYPE (s1), r - p1));
+	  return fold_convert (type, tem);
+	}
+
+      if (! integer_zerop (s2))
+	return 0;
+
+      fn = implicit_built_in_decls[BUILT_IN_STRCHR];
+      if (!fn)
+	return 0;
+
+      /* Transform strrchr(s1, '\0') to strchr(s1, '\0').  */
+      return build_function_call_expr (fn, arglist);
+    }
+}
+
+/* Simplify a call to the strpbrk builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strpbrk (tree arglist, tree type)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      tree fn;
+      const char *p1, *p2;
+
+      p2 = c_getstr (s2);
+      if (p2 == NULL)
+	return 0;
+
+      p1 = c_getstr (s1);
+      if (p1 != NULL)
+	{
+	  const char *r = strpbrk (p1, p2);
+	  tree tem;
+
+	  if (r == NULL)
+	    return build_int_cst (TREE_TYPE (s1), 0);
+
+	  /* Return an offset into the constant string argument.  */
+	  tem = fold_build2 (PLUS_EXPR, TREE_TYPE (s1),
+			     s1, build_int_cst (TREE_TYPE (s1), r - p1));
+	  return fold_convert (type, tem);
+	}
+
+      if (p2[0] == '\0')
+	/* strpbrk(x, "") == NULL.
+	   Evaluate and ignore s1 in case it had side-effects.  */
+	return omit_one_operand (TREE_TYPE (s1), integer_zero_node, s1);
+
+      if (p2[1] != '\0')
+	return 0;  /* Really call strpbrk.  */
+
+      fn = implicit_built_in_decls[BUILT_IN_STRCHR];
+      if (!fn)
+	return 0;
+
+      /* New argument list transforming strpbrk(s1, s2) to
+	 strchr(s1, s2[0]).  */
+      arglist = build_tree_list (NULL_TREE,
+				 build_int_cst (NULL_TREE, p2[0]));
+      arglist = tree_cons (NULL_TREE, s1, arglist);
+      return build_function_call_expr (fn, arglist);
+    }
+}
+
+/* Simplify a call to the strcat builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strcat (tree arglist)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dst = TREE_VALUE (arglist),
+	src = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p = c_getstr (src);
+
+      /* If the string length is zero, return the dst parameter.  */
+      if (p && *p == '\0')
+	return dst;
+
+      return 0;
+    }
+}
+
+/* Simplify a call to the strncat builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strncat (tree arglist)
+{
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree dst = TREE_VALUE (arglist);
+      tree src = TREE_VALUE (TREE_CHAIN (arglist));
+      tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      const char *p = c_getstr (src);
+
+      /* If the requested length is zero, or the src parameter string
+	 length is zero, return the dst parameter.  */
+      if (integer_zerop (len) || (p && *p == '\0'))
+        return omit_two_operands (TREE_TYPE (dst), dst, src, len);
+
+      /* If the requested len is greater than or equal to the string
+         length, call strcat.  */
+      if (TREE_CODE (len) == INTEGER_CST && p
+	  && compare_tree_int (len, strlen (p)) >= 0)
+	{
+	  tree newarglist
+	    = tree_cons (NULL_TREE, dst, build_tree_list (NULL_TREE, src));
+	  tree fn = implicit_built_in_decls[BUILT_IN_STRCAT];
+
+	  /* If the replacement _DECL isn't initialized, don't do the
+	     transformation.  */
+	  if (!fn)
+	    return 0;
+
+	  return build_function_call_expr (fn, newarglist);
+	}
+      return 0;
+    }
+}
+
+/* Simplify a call to the strspn builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strspn (tree arglist)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p1 = c_getstr (s1), *p2 = c_getstr (s2);
+
+      /* If both arguments are constants, evaluate at compile-time.  */
+      if (p1 && p2)
+	{
+	  const size_t r = strspn (p1, p2);
+	  return size_int (r);
+	}
+
+      /* If either argument is "", return 0.  */
+      if ((p1 && *p1 == '\0') || (p2 && *p2 == '\0'))
+	/* Evaluate and ignore both arguments in case either one has
+	   side-effects.  */
+	return omit_two_operands (integer_type_node, integer_zero_node,
+				  s1, s2);
+      return 0;
+    }
+}
+
+/* Simplify a call to the strcspn builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.
+
+   The simplified form may be a constant or other expression which
+   computes the same value, but in a more efficient manner (including
+   calls to other builtin functions).
+
+   The call may contain arguments which need to be evaluated, but
+   which are not useful to determine the result of the call.  In
+   this case we return a chain of COMPOUND_EXPRs.  The LHS of each
+   COMPOUND_EXPR will be an argument which must be evaluated.
+   COMPOUND_EXPRs are chained through their RHS.  The RHS of the last
+   COMPOUND_EXPR in the chain will contain the tree for the simplified
+   form of the builtin function call.  */
+
+static tree
+fold_builtin_strcspn (tree arglist)
+{
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+  else
+    {
+      tree s1 = TREE_VALUE (arglist), s2 = TREE_VALUE (TREE_CHAIN (arglist));
+      const char *p1 = c_getstr (s1), *p2 = c_getstr (s2);
+
+      /* If both arguments are constants, evaluate at compile-time.  */
+      if (p1 && p2)
+	{
+	  const size_t r = strcspn (p1, p2);
+	  return size_int (r);
+	}
+
+      /* If the first argument is "", return 0.  */
+      if (p1 && *p1 == '\0')
+	{
+	  /* Evaluate and ignore argument s2 in case it has
+	     side-effects.  */
+	  return omit_one_operand (integer_type_node,
+				   integer_zero_node, s2);
+	}
+
+      /* If the second argument is "", return __builtin_strlen(s1).  */
+      if (p2 && *p2 == '\0')
+	{
+	  tree newarglist = build_tree_list (NULL_TREE, s1),
+	    fn = implicit_built_in_decls[BUILT_IN_STRLEN];
+
+	  /* If the replacement _DECL isn't initialized, don't do the
+	     transformation.  */
+	  if (!fn)
+	    return 0;
+
+	  return build_function_call_expr (fn, newarglist);
+	}
+      return 0;
+    }
+}
+
+/* Fold a call to the fputs builtin.  IGNORE is true if the value returned
+   by the builtin will be ignored.  UNLOCKED is true is true if this
+   actually a call to fputs_unlocked.  If LEN in non-NULL, it represents
+   the known length of the string.  Return NULL_TREE if no simplification
+   was possible.  */
+
+tree
+fold_builtin_fputs (tree arglist, bool ignore, bool unlocked, tree len)
+{
+  tree fn;
+  /* If we're using an unlocked function, assume the other unlocked
+     functions exist explicitly.  */
+  tree const fn_fputc = unlocked ? built_in_decls[BUILT_IN_FPUTC_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_FPUTC];
+  tree const fn_fwrite = unlocked ? built_in_decls[BUILT_IN_FWRITE_UNLOCKED]
+    : implicit_built_in_decls[BUILT_IN_FWRITE];
+
+  /* If the return value is used, don't do the transformation.  */
+  if (!ignore)
+    return 0;
+
+  /* Verify the arguments in the original call.  */
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE))
+    return 0;
+
+  if (! len)
+    len = c_strlen (TREE_VALUE (arglist), 0);
+
+  /* Get the length of the string passed to fputs.  If the length
+     can't be determined, punt.  */
+  if (!len
+      || TREE_CODE (len) != INTEGER_CST)
+    return 0;
+
+  switch (compare_tree_int (len, 1))
+    {
+    case -1: /* length is 0, delete the call entirely .  */
+      return omit_one_operand (integer_type_node, integer_zero_node,
+			       TREE_VALUE (TREE_CHAIN (arglist)));
+
+    case 0: /* length is 1, call fputc.  */
+      {
+	const char *p = c_getstr (TREE_VALUE (arglist));
+
+	if (p != NULL)
+	  {
+	    /* New argument list transforming fputs(string, stream) to
+	       fputc(string[0], stream).  */
+	    arglist = build_tree_list (NULL_TREE,
+				       TREE_VALUE (TREE_CHAIN (arglist)));
+	    arglist = tree_cons (NULL_TREE,
+				 build_int_cst (NULL_TREE, p[0]),
+				 arglist);
+	    fn = fn_fputc;
+	    break;
+	  }
+      }
+      /* FALLTHROUGH */
+    case 1: /* length is greater than 1, call fwrite.  */
+      {
+	tree string_arg;
+
+	/* If optimizing for size keep fputs.  */
+	if (optimize_size)
+	  return 0;
+	string_arg = TREE_VALUE (arglist);
+	/* New argument list transforming fputs(string, stream) to
+	   fwrite(string, 1, len, stream).  */
+	arglist = build_tree_list (NULL_TREE,
+				   TREE_VALUE (TREE_CHAIN (arglist)));
+	arglist = tree_cons (NULL_TREE, len, arglist);
+	arglist = tree_cons (NULL_TREE, size_one_node, arglist);
+	arglist = tree_cons (NULL_TREE, string_arg, arglist);
+	fn = fn_fwrite;
+	break;
+      }
+    default:
+      gcc_unreachable ();
+    }
+
+  /* If the replacement _DECL isn't initialized, don't do the
+     transformation.  */
+  if (!fn)
+    return 0;
+
+  /* These optimizations are only performed when the result is ignored,
+     hence there's no need to cast the result to integer_type_node.  */
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold the new_arg's arguments (ARGLIST). Returns true if there was an error
+   produced.  False otherwise.  This is done so that we don't output the error
+   or warning twice or three times.  */
+bool
+fold_builtin_next_arg (tree arglist)
+{
+  tree fntype = TREE_TYPE (current_function_decl);
+
+  if (TYPE_ARG_TYPES (fntype) == 0
+      || (TREE_VALUE (tree_last (TYPE_ARG_TYPES (fntype)))
+	  == void_type_node))
+    {
+      error ("%<va_start%> used in function with fixed args");
+      return true;
+    }
+  else if (!arglist)
+    {
+      /* Evidently an out of date version of <stdarg.h>; can't validate
+	 va_start's second argument, but can still work as intended.  */
+      warning (0, "%<__builtin_next_arg%> called without an argument");
+      return true;
+    }
+  /* We use __builtin_va_start (ap, 0, 0) or __builtin_next_arg (0, 0)
+     when we checked the arguments and if needed issued a warning.  */
+  else if (!TREE_CHAIN (arglist)
+           || !integer_zerop (TREE_VALUE (arglist))
+           || !integer_zerop (TREE_VALUE (TREE_CHAIN (arglist)))
+           || TREE_CHAIN (TREE_CHAIN (arglist)))
+    {
+      tree last_parm = tree_last (DECL_ARGUMENTS (current_function_decl));
+      tree arg = TREE_VALUE (arglist);
+
+      if (TREE_CHAIN (arglist))
+        {
+          error ("%<va_start%> used with too many arguments");
+          return true;
+        }
+
+      /* Strip off all nops for the sake of the comparison.  This
+	 is not quite the same as STRIP_NOPS.  It does more.
+	 We must also strip off INDIRECT_EXPR for C++ reference
+	 parameters.  */
+      while (TREE_CODE (arg) == NOP_EXPR
+	     || TREE_CODE (arg) == CONVERT_EXPR
+	     || TREE_CODE (arg) == NON_LVALUE_EXPR
+	     || TREE_CODE (arg) == INDIRECT_REF)
+	arg = TREE_OPERAND (arg, 0);
+      if (arg != last_parm)
+        {
+	  /* FIXME: Sometimes with the tree optimizers we can get the
+	     not the last argument even though the user used the last
+	     argument.  We just warn and set the arg to be the last
+	     argument so that we will get wrong-code because of
+	     it.  */
+	  warning (0, "second parameter of %<va_start%> not last named argument");
+	}
+      /* We want to verify the second parameter just once before the tree
+         optimizers are run and then avoid keeping it in the tree,
+         as otherwise we could warn even for correct code like:
+         void foo (int i, ...)
+         { va_list ap; i++; va_start (ap, i); va_end (ap); }  */
+      TREE_VALUE (arglist) = integer_zero_node;
+      TREE_CHAIN (arglist) = build_tree_list (NULL, integer_zero_node);
+    }
+  return false;
+}
+
+
+/* Simplify a call to the sprintf builtin.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.  If IGNORED is true, it means that
+   the caller does not use the returned value of the function.  */
+
+static tree
+fold_builtin_sprintf (tree arglist, int ignored)
+{
+  tree call, retval, dest, fmt;
+  const char *fmt_str = NULL;
+
+  /* Verify the required arguments in the original call.  We deal with two
+     types of sprintf() calls: 'sprintf (str, fmt)' and
+     'sprintf (dest, "%s", orig)'.  */
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, VOID_TYPE)
+      && !validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, POINTER_TYPE,
+			    VOID_TYPE))
+    return NULL_TREE;
+
+  /* Get the destination string and the format specifier.  */
+  dest = TREE_VALUE (arglist);
+  fmt = TREE_VALUE (TREE_CHAIN (arglist));
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return NULL_TREE;
+
+  call = NULL_TREE;
+  retval = NULL_TREE;
+
+  if (!init_target_chars())
+    return 0;
+
+  /* If the format doesn't contain % args or %%, use strcpy.  */
+  if (strchr (fmt_str, target_percent) == NULL)
+    {
+      tree fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+
+      if (!fn)
+	return NULL_TREE;
+
+      /* Convert sprintf (str, fmt) into strcpy (str, fmt) when
+	 'format' is known to contain no % formats.  */
+      arglist = build_tree_list (NULL_TREE, fmt);
+      arglist = tree_cons (NULL_TREE, dest, arglist);
+      call = build_function_call_expr (fn, arglist);
+      if (!ignored)
+	retval = build_int_cst (NULL_TREE, strlen (fmt_str));
+    }
+
+  /* If the format is "%s", use strcpy if the result isn't used.  */
+  else if (fmt_str && strcmp (fmt_str, target_percent_s) == 0)
+    {
+      tree fn, orig;
+      fn = implicit_built_in_decls[BUILT_IN_STRCPY];
+
+      if (!fn)
+	return NULL_TREE;
+
+      /* Convert sprintf (str1, "%s", str2) into strcpy (str1, str2).  */
+      orig = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+      arglist = build_tree_list (NULL_TREE, orig);
+      arglist = tree_cons (NULL_TREE, dest, arglist);
+      if (!ignored)
+	{
+	  retval = c_strlen (orig, 1);
+	  if (!retval || TREE_CODE (retval) != INTEGER_CST)
+	    return NULL_TREE;
+	}
+      call = build_function_call_expr (fn, arglist);
+    }
+
+  if (call && retval)
+    {
+      retval = convert
+	(TREE_TYPE (TREE_TYPE (implicit_built_in_decls[BUILT_IN_SPRINTF])),
+	 retval);
+      return build2 (COMPOUND_EXPR, TREE_TYPE (retval), call, retval);
+    }
+  else
+    return call;
+}
+
+/* Expand a call to __builtin_object_size.  */
+
+rtx
+expand_builtin_object_size (tree exp)
+{
+  tree ost;
+  int object_size_type;
+  tree fndecl = get_callee_fndecl (exp);
+  tree arglist = TREE_OPERAND (exp, 1);
+  location_t locus = EXPR_LOCATION (exp);
+
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    {
+      error ("%Hfirst argument of %D must be a pointer, second integer constant",
+	     &locus, fndecl);
+      expand_builtin_trap ();
+      return const0_rtx;
+    }
+
+  ost = TREE_VALUE (TREE_CHAIN (arglist));
+  STRIP_NOPS (ost);
+
+  if (TREE_CODE (ost) != INTEGER_CST
+      || tree_int_cst_sgn (ost) < 0
+      || compare_tree_int (ost, 3) > 0)
+    {
+      error ("%Hlast argument of %D is not integer constant between 0 and 3",
+	     &locus, fndecl);
+      expand_builtin_trap ();
+      return const0_rtx;
+    }
+
+  object_size_type = tree_low_cst (ost, 0);
+
+  return object_size_type < 2 ? constm1_rtx : const0_rtx;
+}
+
+/* Expand EXP, a call to the __mem{cpy,pcpy,move,set}_chk builtin.
+   FCODE is the BUILT_IN_* to use.
+   Return 0 if we failed; the caller should emit a normal call,
+   otherwise try to get the result in TARGET, if convenient (and in
+   mode MODE if that's convenient).  */
+
+static rtx
+expand_builtin_memory_chk (tree exp, rtx target, enum machine_mode mode,
+			   enum built_in_function fcode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree dest, src, len, size;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE,
+			 fcode == BUILT_IN_MEMSET_CHK
+			 ? INTEGER_TYPE : POINTER_TYPE,
+			 INTEGER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (host_integerp (len, 1) || integer_all_onesp (size))
+    {
+      tree fn;
+
+      if (! integer_all_onesp (size) && tree_int_cst_lt (size, len))
+	{
+	  location_t locus = EXPR_LOCATION (exp);
+	  warning (0, "%Hcall to %D will always overflow destination buffer",
+		   &locus, get_callee_fndecl (exp));
+	  return 0;
+	}
+
+      arglist = build_tree_list (NULL_TREE, len);
+      arglist = tree_cons (NULL_TREE, src, arglist);
+      arglist = tree_cons (NULL_TREE, dest, arglist);
+
+      fn = NULL_TREE;
+      /* If __builtin_mem{cpy,pcpy,move,set}_chk is used, assume
+	 mem{cpy,pcpy,move,set} is available.  */
+      switch (fcode)
+	{
+	case BUILT_IN_MEMCPY_CHK:
+	  fn = built_in_decls[BUILT_IN_MEMCPY];
+	  break;
+	case BUILT_IN_MEMPCPY_CHK:
+	  fn = built_in_decls[BUILT_IN_MEMPCPY];
+	  break;
+	case BUILT_IN_MEMMOVE_CHK:
+	  fn = built_in_decls[BUILT_IN_MEMMOVE];
+	  break;
+	case BUILT_IN_MEMSET_CHK:
+	  fn = built_in_decls[BUILT_IN_MEMSET];
+	  break;
+	default:
+	  break;
+	}
+
+      if (! fn)
+	return 0;
+
+      fn = build_function_call_expr (fn, arglist);
+      if (TREE_CODE (fn) == CALL_EXPR)
+	CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+      return expand_expr (fn, target, mode, EXPAND_NORMAL);
+    }
+  else if (fcode == BUILT_IN_MEMSET_CHK)
+    return 0;
+  else
+    {
+      unsigned int dest_align
+	= get_pointer_alignment (dest, BIGGEST_ALIGNMENT);
+
+      /* If DEST is not a pointer type, call the normal function.  */
+      if (dest_align == 0)
+	return 0;
+
+      /* If SRC and DEST are the same (and not volatile), do nothing.  */
+      if (operand_equal_p (src, dest, 0))
+	{
+	  tree expr;
+
+	  if (fcode != BUILT_IN_MEMPCPY_CHK)
+	    {
+	      /* Evaluate and ignore LEN in case it has side-effects.  */
+	      expand_expr (len, const0_rtx, VOIDmode, EXPAND_NORMAL);
+	      return expand_expr (dest, target, mode, EXPAND_NORMAL);
+	    }
+
+	  len = fold_convert (TREE_TYPE (dest), len);
+	  expr = fold_build2 (PLUS_EXPR, TREE_TYPE (dest), dest, len);
+	  return expand_expr (expr, target, mode, EXPAND_NORMAL);
+	}
+
+      /* __memmove_chk special case.  */
+      if (fcode == BUILT_IN_MEMMOVE_CHK)
+	{
+	  unsigned int src_align
+	    = get_pointer_alignment (src, BIGGEST_ALIGNMENT);
+
+	  if (src_align == 0)
+	    return 0;
+
+	  /* If src is categorized for a readonly section we can use
+	     normal __memcpy_chk.  */
+	  if (readonly_data_expr (src))
+	    {
+	      tree fn = built_in_decls[BUILT_IN_MEMCPY_CHK];
+	      if (!fn)
+		return 0;
+	      fn = build_function_call_expr (fn, arglist);
+	      if (TREE_CODE (fn) == CALL_EXPR)
+		CALL_EXPR_TAILCALL (fn) = CALL_EXPR_TAILCALL (exp);
+	      return expand_expr (fn, target, mode, EXPAND_NORMAL);
+	    }
+	}
+      return 0;
+    }
+}
+
+/* Emit warning if a buffer overflow is detected at compile time.  */
+
+static void
+maybe_emit_chk_warning (tree exp, enum built_in_function fcode)
+{
+  int arg_mask, is_strlen = 0;
+  tree arglist = TREE_OPERAND (exp, 1), a;
+  tree len, size;
+  location_t locus;
+
+  switch (fcode)
+    {
+    case BUILT_IN_STRCPY_CHK:
+    case BUILT_IN_STPCPY_CHK:
+    /* For __strcat_chk the warning will be emitted only if overflowing
+       by at least strlen (dest) + 1 bytes.  */
+    case BUILT_IN_STRCAT_CHK:
+      arg_mask = 6;
+      is_strlen = 1;
+      break;
+    case BUILT_IN_STRNCPY_CHK:
+      arg_mask = 12;
+      break;
+    case BUILT_IN_SNPRINTF_CHK:
+    case BUILT_IN_VSNPRINTF_CHK:
+      arg_mask = 10;
+      break;
+    default:
+      gcc_unreachable ();
+    }
+
+  len = NULL_TREE;
+  size = NULL_TREE;
+  for (a = arglist; a && arg_mask; a = TREE_CHAIN (a), arg_mask >>= 1)
+    if (arg_mask & 1)
+      {
+	if (len)
+	  size = a;
+	else
+	  len = a;
+      }
+
+  if (!len || !size)
+    return;
+
+  len = TREE_VALUE (len);
+  size = TREE_VALUE (size);
+
+  if (! host_integerp (size, 1) || integer_all_onesp (size))
+    return;
+
+  if (is_strlen)
+    {
+      len = c_strlen (len, 1);
+      if (! len || ! host_integerp (len, 1) || tree_int_cst_lt (len, size))
+	return;
+    }
+  else if (! host_integerp (len, 1) || ! tree_int_cst_lt (size, len))
+    return;
+
+  locus = EXPR_LOCATION (exp);
+  warning (0, "%Hcall to %D will always overflow destination buffer",
+	   &locus, get_callee_fndecl (exp));
+}
+
+/* Emit warning if a buffer overflow is detected at compile time
+   in __sprintf_chk/__vsprintf_chk calls.  */
+
+static void
+maybe_emit_sprintf_chk_warning (tree exp, enum built_in_function fcode)
+{
+  tree arglist = TREE_OPERAND (exp, 1);
+  tree dest, size, len, fmt, flag;
+  const char *fmt_str;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return;
+  dest = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return;
+  flag = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return;
+  size = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return;
+  fmt = TREE_VALUE (arglist);
+  arglist = TREE_CHAIN (arglist);
+
+  if (! host_integerp (size, 1) || integer_all_onesp (size))
+    return;
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return;
+
+  if (!init_target_chars())
+    return;
+
+  /* If the format doesn't contain % args or %%, we know its size.  */
+  if (strchr (fmt_str, target_percent) == 0)
+    len = build_int_cstu (size_type_node, strlen (fmt_str));
+  /* If the format is "%s" and first ... argument is a string literal,
+     we know it too.  */
+  else if (fcode == BUILT_IN_SPRINTF_CHK && strcmp (fmt_str, target_percent_s) == 0)
+    {
+      tree arg;
+
+      if (! arglist)
+	return;
+      arg = TREE_VALUE (arglist);
+      if (! POINTER_TYPE_P (TREE_TYPE (arg)))
+	return;
+
+      len = c_strlen (arg, 1);
+      if (!len || ! host_integerp (len, 1))
+	return;
+    }
+  else
+    return;
+
+  if (! tree_int_cst_lt (len, size))
+    {
+      location_t locus = EXPR_LOCATION (exp);
+      warning (0, "%Hcall to %D will always overflow destination buffer",
+	       &locus, get_callee_fndecl (exp));
+    }
+}
+
+/* Fold a call to __builtin_object_size, if possible.  */
+
+tree
+fold_builtin_object_size (tree arglist)
+{
+  tree ptr, ost, ret = 0;
+  int object_size_type;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  ptr = TREE_VALUE (arglist);
+  ost = TREE_VALUE (TREE_CHAIN (arglist));
+  STRIP_NOPS (ost);
+
+  if (TREE_CODE (ost) != INTEGER_CST
+      || tree_int_cst_sgn (ost) < 0
+      || compare_tree_int (ost, 3) > 0)
+    return 0;
+
+  object_size_type = tree_low_cst (ost, 0);
+
+  /* __builtin_object_size doesn't evaluate side-effects in its arguments;
+     if there are any side-effects, it returns (size_t) -1 for types 0 and 1
+     and (size_t) 0 for types 2 and 3.  */
+  if (TREE_SIDE_EFFECTS (ptr))
+    return fold_convert (size_type_node,
+			 object_size_type < 2
+			 ? integer_minus_one_node : integer_zero_node);
+
+  if (TREE_CODE (ptr) == ADDR_EXPR)
+    ret = build_int_cstu (size_type_node,
+			compute_builtin_object_size (ptr, object_size_type));
+
+  else if (TREE_CODE (ptr) == SSA_NAME)
+    {
+      unsigned HOST_WIDE_INT bytes;
+
+      /* If object size is not known yet, delay folding until
+       later.  Maybe subsequent passes will help determining
+       it.  */
+      bytes = compute_builtin_object_size (ptr, object_size_type);
+      if (bytes != (unsigned HOST_WIDE_INT) (object_size_type < 2
+					     ? -1 : 0))
+	ret = build_int_cstu (size_type_node, bytes);
+    }
+
+  if (ret)
+    {
+      ret = force_fit_type (ret, -1, false, false);
+      if (TREE_CONSTANT_OVERFLOW (ret))
+	ret = 0;
+    }
+
+  return ret;
+}
+
+/* Fold a call to the __mem{cpy,pcpy,move,set}_chk builtin.
+   IGNORE is true, if return value can be ignored.  FCODE is the BUILT_IN_*
+   code of the builtin.  If MAXLEN is not NULL, it is maximum length
+   passed as third argument.  */
+
+tree
+fold_builtin_memory_chk (tree fndecl, tree arglist, tree maxlen, bool ignore,
+			 enum built_in_function fcode)
+{
+  tree dest, src, len, size, fn;
+
+  if (!validate_arglist (arglist,
+			 POINTER_TYPE,
+			 fcode == BUILT_IN_MEMSET_CHK
+			 ? INTEGER_TYPE : POINTER_TYPE,
+			 INTEGER_TYPE, INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  /* Actually val for __memset_chk, but it doesn't matter.  */
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));
+
+  /* If SRC and DEST are the same (and not volatile), return DEST
+     (resp. DEST+LEN for __mempcpy_chk).  */
+  if (fcode != BUILT_IN_MEMSET_CHK && operand_equal_p (src, dest, 0))
+    {
+      if (fcode != BUILT_IN_MEMPCPY_CHK)
+	return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, len);
+      else
+	{
+	  tree temp = fold_convert (TREE_TYPE (dest), len);
+	  temp = fold_build2 (PLUS_EXPR, TREE_TYPE (dest), dest, temp);
+	  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), temp);
+	}
+    }
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      if (! host_integerp (len, 1))
+	{
+	  /* If LEN is not constant, try MAXLEN too.
+	     For MAXLEN only allow optimizing into non-_ocs function
+	     if SIZE is >= MAXLEN, never convert to __ocs_fail ().  */
+	  if (maxlen == NULL_TREE || ! host_integerp (maxlen, 1))
+	    {
+	      if (fcode == BUILT_IN_MEMPCPY_CHK && ignore)
+		{
+		  /* (void) __mempcpy_chk () can be optimized into
+		     (void) __memcpy_chk ().  */
+		  fn = built_in_decls[BUILT_IN_MEMCPY_CHK];
+		  if (!fn)
+		    return 0;
+
+		  return build_function_call_expr (fn, arglist);
+		}
+	      return 0;
+	    }
+	}
+      else
+	maxlen = len;
+
+      if (tree_int_cst_lt (size, maxlen))
+	return 0;
+    }
+
+  arglist = build_tree_list (NULL_TREE, len);
+  arglist = tree_cons (NULL_TREE, src, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  fn = NULL_TREE;
+  /* If __builtin_mem{cpy,pcpy,move,set}_chk is used, assume
+     mem{cpy,pcpy,move,set} is available.  */
+  switch (fcode)
+    {
+    case BUILT_IN_MEMCPY_CHK:
+      fn = built_in_decls[BUILT_IN_MEMCPY];
+      break;
+    case BUILT_IN_MEMPCPY_CHK:
+      fn = built_in_decls[BUILT_IN_MEMPCPY];
+      break;
+    case BUILT_IN_MEMMOVE_CHK:
+      fn = built_in_decls[BUILT_IN_MEMMOVE];
+      break;
+    case BUILT_IN_MEMSET_CHK:
+      fn = built_in_decls[BUILT_IN_MEMSET];
+      break;
+    default:
+      break;
+    }
+
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the __st[rp]cpy_chk builtin.
+   IGNORE is true, if return value can be ignored.  FCODE is the BUILT_IN_*
+   code of the builtin.  If MAXLEN is not NULL, it is maximum length of
+   strings passed as second argument.  */
+
+tree
+fold_builtin_stxcpy_chk (tree fndecl, tree arglist, tree maxlen, bool ignore,
+			 enum built_in_function fcode)
+{
+  tree dest, src, size, len, fn;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE,
+			 VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  /* If SRC and DEST are the same (and not volatile), return DEST.  */
+  if (fcode == BUILT_IN_STRCPY_CHK && operand_equal_p (src, dest, 0))
+    return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), dest);
+ 
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      len = c_strlen (src, 1);
+      if (! len || ! host_integerp (len, 1))
+	{
+	  /* If LEN is not constant, try MAXLEN too.
+	     For MAXLEN only allow optimizing into non-_ocs function
+	     if SIZE is >= MAXLEN, never convert to __ocs_fail ().  */
+	  if (maxlen == NULL_TREE || ! host_integerp (maxlen, 1))
+	    {
+	      if (fcode == BUILT_IN_STPCPY_CHK)
+		{
+		  if (! ignore)
+		    return 0;
+
+		  /* If return value of __stpcpy_chk is ignored,
+		     optimize into __strcpy_chk.  */
+		  fn = built_in_decls[BUILT_IN_STRCPY_CHK];
+		  if (!fn)
+		    return 0;
+
+		  return build_function_call_expr (fn, arglist);
+		}
+
+	      if (! len || TREE_SIDE_EFFECTS (len))
+		return 0;
+
+	      /* If c_strlen returned something, but not a constant,
+		 transform __strcpy_chk into __memcpy_chk.  */
+	      fn = built_in_decls[BUILT_IN_MEMCPY_CHK];
+	      if (!fn)
+		return 0;
+
+	      len = size_binop (PLUS_EXPR, len, ssize_int (1));
+	      arglist = build_tree_list (NULL_TREE, size);
+	      arglist = tree_cons (NULL_TREE, len, arglist);
+	      arglist = tree_cons (NULL_TREE, src, arglist);
+	      arglist = tree_cons (NULL_TREE, dest, arglist);
+	      return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)),
+				   build_function_call_expr (fn, arglist));
+	    }
+	}
+      else
+	maxlen = len;
+
+      if (! tree_int_cst_lt (maxlen, size))
+	return 0;
+    }
+
+  arglist = build_tree_list (NULL_TREE, src);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_st{r,p}cpy_chk is used, assume st{r,p}cpy is available.  */
+  fn = built_in_decls[fcode == BUILT_IN_STPCPY_CHK
+		      ? BUILT_IN_STPCPY : BUILT_IN_STRCPY];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the __strncpy_chk builtin.
+   If MAXLEN is not NULL, it is maximum length passed as third argument.  */
+
+tree
+fold_builtin_strncpy_chk (tree arglist, tree maxlen)
+{
+  tree dest, src, size, len, fn;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE,
+			 INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      if (! host_integerp (len, 1))
+	{
+	  /* If LEN is not constant, try MAXLEN too.
+	     For MAXLEN only allow optimizing into non-_ocs function
+	     if SIZE is >= MAXLEN, never convert to __ocs_fail ().  */
+	  if (maxlen == NULL_TREE || ! host_integerp (maxlen, 1))
+	    return 0;
+	}
+      else
+	maxlen = len;
+
+      if (tree_int_cst_lt (size, maxlen))
+	return 0;
+    }
+
+  arglist = build_tree_list (NULL_TREE, len);
+  arglist = tree_cons (NULL_TREE, src, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_strncpy_chk is used, assume strncpy is available.  */
+  fn = built_in_decls[BUILT_IN_STRNCPY];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the __strcat_chk builtin FNDECL with ARGLIST.  */
+
+static tree
+fold_builtin_strcat_chk (tree fndecl, tree arglist)
+{
+  tree dest, src, size, fn;
+  const char *p;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE,
+			 VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+
+  p = c_getstr (src);
+  /* If the SRC parameter is "", return DEST.  */
+  if (p && *p == '\0')
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, src);
+
+  if (! host_integerp (size, 1) || ! integer_all_onesp (size))
+    return 0;
+
+  arglist = build_tree_list (NULL_TREE, src);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_strcat_chk is used, assume strcat is available.  */
+  fn = built_in_decls[BUILT_IN_STRCAT];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the __strncat_chk builtin EXP.  */
+
+static tree
+fold_builtin_strncat_chk (tree fndecl, tree arglist)
+{
+  tree dest, src, size, len, fn;
+  const char *p;
+
+  if (!validate_arglist (arglist, POINTER_TYPE, POINTER_TYPE, INTEGER_TYPE,
+			 INTEGER_TYPE, VOID_TYPE))
+    return 0;
+
+  dest = TREE_VALUE (arglist);
+  src = TREE_VALUE (TREE_CHAIN (arglist));
+  len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));
+  size = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));
+
+  p = c_getstr (src);
+  /* If the SRC parameter is "" or if LEN is 0, return DEST.  */
+  if (p && *p == '\0')
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, len);
+  else if (integer_zerop (len))
+    return omit_one_operand (TREE_TYPE (TREE_TYPE (fndecl)), dest, src);
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      tree src_len = c_strlen (src, 1);
+      if (src_len
+	  && host_integerp (src_len, 1)
+	  && host_integerp (len, 1)
+	  && ! tree_int_cst_lt (len, src_len))
+	{
+	  /* If LEN >= strlen (SRC), optimize into __strcat_chk.  */
+	  fn = built_in_decls[BUILT_IN_STRCAT_CHK];
+	  if (!fn)
+	    return 0;
+
+	  arglist = build_tree_list (NULL_TREE, size);
+	  arglist = tree_cons (NULL_TREE, src, arglist);
+	  arglist = tree_cons (NULL_TREE, dest, arglist);
+	  return build_function_call_expr (fn, arglist);
+	}
+      return 0;
+    }
+
+  arglist = build_tree_list (NULL_TREE, len);
+  arglist = tree_cons (NULL_TREE, src, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_strncat_chk is used, assume strncat is available.  */
+  fn = built_in_decls[BUILT_IN_STRNCAT];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to __{,v}sprintf_chk with argument list ARGLIST.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   inline.  FCODE is either BUILT_IN_SPRINTF_CHK or BUILT_IN_VSPRINTF_CHK.  */
+
+static tree
+fold_builtin_sprintf_chk (tree arglist, enum built_in_function fcode)
+{
+  tree dest, size, len, fn, fmt, flag;
+  const char *fmt_str;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  dest = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (dest)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  flag = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (flag)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  size = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (size)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  len = NULL_TREE;
+
+  if (!init_target_chars())
+    return 0;
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str != NULL)
+    {
+      /* If the format doesn't contain % args or %%, we know the size.  */
+      if (strchr (fmt_str, target_percent) == 0)
+	{
+	  if (fcode != BUILT_IN_SPRINTF_CHK || arglist == NULL_TREE)
+	    len = build_int_cstu (size_type_node, strlen (fmt_str));
+	}
+      /* If the format is "%s" and first ... argument is a string literal,
+	 we know the size too.  */
+      else if (fcode == BUILT_IN_SPRINTF_CHK && strcmp (fmt_str, target_percent_s) == 0)
+	{
+	  tree arg;
+
+	  if (arglist && !TREE_CHAIN (arglist))
+	    {
+	      arg = TREE_VALUE (arglist);
+	      if (POINTER_TYPE_P (TREE_TYPE (arg)))
+		{
+		  len = c_strlen (arg, 1);
+		  if (! len || ! host_integerp (len, 1))
+		    len = NULL_TREE;
+		}
+	    }
+	}
+    }
+
+  if (! integer_all_onesp (size))
+    {
+      if (! len || ! tree_int_cst_lt (len, size))
+	return 0;
+    }
+
+  /* Only convert __{,v}sprintf_chk to {,v}sprintf if flag is 0
+     or if format doesn't contain % chars or is "%s".  */
+  if (! integer_zerop (flag))
+    {
+      if (fmt_str == NULL)
+	return 0;
+      if (strchr (fmt_str, target_percent) != NULL && strcmp (fmt_str, target_percent_s))
+	return 0;
+    }
+
+  arglist = tree_cons (NULL_TREE, fmt, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_{,v}sprintf_chk is used, assume {,v}sprintf is available.  */
+  fn = built_in_decls[fcode == BUILT_IN_VSPRINTF_CHK
+		      ? BUILT_IN_VSPRINTF : BUILT_IN_SPRINTF];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to {,v}snprintf with argument list ARGLIST.  Return 0 if
+   a normal call should be emitted rather than expanding the function
+   inline.  FCODE is either BUILT_IN_SNPRINTF_CHK or
+   BUILT_IN_VSNPRINTF_CHK.  If MAXLEN is not NULL, it is maximum length
+   passed as second argument.  */
+
+tree
+fold_builtin_snprintf_chk (tree arglist, tree maxlen,
+			   enum built_in_function fcode)
+{
+  tree dest, size, len, fn, fmt, flag;
+  const char *fmt_str;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  dest = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (dest)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  len = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (len)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  flag = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (len)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  size = TREE_VALUE (arglist);
+  if (TREE_CODE (TREE_TYPE (size)) != INTEGER_TYPE)
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  if (! host_integerp (size, 1))
+    return 0;
+
+  if (! integer_all_onesp (size))
+    {
+      if (! host_integerp (len, 1))
+	{
+	  /* If LEN is not constant, try MAXLEN too.
+	     For MAXLEN only allow optimizing into non-_ocs function
+	     if SIZE is >= MAXLEN, never convert to __ocs_fail ().  */
+	  if (maxlen == NULL_TREE || ! host_integerp (maxlen, 1))
+	    return 0;
+	}
+      else
+	maxlen = len;
+
+      if (tree_int_cst_lt (size, maxlen))
+	return 0;
+    }
+
+  if (!init_target_chars())
+    return 0;
+
+  /* Only convert __{,v}snprintf_chk to {,v}snprintf if flag is 0
+     or if format doesn't contain % chars or is "%s".  */
+  if (! integer_zerop (flag))
+    {
+      fmt_str = c_getstr (fmt);
+      if (fmt_str == NULL)
+	return 0;
+      if (strchr (fmt_str, target_percent) != NULL && strcmp (fmt_str, target_percent_s))
+	return 0;
+    }
+
+  arglist = tree_cons (NULL_TREE, fmt, arglist);
+  arglist = tree_cons (NULL_TREE, len, arglist);
+  arglist = tree_cons (NULL_TREE, dest, arglist);
+
+  /* If __builtin_{,v}snprintf_chk is used, assume {,v}snprintf is
+     available.  */
+  fn = built_in_decls[fcode == BUILT_IN_VSNPRINTF_CHK
+		      ? BUILT_IN_VSNPRINTF : BUILT_IN_SNPRINTF];
+  if (!fn)
+    return 0;
+
+  return build_function_call_expr (fn, arglist);
+}
+
+/* Fold a call to the {,v}printf{,_unlocked} and __{,v}printf_chk builtins.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.  FCODE is the BUILT_IN_*
+   code of the function to be simplified.  */
+
+static tree
+fold_builtin_printf (tree fndecl, tree arglist, bool ignore,
+		     enum built_in_function fcode)
+{
+  tree fmt, fn = NULL_TREE, fn_putchar, fn_puts, arg, call;
+  const char *fmt_str = NULL;
+
+  /* If the return value is used, don't do the transformation.  */
+  if (! ignore)
+    return 0;
+
+  /* Verify the required arguments in the original call.  */
+  if (fcode == BUILT_IN_PRINTF_CHK || fcode == BUILT_IN_VPRINTF_CHK)
+    {
+      tree flag;
+
+      if (! arglist)
+	return 0;
+      flag = TREE_VALUE (arglist);
+      if (TREE_CODE (TREE_TYPE (flag)) != INTEGER_TYPE
+	  || TREE_SIDE_EFFECTS (flag))
+	return 0;
+      arglist = TREE_CHAIN (arglist);
+    }
+
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return NULL_TREE;
+
+  if (fcode == BUILT_IN_PRINTF_UNLOCKED)
+    {
+      /* If we're using an unlocked function, assume the other
+	 unlocked functions exist explicitly.  */
+      fn_putchar = built_in_decls[BUILT_IN_PUTCHAR_UNLOCKED];
+      fn_puts = built_in_decls[BUILT_IN_PUTS_UNLOCKED];
+    }
+  else
+    {
+      fn_putchar = implicit_built_in_decls[BUILT_IN_PUTCHAR];
+      fn_puts = implicit_built_in_decls[BUILT_IN_PUTS];
+    }
+
+  if (!init_target_chars())
+    return 0;
+  
+  if (strcmp (fmt_str, target_percent_s) == 0 || strchr (fmt_str, target_percent) == NULL)
+    {
+      const char *str;
+
+      if (strcmp (fmt_str, target_percent_s) == 0)
+	{
+	  if (fcode == BUILT_IN_VPRINTF || fcode == BUILT_IN_VPRINTF_CHK)
+	    return 0;
+
+	  if (! arglist
+	      || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	      || TREE_CHAIN (arglist))
+	    return 0;
+
+	  str = c_getstr (TREE_VALUE (arglist));
+	  if (str == NULL)
+	    return 0;
+	}
+      else
+	{
+	  /* The format specifier doesn't contain any '%' characters.  */
+	  if (fcode != BUILT_IN_VPRINTF && fcode != BUILT_IN_VPRINTF_CHK
+	      && arglist)
+	    return 0;
+	  str = fmt_str;
+	}
+
+      /* If the string was "", printf does nothing.  */
+      if (str[0] == '\0')
+	return build_int_cst (TREE_TYPE (TREE_TYPE (fndecl)), 0);
+
+      /* If the string has length of 1, call putchar.  */
+      if (str[1] == '\0')
+	{
+	  /* Given printf("c"), (where c is any one character,)
+	     convert "c"[0] to an int and pass that to the replacement
+	     function.  */
+	  arg = build_int_cst (NULL_TREE, str[0]);
+	  arglist = build_tree_list (NULL_TREE, arg);
+	  fn = fn_putchar;
+	}
+      else
+	{
+	  /* If the string was "string\n", call puts("string").  */
+	  size_t len = strlen (str);
+	  if ((unsigned char)str[len - 1] == target_newline)
+	    {
+	      /* Create a NUL-terminated string that's one char shorter
+		 than the original, stripping off the trailing '\n'.  */
+	      char *newstr = alloca (len);
+	      memcpy (newstr, str, len - 1);
+	      newstr[len - 1] = 0;
+
+	      arg = build_string_literal (len, newstr);
+	      arglist = build_tree_list (NULL_TREE, arg);
+	      fn = fn_puts;
+	    }
+	  else
+	    /* We'd like to arrange to call fputs(string,stdout) here,
+	       but we need stdout and don't have a way to get it yet.  */
+	    return 0;
+	}
+    }
+
+  /* The other optimizations can be done only on the non-va_list variants.  */
+  else if (fcode == BUILT_IN_VPRINTF || fcode == BUILT_IN_VPRINTF_CHK)
+    return 0;
+
+  /* If the format specifier was "%s\n", call __builtin_puts(arg).  */
+  else if (strcmp (fmt_str, target_percent_s_newline) == 0)
+    {
+      if (! arglist
+	  || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	  || TREE_CHAIN (arglist))
+	return 0;
+      fn = fn_puts;
+    }
+
+  /* If the format specifier was "%c", call __builtin_putchar(arg).  */
+  else if (strcmp (fmt_str, target_percent_c) == 0)
+    {
+      if (! arglist
+	  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != INTEGER_TYPE
+	  || TREE_CHAIN (arglist))
+	return 0;
+      fn = fn_putchar;
+    }
+
+  if (!fn)
+    return 0;
+
+  call = build_function_call_expr (fn, arglist);
+  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), call);
+}
+
+/* Fold a call to the {,v}fprintf{,_unlocked} and __{,v}printf_chk builtins.
+
+   Return 0 if no simplification was possible, otherwise return the
+   simplified form of the call as a tree.  FCODE is the BUILT_IN_*
+   code of the function to be simplified.  */
+
+static tree
+fold_builtin_fprintf (tree fndecl, tree arglist, bool ignore,
+		      enum built_in_function fcode)
+{
+  tree fp, fmt, fn = NULL_TREE, fn_fputc, fn_fputs, arg, call;
+  const char *fmt_str = NULL;
+
+  /* If the return value is used, don't do the transformation.  */
+  if (! ignore)
+    return 0;
+
+  /* Verify the required arguments in the original call.  */
+  if (! arglist)
+    return 0;
+  fp = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fp)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  if (fcode == BUILT_IN_FPRINTF_CHK || fcode == BUILT_IN_VFPRINTF_CHK)
+    {
+      tree flag;
+
+      if (! arglist)
+	return 0;
+      flag = TREE_VALUE (arglist);
+      if (TREE_CODE (TREE_TYPE (flag)) != INTEGER_TYPE
+	  || TREE_SIDE_EFFECTS (flag))
+	return 0;
+      arglist = TREE_CHAIN (arglist);
+    }
+
+  if (! arglist)
+    return 0;
+  fmt = TREE_VALUE (arglist);
+  if (! POINTER_TYPE_P (TREE_TYPE (fmt)))
+    return 0;
+  arglist = TREE_CHAIN (arglist);
+
+  /* Check whether the format is a literal string constant.  */
+  fmt_str = c_getstr (fmt);
+  if (fmt_str == NULL)
+    return NULL_TREE;
+
+  if (fcode == BUILT_IN_FPRINTF_UNLOCKED)
+    {
+      /* If we're using an unlocked function, assume the other
+	 unlocked functions exist explicitly.  */
+      fn_fputc = built_in_decls[BUILT_IN_FPUTC_UNLOCKED];
+      fn_fputs = built_in_decls[BUILT_IN_FPUTS_UNLOCKED];
+    }
+  else
+    {
+      fn_fputc = implicit_built_in_decls[BUILT_IN_FPUTC];
+      fn_fputs = implicit_built_in_decls[BUILT_IN_FPUTS];
+    }
+
+  if (!init_target_chars())
+    return 0;
+  
+  /* If the format doesn't contain % args or %%, use strcpy.  */
+  if (strchr (fmt_str, target_percent) == NULL)
+    {
+      if (fcode != BUILT_IN_VFPRINTF && fcode != BUILT_IN_VFPRINTF_CHK
+	  && arglist)
+	return 0;
+
+      /* If the format specifier was "", fprintf does nothing.  */
+      if (fmt_str[0] == '\0')
+	{
+	  /* If FP has side-effects, just wait until gimplification is
+	     done.  */
+	  if (TREE_SIDE_EFFECTS (fp))
+	    return 0;
+
+	  return build_int_cst (TREE_TYPE (TREE_TYPE (fndecl)), 0);
+	}
+
+      /* When "string" doesn't contain %, replace all cases of
+	 fprintf (fp, string) with fputs (string, fp).  The fputs
+	 builtin will take care of special cases like length == 1.  */
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, fmt, arglist);
+      fn = fn_fputs;
+    }
+
+  /* The other optimizations can be done only on the non-va_list variants.  */
+  else if (fcode == BUILT_IN_VFPRINTF || fcode == BUILT_IN_VFPRINTF_CHK)
+    return 0;
+
+  /* If the format specifier was "%s", call __builtin_fputs (arg, fp).  */
+  else if (strcmp (fmt_str, target_percent_s) == 0)
+    {
+      if (! arglist
+	  || ! POINTER_TYPE_P (TREE_TYPE (TREE_VALUE (arglist)))
+	  || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, arg, arglist);
+      fn = fn_fputs;
+    }
+
+  /* If the format specifier was "%c", call __builtin_fputc (arg, fp).  */
+  else if (strcmp (fmt_str, target_percent_c) == 0)
+    {
+      if (! arglist
+	  || TREE_CODE (TREE_TYPE (TREE_VALUE (arglist))) != INTEGER_TYPE
+	  || TREE_CHAIN (arglist))
+	return 0;
+      arg = TREE_VALUE (arglist);
+      arglist = build_tree_list (NULL_TREE, fp);
+      arglist = tree_cons (NULL_TREE, arg, arglist);
+      fn = fn_fputc;
+    }
+
+  if (!fn)
+    return 0;
+
+  call = build_function_call_expr (fn, arglist);
+  return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), call);
+}
+
+/* Initialize format string characters in the target charset.  */
+
+static bool
+init_target_chars (void)
+{
+  static bool init;
+  if (!init)
+    {
+      target_newline = lang_hooks.to_target_charset ('\n');
+      target_percent = lang_hooks.to_target_charset ('%');
+      target_c = lang_hooks.to_target_charset ('c');
+      target_s = lang_hooks.to_target_charset ('s');
+      if (target_newline == 0 || target_percent == 0 || target_c == 0
+	  || target_s == 0)
+	return false;
+
+      target_percent_c[0] = target_percent;
+      target_percent_c[1] = target_c;
+      target_percent_c[2] = '\0';
+
+      target_percent_s[0] = target_percent;
+      target_percent_s[1] = target_s;
+      target_percent_s[2] = '\0';
+
+      target_percent_s_newline[0] = target_percent;
+      target_percent_s_newline[1] = target_s;
+      target_percent_s_newline[2] = target_newline;
+      target_percent_s_newline[3] = '\0';
+      
+      init = true;
+    }
+  return true;
+}
diff -Naur gcc-4.1-20051216.orig/gcc/builtins.c.rej gcc-4.1-20051216-src/gcc/builtins.c.rej
--- gcc-4.1-20051216.orig/gcc/builtins.c.rej	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/builtins.c.rej	2005-12-18 22:24:28.000000000 +0100
@@ -0,0 +1,249 @@
+***************
+*** 91,114 ****
+  static void expand_builtin_return (rtx);
+  static enum type_class type_to_class (tree);
+  static rtx expand_builtin_classify_type (tree);
+  static void expand_errno_check (tree, rtx);
+  static rtx expand_builtin_mathfn (tree, rtx, rtx);
+  static rtx expand_builtin_mathfn_2 (tree, rtx, rtx);
+  static rtx expand_builtin_mathfn_3 (tree, rtx, rtx);
+  static rtx expand_builtin_args_info (tree);
+  static rtx expand_builtin_next_arg (void);
+  static rtx expand_builtin_va_start (tree);
+  static rtx expand_builtin_va_end (tree);
+  static rtx expand_builtin_va_copy (tree);
+  static rtx expand_builtin_memcmp (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strcmp (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strncmp (tree, rtx, enum machine_mode);
+  static rtx builtin_memcpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_strcat (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strncat (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strspn (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strcspn (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_memcpy (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_mempcpy (tree, tree, rtx, enum machine_mode, int);
+  static rtx expand_builtin_memmove (tree, tree, rtx, enum machine_mode, tree);
+  static rtx expand_builtin_bcopy (tree);
+--- 94,124 ----
+  static void expand_builtin_return (rtx);
+  static enum type_class type_to_class (tree);
+  static rtx expand_builtin_classify_type (tree);
++ #if 0
+  static void expand_errno_check (tree, rtx);
+  static rtx expand_builtin_mathfn (tree, rtx, rtx);
+  static rtx expand_builtin_mathfn_2 (tree, rtx, rtx);
+  static rtx expand_builtin_mathfn_3 (tree, rtx, rtx);
++ #endif /* 0 */
+  static rtx expand_builtin_args_info (tree);
+  static rtx expand_builtin_next_arg (void);
+  static rtx expand_builtin_va_start (tree);
+  static rtx expand_builtin_va_end (tree);
+  static rtx expand_builtin_va_copy (tree);
++ #if 0
+  static rtx expand_builtin_memcmp (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strcmp (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strncmp (tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static rtx builtin_memcpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
++ #if 0
+  static rtx expand_builtin_strcat (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strncat (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strspn (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strcspn (tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static rtx expand_builtin_memcpy (tree, rtx, enum machine_mode);
++ #if 0
+  static rtx expand_builtin_mempcpy (tree, tree, rtx, enum machine_mode, int);
+  static rtx expand_builtin_memmove (tree, tree, rtx, enum machine_mode, tree);
+  static rtx expand_builtin_bcopy (tree);
+***************
+*** 116,148 ****
+  static rtx expand_builtin_stpcpy (tree, rtx, enum machine_mode);
+  static rtx builtin_strncpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_strncpy (tree, rtx, enum machine_mode);
+  static rtx builtin_memset_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx builtin_memset_gen_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_memset (tree, rtx, enum machine_mode, tree);
+  static rtx expand_builtin_bzero (tree);
+  static rtx expand_builtin_strlen (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strstr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strpbrk (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strchr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strrchr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_alloca (tree, rtx);
+  static rtx expand_builtin_unop (enum machine_mode, tree, rtx, rtx, optab);
+  static rtx expand_builtin_frame_address (tree, tree);
+  static rtx expand_builtin_fputs (tree, rtx, bool);
+  static rtx expand_builtin_printf (tree, rtx, enum machine_mode, bool);
+  static rtx expand_builtin_fprintf (tree, rtx, enum machine_mode, bool);
+  static rtx expand_builtin_sprintf (tree, rtx, enum machine_mode);
+  static tree stabilize_va_list (tree, int);
+  static rtx expand_builtin_expect (tree, rtx);
+  static tree fold_builtin_constant_p (tree);
+  static tree fold_builtin_classify_type (tree);
+  static tree fold_builtin_strlen (tree);
+  static tree fold_builtin_inf (tree, int);
+  static tree fold_builtin_nan (tree, tree, int);
+  static int validate_arglist (tree, ...);
+  static bool integer_valued_real_p (tree);
+  static tree fold_trunc_transparent_mathfn (tree);
+  static bool readonly_data_expr (tree);
+  static rtx expand_builtin_fabs (tree, rtx, rtx);
+  static rtx expand_builtin_signbit (tree, rtx);
+  static tree fold_builtin_cabs (tree, tree);
+--- 126,168 ----
+  static rtx expand_builtin_stpcpy (tree, rtx, enum machine_mode);
+  static rtx builtin_strncpy_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_strncpy (tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static rtx builtin_memset_read_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx builtin_memset_gen_str (void *, HOST_WIDE_INT, enum machine_mode);
+  static rtx expand_builtin_memset (tree, rtx, enum machine_mode, tree);
++ #if 0
+  static rtx expand_builtin_bzero (tree);
+  static rtx expand_builtin_strlen (tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strstr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strpbrk (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strchr (tree, tree, rtx, enum machine_mode);
+  static rtx expand_builtin_strrchr (tree, tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static rtx expand_builtin_alloca (tree, rtx);
+  static rtx expand_builtin_unop (enum machine_mode, tree, rtx, rtx, optab);
+  static rtx expand_builtin_frame_address (tree, tree);
++ #if 0
+  static rtx expand_builtin_fputs (tree, rtx, bool);
+  static rtx expand_builtin_printf (tree, rtx, enum machine_mode, bool);
+  static rtx expand_builtin_fprintf (tree, rtx, enum machine_mode, bool);
+  static rtx expand_builtin_sprintf (tree, rtx, enum machine_mode);
++ #endif /* 0 */
+  static tree stabilize_va_list (tree, int);
+  static rtx expand_builtin_expect (tree, rtx);
+  static tree fold_builtin_constant_p (tree);
+  static tree fold_builtin_classify_type (tree);
++ #if 0
+  static tree fold_builtin_strlen (tree);
+  static tree fold_builtin_inf (tree, int);
+  static tree fold_builtin_nan (tree, tree, int);
++ #endif /* 0 */
+  static int validate_arglist (tree, ...);
++ #if 0
+  static bool integer_valued_real_p (tree);
+  static tree fold_trunc_transparent_mathfn (tree);
++ #endif /* 0 */
+  static bool readonly_data_expr (tree);
++ #if 0
+  static rtx expand_builtin_fabs (tree, rtx, rtx);
+  static rtx expand_builtin_signbit (tree, rtx);
+  static tree fold_builtin_cabs (tree, tree);
+***************
+*** 159,165 ****
+  static tree fold_builtin_ceil (tree);
+  static tree fold_builtin_round (tree);
+  static tree fold_builtin_bitop (tree);
+  static tree fold_builtin_memcpy (tree);
+  static tree fold_builtin_mempcpy (tree, tree, int);
+  static tree fold_builtin_memmove (tree, tree);
+  static tree fold_builtin_strchr (tree, tree);
+--- 179,187 ----
+  static tree fold_builtin_ceil (tree);
+  static tree fold_builtin_round (tree);
+  static tree fold_builtin_bitop (tree);
++ #endif /* 0 */
+  static tree fold_builtin_memcpy (tree);
++ #if 0
+  static tree fold_builtin_mempcpy (tree, tree, int);
+  static tree fold_builtin_memmove (tree, tree);
+  static tree fold_builtin_strchr (tree, tree);
+***************
+*** 174,181 ****
+  static tree fold_builtin_fabs (tree, tree);
+  static tree fold_builtin_abs (tree, tree);
+  static tree fold_builtin_unordered_cmp (tree, enum tree_code, enum tree_code);
+  static tree fold_builtin_1 (tree, bool);
+  
+  static tree fold_builtin_strpbrk (tree, tree);
+  static tree fold_builtin_strstr (tree, tree);
+  static tree fold_builtin_strrchr (tree, tree);
+--- 196,205 ----
+  static tree fold_builtin_fabs (tree, tree);
+  static tree fold_builtin_abs (tree, tree);
+  static tree fold_builtin_unordered_cmp (tree, enum tree_code, enum tree_code);
++ #endif /* 0 */
+  static tree fold_builtin_1 (tree, bool);
+  
++ #if 0
+  static tree fold_builtin_strpbrk (tree, tree);
+  static tree fold_builtin_strstr (tree, tree);
+  static tree fold_builtin_strrchr (tree, tree);
+***************
+*** 184,190 ****
+  static tree fold_builtin_strspn (tree);
+  static tree fold_builtin_strcspn (tree);
+  static tree fold_builtin_sprintf (tree, int);
+  
+  
+  /* Return the alignment in bits of EXP, a pointer valued expression.
+     But don't return more than MAX_ALIGN no matter what.
+--- 208,217 ----
+  static tree fold_builtin_strspn (tree);
+  static tree fold_builtin_strcspn (tree);
+  static tree fold_builtin_sprintf (tree, int);
++ #endif /* 0 */
+  
++ /* (TIGCC 20050206) Implement ER_throw. */
++ static void expand_builtin_ER_throw (tree);
+  
+  /* Return the alignment in bits of EXP, a pointer valued expression.
+     But don't return more than MAX_ALIGN no matter what.
+***************
+*** 5831,5836 ****
+        if (target)
+  	return target;
+        break;
+  
+      default:	/* just do library call, if unknown builtin */
+        break;
+--- 5917,5927 ----
+        if (target)
+  	return target;
+        break;
++ #endif /* 0 */
++ 
++     case BUILT_IN_ER_THROW:
++       expand_builtin_ER_throw (arglist);
++       return const0_rtx;
+  
+      default:	/* just do library call, if unknown builtin */
+        break;
+***************
+*** 8882,8887 ****
+      case BUILT_IN_LLRINTF:
+      case BUILT_IN_LLRINTL:
+        return fold_fixed_mathfn (exp);
+  
+      case BUILT_IN_FFS:
+      case BUILT_IN_FFSL:
+--- 8986,8992 ----
+      case BUILT_IN_LLRINTF:
+      case BUILT_IN_LLRINTL:
+        return fold_fixed_mathfn (exp);
++ #endif /* 0 */
+  
+      case BUILT_IN_FFS:
+      case BUILT_IN_FFSL:
+***************
+*** 8362,8367 ****
+        return fold_builtin_unordered_cmp (exp, UNEQ_EXPR, EQ_EXPR);
+      case BUILT_IN_ISUNORDERED:
+        return fold_builtin_unordered_cmp (exp, UNORDERED_EXPR, NOP_EXPR);
+  
+        /* We do the folding for va_start in the expander.  */
+      case BUILT_IN_VA_START:
+--- 8468,8474 ----
+        return fold_builtin_unordered_cmp (exp, UNEQ_EXPR, EQ_EXPR);
+      case BUILT_IN_ISUNORDERED:
+        return fold_builtin_unordered_cmp (exp, UNORDERED_EXPR, NOP_EXPR);
++ #endif /* 0 */
+  
+        /* We do the folding for va_start in the expander.  */
+      case BUILT_IN_VA_START:
diff -Naur gcc-4.1-20051216.orig/gcc/builtins.def gcc-4.1-20051216-src/gcc/builtins.def
--- gcc-4.1-20051216.orig/gcc/builtins.def	2005-07-24 10:36:33.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/builtins.def	2005-12-18 22:24:28.000000000 +0100
@@ -507,6 +507,7 @@
 DEF_LIB_BUILTIN        (BUILT_IN_STRSPN, "strspn", BT_FN_SIZE_CONST_STRING_CONST_STRING, ATTR_PURE_NOTHROW_NONNULL)
 DEF_LIB_BUILTIN        (BUILT_IN_STRSTR, "strstr", BT_FN_STRING_CONST_STRING_CONST_STRING, ATTR_PURE_NOTHROW_NONNULL)
 
+#if 0
 /* Category: stdio builtins.  */
 DEF_LIB_BUILTIN        (BUILT_IN_FPRINTF, "fprintf", BT_FN_INT_FILEPTR_CONST_STRING_VAR, ATTR_FORMAT_PRINTF_2_3)
 DEF_EXT_LIB_BUILTIN    (BUILT_IN_FPRINTF_UNLOCKED, "fprintf_unlocked", BT_FN_INT_FILEPTR_CONST_STRING_VAR, ATTR_FORMAT_PRINTF_2_3)
@@ -568,6 +569,7 @@
 DEF_C94_BUILTIN        (BUILT_IN_ISWXDIGIT, "iswxdigit", BT_FN_INT_WINT, ATTR_PURE_NOTHROW_LIST)
 DEF_C94_BUILTIN        (BUILT_IN_TOWLOWER, "towlower", BT_FN_WINT_WINT, ATTR_PURE_NOTHROW_LIST)
 DEF_C94_BUILTIN        (BUILT_IN_TOWUPPER, "towupper", BT_FN_WINT_WINT, ATTR_PURE_NOTHROW_LIST)
+#endif /* 0 */
 
 /* Category: miscellaneous builtins.  */
 DEF_LIB_BUILTIN        (BUILT_IN_ABORT, "abort", BT_FN_VOID, ATTR_NORETURN_NOTHROW_LIST)
@@ -577,7 +579,9 @@
 DEF_GCC_BUILTIN        (BUILT_IN_APPLY, "apply", BT_FN_PTR_PTR_FN_VOID_VAR_PTR_SIZE, ATTR_NULL)
 DEF_GCC_BUILTIN        (BUILT_IN_APPLY_ARGS, "apply_args", BT_FN_PTR_VAR, ATTR_NULL)
 DEF_GCC_BUILTIN        (BUILT_IN_ARGS_INFO, "args_info", BT_FN_INT_INT, ATTR_NULL)
+#if 0
 DEF_LIB_BUILTIN        (BUILT_IN_CALLOC, "calloc", BT_FN_PTR_SIZE_SIZE, ATTR_MALLOC_NOTHROW_LIST)
+#endif /* 0 */
 DEF_GCC_BUILTIN        (BUILT_IN_CLASSIFY_TYPE, "classify_type", BT_FN_INT_VAR, ATTR_NULL)
 DEF_GCC_BUILTIN        (BUILT_IN_CLZ, "clz", BT_FN_INT_UINT, ATTR_CONST_NOTHROW_LIST)
 DEF_GCC_BUILTIN        (BUILT_IN_CLZIMAX, "clzimax", BT_FN_INT_UINTMAX, ATTR_CONST_NOTHROW_LIST)
@@ -659,6 +663,9 @@
 DEF_EXT_LIB_BUILTIN    (BUILT_IN__EXIT, "_exit", BT_FN_VOID_INT, ATTR_NORETURN_NOTHROW_LIST)
 DEF_C99_BUILTIN        (BUILT_IN__EXIT2, "_Exit", BT_FN_VOID_INT, ATTR_NORETURN_NOTHROW_LIST)
 
+/* (TIGCC 20050206) Implement ER_throw. */
+DEF_GCC_BUILTIN        (BUILT_IN_ER_THROW, "ER_throw", BT_FN_VOID_INT, ATTR_NORETURN_NOTHROW_LIST)
+
 /* Implementing nested functions.  */
 DEF_BUILTIN_STUB (BUILT_IN_INIT_TRAMPOLINE, "__builtin_init_trampoline")
 DEF_BUILTIN_STUB (BUILT_IN_ADJUST_TRAMPOLINE, "__builtin_adjust_trampoline")
diff -Naur gcc-4.1-20051216.orig/gcc/c-common.c gcc-4.1-20051216-src/gcc/c-common.c
--- gcc-4.1-20051216.orig/gcc/c-common.c	2005-12-08 12:24:07.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-common.c	2005-12-18 22:24:28.000000000 +0100
@@ -2934,16 +2934,20 @@
 #define DEF_ATTR_INT(ENUM, VALUE) ENUM,
 #define DEF_ATTR_IDENT(ENUM, STRING) ENUM,
 #define DEF_ATTR_TREE_LIST(ENUM, PURPOSE, VALUE, CHAIN) ENUM,
+#define DEF_FN_ATTR(NAME, ATTRS, PREDICATE) /* No entry needed in enum.  */
 #include "builtin-attrs.def"
 #undef DEF_ATTR_NULL_TREE
 #undef DEF_ATTR_INT
 #undef DEF_ATTR_IDENT
 #undef DEF_ATTR_TREE_LIST
+#undef DEF_FN_ATTR
   ATTR_LAST
 };
 
 static GTY(()) tree built_in_attributes[(int) ATTR_LAST];
 
+static bool c_attrs_initialized = false;
+
 static void c_init_attributes (void);
 
 /* Build tree nodes and builtin functions common to both C and C++ language
@@ -3354,7 +3358,8 @@
 #undef DEF_POINTER_TYPE
   builtin_types[(int) BT_LAST] = NULL_TREE;
 
-  c_init_attributes ();
+  if (!c_attrs_initialized)
+    c_init_attributes ();
 
 #define DEF_BUILTIN(ENUM, NAME, CLASS, TYPE, LIBTYPE, BOTH_P, FALLBACK_P, \
 		    NONANSI_P, ATTRS, IMPLICIT, COND)			\
@@ -4037,11 +4042,40 @@
     = tree_cons (built_in_attributes[(int) PURPOSE],	\
 		 built_in_attributes[(int) VALUE],	\
 		 built_in_attributes[(int) CHAIN]);
+#define DEF_FN_ATTR(NAME, ATTRS, PREDICATE) /* No initialization needed.  */
+#include "builtin-attrs.def"
+#undef DEF_ATTR_NULL_TREE
+#undef DEF_ATTR_INT
+#undef DEF_ATTR_IDENT
+#undef DEF_ATTR_TREE_LIST
+#undef DEF_FN_ATTR
+  c_attrs_initialized = true;
+}
+
+/* Depending on the name of DECL, apply default attributes to it.  */
+
+void
+c_common_insert_default_attributes (tree decl)
+{
+  tree name = DECL_NAME (decl);
+
+  if (!c_attrs_initialized)
+    c_init_attributes ();
+
+#define DEF_ATTR_NULL_TREE(ENUM) /* Nothing needed after initialization.  */
+#define DEF_ATTR_INT(ENUM, VALUE)
+#define DEF_ATTR_IDENT(ENUM, STRING)
+#define DEF_ATTR_TREE_LIST(ENUM, PURPOSE, VALUE, CHAIN)
+#define DEF_FN_ATTR(NAME, ATTRS, PREDICATE)			\
+  if ((PREDICATE) && name == built_in_attributes[(int) NAME])	\
+    decl_attributes (&decl, built_in_attributes[(int) ATTRS],	\
+		     ATTR_FLAG_BUILT_IN);
 #include "builtin-attrs.def"
 #undef DEF_ATTR_NULL_TREE
 #undef DEF_ATTR_INT
 #undef DEF_ATTR_IDENT
 #undef DEF_ATTR_TREE_LIST
+#undef DEF_FN_ATTR
 }
 
 /* Attribute handlers common to C front ends.  */
diff -Naur gcc-4.1-20051216.orig/gcc/c-common.h gcc-4.1-20051216-src/gcc/c-common.h
--- gcc-4.1-20051216.orig/gcc/c-common.h	2005-12-08 12:24:07.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-common.h	2005-12-18 22:24:28.000000000 +0100
@@ -632,6 +632,7 @@
 extern void set_Wformat (int);
 extern tree handle_format_attribute (tree *, tree, tree, int, bool *);
 extern tree handle_format_arg_attribute (tree *, tree, tree, int, bool *);
+extern void c_common_insert_default_attributes (tree);
 extern int c_common_handle_option (size_t code, const char *arg, int value);
 extern bool c_common_missing_argument (const char *opt, size_t code);
 extern tree c_common_type_for_mode (enum machine_mode, int);
diff -Naur gcc-4.1-20051216.orig/gcc/c-cppbuiltin.c gcc-4.1-20051216-src/gcc/c-cppbuiltin.c
--- gcc-4.1-20051216.orig/gcc/c-cppbuiltin.c	2005-08-13 22:58:02.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-cppbuiltin.c	2005-12-18 22:24:28.000000000 +0100
@@ -51,9 +51,11 @@
 static void builtin_define_with_value_n (const char *, const char *,
 					 size_t);
 static void builtin_define_with_int_value (const char *, HOST_WIDE_INT);
+#if 0
 static void builtin_define_with_hex_fp_value (const char *, tree,
 					      int, const char *,
 					      const char *);
+#endif /* 0 */
 static void builtin_define_stdint_macros (void);
 static void builtin_define_type_max (const char *, tree, int);
 static void builtin_define_type_precision (const char *, tree);
@@ -72,6 +74,7 @@
 static void
 builtin_define_float_constants (const char *name_prefix, const char *fp_suffix, tree type)
 {
+#if 0 /* (TIGCC) Do nothing. We have our own float.h! */
   /* Used to convert radix-based values to base 10 values in several cases.
 
      In the max_exp -> max_10_exp conversion for 128-bit IEEE, we need at
@@ -254,6 +257,7 @@
      NaN has quiet NaNs.  */
   sprintf (name, "__%s_HAS_QUIET_NAN__", name_prefix);
   builtin_define_with_int_value (name, MODE_HAS_NANS (TYPE_MODE (type)));
+#endif /* 0 */
 }
 
 /* Define __GNUC__, __GNUC_MINOR__ and __GNUC_PATCHLEVEL__.  */
@@ -571,6 +575,7 @@
   cpp_define (parse_in, buf);
 }
 
+#if 0
 /* Pass an object-like macro a hexadecimal floating-point value.  */
 static void
 builtin_define_with_hex_fp_value (const char *macro,
@@ -596,6 +601,7 @@
   sprintf (buf, "%s=%s%s", macro, dec_str, fp_suffix);
   cpp_define (parse_in, buf);
 }
+#endif /* 0 */
 
 /* Define MAX for TYPE based on the precision of the type.  IS_LONG is
    1 for type "long" and 2 for "long long".  We have to handle
diff -Naur gcc-4.1-20051216.orig/gcc/c-decl.c gcc-4.1-20051216-src/gcc/c-decl.c
--- gcc-4.1-20051216.orig/gcc/c-decl.c	2005-11-30 11:29:09.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-decl.c	2005-12-19 00:27:27.000000000 +0100
@@ -2418,7 +2418,6 @@
 void
 undeclared_variable (tree id, location_t loc)
 {
-  static bool already = false;
   struct c_scope *scope;
 
   if (current_function_decl == 0)
@@ -2430,13 +2429,6 @@
     {
       error ("%H%qE undeclared (first use in this function)", &loc, id);
 
-      if (!already)
-	{
-	  error ("%H(Each undeclared identifier is reported only once", &loc);
-	  error ("%Hfor each function it appears in.)", &loc);
-	  already = true;
-	}
-
       /* If we are parsing old-style parameter decls, current_function_decl
          will be nonnull but current_function_scope will be null.  */
       scope = current_function_scope ? current_function_scope : current_scope;
@@ -2730,7 +2722,7 @@
 
   input_location = save_loc;
 
-  pedantic_lvalues = true;
+  pedantic_lvalues = pedantic;
 
   make_fname_decl = c_make_fname_decl;
   start_fname_decls ();
@@ -2825,6 +2817,18 @@
 
   return decl;
 }
+
+/* Apply default attributes to a function, if a system function with default
+   attributes.  */
+
+void
+c_insert_default_attributes (decl)
+     tree decl;
+{
+  if (!TREE_PUBLIC (decl))
+    return;
+  c_common_insert_default_attributes (decl);
+}
 
 /* Called when a declaration is seen that contains no names to declare.
    If its type is a reference to a structure, union or enum inherited
@@ -3573,10 +3577,86 @@
 push_parm_decl (const struct c_parm *parm)
 {
   tree decl;
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+  tree asmspec;
 
+  asmspec = parm->asmspec;
+/* end-TIGCC-local (regparms) */
   decl = grokdeclarator (parm->declarator, parm->specs, PARM, false, NULL);
   decl_attributes (&decl, parm->attrs, 0);
 
+  /* begin-TIGCC-local (regparms): explicit register specification for parameters */
+  if (asmspec)
+#ifdef EXPLICIT_REGPARM
+    {
+      const char *regname=TREE_STRING_POINTER(asmspec);
+      int regnum;
+      if ((regnum=decode_reg_name(regname))>=0)
+	{
+	  tree type=TREE_TYPE(decl);
+	  if (HARD_REGNO_MODE_OK(regnum, TYPE_MODE(type)))
+	    {
+	      tree t, attrs;
+/*	      push_obstacks_nochange();
+	      end_temporary_allocation(); */
+	      /* Build tree for __attribute__ ((asm(regnum))). */
+#if 0
+	      /* This doesn't work well because of a bug in
+		 attribute_list_contained(), which passes list of arguments to
+		 simple_cst_equal() instead of passing every argument
+		 separately. */
+	      attrs=tree_cons(get_identifier("asm"), tree_cons(NULL_TREE,
+		    build_int_cstu(NULL_TREE, regnum), NULL_TREE), NULL_TREE);
+#else
+	      attrs=tree_cons(get_identifier("asm"),
+			      build_int_cstu(NULL_TREE, regnum), NULL_TREE);
+#endif
+#if 0
+	      /* build_type_attribute_variant() would seem to be more
+		 appropriate here. However, that function does not support
+		 attributes for parameters properly. It modifies
+		 TYPE_MAIN_VARIANT of a new type. As a result, comptypes()
+		 thinks that types of parameters in prototype and definition
+		 are different and issues error messages. See also comment
+		 below. */
+	      type=build_type_attribute_variant(type, attrs);
+#else
+	      /* First check whether such a type already exists - if yes, use
+		 that one. This is very important, since otherwise
+		 common_type() would think that it sees two different
+		 types and would try to merge them - this could result in
+		 warning messages. */
+	      for (t=TYPE_MAIN_VARIANT(type); t; t=TYPE_NEXT_VARIANT(t))
+		if (comptypes(t, type)==1
+		    && attribute_list_equal(TYPE_ATTRIBUTES(t), attrs))
+		      break;
+	      if (t)
+		type=t;
+	      else
+		{
+		  /* Create a new variant, with differing attributes.
+		     (Hack! Type with differing attributes should no longer be
+		     a variant of its main type. See comment above for
+		     explanation why this was necessary). */
+		  type=build_variant_type_copy(type);
+		  TYPE_ATTRIBUTES(type)=attrs;
+		}
+#endif
+	      TREE_TYPE(decl)=type;
+/*	      pop_obstacks(); */
+	    }
+	  else
+	    error("%Jregister number for `%s' isn't suitable for the data type",
+	          decl);
+	}
+      else
+	error("invalid register name `%s'", regname);
+    }
+#else /* !EXPLICIT_REGPARM */
+    error("explicit register specification for parameters is not supported for this target");
+#endif
+  /* end-TIGCC-local (regparms) */
+
   decl = pushdecl (decl);
 
   finish_decl (decl, NULL_TREE, NULL_TREE);
@@ -3628,7 +3708,11 @@
   DECL_CONTEXT (decl) = current_function_decl;
   TREE_USED (decl) = 1;
   TREE_TYPE (decl) = type;
-  TREE_READONLY (decl) = TYPE_READONLY (type);
+  /* (TIGCC 20050206) If -fglobal-compound-literals (on by default) is given,
+     for constant constructors, the compound literal is written out as if it was
+     const, which gets GCC to output it as a global, avoiding the copy.  */
+  TREE_READONLY (decl) = TYPE_READONLY (type)
+                         || (flag_global_compound_literals && TREE_CONSTANT (init));
   store_init_value (decl, init);
 
   if (TREE_CODE (type) == ARRAY_TYPE && !COMPLETE_TYPE_P (type))
@@ -6854,12 +6938,13 @@
 
 struct c_parm *
 build_c_parm (struct c_declspecs *specs, tree attrs,
-	      struct c_declarator *declarator)
+	      struct c_declarator *declarator, tree asmspec)
 {
   struct c_parm *ret = XOBNEW (&parser_obstack, struct c_parm);
   ret->specs = specs;
   ret->attrs = attrs;
   ret->declarator = declarator;
+  ret->asmspec = asmspec; /* (TIGCC 20050203) */
   return ret;
 }
 
diff -Naur gcc-4.1-20051216.orig/gcc/cfgexpand.c gcc-4.1-20051216-src/gcc/cfgexpand.c
--- gcc-4.1-20051216.orig/gcc/cfgexpand.c	2005-10-19 18:27:10.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/cfgexpand.c	2005-12-18 22:24:35.000000000 +0100
@@ -1322,6 +1322,23 @@
 	    }
 	  else
 	    {
+	      /* (TIGCC 20050206) If -fno-function-cse, restore function call
+	                          sequences to their expected form. */
+	      if (flag_no_function_cse && TREE_CODE (stmt) == MODIFY_EXPR)
+	        {
+	          block_stmt_iterator bsi2 = bsi;
+	          bsi_next (&bsi2);
+	          if (!bsi_end_p (bsi2))
+	            {
+	              tree call = get_call_expr_in (bsi_stmt (bsi2));
+	              if (call && TREE_OPERAND (stmt, 0) == TREE_OPERAND (call, 0)
+	                  && !TREE_SIDE_EFFECTS (TREE_OPERAND (stmt, 0))
+	                  && !TREE_SIDE_EFFECTS (TREE_OPERAND (stmt, 1)))
+	              {
+	                TREE_OPERAND (call, 0) = TREE_OPERAND (stmt, 1);
+	              }
+	            }
+	        }
 	      last = get_last_insn ();
 	      expand_expr_stmt (stmt);
 	      maybe_dump_rtl_for_tree_stmt (stmt, last);
diff -Naur gcc-4.1-20051216.orig/gcc/c-format.c gcc-4.1-20051216-src/gcc/c-format.c
--- gcc-4.1-20051216.orig/gcc/c-format.c	2005-10-26 04:15:02.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-format.c	2005-12-18 22:24:28.000000000 +0100
@@ -281,16 +281,12 @@
 } format_wanted_type;
 
 
+/* (TIGCC 20040219) AMS doesn't support any C99 or extended modifiers.
+    -- Kevin Kofler */
 static const format_length_info printf_length_specs[] =
 {
-  { "h", FMT_LEN_h, STD_C89, "hh", FMT_LEN_hh, STD_C99 },
-  { "l", FMT_LEN_l, STD_C89, "ll", FMT_LEN_ll, STD_C9L },
-  { "q", FMT_LEN_ll, STD_EXT, NULL, 0, 0 },
-  { "L", FMT_LEN_L, STD_C89, NULL, 0, 0 },
-  { "z", FMT_LEN_z, STD_C99, NULL, 0, 0 },
-  { "Z", FMT_LEN_z, STD_EXT, NULL, 0, 0 },
-  { "t", FMT_LEN_t, STD_C99, NULL, 0, 0 },
-  { "j", FMT_LEN_j, STD_C99, NULL, 0, 0 },
+  { "h", FMT_LEN_h, STD_C89, NULL, 0, 0 },
+  { "l", FMT_LEN_l, STD_C89, NULL, 0, 0 },
   { NULL, 0, 0, NULL, 0, 0 }
 };
 
@@ -315,16 +311,12 @@
 #define gcc_cdiag_length_specs gcc_diag_length_specs
 #define gcc_cxxdiag_length_specs gcc_diag_length_specs
 
-/* This differs from printf_length_specs only in that "Z" is not accepted.  */
+/* (TIGCC 20040219) My *scanf doesn't support any C99 or extended modifiers.
+    -- Kevin Kofler */
 static const format_length_info scanf_length_specs[] =
 {
-  { "h", FMT_LEN_h, STD_C89, "hh", FMT_LEN_hh, STD_C99 },
-  { "l", FMT_LEN_l, STD_C89, "ll", FMT_LEN_ll, STD_C9L },
-  { "q", FMT_LEN_ll, STD_EXT, NULL, 0, 0 },
-  { "L", FMT_LEN_L, STD_C89, NULL, 0, 0 },
-  { "z", FMT_LEN_z, STD_C99, NULL, 0, 0 },
-  { "t", FMT_LEN_t, STD_C99, NULL, 0, 0 },
-  { "j", FMT_LEN_j, STD_C99, NULL, 0, 0 },
+  { "h", FMT_LEN_h, STD_C89, NULL, 0, 0 },
+  { "l", FMT_LEN_l, STD_C89, NULL, 0, 0 },
   { NULL, 0, 0, NULL, 0, 0 }
 };
 
@@ -338,6 +330,9 @@
   { NULL, 0, 0, NULL, 0, 0 }
 };
 
+/* (TIGCC 20040219) AMS doesn't support any of the GNU extended modifiers.
+                    However, it supports some of its own.
+    -- Kevin Kofler */
 static const format_flag_spec printf_flag_specs[] =
 {
   { ' ',  0, 0, N_("' ' flag"),        N_("the ' ' printf flag"),              STD_C89 },
@@ -345,8 +340,9 @@
   { '#',  0, 0, N_("'#' flag"),        N_("the '#' printf flag"),              STD_C89 },
   { '0',  0, 0, N_("'0' flag"),        N_("the '0' printf flag"),              STD_C89 },
   { '-',  0, 0, N_("'-' flag"),        N_("the '-' printf flag"),              STD_C89 },
-  { '\'', 0, 0, N_("''' flag"),        N_("the ''' printf flag"),              STD_EXT },
-  { 'I',  0, 0, N_("'I' flag"),        N_("the 'I' printf flag"),              STD_EXT },
+  { 'z',  0, 0, N_("'z' flag"),        N_("the 'z' printf flag"),              STD_EXT },
+  { '^',  0, 0, N_("'^' flag"),        N_("the '^' printf flag"),              STD_EXT },
+  { '|',  0, 0, N_("'|' flag"),        N_("the '|' printf flag"),              STD_EXT },
   { 'w',  0, 0, N_("field width"),     N_("field width in printf format"),     STD_C89 },
   { 'p',  0, 0, N_("precision"),       N_("precision in printf format"),       STD_C89 },
   { 'L',  0, 0, N_("length modifier"), N_("length modifier in printf format"), STD_C89 },
@@ -419,14 +415,13 @@
   { 0, 0, 0, NULL, NULL, 0 }
 };
 
+/* (TIGCC 20040219) My *scanf doesn't support any extended modifiers.
+    -- Kevin Kofler */
 static const format_flag_spec scanf_flag_specs[] =
 {
   { '*',  0, 0, N_("assignment suppression"), N_("the assignment suppression scanf feature"), STD_C89 },
-  { 'a',  0, 0, N_("'a' flag"),               N_("the 'a' scanf flag"),                       STD_EXT },
   { 'w',  0, 0, N_("field width"),            N_("field width in scanf format"),              STD_C89 },
   { 'L',  0, 0, N_("length modifier"),        N_("length modifier in scanf format"),          STD_C89 },
-  { '\'', 0, 0, N_("''' flag"),               N_("the ''' scanf flag"),                       STD_EXT },
-  { 'I',  0, 0, N_("'I' flag"),               N_("the 'I' scanf flag"),                       STD_EXT },
   { 0, 0, 0, NULL, NULL, 0 }
 };
 
@@ -486,26 +481,22 @@
 };
 
 
+/* (TIGCC 20040219) AMS doesn't support any of the C99 or GNU extended
+                    modifiers. However, it supports some of its own.
+    -- Kevin Kofler */
 static const format_char_info print_char_table[] =
 {
   /* C89 conversion specifiers.  */
-  { "di",  0, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  TEX_LL,  T99_SST, T99_PD,  T99_IM  }, "-wp0 +'I",  "i",  NULL },
-  { "oxX", 0, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "-wp0#",     "i",  NULL },
-  { "u",   0, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "-wp0'I",    "i",  NULL },
-  { "fgG", 0, STD_C89, { T89_D,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T89_LD,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#'I", "",   NULL },
-  { "eE",  0, STD_C89, { T89_D,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T89_LD,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#I",  "",   NULL },
-  { "c",   0, STD_C89, { T89_I,   BADLEN,  BADLEN,  T94_WI,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w",        "",   NULL },
-  { "s",   1, STD_C89, { T89_C,   BADLEN,  BADLEN,  T94_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp",       "cR", NULL },
-  { "p",   1, STD_C89, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w",        "c",  NULL },
-  { "n",   1, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  BADLEN,  T99_SST, T99_PD,  T99_IM  }, "",          "W",  NULL },
-  /* C99 conversion specifiers.  */
-  { "F",   0, STD_C99, { T99_D,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T99_LD,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#'I", "",   NULL },
-  { "aA",  0, STD_C99, { T99_D,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T99_LD,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#",   "",   NULL },
-  /* X/Open conversion specifiers.  */
-  { "C",   0, STD_EXT, { TEX_WI,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w",        "",   NULL },
-  { "S",   1, STD_EXT, { TEX_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp",       "R",  NULL },
-  /* GNU conversion specifiers.  */
-  { "m",   0, STD_EXT, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp",       "",   NULL },
+  { "di",  0, STD_C89, { T89_S,   BADLEN,  T89_S,   T89_L,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +|z",  "i", NULL  },
+  { "xX", 0, STD_C89, { T89_US,  BADLEN,  T89_US,  T89_UL,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0#|z",     "i", NULL  },
+  { "u",   0, STD_C89, { T89_US,  BADLEN,  T89_US,  T89_UL,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0|z",    "i", NULL  },
+  { "fgG", 0, STD_C89, { T89_D,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#^|z", "", NULL   },
+  { "eE",  0, STD_C89, { T89_D,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#^|z",  "", NULL   },
+  { "rR",  0, STD_EXT, { T89_D,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#^|z",  "", NULL   },
+  { "yY",  0, STD_EXT, { T89_D,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp0 +#^|z",  "", NULL   },
+  { "c",   0, STD_C89, { T89_S,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w|z",        "", NULL   },
+  { "s",   1, STD_C89, { T89_C,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-wp|z",       "cR", NULL },
+  { "p",   1, STD_C89, { BADLEN,  BADLEN,  BADLEN,  T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "-w|z",        "c", NULL  },
   { NULL,  0, 0, NOLENGTHS, NULL, NULL, NULL }
 };
 
@@ -641,23 +632,18 @@
   { NULL,  0, 0, NOLENGTHS, NULL, NULL, NULL }
 };
 
+/* (TIGCC 20040219) My *scanf doesn't support any extended modifiers. -- Kevin Kofler */
 static const format_char_info scan_char_table[] =
 {
   /* C89 conversion specifiers.  */
-  { "di",    1, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  TEX_LL,  T99_SST, T99_PD,  T99_IM  }, "*w'I", "W",   NULL },
-  { "u",     1, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "*w'I", "W",   NULL },
-  { "oxX",   1, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "*w",   "W",   NULL },
-  { "efgEG", 1, STD_C89, { T89_F,   BADLEN,  BADLEN,  T89_D,   BADLEN,  T89_LD,  BADLEN,  BADLEN,  BADLEN  }, "*w'",  "W",   NULL },
+  { "di",    1, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  TEX_LL,  T99_SST, T99_PD,  T99_IM  }, "*w", "W", NULL   },
+  { "u",     1, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "*w", "W", NULL   },
+  { "oxX",   1, STD_C89, { T89_UI,  T99_UC,  T89_US,  T89_UL,  T9L_ULL, TEX_ULL, T99_ST,  T99_UPD, T99_UIM }, "*w",   "W", NULL   },
+  { "efgEG", 1, STD_C89, { T89_F,   BADLEN,  BADLEN,  T89_D,   BADLEN,  T89_LD,  BADLEN,  BADLEN,  BADLEN  }, "*w",  "W", NULL   },
   { "c",     1, STD_C89, { T89_C,   BADLEN,  BADLEN,  T94_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*w",   "cW",  NULL },
   { "s",     1, STD_C89, { T89_C,   BADLEN,  BADLEN,  T94_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*aw",  "cW",  NULL },
   { "[",     1, STD_C89, { T89_C,   BADLEN,  BADLEN,  T94_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*aw",  "cW[", NULL },
   { "p",     2, STD_C89, { T89_V,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*w",   "W",   NULL },
-  { "n",     1, STD_C89, { T89_I,   T99_SC,  T89_S,   T89_L,   T9L_LL,  BADLEN,  T99_SST, T99_PD,  T99_IM  }, "",     "W",   NULL },
-  /* C99 conversion specifiers.  */
-  { "FaA",   1, STD_C99, { T99_F,   BADLEN,  BADLEN,  T99_D,   BADLEN,  T99_LD,  BADLEN,  BADLEN,  BADLEN  }, "*w'",  "W",   NULL },
-  /* X/Open conversion specifiers.  */
-  { "C",     1, STD_EXT, { TEX_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*w",   "W",   NULL },
-  { "S",     1, STD_EXT, { TEX_W,   BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN,  BADLEN  }, "*aw",  "W",   NULL },
   { NULL, 0, 0, NOLENGTHS, NULL, NULL, NULL }
 };
 
@@ -695,9 +681,10 @@
 };
 
 /* This must be in the same order as enum format_type.  */
+/* (TIGCC 20040219) Changed the flag chars. See the *f_flag_specs comments. */
 static const format_kind_info format_types_orig[] =
 {
-  { "printf",   printf_length_specs,  print_char_table, " +#0-'I", NULL, 
+  { "printf",   printf_length_specs,  print_char_table, " +#0-z^|", NULL, 
     printf_flag_specs, printf_flag_pairs,
     FMT_FLAG_ARG_CONVERT|FMT_FLAG_DOLLAR_MULTIPLE|FMT_FLAG_USE_DOLLAR|FMT_FLAG_EMPTY_PREC_OK,
     'w', 0, 'p', 0, 'L',
@@ -739,7 +726,7 @@
     0, 0, 0, 0, 0,
     NULL, NULL
   },
-  { "scanf",    scanf_length_specs,   scan_char_table,  "*'I", NULL, 
+  { "scanf",    scanf_length_specs,   scan_char_table,  "*", NULL, 
     scanf_flag_specs, scanf_flag_pairs,
     FMT_FLAG_ARG_CONVERT|FMT_FLAG_SCANF_A_KLUDGE|FMT_FLAG_USE_DOLLAR|FMT_FLAG_ZERO_WIDTH_BAD|FMT_FLAG_DOLLAR_GAP_POINTER_OK,
     'w', 0, 0, '*', 'L',
@@ -2215,6 +2202,17 @@
 			  || cur_type == signed_char_type_node
 			  || cur_type == unsigned_char_type_node);
 
+      /* (TIGCC) Account for *printf and *scanf not actually supporting -mlong.  */
+      if (!TARGET_SHORT) {
+        if (cur_type == short_integer_type_node
+            || cur_type == integer_type_node)
+          orig_cur_type = cur_type = long_integer_type_node;
+
+        if (cur_type == short_unsigned_type_node
+            || cur_type == unsigned_type_node)
+          orig_cur_type = cur_type = long_unsigned_type_node;
+      }
+
       /* Check the type of the "real" argument, if there's a type we want.  */
       if (lang_hooks.types_compatible_p (wanted_type, cur_type))
 	continue;
@@ -2229,12 +2227,18 @@
 	 -pedantic.  With -pedantic, warn if the type is a pointer
 	 target and not a character type, and for character types at
 	 a second level of indirection.  */
-      if (TREE_CODE (wanted_type) == INTEGER_TYPE
+      /* TIGCC Patch: Don't warn about differences in floating point
+         format; they're all the same.
+         (TIGCC 20040728) But do warn if someone passes an integer where a float
+                          is expected! -- Kevin Kofler  */
+      if ((TREE_CODE (wanted_type) == REAL_TYPE
+           && TREE_CODE (cur_type) == REAL_TYPE)
+	  || (TREE_CODE (wanted_type) == INTEGER_TYPE
 	  && TREE_CODE (cur_type) == INTEGER_TYPE
 	  && (!pedantic || i == 0 || (i == 1 && char_type_flag))
 	  && (TYPE_UNSIGNED (wanted_type)
 	      ? wanted_type == c_common_unsigned_type (cur_type)
-	      : wanted_type == c_common_signed_type (cur_type)))
+	      : wanted_type == c_common_signed_type (cur_type))))
 	continue;
       /* Likewise, "signed char", "unsigned char" and "char" are
 	 equivalent but the above test won't consider them equivalent.  */
diff -Naur gcc-4.1-20051216.orig/gcc/c-incpath.c gcc-4.1-20051216-src/gcc/c-incpath.c
--- gcc-4.1-20051216.orig/gcc/c-incpath.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-incpath.c	2005-12-18 22:24:28.000000000 +0100
@@ -335,9 +335,13 @@
      function does not recognize a directory that ends in a backslash
      (unless it is a drive root dir, such "c:\").  Forward slashes,
      trailing or otherwise, cause no problems for stat().  */
+  /* (TIGCC 20050206) This is entirely backwards! We need backslashes.
+                      Forward-slashes are no good. But we need to get rid of
+                      trailing backslashes. -- Kevin Kofler  */
   char* c;
   for (c = path; *c; c++)
-    if (*c == '\\') *c = '/';
+    if (*c == '/') *c = '\\';
+  if (c[strlen(c)-1] == '\\') c[strlen(c)-1] = '\0';
 #endif
 
   p = xmalloc (sizeof (cpp_dir));
@@ -360,6 +364,7 @@
 			 const char *iprefix, int stdinc, int cxx_stdinc,
 			 int verbose)
 {
+#if 0 /* (TIGCC 20050205) Don't use environment variables. */
   static const char *const lang_env_vars[] =
     { "C_INCLUDE_PATH", "CPLUS_INCLUDE_PATH",
       "OBJC_INCLUDE_PATH", "OBJCPLUS_INCLUDE_PATH" };
@@ -375,11 +380,14 @@
      include chain.  */
   add_env_var_paths ("CPATH", BRACKET);
   add_env_var_paths (lang_env_vars[idx], SYSTEM);
+#endif /* 0 */
   
   target_c_incpath.extra_pre_includes (sysroot, iprefix, stdinc);
 
   /* Finally chain on the standard directories.  */
-  if (stdinc)
+  /* (TIGCC 20031007) We don't want any "standard" include directories.
+                      -- Kevin Kofler  */
+  if (0 /*stdinc*/)
     add_standard_paths (sysroot, iprefix, cxx_stdinc);
 
   target_c_incpath.extra_includes (sysroot, iprefix, stdinc);
diff -Naur gcc-4.1-20051216.orig/gcc/c-lang.c gcc-4.1-20051216-src/gcc/c-lang.c
--- gcc-4.1-20051216.orig/gcc/c-lang.c	2005-07-01 01:09:06.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-lang.c	2005-12-18 22:24:28.000000000 +0100
@@ -44,6 +44,8 @@
 #define LANG_HOOKS_NAME "GNU C"
 #undef LANG_HOOKS_INIT
 #define LANG_HOOKS_INIT c_objc_common_init
+#undef LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES
+#define LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES c_insert_default_attributes
 
 /* Each front end provides its own lang hook initializer.  */
 const struct lang_hooks lang_hooks = LANG_HOOKS_INITIALIZER;
diff -Naur gcc-4.1-20051216.orig/gcc/c-lex.c gcc-4.1-20051216-src/gcc/c-lex.c
--- gcc-4.1-20051216.orig/gcc/c-lex.c	2005-07-19 22:19:16.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-lex.c	2005-12-18 22:24:28.000000000 +0100
@@ -433,7 +433,7 @@
 	cppchar_t c = tok->val.str.text[0];
 
 	if (c == '"' || c == '\'')
-	  error ("missing terminating %c character", (int) c);
+	  cpp_unterminated (parse_in, c);
 	else if (ISGRAPH (c))
 	  error ("stray %qc in program", (int) c);
 	else
diff -Naur gcc-4.1-20051216.orig/gcc/combine.c gcc-4.1-20051216-src/gcc/combine.c
--- gcc-4.1-20051216.orig/gcc/combine.c	2005-12-01 04:24:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/combine.c	2005-12-18 22:24:35.000000000 +0100
@@ -4396,8 +4396,10 @@
       /* x - 0 is the same as x unless x's mode has signed zeros and
 	 allows rounding towards -infinity.  Under those conditions,
 	 0 - 0 is -0.  */
+      /* (TIGCC 20050210) This is invalid independently of the rounding mode
+                          for 3-sign-zeros. */
       if (!(HONOR_SIGNED_ZEROS (GET_MODE (XEXP (x, 0)))
-	    && HONOR_SIGN_DEPENDENT_ROUNDING (GET_MODE (XEXP (x, 0))))
+	    /*&& HONOR_SIGN_DEPENDENT_ROUNDING (GET_MODE (XEXP (x, 0)))*/)
 	  && XEXP (x, 1) == CONST0_RTX (GET_MODE (XEXP (x, 0))))
 	return XEXP (x, 0);
       break;
diff -Naur gcc-4.1-20051216.orig/gcc/common.opt gcc-4.1-20051216-src/gcc/common.opt
--- gcc-4.1-20051216.orig/gcc/common.opt	2005-11-11 18:59:54.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/common.opt	2005-12-18 22:24:35.000000000 +0100
@@ -447,6 +447,14 @@
 Perform global common subexpression elimination after register allocation
 has finished
 
+fglobal-cast-constructors
+Common Report Var(flag_global_compound_literals) Init(1)
+Make compound literals (cast constructors) global for backwards compatibility
+
+fglobal-compound-literals
+Common Report Var(flag_global_compound_literals) VarExists
+Make compound literals (cast constructors) global for backwards compatibility
+
 fguess-branch-probability
 Common Report Var(flag_guess_branch_prob)
 Enable guessing of branch probabilities
@@ -562,6 +570,10 @@
 Common Report Var(flag_merge_constants,2) Init(1)
 Attempt to merge identical constants and constant variables
 
+fmerge-constant-pools
+Common Report Var(flag_merge_constant_pools) Init(1)
+When merging constants, also merge constant pools
+
 fmerge-constants
 Common Report Var(flag_merge_constants,1) VarExists
 Attempt to merge identical constants across compilation units
@@ -590,6 +602,10 @@
 Common RejectNegative Report Var(flag_mudflap_ignore_reads)
 Ignore read operations when inserting mudflap instrumentation
 
+freg-relative-
+Common Joined RejectNegative
+-freg-relative-<register>	Emit code relative to the base register <register>
+
 freschedule-modulo-scheduled-loops
 Common Report Var(flag_resched_modulo_sched)
 Enable/Disable the traditional scheduling in loops that already passed modulo scheduling
@@ -1042,7 +1058,7 @@
 Assume signed arithmetic overflow wraps around
 
 fzero-initialized-in-bss
-Common Report Var(flag_zero_initialized_in_bss) Init(1)
+Common Report Var(flag_zero_initialized_in_bss) Init(0)
 Put zero initialized data in the bss section
 
 g
diff -Naur gcc-4.1-20051216.orig/gcc/config/dbxcoff.h gcc-4.1-20051216-src/gcc/config/dbxcoff.h
--- gcc-4.1-20051216.orig/gcc/config/dbxcoff.h	2005-06-25 03:22:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/dbxcoff.h	2005-12-18 22:24:35.000000000 +0100
@@ -48,8 +48,13 @@
 
 /* Like block addresses, stabs line numbers are relative to the
    current function.  */
+/* TIGCC Patch: We don't want COFF line numbers to be function-relative.
+   That's why we write '.ln LINE'. This will break support for existing
+   debuggers, but there are none for TIGCC. The line numbers can be
+   extracted from the .s file, plus they are passed on to the object file
+   symbol table. */
 
-#define DBX_LINES_FUNCTION_RELATIVE 1
+#define DBX_LINES_FUNCTION_RELATIVE (!TARGET_COFFABSLINES)
 
 /* When generating stabs debugging, use N_BINCL entries.  */
 
diff -Naur gcc-4.1-20051216.orig/gcc/config/i386/xm-mingw32.h gcc-4.1-20051216-src/gcc/config/i386/xm-mingw32.h
--- gcc-4.1-20051216.orig/gcc/config/i386/xm-mingw32.h	2005-06-25 03:22:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/i386/xm-mingw32.h	2005-12-18 22:24:35.000000000 +0100
@@ -20,6 +20,10 @@
 Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA
 02110-1301, USA.  */
 
+/* Mingw32 does not try to hide the underlying DOS-based file system
+   like Cygwin does.  */
+#define HAVE_DOS_BASED_FILE_SYSTEM
+
 #define HOST_EXECUTABLE_SUFFIX ".exe"
 
 #undef PATH_SEPARATOR
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k.c gcc-4.1-20051216-src/gcc/config/m68k/m68k.c
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k.c	2005-07-12 01:32:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k.c	2005-12-19 02:00:46.000000000 +0100
@@ -43,6 +43,11 @@
 #include "target-def.h"
 #include "debug.h"
 #include "flags.h"
+#include "c-pragma.h"
+#include "cgraph.h"
+
+/* TIGCC register for reg-relative code.  */
+char TARGET_RELATION_REG[10] = "a4";
 
 enum reg_class regno_reg_class[] =
 {
@@ -122,10 +127,20 @@
 static bool m68k_save_reg (unsigned int regno, bool interrupt_handler);
 static int const_int_cost (rtx);
 static bool m68k_rtx_costs (rtx, int, int, int *);
+static bool m68k_cannot_force_const_mem (rtx); /* (TIGCC 20050424) */
+
+static int comp_m68k_type_attributes (tree, tree);
+static int comp_amigaos_type_attributes (tree, tree);
+static tree m68k_handle_stkparm_attribute (tree *, tree, tree, int, bool *);
+static tree m68k_handle_regparm_attribute (tree *, tree, tree, int, bool *);
 
 
 /* Specify the identification number of the library being built */
 const char *m68k_library_id_string = "_current_shared_library_a5_offset_";
+/* Specify number of registers for integer, pointer and float arguments.  */
+const char *m68k_regparm_string;
+/* Specify number of registers for integer, pointer and float arguments.  */
+int m68k_regparm;
 
 /* Nonzero if the last compare/test insn had FP operands.  The
    sCC expanders peek at this to determine what to do for the
@@ -133,6 +148,8 @@
 int m68k_last_compare_had_fp_operands;
 
 /* Initialize the GCC target structure.  */
+#undef TARGET_COMP_TYPE_ATTRIBUTES
+#define TARGET_COMP_TYPE_ATTRIBUTES comp_amigaos_type_attributes
 
 #if INT_OP_GROUP == INT_OP_DOT_WORD
 #undef TARGET_ASM_ALIGNED_HI_OP
@@ -186,15 +203,35 @@
 #undef TARGET_ATTRIBUTE_TABLE
 #define TARGET_ATTRIBUTE_TABLE m68k_attribute_table
 
+/* Pass the right values to functions whose prototypes contain "char"
+   or "short". */
+#if 0
 #undef TARGET_PROMOTE_PROTOTYPES
 #define TARGET_PROMOTE_PROTOTYPES hook_bool_tree_true
+#endif /* 0 */
 
 #undef TARGET_STRUCT_VALUE_RTX
 #define TARGET_STRUCT_VALUE_RTX m68k_struct_value_rtx
 
+#undef TARGET_ASM_FILE_START
+#define TARGET_ASM_FILE_START m68k_asm_file_start
+
+/* (TIGCC 20050424) Everything which is not a CONST_DOUBLE has no business of
+                    being in the constant pool. This is especially valid for
+                    expressions containing relocations. -- Kevin Kofler */
+#undef TARGET_CANNOT_FORCE_CONST_MEM
+#define TARGET_CANNOT_FORCE_CONST_MEM m68k_cannot_force_const_mem
+
 static const struct attribute_spec m68k_attribute_table[] =
 {
   /* { name, min_len, max_len, decl_req, type_req, fn_type_req, handler } */
+  /* The stkparm attribute means a function takes its parameters on the stack
+     (AMS calling convention). */
+  { "stkparm",   0, 0, false, true,  true,  m68k_handle_stkparm_attribute },
+  /* The regparm attribute means a function takes its parameters in registers.
+     Its optional argument specifies the maximum number of arguments to be
+     passed in each category of registers (data registers, address registers). */
+  { "regparm",   0, 1, false, true,  true,  m68k_handle_regparm_attribute },
   { "interrupt_handler", 0, 0, true,  false, false, m68k_handle_fndecl_attribute },
   { NULL,                0, 0, false, false, false, NULL }
 };
@@ -314,6 +351,19 @@
 void
 override_options (void)
 {
+   /* Validate -mregparm and -mregparm= value.  */
+   if (m68k_regparm_string)
+     {
+       m68k_regparm = atoi (m68k_regparm_string);
+       if (m68k_regparm < 1 || m68k_regparm > M68K_MAX_REGPARM)
+ 	error ("-mregparm=%d is not between 1 and %d",
+ 	       m68k_regparm, M68K_MAX_REGPARM);
+       target_flags |= MASK_REGPARM;
+     }
+   else
+     if (TARGET_REGPARM)
+       m68k_regparm = M68K_DEFAULT_REGPARM;
+
   /* Sanity check to ensure that msep-data and mid-sahred-library are not
    * both specified together.  Doing so simply doesn't make sense.
    */
@@ -349,6 +399,116 @@
   SUBTARGET_OVERRIDE_OPTIONS;
 }
 
+/* Handle a "stkparm" attribute;
+   arguments as in struct attribute_spec.handler. */
+static tree
+m68k_handle_stkparm_attribute (tree *node, tree name, tree args ATTRIBUTE_UNUSED,
+                               int flags ATTRIBUTE_UNUSED, bool *no_add_attrs)
+{
+  if (lookup_attribute ("regparm", TYPE_ATTRIBUTES (*node)))
+  {
+    error ("`regparm' and `stkparm' are mutually exclusive");
+    *no_add_attrs = true;
+  }
+
+  if (TREE_CODE (*node) != FUNCTION_TYPE
+      && TREE_CODE (*node) != METHOD_TYPE
+      && TREE_CODE (*node) != FIELD_DECL
+      && TREE_CODE (*node) != TYPE_DECL)
+    {
+      warning ("`%s' attribute only applies to functions",
+	       IDENTIFIER_POINTER (name));
+      *no_add_attrs = true;
+    }
+
+  return NULL_TREE;
+}
+
+/* Handle a "regparm" attribute;
+   arguments as in struct attribute_spec.handler. */
+static tree
+m68k_handle_regparm_attribute (tree *node, tree name, tree args,
+                               int flags ATTRIBUTE_UNUSED, bool *no_add_attrs)
+{
+  if (lookup_attribute ("stkparm", TYPE_ATTRIBUTES (*node)))
+  {
+    error ("`regparm' and `stkparm' are mutually exclusive");
+    *no_add_attrs = true;
+  }
+
+  if (TREE_CODE (*node) != FUNCTION_TYPE
+      && TREE_CODE (*node) != METHOD_TYPE
+      && TREE_CODE (*node) != FIELD_DECL
+      && TREE_CODE (*node) != TYPE_DECL)
+    {
+      warning ("`%s' attribute only applies to functions",
+	       IDENTIFIER_POINTER (name));
+      *no_add_attrs = true;
+    }
+  else
+    {
+      /* 'regparm' accepts one optional argument - number of registers per
+         single class (data, address) that should be used to pass arguments. */
+      if (args && TREE_CODE (args) == TREE_LIST)
+      {
+        tree numofregs = TREE_VALUE (args);
+        if (numofregs)
+          if (TREE_CODE (numofregs) != INTEGER_CST
+              || TREE_INT_CST_HIGH (numofregs)
+              || TREE_INT_CST_LOW (numofregs) < 1
+              || TREE_INT_CST_LOW (numofregs) > M68K_MAX_REGPARM)
+          {
+            error ("invalid argument to `regparm' attribute");
+       	    *no_add_attrs = true;
+          }
+      }
+    }
+
+  return NULL_TREE;
+}
+
+/* Return zero if the attributes on TYPE1 and TYPE2 are incompatible,
+   one if they are compatible, and two if they are nearly compatible
+   (which causes a warning to be generated). */
+
+int
+comp_m68k_type_attributes (tree type1, tree type2)
+{
+  /* Functions or methods are incompatible if they specify mutually
+     exclusive ways of passing arguments.  */
+  if (TREE_CODE (type1) == FUNCTION_TYPE || TREE_CODE (type1) == METHOD_TYPE)
+    {
+      tree arg1, arg2;
+      if (!! lookup_attribute ("stkparm", TYPE_ATTRIBUTES (type1)) !=
+	     !! lookup_attribute ("stkparm", TYPE_ATTRIBUTES (type2))
+	  || !! lookup_attribute ("regparm", TYPE_ATTRIBUTES (type1)) !=
+	     !! lookup_attribute ("regparm", TYPE_ATTRIBUTES (type2)))
+	return 0; /* 'regparm' and 'stkparm' are mutually exclusive.  */
+
+      arg1 = lookup_attribute ("regparm", TYPE_ATTRIBUTES (type1));
+      arg2 = lookup_attribute ("regparm", TYPE_ATTRIBUTES (type2));
+      if (arg1 && arg2)
+	{
+	  int num1 = 0, num2 = 0;
+	  if (TREE_VALUE (arg1) && TREE_CODE (TREE_VALUE (arg1)) == TREE_LIST)
+	    {
+	      tree numofregs = TREE_VALUE (TREE_VALUE (arg1));
+	      if (numofregs)
+		num1 = TREE_INT_CST_LOW (numofregs);
+	    }
+	  if (TREE_VALUE (arg2) && TREE_CODE (TREE_VALUE (arg2)) == TREE_LIST)
+	    {
+	      tree numofregs = TREE_VALUE (TREE_VALUE (arg2));
+	      if (numofregs)
+		num2 = TREE_INT_CST_LOW (numofregs);
+	    }
+	  if (num1 != num2)
+	    return 0; /* Different numbers, or no number in one type.  */
+	}
+    }
+  return 1;
+}
+
 /* Return nonzero if FUNC is an interrupt function as specified by the
    "interrupt_handler" attribute.  */
 static bool
@@ -464,6 +624,11 @@
 static bool
 m68k_save_reg (unsigned int regno, bool interrupt_handler)
 {
+  /* (TIGCC 20050208) Handle OPTIMIZE_ROM_CALLS. Register #13 is %a5. */
+  if (interrupt_handler && regno == 13 && global_regs[13]
+      && cpp_defined (parse_in, "OPTIMIZE_ROM_CALLS", 18))
+    return true;
+
   if (flag_pic && regno == PIC_OFFSET_TABLE_REGNUM)
     {
       if (current_function_uses_pic_offset_table)
@@ -603,7 +768,8 @@
 
       if (dwarf2out_do_frame ())
 	{
-	  cfa_offset += current_frame.size + 4;
+	  /* (TIGCC 20050407) This +4 seems wrong from my tests. */
+	  cfa_offset += current_frame.size /*+ 4*/;
 	  dwarf2out_def_cfa ("", STACK_POINTER_REGNUM, cfa_offset);
 	}
     } /* !frame_pointer_needed */
@@ -724,6 +890,11 @@
 	    }
 	}
     }
+
+  /* (TIGCC 20050208) Handle OPTIMIZE_ROM_CALLS. Register #13 is %a5. */
+  if (global_regs[13] && m68k_interrupt_function_p (current_function_decl)
+      && cpp_defined (parse_in, "OPTIMIZE_ROM_CALLS", 18))
+    asm_fprintf (stream, "\tmove.l 200.w,%%a5\n");
 }
 
 /* Return true if this function's epilogue can be output as RTL.  */
@@ -763,9 +934,11 @@
     insn = prev_nonnote_insn (insn);
   if (insn && GET_CODE (insn) == BARRIER)
     {
+#if 0 /* (TIGCC 20050206) */
       /* Output just a no-op so that debuggers don't get confused
 	 about which function the pc is in at this address.  */
       fprintf (stream, "\tnop\n");
+#endif /* 0 */
       return;
     }
 
@@ -1054,8 +1227,17 @@
        * We'll use the -Os command-line flag to decide which to generate.
        * Both sequences take the same time to execute on the ColdFire.
        */
+/* (TIGCC 20040222, 20050204) No long branches please... */
+/* (TIGCC 20050209) FIXME: This should really be handled fully in one place.
+                           Currently, part of this logic is in the patching code
+                           and part is in GCC. It should be all in GCC IMHO. */
+  else if (TARGET_PCREL && GET_CODE (dest) == MEM
+           && GET_CODE (XEXP (dest, 0)) == SYMBOL_REF
+           && (!strncmp(XSTR (XEXP (dest, 0), 0),"_ROM_CALL_",10)
+               || !strncmp(XSTR (XEXP (dest, 0), 0),"_RAM_CALL_",10)))
+    out = "jbsr %o0";
   else if (TARGET_PCREL)
-    out = "bsr.l %o0";
+    out = "bsr %o0";
   else if ((flag_pic == 1) || TARGET_68020)
 #if defined(USE_GAS)
     out = "bsr.l %0@PLTPC";
@@ -1457,11 +1639,11 @@
 
 typedef enum { MOVL, SWAP, NEGW, NOTW, NOTB, MOVQ, MVS, MVZ } CONST_METHOD;
 
-static CONST_METHOD const_method (rtx);
+CONST_METHOD const_method (rtx);
 
 #define USE_MOVQ(i)	((unsigned)((i) + 128) <= 255)
 
-static CONST_METHOD
+CONST_METHOD
 const_method (rtx constant)
 {
   int i;
@@ -1563,10 +1745,15 @@
        for add and the time for shift, taking away a little more because
        sometimes move insns are needed.  */
     /* div?.w is relatively cheaper on 68000 counted in COSTS_N_INSNS terms.  */
+    /* (TIGCC 20030705) Decrease multiplication/division cost under -Os, so that
+                        muls/divs/divu gets preferred over large expansions of
+                        shifts & adds.
+                        -- Kevin Kofler */
 #define MULL_COST (TARGET_68060 ? 2 : TARGET_68040 ? 5 : (TARGET_COLDFIRE && !TARGET_5200) ? 3 : TARGET_COLDFIRE ? 10 : 13)
-#define MULW_COST (TARGET_68060 ? 2 : TARGET_68040 ? 3 : TARGET_68020 ? 8 : \
-			(TARGET_COLDFIRE && !TARGET_5200) ? 2 : 5)
-#define DIVW_COST (TARGET_68020 ? 27 : TARGET_CF_HWDIV ? 11 : 12)
+#define MULW_COST (optimize_size ? 3 : (TARGET_68060 ? 2 : TARGET_68040 ? 3 : TARGET_68020 ? 8 : \
+			(TARGET_COLDFIRE && !TARGET_5200) ? 2 : 5))
+#define DIVW_COST (optimize_size ? 3 : (TARGET_68020 ? 27 : TARGET_CF_HWDIV ? 11 : 12))
+#define UDIVW_COST (optimize_size ? 6 : (TARGET_68020 ? 27 : TARGET_CF_HWDIV ? 11 : 12))
 
     case PLUS:
       /* An lea costs about three times as much as a simple add.  */
@@ -1597,11 +1784,15 @@
         {
 	  if (GET_CODE (XEXP (x, 1)) == CONST_INT)
 	    {
+/* (TIGCC 20030705) shifts costs under -Os are instruction counts, not cycle counts -- Kevin Kofler */ \
+/* (TIGCC 20050210) lsl #2 is cheaper than 2 adds even when optimizing for speed.
+                    This ugly hack (making long shifts "cost less" than word
+                    shifts) accounts for that. */ \
 	      if (INTVAL (XEXP (x, 1)) < 16)
-	        *total = COSTS_N_INSNS (2) + INTVAL (XEXP (x, 1)) / 2;
+	        *total = COSTS_N_INSNS (2) + INTVAL (XEXP (x, 1)) / (optimize_size ? 9 : GET_MODE (x) == SImode ? 3 : 2);
 	      else
 	        /* We're using clrw + swap for these cases.  */
-	        *total = COSTS_N_INSNS (4) + (INTVAL (XEXP (x, 1)) - 16) / 2;
+	        *total = COSTS_N_INSNS (4) + (INTVAL (XEXP (x, 1)) - 16) / (optimize_size ? 9 : GET_MODE (x) == SImode ? 3 : 2);
 	    }
 	  else
 	    *total = COSTS_N_INSNS (10); /* worst case */
@@ -1634,10 +1825,10 @@
         *total = COSTS_N_INSNS (MULL_COST);
       return true;
 
+/* (TIGCC 20030705) distinguish signed vs. unsigned division */ \
+/* - ext is cheaper than the unsigned equivalent -- Kevin Kofler */ \
     case DIV:
-    case UDIV:
     case MOD:
-    case UMOD:
       if (GET_MODE (x) == QImode || GET_MODE (x) == HImode)
         *total = COSTS_N_INSNS (DIVW_COST);	/* div.w */
       else if (TARGET_CF_HWDIV)
@@ -1646,6 +1837,16 @@
 	*total = COSTS_N_INSNS (43);		/* div.l */
       return true;
 
+    case UDIV:							\
+    case UMOD:							\
+      if (GET_MODE (x) == QImode || GET_MODE (x) == HImode)
+        *total = COSTS_N_INSNS (UDIVW_COST);	/* div.w */
+      else if (TARGET_CF_HWDIV)
+        *total = COSTS_N_INSNS (18);
+      else
+	*total = COSTS_N_INSNS (43);		/* div.l */
+      return true;
+
     default:
       return false;
     }
@@ -1862,6 +2063,24 @@
   return "move%.b %1,%0";
 }
 
+static const char *
+output_move_himode_const (rtx *operands)
+{
+  if (operands[1] == const0_rtx
+      && (DATA_REG_P (operands[0])
+	  || GET_CODE (operands[0]) == MEM)
+      /* clr insns on 68000 read before writing.
+	 This isn't so on the 68010, but we have no TARGET_68010.  */
+      && ((TARGET_68020 || TARGET_5200)
+	  || !(GET_CODE (operands[0]) == MEM
+	       && MEM_VOLATILE_P (operands[0]))))
+    return "clr%.w %0";
+  else if (operands[1] == const0_rtx
+	   && ADDRESS_REG_P (operands[0]))
+    return "sub%.w %0,%0";
+  return "move%.w %1,%0";
+}
+
 const char *
 output_move_stricthi (rtx *operands)
 {
@@ -1886,6 +2105,17 @@
   return "move%.b %1,%0";
 }
 
+/* (TIGCC) Return the best assembler insn template
+   for moving operands[1] into operands[0] as a halfword.  */
+
+static const char *
+halfsinglemove_string (rtx *operands)
+{
+  if (GET_CODE (operands[1]) == CONST_INT)
+    return output_move_himode_const (operands);
+  return "move%.w %1,%0";
+}
+
 /* Return the best assembler insn template
    for moving operands[1] into operands[0] as a fullword.  */
 
@@ -1962,10 +2192,14 @@
       operands[0] = XEXP (XEXP (operands[0], 0), 0);
       if (size == 12)
         output_asm_insn ("sub%.l #12,%0", operands);
+      else if (size == 10)
+        output_asm_insn ("sub%.l #10,%0", operands);
       else
         output_asm_insn ("subq%.l #8,%0", operands);
-      if (GET_MODE (operands[1]) == XFmode)
+      if (GET_MODE (operands[0]) == XFmode)
 	operands[0] = gen_rtx_MEM (XFmode, operands[0]);
+      else if (GET_MODE (operands[0]) == BFmode)
+	operands[0] = gen_rtx_MEM (BFmode, operands[0]);
       else if (GET_MODE (operands[0]) == DFmode)
 	operands[0] = gen_rtx_MEM (DFmode, operands[0]);
       else
@@ -1977,10 +2211,14 @@
       operands[1] = XEXP (XEXP (operands[1], 0), 0);
       if (size == 12)
         output_asm_insn ("sub%.l #12,%1", operands);
+      else if (size == 10)
+        output_asm_insn ("sub%.l #10,%1", operands);
       else
         output_asm_insn ("subq%.l #8,%1", operands);
       if (GET_MODE (operands[1]) == XFmode)
 	operands[1] = gen_rtx_MEM (XFmode, operands[1]);
+      else if (GET_MODE (operands[1]) == BFmode)
+	operands[1] = gen_rtx_MEM (BFmode, operands[1]);
       else if (GET_MODE (operands[1]) == DFmode)
 	operands[1] = gen_rtx_MEM (DFmode, operands[1]);
       else
@@ -2016,7 +2254,7 @@
       else if (optype0 == OFFSOP)
 	{
 	  middlehalf[0] = adjust_address (operands[0], SImode, 4);
-	  latehalf[0] = adjust_address (operands[0], SImode, size - 4);
+	  latehalf[0] = adjust_address (operands[0], SImode, 8);
 	}
       else
 	{
@@ -2032,7 +2270,7 @@
       else if (optype1 == OFFSOP)
 	{
 	  middlehalf[1] = adjust_address (operands[1], SImode, 4);
-	  latehalf[1] = adjust_address (operands[1], SImode, size - 4);
+	  latehalf[1] = adjust_address (operands[1], SImode, 8);
 	}
       else if (optype1 == CNSTOP)
 	{
@@ -2060,8 +2298,66 @@
 	  latehalf[1] = operands[1];
 	}
     }
-  else
-    /* size is not 12: */
+  else if (size == 10)
+    {
+      if (optype0 == REGOP)
+	{
+	  latehalf[0] = gen_rtx_REG (HImode, REGNO (operands[0]) + 2);
+	  middlehalf[0] = gen_rtx_REG (SImode, REGNO (operands[0]) + 1);
+	}
+      else if (optype0 == OFFSOP)
+	{
+	  middlehalf[0] = adjust_address (operands[0], SImode, 4);
+	  latehalf[0] = adjust_address (operands[0], SImode, 8);
+	}
+      else
+	{
+	  middlehalf[0] = operands[0];
+	  latehalf[0] = operands[0];
+	}
+
+      if (optype1 == REGOP)
+	{
+	  latehalf[1] = gen_rtx_REG (HImode, REGNO (operands[1]) + 2);
+	  middlehalf[1] = gen_rtx_REG (SImode, REGNO (operands[1]) + 1);
+	}
+      else if (optype1 == OFFSOP)
+	{
+	  middlehalf[1] = adjust_address (operands[1], SImode, 4);
+	  latehalf[1] = adjust_address (operands[1], SImode, 8);
+	}
+      else if (optype1 == CNSTOP)
+	{
+	  if (GET_CODE (operands[1]) == CONST_DOUBLE)
+	    {
+	      REAL_VALUE_TYPE r;
+	      long l[3];
+
+	      abort ();
+	      REAL_VALUE_FROM_CONST_DOUBLE (r, operands[1]);
+	      REAL_VALUE_TO_TARGET_LONG_DOUBLE (r, l);
+	      operands[1] = GEN_INT (l[0]);
+	      middlehalf[1] = GEN_INT (l[1]);
+	      latehalf[1] = GEN_INT (l[2]);
+	    }
+	  else if (CONSTANT_P (operands[1]))
+	    {
+	      /* actually, no non-CONST_DOUBLE constant should ever
+		 appear here.  */
+	      abort ();
+	      if (GET_CODE (operands[1]) == CONST_INT && INTVAL (operands[1]) < 0)
+		latehalf[1] = constm1_rtx;
+	      else
+		latehalf[1] = const0_rtx;
+	    }
+	}
+      else
+	{
+	  middlehalf[1] = operands[1];
+	  latehalf[1] = operands[1];
+	}
+    }
+  else    /* size is neither 12 or 10: */
     {
       if (optype0 == REGOP)
 	latehalf[0] = gen_rtx_REG (SImode, REGNO (operands[0]) + 1);
@@ -2086,7 +2382,16 @@
   if (optype0 == PUSHOP
       && REGNO (XEXP (XEXP (operands[0], 0), 0)) == STACK_POINTER_REGNUM
       && reg_overlap_mentioned_p (stack_pointer_rtx, operands[1]))
+  {
+    if (size==10) {
+      /* (TIGCC 20040219) The above is not quite right for size==10. What we
+         have to do here is: (1) move.w operands[1]+8,-(%sp);
+         (2) move.l operands[1]+6,-(%sp); (3) move.l operands[1]+6,-(%sp).
+         -- Kevin Kofler */
+      operands[1] = middlehalf[1] = adjust_address (operands[1], SImode, 6);
+    } else
     operands[1] = middlehalf[1] = latehalf[1];
+  }
 
   /* For (set (reg:DI N) (mem:DI ... (reg:SI N) ...)),
      if the upper part of reg N does not appear in the MEM, arrange to
@@ -2114,6 +2419,12 @@
 	      middlehalf[1] = adjust_address (operands[1], DImode, size - 8);
 	      latehalf[1] = adjust_address (operands[1], DImode, size - 4);
 	    }
+	  else if( GET_MODE (operands[1]) == BFmode )
+	    {
+	      operands[1] = gen_rtx_MEM (BFmode, latehalf[0]);
+	      middlehalf[1] = adjust_address (operands[1], DImode, 4);
+	      latehalf[1] = adjust_address (operands[1], DImode, 8);
+	    }
 	  else
 	    {
 	      operands[1] = gen_rtx_MEM (DImode, latehalf[0]);
@@ -2143,6 +2454,30 @@
 	  output_asm_insn (singlemove_string (middlehalf), middlehalf);
 	  return "";
 	}
+      else if (size == 10
+	       && reg_overlap_mentioned_p (middlehalf[0],
+					   XEXP (operands[1], 0)))
+	{
+	  /* Check for two regs used by both source and dest.
+	     Note that this can't happen if the dest is all data regs.
+	     It can happen if the dest is d6, d7, a0.
+	     But in that case, latehalf is an addr reg, so
+	     the code at compadr does ok.  */
+
+	  if (reg_overlap_mentioned_p (testlow, XEXP (operands[1], 0))
+	      || reg_overlap_mentioned_p (latehalf[0], XEXP (operands[1], 0)))
+	    goto compadr;
+
+	  /* JRV says this can't happen: */
+	  if (addreg0 || addreg1)
+	    abort ();
+
+	  /* Only the middle reg conflicts; simply put it last. */
+	  output_asm_insn (singlemove_string (operands), operands);
+	  output_asm_insn (halfsinglemove_string (latehalf), latehalf);
+	  output_asm_insn (singlemove_string (middlehalf), middlehalf);
+	  return "";
+	}
       else if (reg_overlap_mentioned_p (testlow, XEXP (operands[1], 0)))
 	/* If the low half of dest is mentioned in the source memory
 	   address, the arrange to emit the move late half first.  */
@@ -2166,21 +2501,24 @@
       /* Make any unoffsettable addresses point at high-numbered word.  */
       if (addreg0)
 	{
-	  if (size == 12)
+	  if (size == 12 || size == 10)
 	    output_asm_insn ("addq%.l #8,%0", &addreg0);
 	  else
 	    output_asm_insn ("addq%.l #4,%0", &addreg0);
 	}
       if (addreg1)
 	{
-	  if (size == 12)
+	  if (size == 12 || size == 10)
 	    output_asm_insn ("addq%.l #8,%0", &addreg1);
 	  else
 	    output_asm_insn ("addq%.l #4,%0", &addreg1);
 	}
 
       /* Do that word.  */
-      output_asm_insn (singlemove_string (latehalf), latehalf);
+      if (size == 10)
+        output_asm_insn (halfsinglemove_string (latehalf), latehalf);
+      else
+        output_asm_insn (singlemove_string (latehalf), latehalf);
 
       /* Undo the adds we just did.  */
       if (addreg0)
@@ -2188,7 +2526,7 @@
       if (addreg1)
 	output_asm_insn ("subq%.l #4,%0", &addreg1);
 
-      if (size == 12)
+      if (size == 12 || size == 10)
 	{
 	  output_asm_insn (singlemove_string (middlehalf), middlehalf);
 	  if (addreg0)
@@ -2206,7 +2544,7 @@
   output_asm_insn (singlemove_string (operands), operands);
 
   /* Do the middle one of the three words for long double */
-  if (size == 12)
+  if (size == 12 || size == 10)
     {
       if (addreg0)
 	output_asm_insn ("addq%.l #4,%0", &addreg0);
@@ -2223,19 +2561,22 @@
     output_asm_insn ("addq%.l #4,%0", &addreg1);
 
   /* Do that word.  */
-  output_asm_insn (singlemove_string (latehalf), latehalf);
+  if (size == 10)
+    output_asm_insn (halfsinglemove_string (latehalf), latehalf);
+  else
+    output_asm_insn (singlemove_string (latehalf), latehalf);
 
   /* Undo the adds we just did.  */
   if (addreg0)
     {
-      if (size == 12)
+      if (size == 12 || size == 10)
         output_asm_insn ("subq%.l #8,%0", &addreg0);
       else
         output_asm_insn ("subq%.l #4,%0", &addreg0);
     }
   if (addreg1)
     {
-      if (size == 12)
+      if (size == 12 || size == 10)
         output_asm_insn ("subq%.l #8,%0", &addreg1);
       else
         output_asm_insn ("subq%.l #4,%0", &addreg1);
@@ -2565,6 +2906,8 @@
 int
 floating_exact_log2 (rtx x)
 {
+abort();
+#if 0
   REAL_VALUE_TYPE r, r1;
   int exp;
 
@@ -2579,6 +2922,7 @@
     return exp;
 
   return 0;
+#endif /* 0 */
 }
 
 /* A C compound statement to output to stdio stream STREAM the
@@ -2625,6 +2969,8 @@
    'x' for float insn (print a CONST_DOUBLE as a float rather than in hex),
        or print pair of registers as rx:ry.
 
+(TIGCC 20040222) 'A' like 'o', but for addresses.
+
    */
 
 void
@@ -2665,6 +3011,14 @@
 		  && TARGET_PCREL);
       output_addr_const (file, XEXP (op, 0));
     }
+  else if (letter == 'A') /* (TIGCC 20040222) */
+    {
+      if (TARGET_PCREL) {
+        target_flags&=~MASK_PCREL; /* ugly hack, but works */
+        print_operand_address(file,op);
+        target_flags|=MASK_PCREL;
+      } else print_operand_address(file,op);
+    }
   else if (GET_CODE (op) == REG)
     {
       if (letter == 'R')
@@ -2677,13 +3031,24 @@
   else if (GET_CODE (op) == MEM)
     {
       output_address (XEXP (op, 0));
+      /* TIGCC Patch: This is a very bad try to implement addresses relative to a register.
+         Julien Muchembled says this should work.
+         At least it should if only one file is used.
+         (TIGCC 20040808) Added CONST. A MEM(CONST) is used for sym+const addressing. This
+                          needs to be made reg-relative too. -- Kevin Kofler  */
+      if (TARGET_REG_RELATIVE && (GET_CODE (XEXP (op, 0)) == SYMBOL_REF || GET_CODE (XEXP (op, 0)) == LABEL_REF || GET_CODE (XEXP (op, 0)) == CODE_LABEL || GET_CODE (XEXP (op, 0)) == CONST))
+        fprintf (file, "-__relation(%%%s)", TARGET_RELATION_REG);
+      else
+	{
       if (letter == 'd' && ! TARGET_68020
 	  && CONSTANT_ADDRESS_P (XEXP (op, 0))
 	  && !(GET_CODE (XEXP (op, 0)) == CONST_INT
 	       && INTVAL (XEXP (op, 0)) < 0x8000
 	       && INTVAL (XEXP (op, 0)) >= -0x8000))
 	fprintf (file, MOTOROLA ? ".l" : ":l");
+	}
     }
+#if 0
   else if (GET_CODE (op) == CONST_DOUBLE && GET_MODE (op) == SFmode)
     {
       REAL_VALUE_TYPE r;
@@ -2702,6 +3067,7 @@
       REAL_VALUE_FROM_CONST_DOUBLE (r, op);
       ASM_OUTPUT_DOUBLE_OPERAND (file, r);
     }
+#endif /* 0 */
   else
     {
       /* Use `print_operand_address' instead of `output_addr_const'
@@ -3199,6 +3565,166 @@
   return "or%.l %2,%0";
 }
 
+/* Argument-passing support functions.  */
+
+/* Initialize a variable CUM of type CUMULATIVE_ARGS
+   for a call to a function whose data type is FNTYPE.
+   For a library call, FNTYPE is 0.  */
+
+static void
+m68k_init_cumulative_args (CUMULATIVE_ARGS *cum, tree fntype, tree fndecl)
+{
+  cum->last_arg_reg = -1;
+  cum->regs_already_used = 0;
+  if (fntype)
+    {
+      if (lookup_attribute ("stkparm", TYPE_ATTRIBUTES (fntype)))
+	cum->num_of_regs = 0;
+      else
+	{
+	  tree ratree = lookup_attribute ("regparm", TYPE_ATTRIBUTES (fntype));
+	  if (ratree)
+	    {
+	      cum->num_of_regs = m68k_regparm ? m68k_regparm
+					      : M68K_DEFAULT_REGPARM;
+	      if (TREE_VALUE (ratree)
+		  && TREE_CODE (TREE_VALUE (ratree)) == TREE_LIST)
+		{
+		  tree num_of_regs = TREE_VALUE (TREE_VALUE (ratree));
+		  cum->num_of_regs =
+		    num_of_regs ? TREE_INT_CST_LOW (num_of_regs) :
+		      (m68k_regparm ? m68k_regparm : M68K_DEFAULT_REGPARM);
+		}
+	    }
+/* (TIGCC 20050208) Use register calling convention for local functions when
+                    possible. Partially copied from i386.c. */
+	  else if (fndecl && flag_unit_at_a_time)
+	    {
+	      struct cgraph_local_info *i = cgraph_local_info (fndecl);
+	      if (i && i->local)
+	        {
+	          cum->num_of_regs = m68k_regparm ? m68k_regparm
+	                             : M68K_DEFAULT_REGPARM;
+	        }
+	      else
+	        cum->num_of_regs = m68k_regparm;
+	    }
+	  else
+	    cum->num_of_regs = m68k_regparm;
+	}
+    }
+  else /* Libcall.  */
+    cum->num_of_regs = 0;
+
+  if (cum->num_of_regs)
+    {
+      /* If this is a vararg call, put all arguments on stack.  */
+      tree param, next_param;
+      for (param = TYPE_ARG_TYPES (fntype); param; param = next_param)
+	{
+	  next_param = TREE_CHAIN (param);
+	  if (!next_param && TREE_VALUE (param) != void_type_node)
+	    cum->num_of_regs = 0;
+	}
+    }
+
+#if ! defined (PCC_STATIC_STRUCT_RETURN) && defined (M68K_STRUCT_VALUE_REGNUM)
+  /* If return value is a structure, and we pass the buffer address in a
+     register, we can't use this register for our own purposes.
+     FIXME: Something similar would be useful for static chain.  */
+  if (fntype && aggregate_value_p (TREE_TYPE (fntype), fntype))
+    cum->regs_already_used |= (1 << M68K_STRUCT_VALUE_REGNUM);
+#endif
+}
+
+/* Update the data in CUM to advance over an argument.  */
+
+static void
+m68k_function_arg_advance (CUMULATIVE_ARGS *cum)
+{
+  if (cum->last_arg_reg != -1)
+    {
+      int count;
+      for (count = 0; count < cum->last_arg_len; count++)
+	cum->regs_already_used |= (1 << (cum->last_arg_reg + count));
+      cum->last_arg_reg = -1;
+    }
+}
+
+/* Define where to put the arguments to a function.
+   Value is zero to push the argument on the stack,
+   or a hard register in which to store the argument.
+
+   MODE is the argument's machine mode.
+   TYPE is the data type of the argument (as a tree).
+   This is null for libcalls where that information may
+    not be available.
+   CUM is a variable of type CUMULATIVE_ARGS which gives info about
+    the preceding args and about the function being called.  */
+
+static struct rtx_def *
+m68k_function_arg (CUMULATIVE_ARGS *cum, enum machine_mode mode, tree type)
+{
+  if (cum->num_of_regs)
+    {
+      int regbegin = -1, altregbegin = -1, len;
+
+      /* FIXME: The last condition below is a workaround for a bug.  */
+      if (TARGET_68881 && FLOAT_MODE_P (mode) &&
+	  GET_MODE_UNIT_SIZE (mode) <= 12 &&
+	  (GET_MODE_CLASS (mode) != MODE_COMPLEX_FLOAT || mode == SCmode))
+	{
+	  regbegin = 16; /* FPx */
+	  len = GET_MODE_NUNITS (mode);
+	}
+      /* FIXME: Two last conditions below are workarounds for bugs.  */
+      else if (INTEGRAL_MODE_P (mode) && mode !=CQImode && mode != CHImode)
+	{
+	  if (POINTER_TYPE_P (type))
+	    regbegin = 8; /* Ax */
+	  else
+	    regbegin = 0; /* Dx */
+	  altregbegin = 8 - regbegin;
+	  len = (GET_MODE_SIZE (mode) + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD;
+	}
+
+      if (regbegin != -1)
+	{
+	  int reg;
+	  long mask;
+
+look_for_reg:
+	  mask = 1 << regbegin;
+	  for (reg = 0; reg < cum->num_of_regs; reg++, mask <<= 1)
+	    if (!(cum->regs_already_used & mask))
+	      {
+		int end;
+		for (end = reg; end < cum->num_of_regs && end < reg + len;
+		     end++, mask <<= 1)
+		  if (cum->regs_already_used & mask)
+		    break;
+		if (end == reg + len)
+		  {
+		    cum->last_arg_reg = reg + regbegin;
+		    cum->last_arg_len = len;
+		    break;
+		  }
+	      }
+
+	  if (reg == cum->num_of_regs && altregbegin != -1)
+	    {
+	      regbegin = altregbegin;
+	      altregbegin = -1;
+	      goto look_for_reg;
+	    }
+	}
+
+      if (cum->last_arg_reg != -1)
+	return gen_rtx_REG (mode, cum->last_arg_reg);
+    }
+  return 0;
+}
+
 const char *
 output_xorsi3 (rtx *operands)
 {
@@ -3243,13 +3769,28 @@
 			     tree decl ATTRIBUTE_UNUSED)
 {
   char flagchar;
-
-  if (flags & SECTION_WRITE)
+  /* (TIGCC 20040725) Constant/string merging flags for TIGCC-extended COFF.
+                      SECTION_STRINGS is abused for the unaligned flag. */
+  const char *xflags = "";
+
+  /* (TIGCC 20040619) Handle BSS sections properly with -fdata-sections.
+                      -- Kevin Kofler*/
+  if ((flags & SECTION_BSS) && !TARGET_NO_BSS)
+    flagchar = 'b';
+  /* (TIGCC 20040620) Handle rodata sections properly with -fdata-sections.
+                      -- Kevin Kofler*/
+  else if ((flags & SECTION_WRITE)
+           || (!TARGET_RODATA_TO_TEXT && !(flags & SECTION_CODE)))
     flagchar = 'd';
   else
     flagchar = 'x';
 
-  fprintf (asm_out_file, "\t.section\t%s,\"%c\"\n", name, flagchar);
+  if (flags & SECTION_MERGE)
+    xflags = (flags & SECTION_STRINGS)?"mu":"m";
+  else if (flags & SECTION_STRINGS)
+    xflags = "u";
+
+  fprintf (asm_out_file, "\t.section\t%s,\"%c%s\"\n", name, flagchar, xflags);
 }
 
 #endif /* M68K_TARGET_COFF */
@@ -3302,7 +3843,7 @@
   if (flag_pic)
     {
       if (TARGET_PCREL)
-	fmt = "bra.l %o0";
+	fmt = "bra %o0"; /* (TIGCC 20040222, 20050204) No long branches please... */
       else if ((flag_pic == 1) || TARGET_68020)
 	{
 	  if (MOTOROLA)
@@ -3377,7 +3918,10 @@
     {
 	/* Address Registers, can't hold bytes, can hold aggregate if
 	   fits in.  */
-	if (GET_MODE_SIZE (mode) == 1)
+	/* (TIGCC 20050924) We can put bytes in address registers on non-Coldfire.
+	   GCC just uses word moves where appropriate. This always worked for us.
+	   -- Kevin Kofler */
+	if (TARGET_COLDFIRE && GET_MODE_SIZE (mode) == 1)
 	  return false;
 	if (regno + GET_MODE_SIZE (mode) / 4 <= 16)
 	  return true;
@@ -3393,3 +3937,127 @@
     }
   return false;
 }
+
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+
+/* Initialize a variable CUM of type CUMULATIVE_ARGS
+   for a call to a function whose data type is FNTYPE.
+   For a library call, FNTYPE is 0.  */
+
+void
+amigaos_init_cumulative_args(CUMULATIVE_ARGS *cum, tree fntype, tree fndecl)
+{
+  m68k_init_cumulative_args(cum, fntype, fndecl);
+
+  if (fntype)
+    cum->formal_type=TYPE_ARG_TYPES(fntype);
+  else /* Call to compiler-support function. */
+    cum->formal_type=0;
+}
+
+/* Update the data in CUM to advance over an argument.  */
+
+void
+amigaos_function_arg_advance(CUMULATIVE_ARGS *cum)
+{
+  m68k_function_arg_advance(cum);
+
+  if (cum->formal_type)
+    cum->formal_type=TREE_CHAIN((tree)cum->formal_type);
+}
+
+/* A C expression that controls whether a function argument is passed
+   in a register, and which register. */
+
+struct rtx_def *
+amigaos_function_arg(CUMULATIVE_ARGS *cum, enum machine_mode mode,
+  tree type)
+{
+  tree asmtree;
+  if (cum->formal_type && TREE_VALUE((tree)cum->formal_type)
+      && (asmtree=lookup_attribute("asm",
+			TYPE_ATTRIBUTES(TREE_VALUE((tree)cum->formal_type)))))
+    {
+      int i;
+#if 0
+      /* See c-decl.c/push_parm_decl for an explanation why this doesn't work.
+       */
+      cum->last_arg_reg=TREE_INT_CST_LOW(TREE_VALUE(TREE_VALUE(asmtree)));
+#else
+      cum->last_arg_reg=TREE_INT_CST_LOW(TREE_VALUE(asmtree));
+#endif
+      cum->last_arg_len=HARD_REGNO_NREGS(cum->last_arg_reg, mode);
+
+      for (i=0; i<cum->last_arg_len; i++)
+	if (cum->regs_already_used & (1 << (cum->last_arg_reg+i)))
+	  {
+	    error("two parameters allocated for one register");
+	    break;
+	  }
+      return gen_rtx_REG (mode, cum->last_arg_reg);
+    }
+  else
+    return (struct rtx_def *)m68k_function_arg(cum, mode, type);
+}
+
+/* Return zero if the attributes on TYPE1 and TYPE2 are incompatible,
+   one if they are compatible, and two if they are nearly compatible
+   (which causes a warning to be generated). */
+
+int
+comp_amigaos_type_attributes(tree type1, tree type2)
+{
+  int ret;
+  if ((ret=comp_m68k_type_attributes(type1, type2))!=1)
+    return ret;
+
+  /* Functions or methods are incompatible if they specify mutually exclusive
+     ways of passing arguments. */
+  if (TREE_CODE(type1)==FUNCTION_TYPE || TREE_CODE(type1)==METHOD_TYPE)
+    {
+      tree arg1, arg2;
+      arg1=TYPE_ARG_TYPES(type1);
+      arg2=TYPE_ARG_TYPES(type2);
+      for (; arg1 && arg2; arg1=TREE_CHAIN(arg1), arg2=TREE_CHAIN(arg2))
+	if (TREE_VALUE(arg1) && TREE_VALUE(arg2))
+	  {
+	    tree asm1, asm2;
+	    asm1=lookup_attribute("asm", TYPE_ATTRIBUTES(TREE_VALUE(arg1)));
+	    asm2=lookup_attribute("asm", TYPE_ATTRIBUTES(TREE_VALUE(arg2)));
+	    if (asm1 && asm2)
+	      {
+		if (TREE_INT_CST_LOW(TREE_VALUE(asm1))!=
+		    TREE_INT_CST_LOW(TREE_VALUE(asm2)))
+		  return 0; /* Two different registers specified. */
+	      }
+	    else
+	      if (asm1 || asm2)
+		return 0; /* "asm" used in only one type. */
+	  }
+    }
+  return 1;
+}
+
+/* end-TIGCC-local (regparms) */
+
+/* (TIGCC) If TARGET_MERGE_SECTIONS is set (on by default), we need an explicit
+   '.text' or '.data' (depending on TARGET_MERGE_TO_DATA) statement at the
+   beginning of the file. */
+
+void m68k_asm_file_start(void)
+{
+	output_file_directive (asm_out_file, main_input_filename);
+	fprintf (asm_out_file, "#NO_APP\n");
+	if (TARGET_REG_RELATIVE)
+		fprintf (asm_out_file, "\t.set __relation,__ld_entry_point_plus_0x8000\n\t.xdef __ref_all___reg_relative_%s\n", TARGET_RELATION_REG);
+	fprintf (asm_out_file, (TARGET_MERGE_SECTIONS?(TARGET_MERGE_TO_DATA?"\t.data\ntigcc_compiled.:\n":"\t.text\ntigcc_compiled.:\n"):"tigcc_compiled.:\n"));
+}
+
+/* (TIGCC 20050424) Everything which is not a CONST_DOUBLE has no business of
+                    being in the constant pool. This is especially valid for
+                    expressions containing relocations. -- Kevin Kofler */
+static bool m68k_cannot_force_const_mem (rtx r)
+{
+  return (GET_CODE (r) != CONST_DOUBLE);
+}
+
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k.h gcc-4.1-20051216-src/gcc/config/m68k/m68k.h
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k.h	2005-07-12 01:32:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k.h	2005-12-19 02:42:39.000000000 +0100
@@ -113,6 +113,10 @@
 /* Set the default.  */
 #define INT_OP_GROUP INT_OP_DOT_WORD
 
+/* Access everything in relation to a specific register */
+#define MASK_REG_RELATIVE	(1<<30)
+#define TARGET_REG_RELATIVE	(target_flags & MASK_REG_RELATIVE)
+
 /* Compile for a CPU32.  A 68020 without bitfields is a good
    heuristic for a CPU32.  */
 #define TARGET_CPU32	(TARGET_68020 && !TARGET_BITFIELD)
@@ -126,6 +130,8 @@
 /* These are meant to be redefined in the host dependent files */
 #define SUBTARGET_OVERRIDE_OPTIONS
 
+extern char TARGET_RELATION_REG[];
+
 /* target machine storage layout */
 
 #define LONG_DOUBLE_TYPE_SIZE 80
@@ -141,7 +147,7 @@
 
 #define UNITS_PER_WORD 4
 
-#define PARM_BOUNDARY (TARGET_SHORT ? 16 : 32)
+#define PARM_BOUNDARY 16
 #define STACK_BOUNDARY 16
 #define FUNCTION_BOUNDARY 16
 #define EMPTY_FIELD_BOUNDARY 16
@@ -175,7 +181,9 @@
 #define FIRST_PSEUDO_REGISTER 25
 
 /* All m68k targets (except AmigaOS) use %a5 as the PIC register  */
-#define PIC_OFFSET_TABLE_REGNUM (flag_pic ? 13 : INVALID_REGNUM)
+/* (TIGCC 20050209) TIGCC doesn't use a PIC register, and besides this was
+                    forgetting the -mpcrel case.  */
+#define PIC_OFFSET_TABLE_REGNUM (INVALID_REGNUM)
 
 /* 1 for registers that have pervasive standard uses
    and are not available for the register allocator.
@@ -375,6 +383,9 @@
    `S' is for operands that satisfy 'm' when -mpcrel is in effect.
    `T' is for operands that satisfy 's' when -mpcrel is not in effect.
    `U' is for register offset addressing.  */
+/* (TIGCC 20040808) Under -freg-relative-an, the same restrictions on 's'/'T' as
+                    for -mpcrel apply. We can't use immediates as labels if
+                    we need to output reg-relative code. -- Kevin Kofler  */
 #define EXTRA_CONSTRAINT(OP,CODE)			\
   (((CODE) == 'S')					\
    ? (TARGET_PCREL					\
@@ -384,7 +395,7 @@
 	  || GET_CODE (XEXP (OP, 0)) == CONST))		\
    : 							\
   (((CODE) == 'T')					\
-   ? ( !TARGET_PCREL 					\
+   ? ( (!TARGET_PCREL && !TARGET_REG_RELATIVE) 					\
       && (GET_CODE (OP) == SYMBOL_REF			\
 	  || GET_CODE (OP) == LABEL_REF			\
 	  || GET_CODE (OP) == CONST))			\
@@ -486,24 +497,59 @@
 
 #define PCC_STATIC_STRUCT_RETURN
 
-/* On the m68k, all arguments are usually pushed on the stack.  */
-#define FUNCTION_ARG_REGNO_P(N) 0
-
-/* On the m68k, this is a single integer, which is a number of bytes
-   of arguments scanned so far.  */
-#define CUMULATIVE_ARGS int
-
-/* On the m68k, the offset starts at 0.  */
-#define INIT_CUMULATIVE_ARGS(CUM, FNTYPE, LIBNAME, INDIRECT, N_NAMED_ARGS) \
- ((CUM) = 0)
+/* Define this if explicit register specification for parameters
+   is supported.  */
+
+#define EXPLICIT_REGPARM
+
+#define FUNCTION_ARG_REGNO_P(N)			\
+  (((N) >= 0 && (N) < M68K_MAX_REGPARM)		\
+   || ((N) >= 8 && (N) < 8 + M68K_MAX_REGPARM)	\
+   || (TARGET_68881 && (N) >= 16 && (N) < 16 + M68K_MAX_REGPARM))
+
+/* On the m68k, this is a structure:
+   num_of_regs: number of data, address and float registers to use for
+     arguments passing (if it's 2, than pass arguments in d0, d1, a0, a1,
+     fp0 and fp1). 0 - pass everything on stack. vararg calls are
+     always passed entirely on stack.
+   regs_already_used: bitmask of the already used registers.
+   last_arg_reg: register number of the most recently passed argument.
+     -1 if passed on stack.
+   last_arg_len: number of registers used by the most recently passed
+     argument.
+   formal_type: formal type of the current argument.
+*/
+
+struct m68k_args
+{
+  int num_of_regs;
+  long regs_already_used;
+  int last_arg_reg;
+  int last_arg_len;
+  void *formal_type;
+};
+
+#define CUMULATIVE_ARGS struct m68k_args
+
+/* Max. number of data, address and float registers to be used for passing
+   integer, pointer and float arguments when TARGET_REGPARM.
+   It's 6, so d0-d5, a0-a5 and fp0-fp5 can be used.  */
+
+#define M68K_MAX_REGPARM 6  /* was 4 in the original patch */
+
+/* The default number of data, address and float registers to use when
+   user specified '-mregparm' switch, not '-mregparm=<value>' option.  */
+
+#define M68K_DEFAULT_REGPARM 2  /* was 2 in the orginial patch */
+
+#define INIT_CUMULATIVE_ARGS(CUM, FNTYPE, LIBNAME, FNDECL, N_NAMED_ARGS) \
+  (amigaos_init_cumulative_args (&(CUM), (FNTYPE), (FNDECL)))
 
 #define FUNCTION_ARG_ADVANCE(CUM, MODE, TYPE, NAMED)	\
- ((CUM) += ((MODE) != BLKmode			\
-	    ? (GET_MODE_SIZE (MODE) + 3) & ~3	\
-	    : (int_size_in_bytes (TYPE) + 3) & ~3))
+  (amigaos_function_arg_advance (&(CUM)))
 
-/* On the m68k all args are always pushed.  */
-#define FUNCTION_ARG(CUM, MODE, TYPE, NAMED) 0
+#define FUNCTION_ARG(CUM, MODE, TYPE, NAMED) \
+  ((struct rtx_def *)amigaos_function_arg (&(CUM), (MODE), (TYPE)))
 
 #define FUNCTION_PROFILER(FILE, LABELNO)  \
   asm_fprintf (FILE, "\tlea %LLP%d,%Ra0\n\tjsr mcount\n", (LABELNO))
@@ -639,7 +685,11 @@
 
 /* Nonzero if the constant value X is a legitimate general operand.
    It is given that X satisfies CONSTANT_P or is a CONST_DOUBLE.  */
-#define LEGITIMATE_CONSTANT_P(X) (GET_MODE (X) != XFmode)
+/* (TIGCC 20040808) If reg-relative, we need to reject "constants" of the #label
+                    or #label+const form. -- Kevin Kofler  */
+
+#define LEGITIMATE_CONSTANT_P(X) (!TARGET_REG_RELATIVE \
+                                  || !pcrel_address (X, VOIDmode))
 
 #ifndef REG_OK_STRICT
 #define PCREL_GENERAL_OPERAND_OK 0
@@ -950,15 +1000,19 @@
 #define ASM_OUTPUT_SKIP(FILE,SIZE)  \
   fprintf (FILE, "\t.skip %u\n", (int)(SIZE))
 
+#ifndef ASM_OUTPUT_COMMON
 #define ASM_OUTPUT_COMMON(FILE, NAME, SIZE, ROUNDED)  \
 ( fputs (".comm ", (FILE)),			\
   assemble_name ((FILE), (NAME)),		\
   fprintf ((FILE), ",%u\n", (int)(ROUNDED)))
+#endif
 
+#ifndef ASM_OUTPUT_LOCAL
 #define ASM_OUTPUT_LOCAL(FILE, NAME, SIZE, ROUNDED)  \
 ( fputs (".lcomm ", (FILE)),			\
   assemble_name ((FILE), (NAME)),		\
   fprintf ((FILE), ",%u\n", (int)(ROUNDED)))
+#endif
 
 /* Output a float value (represented as a C double) as an immediate operand.
    This macro is m68k-specific.  */
@@ -1030,4 +1084,6 @@
 
 /* Variables in m68k.c */
 extern const char *m68k_library_id_string;
+extern const char *m68k_regparm_string;
+extern int m68k_regparm;
 extern int m68k_last_compare_had_fp_operands;
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k.md gcc-4.1-20051216-src/gcc/config/m68k/m68k.md
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k.md	2005-11-22 21:53:08.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k.md	2005-12-18 22:24:36.000000000 +0100
@@ -329,20 +329,22 @@
                  (match_operand:SI 1 "general_src_operand" "mSr,mSa,KTr,Ksr,>")))]
   "!TARGET_COLDFIRE"
 {
+/* (TIGCC 20040222) This used %d0 and %d1 to force absolute addressing, which
+                    doesn't make sense and breaks -mpcrel. -- Kevin Kofler */
   if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)
     return "cmpm%.l %1,%0";
   if (REG_P (operands[1])
       || (!REG_P (operands[0]) && GET_CODE (operands[0]) != MEM))
     {
       cc_status.flags |= CC_REVERSED;
-      return "cmp%.l %d0,%d1";
+      return "cmp%.l %0,%1";
     }
   if (ADDRESS_REG_P (operands[0])
       && GET_CODE (operands[1]) == CONST_INT
       && INTVAL (operands[1]) < 0x8000
       && INTVAL (operands[1]) >= -0x8000)
     return "cmp%.w %1,%0";
-  return "cmp%.l %d1,%d0";
+  return "cmp%.l %1,%0";
 })
 
 (define_insn ""
@@ -360,52 +362,62 @@
   return "cmp%.l %d1,%d0";
 })
 
+;; (TIGCC 20040808) Don't allow source-only operands as the destination in the
+;;                  compare. We need to use nonimmediate_operand, not
+;;                  nonimmediate_src_operand. Otherwise, -mpcrel outputs invalid
+;;                  assembly code. The SImode patterns already got this right.
+;; -- Kevin Kofler
+
 (define_expand "cmphi"
   [(set (cc0)
-        (compare (match_operand:HI 0 "nonimmediate_src_operand" "")
+        (compare (match_operand:HI 0 "nonimmediate_operand" "")
                  (match_operand:HI 1 "general_src_operand" "")))]
   "!TARGET_COLDFIRE"
   "m68k_last_compare_had_fp_operands = 0;")
 
 (define_insn ""
   [(set (cc0)
-        (compare (match_operand:HI 0 "nonimmediate_src_operand" "rnmS,d,n,mS,>")
+        (compare (match_operand:HI 0 "nonimmediate_operand" "rnmS,d,n,mS,>")
                  (match_operand:HI 1 "general_src_operand" "d,rnmS,mS,n,>")))]
   "!TARGET_COLDFIRE"
 {
+/* (TIGCC 20040222) This used %d0 and %d1 to force absolute addressing, which
+                    doesn't make sense and breaks -mpcrel. -- Kevin Kofler */
   if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)
     return "cmpm%.w %1,%0";
   if ((REG_P (operands[1]) && !ADDRESS_REG_P (operands[1]))
       || (!REG_P (operands[0]) && GET_CODE (operands[0]) != MEM))
     {
       cc_status.flags |= CC_REVERSED;
-      return "cmp%.w %d0,%d1";
+      return "cmp%.w %0,%1";
     }
-  return "cmp%.w %d1,%d0";
+  return "cmp%.w %1,%0";
 })
 
 (define_expand "cmpqi"
   [(set (cc0)
-        (compare (match_operand:QI 0 "nonimmediate_src_operand" "")
+        (compare (match_operand:QI 0 "nonimmediate_operand" "")
                  (match_operand:QI 1 "general_src_operand" "")))]
   "!TARGET_COLDFIRE"
   "m68k_last_compare_had_fp_operands = 0;")
 
 (define_insn ""
   [(set (cc0)
-        (compare (match_operand:QI 0 "nonimmediate_src_operand" "dn,dmS,>")
+        (compare (match_operand:QI 0 "nonimmediate_operand" "dn,dmS,>")
                  (match_operand:QI 1 "general_src_operand" "dmS,nd,>")))]
   "!TARGET_COLDFIRE"
 {
+/* (TIGCC 20040222) This used %d0 and %d1 to force absolute addressing, which
+                    doesn't make sense and breaks -mpcrel. -- Kevin Kofler */
   if (GET_CODE (operands[0]) == MEM && GET_CODE (operands[1]) == MEM)
     return "cmpm%.b %1,%0";
   if (REG_P (operands[1])
       || (!REG_P (operands[0]) && GET_CODE (operands[0]) != MEM))
     {
       cc_status.flags |= CC_REVERSED;
-      return "cmp%.b %d0,%d1";
+      return "cmp%.b %0,%1";
     }
-  return "cmp%.b %d1,%d0";
+  return "cmp%.b %1,%0";
 })
 
 (define_expand "cmpdf"
@@ -693,10 +705,11 @@
 
 ;; Special case of fullword move, where we need to get a non-GOT PIC
 ;; reference into an address register.
+;; (TIGCC 20040808) This is also needed for -freg-relative-an. -- Kevin Kofler
 (define_insn ""
   [(set (match_operand:SI 0 "nonimmediate_operand" "=a<")
         (match_operand:SI 1 "pcrel_address" ""))]
-  "TARGET_PCREL"
+  "TARGET_PCREL || TARGET_REG_RELATIVE"
 {
   if (push_operand (operands[0], SImode))
     return "pea %a1";
@@ -775,13 +788,49 @@
   "TARGET_COLDFIRE"
   "* return output_move_strictqi (operands);")
 
+;; (TIGCC 20050210) Distinguish nonmemory_operand vs. memory_operand here, and
+;;                  optimize pushes from nonmemory_operand to word pushes. We
+;;                  can't do that for memory operands because of odd addresses.
+;;                  The distinction between register_operand and
+;;                  const_int_operand is because of paradoxical subreg
+;;                  technicalities.
+
 (define_expand "pushqi1"
+  [(match_operand:QI 0 "general_operand" "")]
+  "!TARGET_COLDFIRE"
+"{
+  if (const_int_operand (operands[0], QImode))
+    emit_insn (gen_pushqi1_imm (operands[0]));
+  else if (register_operand (operands[0], QImode)) {
+    if (GET_CODE (operands[0]) == SUBREG)
+      emit_insn (gen_pushqi1_reg (SUBREG_REG (operands[0])));
+    else
+      emit_insn (gen_pushqi1_reg (operands[0]));
+  } else
+    emit_insn (gen_pushqi1_mem (operands[0]));
+  DONE;
+}")
+
+(define_expand "pushqi1_mem"
   [(set (reg:SI SP_REG) (plus:SI (reg:SI SP_REG) (const_int -2)))
    (set (mem:QI (plus:SI (reg:SI SP_REG) (const_int 1)))
 	(match_operand:QI 0 "general_operand" ""))]
   "!TARGET_COLDFIRE"
   "")
 
+(define_expand "pushqi1_imm"
+  [(set (mem:HI (pre_dec:SI (reg:SI SP_REG)))
+	(match_operand:HI 0 "const_int_operand" ""))]
+  "!TARGET_COLDFIRE"
+  "")
+
+;; Yes, this is a paradoxical subreg.
+(define_expand "pushqi1_reg"
+  [(set (mem:HI (pre_dec:SI (reg:SI SP_REG)))
+	(subreg:HI (match_operand:QI 0 "register_operand" "") 0))]
+  "!TARGET_COLDFIRE"
+  "")
+
 (define_expand "movsf"
   [(set (match_operand:SF 0 "nonimmediate_operand" "")
 	(match_operand:SF 1 "general_operand" ""))]
@@ -897,6 +946,34 @@
 ;; constants.  Most but not all have output templates that handle constants.
 ;; See also LEGITIMATE_CONSTANT_P.
 
+(define_expand "movbf"
+  ;; SMAP BCD
+  [(set (match_operand:BF 0 "nonimmediate_operand" "")
+	(match_operand:BF 1 "general_operand" ""))]
+  ""
+  "
+{
+  /* We can't rewrite operands during reload.  */
+  if (! reload_in_progress)
+    {
+      if (CONSTANT_P (operands[1]))
+        {
+          operands[1] = force_const_mem (BFmode, operands[1]);
+          if (! memory_address_p (BFmode, XEXP (operands[1], 0)))
+              operands[1] = adjust_address (operands[1], BFmode, 0);
+        }
+      if (flag_pic && TARGET_PCREL)
+        {
+          /* Don't allow writes to memory except via a register; the
+             m68k doesn't consider PC-relative addresses to be writable.  */
+          if (GET_CODE (operands[0]) == MEM
+              && symbolic_operand (XEXP (operands[0], 0), SImode))
+              operands[0] = gen_rtx_MEM (BFmode,
+                                         force_reg (SImode, XEXP (operands[0], 0)));
+        }
+    }
+}")
+ 
 (define_expand "movxf"
   [(set (match_operand:XF 0 "nonimmediate_operand" "")
 	(match_operand:XF 1 "general_operand" ""))]
@@ -963,6 +1040,46 @@
 })
 
 (define_insn ""
+  ;; SMAP BCD
+  [(set (match_operand:BF 0 "nonimmediate_operand" "=rm,rf,&rof<>")
+	(match_operand:BF 1 "nonimmediate_operand" "rf,m,rof<>"))]
+  "! TARGET_68881 && ! TARGET_COLDFIRE"
+{
+  if (FP_REG_P (operands[0]))
+    {
+      if (FP_REG_P (operands[1]))
+	return "fmove%.x %1,%0";
+      if (REG_P (operands[1]))
+	{
+	  rtx xoperands[2];
+	  xoperands[1] = gen_rtx_REG (HImode, REGNO (operands[1]) + 2);
+	  output_asm_insn ("move%.w %1,%-", xoperands);
+	  xoperands[1] = gen_rtx_REG (SImode, REGNO (operands[1]) + 1);
+	  output_asm_insn ("move%.l %1,%-", xoperands);
+	  output_asm_insn ("move%.l %1,%-", operands);
+	  return "fmove%.x %+,%0";
+	}
+      if (GET_CODE (operands[1]) == CONST_DOUBLE)
+        return "fmove%.x %1,%0";
+      return "fmove%.x %f1,%0";
+    }
+  if (FP_REG_P (operands[1]))
+    {
+      if (REG_P (operands[0]))
+        {
+          output_asm_insn ("fmove%.x %f1,%-\;move%.l %+,%0", operands);
+          operands[0] = gen_rtx_REG (SImode, REGNO (operands[0]) + 1);
+          output_asm_insn ("move%.l %+,%0", operands);
+          operands[0] = gen_rtx_REG (HImode, REGNO (operands[0]) + 1);
+          return "move%.w %+,%0";
+        }
+      else
+        return "fmove%.x %f1,%0";
+    }
+  return output_move_double (operands);
+})
+
+(define_insn ""
   [(set (match_operand:XF 0 "nonimmediate_operand" "=rm,rf,&rof<>")
 	(match_operand:XF 1 "nonimmediate_operand" "rf,m,rof<>"))]
   "! TARGET_68881 && ! TARGET_COLDFIRE"
@@ -1233,9 +1350,12 @@
   "TARGET_CFV4"
   "mvz%.w %1,%0")
 
+;; (TIGCC 20050210) We need to mark the register operand as earlyclobber in the
+;;                  case of memory operands to avoid having to split (see
+;;                  reg_mentioned_p below) things.
 (define_insn "zero_extendhisi2"
-  [(set (match_operand:SI 0 "register_operand" "=d")
-	(zero_extend:SI (match_operand:HI 1 "nonimmediate_src_operand" "rmS")))]
+  [(set (match_operand:SI 0 "register_operand" "=d,&d")
+	(zero_extend:SI (match_operand:HI 1 "nonimmediate_src_operand" "r,mS")))]
   ""
   "#")
 
@@ -1258,8 +1378,8 @@
   "mvz%.b %1,%0")
 
 (define_insn "zero_extendqisi2"
-  [(set (match_operand:SI 0 "register_operand" "=d")
-	(zero_extend:SI (match_operand:QI 1 "nonimmediate_src_operand" "dmS")))]
+  [(set (match_operand:SI 0 "register_operand" "=d,&d")
+	(zero_extend:SI (match_operand:QI 1 "nonimmediate_src_operand" "d,mS")))]
   ""
   "#")
 
@@ -4135,7 +4255,11 @@
       output_asm_insn (INTVAL (operands[2]) <= 8 ? "asr%.l %2,%0" :
 			"moveq %2,%1\;asr%.l %1,%0", operands);
       output_asm_insn ("mov%.l %0,%1\;smi %0", operands);
-      return INTVAL (operands[2]) >= 15 ? "ext%.w %d0" :
+/* (TIGCC 20040222) The %d0 here was a typo or thinko. It means 'force absolute
+                    addressing' in this context, not 'data register'. This
+                    doesn't make sense in a context where only data registers
+                    are allowed, so I removed it. -- Kevin Kofler */
+      return INTVAL (operands[2]) >= 15 ? "ext%.w %0" :
 	     TARGET_68020 ? "extb%.l %0" : "ext%.w %0\;ext%.l %0";
     }
 })
@@ -6320,10 +6444,19 @@
   return "rtd %0";
 })
 
+;; (TIGCC 20040222) Use jra instead of jmp here. Also don't add (%pc) under
+;;                  -mpcrel. Moreover, we need to handle extended address
+;;                  operands here. -- Kevin Kofler
+;; (TIGCC 20050204) Use plain bra for labels under -mpcrel to guarantee PC-rel
+;;                  code.
 (define_insn "indirect_jump"
-  [(set (pc) (match_operand:SI 0 "address_operand" "p"))]
+  [(set (pc) (match_operand:SI 0 "extended_address_operand" "p"))]
   ""
-  "jmp %a0")
+{
+  return (TARGET_PCREL && GET_CODE (operands[0]) == MEM
+          && GET_CODE (XEXP (operands[0], 0)) == SYMBOL_REF)?
+         "bra %A0":"jra %A0";
+})
 
 ;; This should not be used unless the add/sub insns can't be.
 
@@ -6417,6 +6550,9 @@
 })
 
 ;; Speed up stack adjust followed by a fullword fixedpoint push.
+;; (TIGCC 20050211) Don't do this if pushing an immediate operand in range for
+;;                  a pea, and a stack adjust is needed anyway. That would
+;;                  generate bigger (or same size) and slower code.
 
 (define_peephole
   [(set (reg:SI SP_REG) (plus:SI (reg:SI SP_REG)
@@ -6424,7 +6560,8 @@
    (set (match_operand:SI 1 "push_operand" "=m")
 	(match_operand:SI 2 "general_operand" "g"))]
   "INTVAL (operands[0]) >= 4
-   && ! reg_mentioned_p (stack_pointer_rtx, operands[2])"
+   && ! reg_mentioned_p (stack_pointer_rtx, operands[2])
+   && !(INTVAL (operands[0]) > 4 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) && INTVAL (operands[2]) >= -0x8000 && INTVAL (operands[2]) < 0x8000)"
 {
   if (INTVAL (operands[0]) > 4)
     {
@@ -6460,6 +6597,77 @@
   return "move%.l %2,%@";
 })
 
+;; (TIGCC 20050207) Bundle 2 immediate word pushes to the stack into 1 immediate
+;;                  longword push.
+
+(define_peephole
+  [(set (match_operand:HI 0 "push_operand" "=m")
+	(match_operand:HI 1 "const_int_operand" "n"))
+   (set (match_operand:HI 2 "push_operand" "=m")
+	(match_operand:HI 3 "const_int_operand" "n"))]
+  ""
+{
+  rtx xoperands[2];
+  xoperands[0] = operands[0];
+  xoperands[1] = GEN_INT ((INTVAL (operands[1]) & 0xFFFF) + (INTVAL (operands[3]) << 16));
+  output_asm_insn (output_move_simode_const (xoperands), xoperands);
+  CC_STATUS_INIT; /* We clobbered the CC. */
+  return "";
+})
+
+;; (TIGCC 20050210) Same as above, but with a stack adjust.
+
+(define_peephole
+  [(set (reg:SI SP_REG) (plus:SI (reg:SI SP_REG)
+				 (match_operand:SI 0 "const_int_operand" "n")))
+   (set (mem:HI (reg:SI SP_REG))
+	(match_operand:HI 1 "const_int_operand" "n"))
+   (set (match_operand:HI 2 "push_operand" "=m")
+	(match_operand:HI 3 "const_int_operand" "n"))]
+  "INTVAL (operands[0]) >= 2"
+{
+  HOST_WIDE_INT longword = (INTVAL (operands[1]) & 0xFFFF) + (INTVAL (operands[3]) << 16);
+  bool usepea = longword && longword < 0x8000 && longword >= -0x8000
+                && INTVAL (operands[0]) > 2;
+  rtx xoperands[2];
+  if (INTVAL (operands[0]) > 2)
+    {
+      xoperands[0] = stack_pointer_rtx;
+      xoperands[1] = GEN_INT (INTVAL (operands[0]) + (usepea?2:-2));
+      if (INTVAL (xoperands[1]) <= 8)
+	{
+	  if (!TARGET_COLDFIRE)
+	    output_asm_insn ("addq%.w %1,%0", xoperands);
+	  else
+	    output_asm_insn ("addq%.l %1,%0", xoperands);
+	}
+      else if (TARGET_CPU32 && INTVAL (xoperands[1]) <= 16)
+	{
+	  xoperands[1] = GEN_INT (INTVAL (xoperands[1]) - 8);
+	  output_asm_insn ("addq%.w #8,%0\;addq%.w %1,%0", xoperands);
+	}
+      else if (INTVAL (xoperands[1]) <= 0x7FFF)
+        {
+	  if (TARGET_68040)
+	    output_asm_insn ("add%.w %1,%0", xoperands);
+	  else if (MOTOROLA)
+	    output_asm_insn ("lea (%c1,%0),%0", xoperands);
+	  else
+	    output_asm_insn ("lea %0@(%c1),%0", xoperands);
+        }
+      else
+        output_asm_insn ("add%.l %1,%0", xoperands);
+    }
+  if (usepea)
+    xoperands[0] = operands[2];
+  else
+    xoperands[0] = gen_rtx_MEM (SImode, stack_pointer_rtx);
+  xoperands[1] = GEN_INT (longword);
+  output_asm_insn (output_move_simode_const (xoperands), xoperands);
+  CC_STATUS_INIT; /* We clobbered the CC. */
+  return "";
+})
+
 ;; Speed up pushing a single byte but leaving four bytes of space.
 
 (define_peephole
@@ -7092,3 +7300,166 @@
   default: gcc_unreachable ();
   }
 })
+
+;; (TIGCC 20050210) Optimize lea (4,%an),%am; move.l foo,-(%am) into
+;;                  move.l %an,%am; move.l foo,(%an)
+;; (TIGCC 20050211) Don't do this if foo is an immediate operand in range for
+;;                  a moveq (because the movsi insn won't like that).
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (const_int 4)))
+   (set (mem:SI (pre_dec:SI (match_dup 0)))
+        (match_operand:SI 2 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && ! reg_mentioned_p (operands[0], operands[2]) && !(GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) && INTVAL (operands[2]) >= -128 && INTVAL (operands[2]) < 128)"
+  [(set (match_dup 0) (match_dup 1))
+   (set (mem:SI (match_dup 1)) (match_dup 2))]
+  "")
+
+;; (TIGCC 20050211) Optimize lea (4,%an),%am; move.l #foo,-(%am), foo!=0,
+;;                  -128<=foo<128 into moveq.l #foo,%dx; move.l %an,%am;
+;;                  move.l %dx,(%an) if we have a free data register to do that.
+(define_peephole2
+  [(match_scratch:SI 0 "d")
+   (set (match_operand:SI 1 "register_operand" "")
+        (plus:SI (match_operand:SI 2 "register_operand" "")
+            (const_int 4)))
+   (match_dup 0)
+   (set (mem:SI (pre_dec:SI (match_dup 1)))
+        (match_operand:SI 3 "const_int_operand" ""))]
+  "REG_P(operands[2]) && (REGNO (operands[2]) ^ 010) < 8 && INTVAL (operands[3]) && INTVAL (operands[3]) >= -128 && INTVAL (operands[3]) < 128"
+  [(set (match_dup 0) (match_dup 3))
+   (set (match_dup 1) (match_dup 2))
+   (set (mem:SI (match_dup 2)) (match_dup 0))]
+  "")
+
+;; (TIGCC 20050210) Optimize lea (2,%an),%am; move.w foo,-(%am) into
+;;                  move.l %an,%am; move.w foo,(%an)
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (const_int 2)))
+   (set (mem:HI (pre_dec:SI (match_dup 0)))
+        (match_operand:HI 2 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && ! reg_mentioned_p (operands[0], operands[2])"
+  [(set (match_dup 0) (match_dup 1))
+   (set (mem:HI (match_dup 1)) (match_dup 2))]
+  "")
+
+;; (TIGCC 20050210) Optimize lea (1,%an),%am; move.w foo,-(%am), m!=7 into
+;;                  move.l %an,%am; move.b foo,(%an)
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (const_int 1)))
+   (set (mem:QI (pre_dec:SI (match_dup 0)))
+        (match_operand:QI 2 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && !(REG_P(operands[0]) && REGNO (operands[0]) == STACK_POINTER_REGNUM) && ! reg_mentioned_p (operands[0], operands[2])"
+  [(set (match_dup 0) (match_dup 1))
+   (set (mem:QI (match_dup 1)) (match_dup 2))]
+  "")
+
+;; (TIGCC 20050210) Optimize lea (x,%an),%am; move.l foo,-(%am), x!=4,
+;;                  x>=-0x7ffc into lea (x-4,%an),%am; move.l foo,(%am)
+;; (TIGCC 20050211) Don't do this if foo is an immediate operand in range for
+;;                  a pea (especially not if in range for a moveq, because the
+;;                  movsi insn won't like that).
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (match_operand:SI 2 "const_int_operand" "")))
+   (set (mem:SI (pre_dec:SI (match_dup 0)))
+        (match_operand:SI 3 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && ! reg_mentioned_p (operands[0], operands[3]) && INTVAL (operands[2]) != 4 && INTVAL (operands[2]) >= -0x7ffc && !(GET_CODE (operands[3]) == CONST_INT && INTVAL (operands[3]) && INTVAL (operands[3]) >= -0x8000 && INTVAL (operands[3]) < 0x8000)"
+  [(set (match_dup 0) (plus:SI (match_dup 1) (match_dup 2)))
+   (set (mem:SI (match_dup 0)) (match_dup 3))]
+  "operands[2] = GEN_INT (INTVAL (operands[2]) - 4);")
+
+;; (TIGCC 20050210) Optimize lea (x,%an),%am; move.w foo,-(%am), m!=7, x!=2,
+;;                  x>=-0x7ffe into lea (x-2,%an),%am; move.w foo,(%am)
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (match_operand:SI 2 "const_int_operand" "")))
+   (set (mem:HI (pre_dec:SI (match_dup 0)))
+        (match_operand:HI 3 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && ! reg_mentioned_p (operands[0], operands[3]) && INTVAL (operands[2]) != 2 && INTVAL (operands[2]) >= -0x7ffe"
+  [(set (match_dup 0) (plus:SI (match_dup 1) (match_dup 2)))
+   (set (mem:HI (match_dup 0)) (match_dup 3))]
+  "operands[2] = GEN_INT (INTVAL (operands[2]) - 2);")
+
+;; (TIGCC 20050210) Optimize lea (x,%an),%am; move.b foo,-(%am), m!=7, x!=1,
+;;                  x>=-0x7fff into lea (x-1,%an),%am; move.b foo,(%am)
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (plus:SI (match_operand:SI 1 "register_operand" "")
+            (match_operand:SI 2 "const_int_operand" "")))
+   (set (mem:QI (pre_dec:SI (match_dup 0)))
+        (match_operand:QI 3 "general_operand" ""))]
+  "REG_P(operands[1]) && (REGNO (operands[1]) ^ 010) < 8 && !(REG_P(operands[0]) && REGNO (operands[0]) == STACK_POINTER_REGNUM) && ! reg_mentioned_p (operands[0], operands[3]) && INTVAL (operands[2]) != 1 && INTVAL (operands[2]) >= -0x7fff"
+  [(set (match_dup 0) (plus:SI (match_dup 1) (match_dup 2)))
+   (set (mem:QI (match_dup 0)) (match_dup 3))]
+  "operands[2] = GEN_INT (INTVAL (operands[2]) - 1);")
+
+;; (TIGCC 20050213) Optimize and #const1,%dn; and #const2,%dn (generated by
+;;                  zero_extend) into and #const1&const2,%dn
+
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (and:SI (match_dup 0)
+            (match_operand:SI 1 "const_int_operand" "")))
+   (set (match_dup 0)
+        (and:SI (match_dup 0)
+            (match_operand:SI 2 "const_int_operand" "")))]
+  ""
+  [(set (match_dup 0) (and:SI (match_dup 0) (match_dup 1)))]
+  "operands[1] = GEN_INT (INTVAL (operands[1]) & INTVAL (operands[2]));")
+
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "")
+        (and:HI (match_dup 0)
+            (match_operand:HI 1 "const_int_operand" "")))
+   (set (match_dup 0)
+        (and:HI (match_dup 0)
+            (match_operand:HI 2 "const_int_operand" "")))]
+  ""
+  [(set (match_dup 0) (and:HI (match_dup 0) (match_dup 1)))]
+  "operands[1] = GEN_INT (INTVAL (operands[1]) & INTVAL (operands[2]));")
+
+(define_peephole2
+  [(set (match_operand:QI 0 "register_operand" "")
+        (and:QI (match_dup 0)
+            (match_operand:QI 1 "const_int_operand" "")))
+   (set (match_dup 0)
+        (and:QI (match_dup 0)
+            (match_operand:QI 2 "const_int_operand" "")))]
+  ""
+  [(set (match_dup 0) (and:QI (match_dup 0) (match_dup 1)))]
+  "operands[1] = GEN_INT (INTVAL (operands[1]) & INTVAL (operands[2]));")
+
+;; (TIGCC 20050213) Optimize and.l #65535,%dn; clr.w %dn (generated by
+;;                  zero_extend) into moveq #0,%dn
+
+(define_peephole2
+  [(set (match_operand:SI 0 "register_operand" "")
+        (and:SI (match_dup 0)
+            (const_int 65535)))
+   (set (strict_low_part (match_operand:HI 1 "register_operand" ""))
+        (const_int 0))]
+  "REG_P(operands[0]) && REG_P(operands[1]) && REGNO(operands[0]) == REGNO(operands[1])"
+  [(set (match_dup 0) (const_int 0))]
+  "")
+
+;; (TIGCC 20050213) Optimize and.w #255,%dn; clr.b %dn (generated by
+;;                  zero_extend) into clr.w %dn
+
+(define_peephole2
+  [(set (match_operand:HI 0 "register_operand" "")
+        (and:HI (match_dup 0)
+            (const_int 255)))
+   (set (strict_low_part (match_operand:QI 1 "register_operand" ""))
+        (const_int 0))]
+  "REG_P(operands[0]) && REG_P(operands[1]) && REGNO(operands[0]) == REGNO(operands[1])"
+  [(set (strict_low_part (match_dup 0)) (const_int 0))]
+  "")
+
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k-modes.def gcc-4.1-20051216-src/gcc/config/m68k/m68k-modes.def
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k-modes.def	2005-06-25 03:22:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k-modes.def	2005-12-18 22:24:35.000000000 +0100
@@ -18,5 +18,6 @@
 the Free Software Foundation, 51 Franklin Street, Fifth Floor,
 Boston, MA 02110-1301, USA.  */
 
-/* 80-bit floating point (IEEE extended, in a 96-bit field) */
-FRACTIONAL_FLOAT_MODE (XF, 80, 12, ieee_extended_motorola_format);
+FLOAT_MODE (BF, 10, 0);
+FLOAT_MODE (XF, 12, 0);
+
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k-none.h gcc-4.1-20051216-src/gcc/config/m68k/m68k-none.h
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k-none.h	2005-06-25 03:22:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k-none.h	2005-12-18 22:24:35.000000000 +0100
@@ -18,10 +18,12 @@
 the Free Software Foundation, 51 Franklin Street, Fifth Floor,
 Boston, MA 02110-1301, USA.  */
 
-/* Default to m68k (m68020).  */
-#ifndef TARGET_CPU_DEFAULT
-#define TARGET_CPU_DEFAULT M68K_CPU_m68k
-#endif
+/* Define the appropriate flags for the TI's architecture */
+#undef TARGET_CPU_DEFAULT
+#define TARGET_CPU_DEFAULT M68K_CPU_m68000
+
+#undef TARGET_DEFAULT
+#define TARGET_DEFAULT ((TARGET_CPU_DEFAULT >> 4) | MASK_SHORT | MASK_TIOS | MASK_MERGE_SECTIONS)
 
 /* These are values set by the configure script in TARGET_CPU_DEFAULT.
    They are (sequential integer + (desired value for TARGET_DEFAULT) << 4).  */
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k.opt gcc-4.1-20051216-src/gcc/config/m68k/m68k.opt
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k.opt	2005-12-19 02:06:37.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k.opt	2005-12-19 02:42:18.000000000 +0100
@@ -92,6 +92,10 @@
 Target Report RejectNegative Mask(BITFIELD)
 Use the bit-field instructions
 
+mbss
+Target Report InverseMask(BSS)
+Output common/lcomm (BSS) symbols for uninitialized data
+
 mc68000
 Target RejectNegative
 Generate code for a 68000
@@ -100,6 +104,10 @@
 Target RejectNegative
 Generate code for a 68020
 
+mcoff-abslines
+Target Report Mask(COFFABSLINES)
+Use absolute line numbers for COFF debugging
+
 mcpu32
 Target RejectNegative
 Generate code for a cpu32
@@ -108,10 +116,26 @@
 Target Report Mask(ID_SHARED_LIBRARY)
 Enable ID based shared library
 
+mlong
+Target InverseMask(SHORT)
+Consider type 'int' to be 32 bits wide
+
+mmerge-sections
+Target Report Mask(MERGE_SECTIONS)
+Merge the .text and .data sections
+
+mmerge-to-data
+Target Report Mask(MERGE_TO_DATA)
+When merging sections, merge to .data rather than to .text
+
 mnobitfield
 Target RejectNegative InverseMask(BITFIELD)
 Do not use the bit-field instructions
 
+mnolong
+Target Report RejectNegative Mask(SHORT)
+Consider type 'int' to be 16 bits wide
+
 mnortd
 Target RejectNegative InverseMask(RTD)
 Use normal calling convention
@@ -124,6 +148,18 @@
 Target Report Mask(PCREL)
 Generate pc-relative code
 
+mregparm
+Target Report Mask(REGPARM)
+Allow passing by registers
+
+mregparm=
+Target Report Joined Var(m68k_regparm_string)
+Number of register parameters of each register type
+
+mrodata-to-text
+Target Report Mask(RODATA_TO_TEXT)
+When not merging sections, put read-only data into .text rather than .data
+
 mrtd
 Target Report RejectNegative Mask(RTD)
 Use different calling convention using 'rtd'
@@ -137,7 +173,7 @@
 ID of shared library to build
 
 mshort
-Target Report RejectNegative Mask(SHORT)
+Target Report Mask(SHORT)
 Consider type 'int' to be 16 bits wide
 
 msoft-float
@@ -147,3 +183,7 @@
 mstrict-align
 Target Report Mask(STRICT_ALIGNMENT)
 Do not use unaligned memory references
+
+mtios
+Target Report Mask(TIOS)
+Enable TIOS interoperability
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k-protos.h gcc-4.1-20051216-src/gcc/config/m68k/m68k-protos.h
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k-protos.h	2005-07-12 01:32:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k-protos.h	2005-12-18 22:24:35.000000000 +0100
@@ -44,6 +44,13 @@
 extern int floating_exact_log2 (rtx);
 extern bool strict_low_part_peephole_ok (enum machine_mode mode, rtx first_insn, rtx target);
 
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+void amigaos_init_cumulative_args(struct m68k_args *, tree, tree);
+void amigaos_function_arg_advance(struct m68k_args *);
+struct rtx_def *amigaos_function_arg(struct m68k_args *, enum machine_mode, tree);
+/* end-TIGCC-local (regparms) */
+void m68k_asm_file_start(void);
+
 /* Functions from m68k.c used in macros.  */
 extern int standard_68881_constant_p (rtx);
 extern void print_operand_address (FILE *, rtx);
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/m68k-ti.h gcc-4.1-20051216-src/gcc/config/m68k/m68k-ti.h
--- gcc-4.1-20051216.orig/gcc/config/m68k/m68k-ti.h	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/m68k/m68k-ti.h	2005-12-18 22:24:35.000000000 +0100
@@ -0,0 +1,215 @@
+/* Definitions of target machine for GNU compiler.
+   TI-68k architecture (68000),
+   COFF object files and debugging version.
+   Derived in part from m68kemb.h and other files.
+   Copyright (C) 1994 Free Software Foundation, Inc.
+   Copyright (C) 2000 mmu_man (Franois Revol)
+   (Modified by Sebastian Reichelt for the Windows release of TIGCC)
+ 
+This file is part of TIGCC.
+
+GNU CC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 2, or (at your option)
+any later version.
+
+GNU CC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GNU CC; see the file COPYING. If not, write to
+the Free Software Foundation, 59 Temple Place - Suite 330,
+Boston, MA 02111-1307, USA. */
+
+/* Define the output of the target version */
+
+#undef TARGET_VERSION
+#define TARGET_VERSION fprintf (stderr, " (MC68000 TI with COFF output)");
+
+/* Even if we compile with -mlong, we want only 16-bit alignment. */
+
+#undef PARM_BOUNDARY
+#define PARM_BOUNDARY 16
+
+/* Don't default to pcc-struct-return, so that we can return small
+   structures and unions in registers, which is slightly more
+   efficient. There are probably no TIOS routines returning structs;
+   if there are, the appropriate program will have to be compiled
+   with the "-fpcc-struct-return" option. But that option will cause
+   problems with ROM_CALLs returning a HSym, which is defined as a
+   structure in TIGCC.  */
+
+#undef DEFAULT_PCC_STRUCT_RETURN
+#define DEFAULT_PCC_STRUCT_RETURN 0
+
+/* In order for bitfields to work on a 68000, or with -mnobitfield, we must
+   define either PCC_BITFIELD_TYPE_MATTERS or STRUCTURE_SIZE_BOUNDARY.
+   Defining STRUCTURE_SIZE_BOUNDARY results in structure packing problems,
+   so we define PCC_BITFIELD_TYPE_MATTERS.  */
+
+#define PCC_BITFIELD_TYPE_MATTERS 1
+
+/* Undefine PCC_STATIC_STRUCT_RETURN so that we get a re-entrant
+   calling convention (whatever that means).  */
+
+#undef PCC_STATIC_STRUCT_RETURN
+
+/* Define how to generate (in the callee) the output value of a
+   function and how to find (in the caller) the value returned by a
+   function. VALTYPE is the data type of the value (as a tree). If
+   the precise function being called is known, FUNC is its
+   FUNCTION_DECL; otherwise, FUNC is 0. When calling TIOS functions,
+   find the result in d0 or a0 as appropriate. */
+ 
+#undef FUNCTION_VALUE
+#define FUNCTION_VALUE(VALTYPE, FUNC) \
+	(((TARGET_TIOS) && (POINTER_TYPE_P (VALTYPE))) \
+	? gen_rtx_REG (TYPE_MODE (VALTYPE), 8) \
+	: LIBCALL_VALUE (TYPE_MODE (VALTYPE)))
+
+/* Define how to find a library call return value. Usually the value will be
+   in d0 (thru d1 or d2), but floats should be assumed to be returned in a
+   stack frame. This happens automatically if the specified register (d1 in
+   this case) is not a possible register for returning the value, because
+   floats take up 3 registers. Never use direct floats if d3 is clobbered
+   by function calls. */
+
+#undef LIBCALL_VALUE
+#define LIBCALL_VALUE(MODE) \
+	(((TARGET_DIRECTFLOAT) && ((MODE) == BFmode)) \
+	? gen_rtx_REG (MODE, 1) \
+	: gen_rtx_REG (MODE, 0))
+
+/* 1 if N is a possible register number for a function value. For
+   calling TIOS functions, allow a0 in addition to d0 (see above). */
+
+#undef FUNCTION_VALUE_REGNO_P
+#define FUNCTION_VALUE_REGNO_P(N) \
+	(((N) == 0) || (TARGET_TIOS && ((N) == 8)) || (TARGET_DIRECTFLOAT && ((N) == 1)))
+
+/* Define this to be true when FUNCTION_VALUE_REGNO_P is true for
+   more than one register (see above). */
+
+#undef NEEDS_UNTYPED_CALL
+#define NEEDS_UNTYPED_CALL (TARGET_TIOS || TARGET_DIRECTFLOAT)
+
+/* This says how to output an assembler line
+   to define a global common symbol. */
+
+#undef ASM_OUTPUT_COMMON
+#define ASM_OUTPUT_COMMON(FILE,NAME,SIZE,ROUNDED) \
+do { \
+	if (TARGET_NO_BSS && ((NAME) [0] != '_')) \
+	{ \
+		long i; \
+		data_section (); \
+		fputs (".globl ", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fputs ("\n\t.even\n", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fputs (":\n", (FILE)); \
+		fprintf ((FILE), "\t.space %u\n", (unsigned)(ROUNDED)); \
+		fputs ("\t.even\n", (FILE)); \
+	} \
+	else \
+	{ \
+		fputs (".comm ", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fprintf ((FILE), ",%u\n", (unsigned)(ROUNDED)); \
+	} \
+} while (0)
+
+/* This says how to output an assembler line
+   to define a local common symbol. */
+
+#undef ASM_OUTPUT_LOCAL
+#define ASM_OUTPUT_LOCAL(FILE,NAME,SIZE,ROUNDED) \
+do { \
+	if (TARGET_NO_BSS) \
+	{ \
+		long i; \
+		data_section (); \
+		fputs ("\t.even\n", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fputs (":\n", (FILE)); \
+		fprintf ((FILE), "\t.space %u\n", (unsigned)(ROUNDED)); \
+		fputs ("\t.even\n", (FILE)); \
+	} \
+	else \
+	{ \
+		fputs (".lcomm ", (FILE)); \
+		assemble_name ((FILE), (NAME)); \
+		fprintf ((FILE), ",%u\n", (unsigned)(ROUNDED)); \
+	} \
+} while (0)
+
+/* If TARGET_MERGE_SECTIONS is set (on by default): if TARGET_MERGE_TO_DATA is
+   set, only use data sections, otherwise only use text sections. Both code and
+   data in RAM programs on a TI-89/92+/V200 are always writable; that's why it
+   does not make sense to have different data and text sections.
+   Those cannot be set to an empty string, since a number may follow, etc.
+   Anyway, better more than less. */
+
+#undef TEXT_SECTION_ASM_OP
+#define TEXT_SECTION_ASM_OP ((TARGET_MERGE_SECTIONS && TARGET_MERGE_TO_DATA)? \
+                             "\t.data":"\t.text")
+
+#undef DATA_SECTION_ASM_OP
+#define DATA_SECTION_ASM_OP ((TARGET_MERGE_SECTIONS && !TARGET_MERGE_TO_DATA)? \
+                             "\t.text":"\t.data")
+
+/* If TARGET_NO_BSS is set (off by default), use the data section here.
+   Otherwise use the BSS section. */
+
+#undef BSS_SECTION_ASM_OP
+#define BSS_SECTION_ASM_OP (TARGET_NO_BSS?DATA_SECTION_ASM_OP:"\t.section .bss")
+
+/* When not merging sections, put read-only data into .data unless
+   TARGET_RODATA_TO_TEXT is set. But jump tables do NOT qualify for going into
+   the data section! */
+#define READONLY_DATA_SECTION() (TARGET_RODATA_TO_TEXT ? text_section() \
+                                                       : data_section())
+#define JUMP_TABLES_IN_TEXT_SECTION 1
+
+/* Define "__INT_SHORT__" if short ints are set, e.g. if the "-mlong" switch
+   is not used. This is necessary for the TIGCC Library, since INT_MAX and
+   others need to be constants. */
+
+#undef CPP_SUBTARGET_SPEC
+#if (defined(__CYGWIN__) || defined(__WIN32__))
+#define CPP_SUBTARGET_SPEC "-D__TIGCC_ENV__ -D__TIGCC_WIN_ENV__ %{!mlong:%{!mnoshort:%{!mno-short:-D__INT_SHORT__ }}}"
+#else
+#define CPP_SUBTARGET_SPEC "-D__TIGCC_ENV__ %{!mlong:%{!mnoshort:%{!mno-short:-D__INT_SHORT__ }}}"
+#endif
+#undef CPP_SPEC
+#define CPP_SPEC CPP_SUBTARGET_SPEC
+
+/* Trampolines are code on the stack, so we need to add 0x40000 to their address
+   for it to work on a TI-89/92+/V200 HW2. On HW3, we should NOT add that
+   address. Moreover, EXECUTE_IN_GHOST_SPACE is required for it to work
+   correctly. Therefore, I am emitting a libcall and letting TIGCCLIB worry
+   about the details.
+   (code partially lifted from gcc/config/sh/sh.h) */
+#define TRAMPOLINE_ADJUST_ADDRESS(TRAMP) do \
+{ \
+  (TRAMP) = expand_simple_binop (Pmode, PLUS, (TRAMP), \
+                                 emit_library_call_value (gen_rtx_SYMBOL_REF (\
+                                                           Pmode, \
+                                                           "__trampoline_offset"), \
+                                                          NULL_RTX, LCT_CONST, \
+                                                          Pmode, 0), \
+                                 gen_reg_rtx (Pmode), 0, \
+                                 OPTAB_LIB_WIDEN); \
+} while (0)
+
+/* We want -fomit-frame-pointer by default. */
+#define CAN_DEBUG_WITHOUT_FP
+
+/* We want DWARF2 debugging and unwinding information */
+#define DWARF2_DEBUGGING_INFO 1
+#define DWARF2_ASM_LINE_DEBUG_INFO 1
+#define DWARF2_UNWIND_INFO 1
+
+/* end of m68k-ti.h */
diff -Naur gcc-4.1-20051216.orig/gcc/config/m68k/predicates.md gcc-4.1-20051216-src/gcc/config/m68k/predicates.md
--- gcc-4.1-20051216.orig/gcc/config/m68k/predicates.md	2005-12-19 01:42:58.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/m68k/predicates.md	2005-12-19 02:04:39.000000000 +0100
@@ -88,7 +88,7 @@
 ;; hosted on 64-bit machines.
 
 (define_predicate "const_uint32_operand"
-  (match_code "const_int,const_double")
+  (match_code "const_int")
 {
   /* It doesn't make sense to ask this question with a mode that is
      not larger than 32 bits.  */
@@ -101,7 +101,7 @@
 	  && (INTVAL (op) >= 0 && INTVAL (op) <= 0xffffffffL));
 #else
   return (GET_CODE (op) == CONST_INT
-	  || (GET_CODE (op) == CONST_DOUBLE && CONST_DOUBLE_HIGH (op) == 0));
+	  && INTVAL (op) >= 0);
 #endif
 })
 
@@ -194,3 +194,13 @@
 {
   return MEM_P (op) && GET_CODE (XEXP (op, 0)) == PRE_DEC;
 })
+
+;; (TIGCC 20040222) This predicate is used to allow straight labels in the
+;;                  indirect_jump pattern. -- Kevin Kofler
+(define_predicate "extended_address_operand"
+  (match_code "const_int,const_double,const,symbol_ref,label_ref,subreg,reg,mem,plus,minus,mult")
+{
+  if (TARGET_PCREL && CONSTANT_ADDRESS_P (op))
+    return 1;
+  return address_operand (op, mode);
+})
diff -Naur gcc-4.1-20051216.orig/gcc/config/smapbcd.h gcc-4.1-20051216-src/gcc/config/smapbcd.h
--- gcc-4.1-20051216.orig/gcc/config/smapbcd.h	1970-01-01 01:00:00.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config/smapbcd.h	2005-12-18 22:24:36.000000000 +0100
@@ -0,0 +1,369 @@
+/* Definitions for SMAP II BCD support in the GNU C Compiler.
+   These macros implement software BCD floating point support;
+   primary use will be TIGCC.
+   Copyright (C) 1994 Free Software Foundation, Inc.
+   Copyright (C) 2000 Sebastian Reichelt
+   Copyright (C) 2003-2005 Kevin Kofler
+
+This file is part of TIGCC.
+
+GNU CC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 2, or (at your option)
+any later version.
+
+GNU CC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GNU CC; see the file COPYING. If not, write to
+the Free Software Foundation, 59 Temple Place - Suite 330,
+Boston, MA 02111-1307, USA. */
+
+#undef TARGET_FLOAT_FORMAT
+#define	TARGET_FLOAT_FORMAT SMAP_BCD_FLOAT_FORMAT
+
+#ifndef __SMAP_BCD_FLOAT
+#define __SMAP_BCD_FLOAT
+
+typedef struct real_value smap_bcd_float;
+
+#endif
+
+#undef REAL_VALUE_TYPE
+#define REAL_VALUE_TYPE smap_bcd_float
+
+#undef FLOAT_TYPE_SIZE
+#undef DOUBLE_TYPE_SIZE
+#undef LONG_DOUBLE_TYPE_SIZE
+
+/* We have to define a special mode for this; one that handles 10 byte
+   floats. There have to be a lot of changes to other files; due to the
+   fact that they are so countless, it would be too hard to make them
+   compatible with a general-purpose GCC. */
+#define FLOAT_TYPE_SIZE 80
+#define DOUBLE_TYPE_SIZE 80
+#define LONG_DOUBLE_TYPE_SIZE 80
+
+#ifndef REAL_IS_NOT_DOUBLE
+#define REAL_IS_NOT_DOUBLE
+#endif
+
+#define ZERO (__extension__(smap_bcd_float){0x4000,0})
+#define UNSIGNED_ZERO (__extension__(smap_bcd_float){0x4000,0})
+#define POSITIVE_ZERO (__extension__(smap_bcd_float){0,0})
+#define NEGATIVE_ZERO (__extension__(smap_bcd_float){0x8000,0})
+
+#define UNSIGNED_INF (__extension__(smap_bcd_float){0x7FFF,0xAA00CC0000000000})
+#define POSITIVE_INF (__extension__(smap_bcd_float){0x7FFF,0xAA00BB0000000000})
+#define NEGATIVE_INF (__extension__(smap_bcd_float){0xFFFF,0xAA00BB0000000000})
+
+#define NAN (__extension__(smap_bcd_float){0x7FFF,0xAA00000000000000})
+
+#ifndef REAL_INFINITY
+#define REAL_INFINITY
+#endif
+
+#undef REAL_VALUE_ISNAN
+#define REAL_VALUE_ISNAN(x) \
+	(REAL_VALUES_IDENTICAL (x, NAN))
+
+#undef REAL_VALUE_ISINF
+#define REAL_VALUE_ISINF(x) \
+	((REAL_VALUES_IDENTICAL (x, POSITIVE_INF)) \
+	|| (REAL_VALUES_IDENTICAL (x, NEGATIVE_INF)) \
+	|| (REAL_VALUES_IDENTICAL (x, UNSIGNED_INF)))
+
+#define REAL_VALUE_ISNANUINF(x) \
+	((REAL_VALUE_ISNAN (x)) \
+	|| (REAL_VALUES_IDENTICAL (x, UNSIGNED_INF)))
+
+#define REAL_VALUE_ISFINITE(x) \
+	(!(REAL_VALUE_ISNAN (x)) \
+	&& !(REAL_VALUE_ISINF (x)))
+
+#define REAL_VALUE_ISZERO(x) \
+	(!((x).mantissa))
+
+#undef REAL_VALUE_MINUS_ZERO
+#define REAL_VALUE_MINUS_ZERO(x) \
+	(REAL_VALUES_IDENTICAL (x, NEGATIVE_ZERO))
+
+#define REAL_VALUE_ISPOSITIVE(x) \
+	(!(REAL_VALUE_ISNANUINF (x)) \
+	&& ((x).exponent < 0x8000) \
+	&& !(REAL_VALUE_ISZERO (x)))
+
+#define REAL_VALUE_ISNEGATIVE(x) \
+	(!(REAL_VALUE_ISNANUINF (x)) \
+	&& ((x).exponent >= 0x8000) \
+	&& !(REAL_VALUE_ISZERO (x)))
+
+#undef REAL_VALUE_POSITIVE
+#define REAL_VALUE_POSITIVE(x) \
+	(REAL_VALUE_ISPOSITIVE (x))
+
+#undef REAL_VALUE_NEGATIVE
+#define REAL_VALUE_NEGATIVE(x) \
+	(REAL_VALUE_ISNEGATIVE (x))
+
+#define real_isneg(x) \
+	(REAL_VALUE_ISNEGATIVE (*(x)))
+
+#undef REAL_VALUES_IDENTICAL
+#define REAL_VALUES_IDENTICAL(x, y) \
+	((x).exponent == (y).exponent && (x).mantissa == (y).mantissa)
+
+#undef REAL_VALUES_EQUAL
+#define REAL_VALUES_EQUAL(x,y) \
+	(((REAL_VALUES_IDENTICAL (x, y)) \
+	&& !REAL_VALUE_ISNANUINF (x) \
+	&& !REAL_VALUE_ISNANUINF (y)) \
+	|| (REAL_VALUE_ISZERO (x) \
+	&& REAL_VALUE_ISZERO (y)))
+
+#undef REAL_VALUES_LESS
+#define REAL_VALUES_LESS(x,y) \
+__extension__ ({ \
+	register int result = 0; \
+	if (REAL_VALUE_ISNANUINF (x) \
+		|| REAL_VALUE_ISNANUINF (y) \
+		|| REAL_VALUES_EQUAL (x, y) \
+		|| (REAL_VALUE_ISPOSITIVE (x) && !(REAL_VALUE_ISPOSITIVE (y))) \
+		|| (!(REAL_VALUE_ISNEGATIVE (x)) && REAL_VALUE_ISNEGATIVE (y))) \
+		result = 0; \
+	else if ((REAL_VALUE_ISNEGATIVE (x) && !(REAL_VALUE_ISNEGATIVE (y))) \
+		|| (!(REAL_VALUE_ISPOSITIVE (x)) && REAL_VALUE_ISPOSITIVE (y))) \
+		result = 1; \
+	else \
+	{ \
+		if ((x).exponent == (y).exponent) \
+		{ \
+			if (REAL_VALUE_ISNEGATIVE (x)) \
+				result = ((x).mantissa > (y).mantissa); \
+			else \
+				result = ((x).mantissa < (y).mantissa); \
+		} \
+		else \
+		{ \
+			if (REAL_VALUE_ISNEGATIVE (x)) \
+				result = ((x).exponent > (y).exponent); \
+			else \
+				result = ((x).exponent < (y).exponent); \
+		} \
+	} \
+	result; \
+})
+
+#undef REAL_VALUE_LDEXP
+#define REAL_VALUE_LDEXP(x,tempscale) \
+__extension__ ({ \
+	REAL_VALUE_TYPE __tempx = x; \
+	int scale; \
+	unsigned long long pmul; \
+	signed short carry, help; \
+	if (REAL_VALUE_ISFINITE (__tempx)) \
+	{ \
+		if (tempscale > 0) \
+			for (scale = 0; scale < tempscale; scale++) \
+			{ \
+				if (__tempx.mantissa >= 0x5000000000000000) \
+				{ \
+					__tempx.mantissa /= 0x10; \
+					__tempx.exponent++; \
+				} \
+				carry = 0; \
+				for (pmul = 1; 1; pmul *= 0x10) \
+				{ \
+					help = (__tempx.mantissa / pmul) & 0xF; \
+					__tempx.mantissa -= ((unsigned long long) help) * pmul; \
+					help *= 2; \
+					help += carry; \
+					carry = help / 10; \
+					__tempx.mantissa += ((unsigned long long) (help % 10)) * pmul; \
+					if (pmul >= 0x1000000000000000) \
+						break; \
+				} \
+			} \
+		else if (tempscale < 0) \
+			for (scale = 0; scale > tempscale; scale--) \
+			{ \
+				carry = 0; \
+				for (pmul = 0x1000000000000000; pmul > 0; pmul /= 0x10) \
+				{ \
+					help = (__tempx.mantissa / pmul) & 0xF; \
+					__tempx.mantissa -= ((unsigned long long) help) * pmul; \
+					help += carry; \
+					__tempx.mantissa += ((unsigned long long) (help / 2)) * pmul; \
+					carry = (help % 2) * 10; \
+				} \
+				if (__tempx.mantissa < 0x1000000000000000) \
+				{ \
+					__tempx.mantissa *= 0x10; \
+					__tempx.mantissa += carry / 2; \
+					__tempx.exponent--; \
+				} \
+			} \
+	} \
+	__tempx; \
+})
+
+#undef REAL_VALUE_FIX
+#define REAL_VALUE_FIX(x) \
+	((REAL_VALUE_ISNEGATIVE (x)) \
+	? (-(REAL_VALUE_UNSIGNED_FIX (REAL_VALUE_NEGATE (x)))) \
+	: (REAL_VALUE_UNSIGNED_FIX (x)))
+
+#undef REAL_VALUE_UNSIGNED_FIX
+#define REAL_VALUE_UNSIGNED_FIX(x) \
+__extension__ ({ \
+	register unsigned int r = 0; \
+	signed char i; \
+	unsigned long long mpmul = 0x1000000000000000; \
+	if (((x.exponent & 0x7FFF) >= 0x4000) && ((x.exponent & 0x7FFF) < 0x4016)) \
+	{ \
+		for (i = 0; i <= (x.exponent & 0x7FFF) - 0x4000; i++) \
+			if (mpmul) \
+			{ \
+				r *= 10; \
+				r += (x.mantissa / mpmul) & 0xF; \
+				mpmul /= 0x10; \
+			} \
+	} \
+	r; \
+})
+
+#undef REAL_VALUE_RNDZINT
+#define REAL_VALUE_RNDZINT(x) \
+__extension__ ({ \
+	REAL_VALUE_TYPE r = ZERO; \
+	signed char i; \
+	unsigned long long mpmul = 0x1000000000000000; \
+	r.exponent = (x).exponent; \
+	if (((r.exponent & 0x7FFF) >= 0x4000) && ((r.exponent & 0x7FFF) < 0x4016)) \
+	{ \
+		for (i = 0; i <= (r.exponent & 0x7FFF) - 0x4000; i++) \
+			if (mpmul) \
+			{ \
+				r.mantissa += x.mantissa & (0xF * mpmul); \
+				mpmul /= 0x10; \
+			} \
+	} \
+	r; \
+})
+
+#undef REAL_VALUE_UNSIGNED_RNDZINT
+#define REAL_VALUE_UNSIGNED_RNDZINT(x) \
+	((REAL_VALUE_ISPOSITIVE (x)) \
+	? (REAL_VALUE_RNDZINT (x)) \
+	: (ZERO))
+
+#undef REAL_VALUE_ATOF
+#define REAL_VALUE_ATOF(string,mode) \
+	real_from_string2((string), (mode))
+
+#undef REAL_ARITHMETIC
+#define REAL_ARITHMETIC(value, code, d1, d2) \
+	real_arithmetic (&(value), (code), &(d1), &(d2))
+
+#undef REAL_VALUE_NEGATE
+#define REAL_VALUE_NEGATE(x) \
+__extension__ ({ \
+	REAL_VALUE_TYPE __tempx = x; \
+	if ((!(REAL_VALUE_ISNANUINF (__tempx))) && ((__tempx.mantissa) || (__tempx.exponent != 0x4000))) \
+		__tempx.exponent ^= 0x8000; \
+	__tempx; \
+})
+
+#undef REAL_VALUE_TRUNCATE
+#define REAL_VALUE_TRUNCATE(mode,x) \
+	(x)
+
+#define real_convert(r,mode,x) \
+	(*(r)=*(x))
+
+#define REAL_VALUE_TO_INT(lo, hi, r) real_to_integer2 ((lo), (hi), &(r))
+
+#define REAL_VALUE_FROM_INT(d, lo, hi, mode) \
+	real_from_integer (&(d), (mode), (lo), (hi), 0)
+
+#define REAL_VALUE_FROM_UNSIGNED_INT(d, lo, hi, mode) \
+	real_from_integer (&(d), (mode), (lo), (hi), 1)
+
+#undef REAL_VALUE_TO_TARGET_SINGLE
+#define REAL_VALUE_TO_TARGET_SINGLE(IN, OUT) \
+	abort();
+
+#undef REAL_VALUE_TO_TARGET_DOUBLE
+#define REAL_VALUE_TO_TARGET_DOUBLE(IN, OUT) \
+	abort();
+
+#undef REAL_VALUE_TO_TARGET_LONG_DOUBLE
+#define REAL_VALUE_TO_TARGET_LONG_DOUBLE(IN, OUT) \
+do { \
+	REAL_VALUE_TYPE f = (IN); \
+	(OUT)[0] = f.exponent * 0x10000 + ((unsigned short) (f.mantissa / 0x1000000000000)), (OUT)[1] = (unsigned long) (f.mantissa / 0x10000), (OUT)[2] = ((unsigned short) (f.mantissa)) * 0x10000; \
+} while (0)
+
+#undef REAL_VALUE_TO_TARGET_SMAP_BCD
+#define REAL_VALUE_TO_TARGET_SMAP_BCD(IN, OUT) \
+do { \
+	REAL_VALUE_TYPE f = (IN); \
+	(OUT)[0] = f.exponent, (OUT)[1] = (unsigned long) (f.mantissa / 0x100000000), (OUT)[2] = (unsigned long) (f.mantissa); \
+} while (0)
+
+#define REAL_VALUE_TO_STRING(IN, OUT) \
+do { \
+	REAL_VALUE_TYPE f = (IN); \
+	if (REAL_VALUE_ISNAN (f)) \
+		sprintf ((OUT), "NaN"); \
+	else if (REAL_VALUES_IDENTICAL (f, UNSIGNED_INF)) \
+		sprintf ((OUT), "Inf"); \
+	else if (REAL_VALUES_IDENTICAL (f, POSITIVE_INF)) \
+		sprintf ((OUT), "+Inf"); \
+	else if (REAL_VALUES_IDENTICAL (f, NEGATIVE_INF)) \
+		sprintf ((OUT), "-Inf"); \
+	else if (REAL_VALUES_IDENTICAL (f, UNSIGNED_ZERO)) \
+		sprintf ((OUT), "0.0"); \
+	else if (REAL_VALUES_IDENTICAL (f, POSITIVE_ZERO)) \
+		sprintf ((OUT), "+0.0"); \
+	else if (REAL_VALUES_IDENTICAL (f, NEGATIVE_ZERO)) \
+		sprintf ((OUT), "-0.0"); \
+	else \
+	{ \
+		long exp; \
+		int neg = REAL_VALUE_ISNEGATIVE (f); \
+		if (neg) \
+			exp = f.exponent - 0xC000; \
+		else \
+			exp = f.exponent - 0x4000; \
+		sprintf ((OUT), "%s%lx.%07lx%08lxe%d", neg ? "-" : "", (unsigned long) (f.mantissa >> 60), (unsigned long) (f.mantissa >> 32) & 0x0ffffffful, (unsigned long) (f.mantissa), (int) (exp)); \
+	} \
+} while (0)
+
+#define REAL_VALUE_ABS(x) ((REAL_VALUE_ISNEGATIVE((x))\
+                            || REAL_VALUE_MINUS_ZERO((x))\
+                            || REAL_VALUES_IDENTICAL ((x), NEGATIVE_INF))?\
+                           REAL_VALUE_NEGATE((x)):(x))
+
+/* WARNING: This is the number of bits we can represent, not the true size of
+            the mantissa. */
+#define significand_size(dummy) (53)
+
+#undef MODE_HAS_NANS
+#define MODE_HAS_NANS(MODE) ((MODE)==BFmode)
+
+#undef MODE_HAS_INFINITIES
+#define MODE_HAS_INFINITIES(MODE) ((MODE)==BFmode)
+
+/* FIXME: GCC expects this to mean that there is only 0 and -0. We actually have
+          0, +0 and -0. This allows a few optimizations GCC is too cautious to
+          do in the presence of signed zeros. */
+#undef MODE_HAS_SIGNED_ZEROS
+#define MODE_HAS_SIGNED_ZEROS(MODE) ((MODE)==BFmode)
+
+#define REAL_MODE_FORMAT_COMPOSITE_P(dummy) (0)
+
+/* end of smapbcd.h */
diff -Naur gcc-4.1-20051216.orig/gcc/config.gcc gcc-4.1-20051216-src/gcc/config.gcc
--- gcc-4.1-20051216.orig/gcc/config.gcc	2005-12-16 14:51:19.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/config.gcc	2005-12-18 22:24:36.000000000 +0100
@@ -1374,7 +1374,7 @@
 m68k-*-coff*)
 	tmake_file=m68k/t-m68kbare
 	tm_defines="MOTOROLA USE_GAS"
-	tm_file="m68k/m68k.h m68k/m68k-none.h m68k/m68kemb.h dbxcoff.h m68k/coff.h dbx.h"
+	tm_file="m68k/m68k.h m68k/m68k-none.h dbxcoff.h m68k/coff.h smapbcd.h m68k/m68k-ti.h dbx.h"
 	use_fixproto=yes
 	;;
 m68020-*-elf* | m68k-*-elf*)
diff -Naur gcc-4.1-20051216.orig/gcc/convert.c gcc-4.1-20051216-src/gcc/convert.c
--- gcc-4.1-20051216.orig/gcc/convert.c	2005-10-11 20:14:57.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/convert.c	2005-12-18 22:24:36.000000000 +0100
@@ -73,6 +73,9 @@
 {
   tree sub, expt, subt;
 
+/* (TIGCC 20050205) We do not implement exact_real_truncate and there is no
+                    narrower float mode anyway. -- Kevin Kofler */
+#if 0
   /*  For floating point constant look up the narrowest type that can hold
       it properly and handle it like (type)(narrowest_type)constant.
       This way we can optimize for instance a=a*2.0 where "a" is float
@@ -93,6 +96,7 @@
       if (type)
 	return build_real (type, real_value_truncate (TYPE_MODE (type), orig));
     }
+#endif /* 0 */
 
   if (TREE_CODE (exp) != NOP_EXPR
       && TREE_CODE (exp) != CONVERT_EXPR)
diff -Naur gcc-4.1-20051216.orig/gcc/c.opt gcc-4.1-20051216-src/gcc/c.opt
--- gcc-4.1-20051216.orig/gcc/c.opt	2005-11-15 20:14:59.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c.opt	2005-12-19 00:46:06.000000000 +0100
@@ -420,7 +420,7 @@
 Give strings the type \"array of char\"
 
 Wpointer-sign
-C ObjC Var(warn_pointer_sign) Init(1)
+C ObjC Var(warn_pointer_sign) Init(0)
 Warn when a pointer differs in signedness in an assignment
 
 ansi
@@ -446,6 +446,10 @@
 C ObjC C++ ObjC++
 Recognize the \"asm\" keyword
 
+fauto-octals
+C ObjC C++ ObjC++
+Numbers starting with zero should be octal (default on).
+
 fbuiltin
 C ObjC C++ ObjC++
 Recognize built-in functions
diff -Naur gcc-4.1-20051216.orig/gcc/c-opts.c gcc-4.1-20051216-src/gcc/c-opts.c
--- gcc-4.1-20051216.orig/gcc/c-opts.c	2005-11-04 09:29:16.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-opts.c	2005-12-18 22:24:28.000000000 +0100
@@ -222,6 +222,9 @@
      before passing on command-line options to cpplib.  */
   cpp_opts->warn_dollars = 0;
 
+  /* (TIGCC 20050217) Enable -fms-extensions by default. */
+  flag_ms_extensions = 1;
+
   flag_const_strings = c_dialect_cxx ();
   flag_exceptions = c_dialect_cxx ();
   warn_pointer_arith = c_dialect_cxx ();
@@ -319,7 +322,9 @@
 	    error ("-I- specified twice");
 	  quote_chain_split = true;
 	  split_quote_chain ();
+#if 0 /* (TIGCC 20050206) */
 	  inform ("obsolete option -I- used, please use -iquote instead");
+#endif /* 0 */
 	}
       break;
 
@@ -874,6 +879,8 @@
     case OPT_pedantic:
       cpp_opts->pedantic = 1;
       cpp_opts->warn_endif_labels = 1;
+      /* (TIGCC 20050217) No Microsoft extensions if -pedantic. */
+      flag_ms_extensions = 0;
       break;
 
     case OPT_print_objc_runtime_info:
@@ -935,6 +942,10 @@
     case OPT_v:
       verbose = true;
       break;
+
+    case OPT_fauto_octals:
+      cpp_opts->no_auto_octals = !value;
+      break;
     }
 
   return result;
@@ -1010,10 +1021,12 @@
 	       "-Wformat-security ignored without -Wformat");
     }
 
+#if 0 /* (TIGCC 20050306) Disable as we don't have these libcalls. */
   /* C99 requires special handling of complex multiplication and division;
      -ffast-math and -fcx-limited-range are handled in process_options.  */
   if (flag_isoc99)
     flag_complex_method = 2;
+#endif /* 0 */
 
   if (flag_preprocess_only)
     {
diff -Naur gcc-4.1-20051216.orig/gcc/cppdefault.c gcc-4.1-20051216-src/gcc/cppdefault.c
--- gcc-4.1-20051216.orig/gcc/cppdefault.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/cppdefault.c	2005-12-18 22:24:36.000000000 +0100
@@ -46,6 +46,7 @@
 = INCLUDE_DEFAULTS;
 #else
 = {
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
 #ifdef GPLUSPLUS_INCLUDE_DIR
     /* Pick up GNU C++ generic include files.  */
     { GPLUSPLUS_INCLUDE_DIR, "G++", 1, 1, 0 },
@@ -85,11 +86,12 @@
     /* /usr/include comes dead last.  */
     { STANDARD_INCLUDE_DIR, STANDARD_INCLUDE_COMPONENT, 0, 0, 1 },
 #endif
+#endif /* 0 */
     { 0, 0, 0, 0, 0 }
   };
 #endif /* no INCLUDE_DEFAULTS */
 
-#ifdef GCC_INCLUDE_DIR
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
 const char cpp_GCC_INCLUDE_DIR[] = GCC_INCLUDE_DIR;
 const size_t cpp_GCC_INCLUDE_DIR_len = sizeof GCC_INCLUDE_DIR - 8;
 #else
diff -Naur gcc-4.1-20051216.orig/gcc/c-ppoutput.c gcc-4.1-20051216-src/gcc/c-ppoutput.c
--- gcc-4.1-20051216.orig/gcc/c-ppoutput.c	2005-10-14 16:56:45.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/c-ppoutput.c	2005-12-18 22:24:35.000000000 +0100
@@ -174,7 +174,8 @@
       print.prev = token;
       cpp_output_token (token, print.outf);
 
-      if (token->type == CPP_COMMENT)
+      if (token->type == CPP_STRING || token->type == CPP_WSTRING
+	  || token->type == CPP_COMMENT)
 	account_for_newlines (token->val.str.text, token->val.str.len);
     }
 }
diff -Naur gcc-4.1-20051216.orig/gcc/c-pretty-print.c gcc-4.1-20051216-src/gcc/c-pretty-print.c
--- gcc-4.1-20051216.orig/gcc/c-pretty-print.c	2005-11-03 04:30:36.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-pretty-print.c	2005-12-18 22:24:35.000000000 +0100
@@ -904,8 +904,7 @@
 static void
 pp_c_floating_constant (c_pretty_printer *pp, tree r)
 {
-  real_to_decimal (pp_buffer (pp)->digit_buffer, &TREE_REAL_CST (r),
-		   sizeof (pp_buffer (pp)->digit_buffer), 0, 1);
+  REAL_VALUE_TO_STRING (TREE_REAL_CST (r), pp_buffer (pp)->digit_buffer);
   pp_string (pp, pp_buffer(pp)->digit_buffer);
   if (TREE_TYPE (r) == float_type_node)
     pp_character (pp, 'f');
@@ -1948,6 +1947,17 @@
       pp_postfix_expression (pp, TREE_OPERAND (e, 1));
       break;
 
+    /* (TIGCC 20050210) Get pp_c_expression to print statement expressions
+                        correctly. We only print the last statement of a list,
+                        because that's the result of the statement expression. */
+    case BIND_EXPR:
+      pp_c_expression (pp, BIND_EXPR_BODY (e));
+      break;
+
+    case STATEMENT_LIST:
+      pp_c_expression (pp, STATEMENT_LIST_TAIL (e)->stmt);
+      break;
+
     default:
       pp_unsupported_tree (pp, e);
       break;
diff -Naur gcc-4.1-20051216.orig/gcc/c-tree.h gcc-4.1-20051216-src/gcc/c-tree.h
--- gcc-4.1-20051216.orig/gcc/c-tree.h	2005-11-19 00:40:29.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-tree.h	2005-12-18 22:24:35.000000000 +0100
@@ -353,6 +353,8 @@
   tree attrs;
   /* The declarator.  */
   struct c_declarator *declarator;
+  /* (TIGCC 20050203) The asmspec.  */
+  tree asmspec;
 };
 
 /* Save and restore the variables in this file and elsewhere
@@ -431,6 +433,7 @@
 extern tree pushdecl (tree);
 extern void c_expand_body (tree);
 
+extern void c_insert_default_attributes (tree);
 extern void c_init_decl_processing (void);
 extern void c_dup_lang_specific_decl (tree);
 extern void c_print_identifier (FILE *, tree, int);
@@ -478,7 +481,7 @@
 extern struct c_typespec parser_xref_tag (enum tree_code, tree);
 extern int c_expand_decl (tree);
 extern struct c_parm *build_c_parm (struct c_declspecs *, tree,
-				    struct c_declarator *);
+				    struct c_declarator *, tree /* (TIGCC 20050203) */);
 extern struct c_declarator *build_attrs_declarator (tree,
 						    struct c_declarator *);
 extern struct c_declarator *build_function_declarator (struct c_arg_info *,
diff -Naur gcc-4.1-20051216.orig/gcc/c-typeck.c gcc-4.1-20051216-src/gcc/c-typeck.c
--- gcc-4.1-20051216.orig/gcc/c-typeck.c	2005-12-08 12:24:07.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/c-typeck.c	2005-12-19 00:34:06.000000000 +0100
@@ -83,6 +83,8 @@
 static tree lookup_field (tree, tree);
 static tree convert_arguments (tree, tree, tree, tree);
 static tree pointer_diff (tree, tree);
+static tree unary_complex_lvalue (enum tree_code, tree, int);
+static void pedantic_lvalue_warning (enum tree_code);
 static tree convert_for_assignment (tree, tree, enum impl_conv, tree, tree,
 				    int);
 static tree valid_compound_expr_initializer (tree, tree);
@@ -2162,6 +2164,7 @@
   /* fntype now gets the type of function pointed to.  */
   fntype = TREE_TYPE (fntype);
 
+#if 0
   /* Check that the function is called through a compatible prototype.
      If it is not, replace the call by a trap, wrapped up in a compound
      expression if necessary.  This has the nice side-effect to prevent
@@ -2200,6 +2203,7 @@
 	  return build2 (COMPOUND_EXPR, return_type, trap, rhs);
 	}
     }
+#endif /* 0 */
 
   /* Convert the parameters to the types declared in the
      function prototype, or apply default promotions.  */
@@ -2774,6 +2778,12 @@
     case POSTINCREMENT_EXPR:
     case PREDECREMENT_EXPR:
     case POSTDECREMENT_EXPR:
+      /* Handle complex lvalues (when permitted)
+	 by reduction to simpler cases.  */
+
+      val = unary_complex_lvalue (code, arg, 0);
+      if (val != 0)
+	return val;
 
       /* Increment or decrement the real part of the value,
 	 and don't change the imaginary part.  */
@@ -2842,6 +2852,57 @@
 
 	inc = convert (argtype, inc);
 
+	/* Handle incrementing a cast-expression.  */
+
+	while (1)
+	  switch (TREE_CODE (arg))
+	    {
+	    case NOP_EXPR:
+	    case CONVERT_EXPR:
+	    case FLOAT_EXPR:
+	    case FIX_TRUNC_EXPR:
+	    case FIX_FLOOR_EXPR:
+	    case FIX_ROUND_EXPR:
+	    case FIX_CEIL_EXPR:
+	      pedantic_lvalue_warning (CONVERT_EXPR);
+	      /* If the real type has the same machine representation
+		 as the type it is cast to, we can make better output
+		 by adding directly to the inside of the cast.  */
+	      if ((TREE_CODE (TREE_TYPE (arg))
+		   == TREE_CODE (TREE_TYPE (TREE_OPERAND (arg, 0))))
+		  && (TYPE_MODE (TREE_TYPE (arg))
+		      == TYPE_MODE (TREE_TYPE (TREE_OPERAND (arg, 0)))))
+		arg = TREE_OPERAND (arg, 0);
+	      else
+		{
+		  tree incremented, modify, value;
+		  if (TREE_CODE (TREE_TYPE (arg)) == BOOLEAN_TYPE)
+		    value = boolean_increment (code, arg);
+		  else
+		    {
+		      arg = stabilize_reference (arg);
+		      if (code == PREINCREMENT_EXPR || code == PREDECREMENT_EXPR)
+			value = arg;
+		      else
+			value = save_expr (arg);
+		      incremented = build (((code == PREINCREMENT_EXPR
+					     || code == POSTINCREMENT_EXPR)
+					    ? PLUS_EXPR : MINUS_EXPR),
+					   argtype, value, inc);
+		      TREE_SIDE_EFFECTS (incremented) = 1;
+		      modify = build_modify_expr (arg, NOP_EXPR, incremented);
+		      value = build (COMPOUND_EXPR, TREE_TYPE (arg), modify, value);
+		    }
+		  TREE_USED (value) = 1;
+		  return value;
+		}
+	      break;
+
+	    default:
+	      goto give_up;
+	    }
+      give_up:
+
 	/* Complain about anything else that is not a true lvalue.  */
 	if (!lvalue_or_else (arg, ((code == PREINCREMENT_EXPR
 				    || code == POSTINCREMENT_EXPR)
@@ -2892,6 +2953,12 @@
 				  TREE_OPERAND (arg, 1), 1);
 	}
 
+      /* Handle complex lvalues (when permitted)
+	 by reduction to simpler cases.  */
+      val = unary_complex_lvalue (code, arg, flag);
+      if (val != 0)
+	return val;
+
       /* Anything not already handled and not a true memory reference
 	 or a non-lvalue array is an error.  */
       else if (typecode != FUNCTION_TYPE && !flag
@@ -2977,6 +3044,69 @@
     }
 }
 
+/* Apply unary lvalue-demanding operator CODE to the expression ARG
+   for certain kinds of expressions which are not really lvalues
+   but which we can accept as lvalues.  If FLAG is nonzero, then
+   non-lvalues are OK since we may be converting a non-lvalue array to
+   a pointer in C99.
+
+   If ARG is not a kind of expression we can handle, return zero.  */
+
+static tree
+unary_complex_lvalue (enum tree_code code, tree arg, int flag)
+{
+  /* Handle (a, b) used as an "lvalue".  */
+  if (TREE_CODE (arg) == COMPOUND_EXPR)
+    {
+      tree real_result = build_unary_op (code, TREE_OPERAND (arg, 1), 0);
+
+      /* If this returns a function type, it isn't really being used as
+	 an lvalue, so don't issue a warning about it.  */
+      if (TREE_CODE (TREE_TYPE (arg)) != FUNCTION_TYPE && !flag)
+	pedantic_lvalue_warning (COMPOUND_EXPR);
+
+      return build (COMPOUND_EXPR, TREE_TYPE (real_result),
+		    TREE_OPERAND (arg, 0), real_result);
+    }
+
+  /* Handle (a ? b : c) used as an "lvalue".  */
+  if (TREE_CODE (arg) == COND_EXPR)
+    {
+      if (!flag)
+	pedantic_lvalue_warning (COND_EXPR);
+      if (TREE_CODE (TREE_TYPE (arg)) != FUNCTION_TYPE && !flag)
+	pedantic_lvalue_warning (COMPOUND_EXPR);
+
+      return (build_conditional_expr
+	      (TREE_OPERAND (arg, 0),
+	       build_unary_op (code, TREE_OPERAND (arg, 1), flag),
+	       build_unary_op (code, TREE_OPERAND (arg, 2), flag)));
+    }
+
+  return 0;
+}
+
+/* If pedantic, warn about improper lvalue.   CODE is either COND_EXPR
+   COMPOUND_EXPR, or CONVERT_EXPR (for casts).  */
+
+static void
+pedantic_lvalue_warning (enum tree_code code)
+{
+  if (pedantic)
+    switch (code)
+      {
+      case COND_EXPR:
+	pedwarn ("ISO C forbids use of conditional expressions as lvalues");
+	break;
+      case COMPOUND_EXPR:
+	pedwarn ("ISO C forbids use of compound expressions as lvalues");
+	break;
+      default:
+	pedwarn ("ISO C forbids use of cast expressions as lvalues");
+	break;
+      }
+}
+  
 /* Give an error for storing in something that is 'const'.  */
 
 static void
@@ -3490,8 +3620,8 @@
 	}
     }
 
-  /* Don't let a cast be an lvalue.  */
-  if (value == expr)
+  /* If pedantic, don't let a cast be an lvalue.  */
+  if (value == expr && pedantic)
     value = non_lvalue (value);
 
   return value;
@@ -3539,6 +3669,45 @@
 
   newrhs = rhs;
 
+  /* Handle control structure constructs used as "lvalues".  */
+
+  switch (TREE_CODE (lhs))
+    {
+      /* Handle (a, b) used as an "lvalue".  */
+    case COMPOUND_EXPR:
+      pedantic_lvalue_warning (COMPOUND_EXPR);
+      newrhs = build_modify_expr (TREE_OPERAND (lhs, 1), modifycode, rhs);
+      if (TREE_CODE (newrhs) == ERROR_MARK)
+	return error_mark_node;
+      return build (COMPOUND_EXPR, lhstype,
+		    TREE_OPERAND (lhs, 0), newrhs);
+
+      /* Handle (a ? b : c) used as an "lvalue".  */
+    case COND_EXPR:
+      pedantic_lvalue_warning (COND_EXPR);
+      rhs = save_expr (rhs);
+      {
+	/* Produce (a ? (b = rhs) : (c = rhs))
+	   except that the RHS goes through a save-expr
+	   so the code to compute it is only emitted once.  */
+	tree cond
+	  = build_conditional_expr (TREE_OPERAND (lhs, 0),
+				    build_modify_expr (TREE_OPERAND (lhs, 1),
+						       modifycode, rhs),
+				    build_modify_expr (TREE_OPERAND (lhs, 2),
+						       modifycode, rhs));
+	if (TREE_CODE (cond) == ERROR_MARK)
+	  return cond;
+	/* Make sure the code to compute the rhs comes out
+	   before the split.  */
+	return build (COMPOUND_EXPR, TREE_TYPE (lhs),
+		      /* But cast it to void to avoid an "unused" error.  */
+		      convert (void_type_node, rhs), cond);
+      }
+    default:
+      break;
+    }
+
   /* If a binary op has been requested, combine the old LHS value with the RHS
      producing the value we should actually store into the LHS.  */
 
@@ -3548,6 +3717,42 @@
       newrhs = build_binary_op (modifycode, lhs, rhs, 1);
     }
 
+  /* Handle a cast used as an "lvalue".
+     We have already performed any binary operator using the value as cast.
+     Now convert the result to the cast type of the lhs,
+     and then true type of the lhs and store it there;
+     then convert result back to the cast type to be the value
+     of the assignment.  */
+
+  switch (TREE_CODE (lhs))
+    {
+    case NOP_EXPR:
+    case CONVERT_EXPR:
+    case FLOAT_EXPR:
+    case FIX_TRUNC_EXPR:
+    case FIX_FLOOR_EXPR:
+    case FIX_ROUND_EXPR:
+    case FIX_CEIL_EXPR:
+      newrhs = default_function_array_conversion (newrhs);
+      {
+	tree inner_lhs = TREE_OPERAND (lhs, 0);
+	tree result;
+	result = build_modify_expr (inner_lhs, NOP_EXPR,
+				    convert (TREE_TYPE (inner_lhs),
+					     convert (lhstype, newrhs)));
+	if (TREE_CODE (result) == ERROR_MARK)
+	  return result;
+	pedantic_lvalue_warning (CONVERT_EXPR);
+	return convert (TREE_TYPE (lhs), result);
+      }
+
+    default:
+      break;
+    }
+
+  /* Now we have handled acceptable kinds of LHS that are not truly lvalues.
+     Reject anything strange now.  */
+
   if (!lvalue_or_else (lhs, lv_assign))
     return error_mark_node;
 
@@ -4343,10 +4548,11 @@
 {
   char *ofwhat;
 
-  error ("%s", _(msgid));
   ofwhat = print_spelling ((char *) alloca (spelling_length () + 1));
   if (*ofwhat)
-    error ("(near initialization for %qs)", ofwhat);
+    error ("%s (near initialization for %qs)", _(msgid), ofwhat);
+  else
+    error ("%s", _(msgid));
 }
 
 /* Issue a pedantic warning for a bad initializer component.
@@ -4358,10 +4564,11 @@
 {
   char *ofwhat;
 
-  pedwarn ("%s", _(msgid));
   ofwhat = print_spelling ((char *) alloca (spelling_length () + 1));
   if (*ofwhat)
-    pedwarn ("(near initialization for %qs)", ofwhat);
+    pedwarn ("%s (near initialization for %qs)", _(msgid), ofwhat);
+  else
+    pedwarn ("%s", _(msgid));
 }
 
 /* Issue a warning for a bad initializer component.
@@ -4373,10 +4580,11 @@
 {
   char *ofwhat;
 
-  warning (0, "%s", _(msgid));
   ofwhat = print_spelling ((char *) alloca (spelling_length () + 1));
   if (*ofwhat)
-    warning (0, "(near initialization for %qs)", ofwhat);
+    warning (0, "%s (near initialization for %qs)", _(msgid), ofwhat);
+  else
+    warning (0, "%s", _(msgid));
 }
 
 /* If TYPE is an array type and EXPR is a parenthesized string
diff -Naur gcc-4.1-20051216.orig/gcc/diagnostic.c gcc-4.1-20051216-src/gcc/diagnostic.c
--- gcc-4.1-20051216.orig/gcc/diagnostic.c	2005-11-04 00:08:18.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/diagnostic.c	2005-12-18 22:24:36.000000000 +0100
@@ -252,9 +252,8 @@
       if (context->abort_on_error)
 	real_abort ();
 
-      fnotice (stderr, "Please submit a full bug report,\n"
-	       "with preprocessed source if appropriate.\n"
-	       "See %s for instructions.\n", bug_report_url);
+      fnotice (stderr, "Please fill out a bug report form at %s.\n",
+               bug_report_url);
       exit (FATAL_EXIT_CODE);
 
     case DK_FATAL:
diff -Naur gcc-4.1-20051216.orig/gcc/dwarf2.h gcc-4.1-20051216-src/gcc/dwarf2.h
--- gcc-4.1-20051216.orig/gcc/dwarf2.h	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/dwarf2.h	2005-12-18 22:24:36.000000000 +0100
@@ -352,6 +352,7 @@
     DW_AT_body_begin = 0x2105,
     DW_AT_body_end   = 0x2106,
     DW_AT_GNU_vector = 0x2107,
+    DW_AT_regparm_location = 0x2120,
     /* VMS extensions.  */
     DW_AT_VMS_rtnbeg_pd_address = 0x2201,
     /* UPC extension.  */
diff -Naur gcc-4.1-20051216.orig/gcc/dwarf2out.c gcc-4.1-20051216-src/gcc/dwarf2out.c
--- gcc-4.1-20051216.orig/gcc/dwarf2out.c	2005-12-09 00:47:48.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/dwarf2out.c	2005-12-20 16:36:14.000000000 +0100
@@ -2164,8 +2164,11 @@
      emit any EH unwind information.  Note that if exceptions aren't
      enabled, we won't have collected nothrow information, and if we
      asked for asynchronous tables, we always want this info.  */
+  /* (TIGCC 20050507) We want unwinding tables for debugging purposes only,
+     so we don't want an .eh_frame section we didn't ask for. */
   if (for_eh)
     {
+#if 0
       bool any_eh_needed = !flag_exceptions || flag_asynchronous_unwind_tables;
 
       for (i = 0; i < fde_table_in_use; i++)
@@ -2178,6 +2181,7 @@
 	  any_eh_needed = true;
 
       if (! any_eh_needed)
+#endif /* 0 */
 	return;
     }
 
@@ -4139,7 +4143,7 @@
 static void decls_for_scope (tree, dw_die_ref, int);
 static int is_redundant_typedef (tree);
 static void gen_namespace_die (tree);
-static void gen_decl_die (tree, dw_die_ref);
+static dw_die_ref gen_decl_die (tree, dw_die_ref);
 static dw_die_ref force_decl_die (tree);
 static dw_die_ref force_type_die (tree);
 static dw_die_ref setup_namespace_context (tree, dw_die_ref);
@@ -4640,6 +4644,8 @@
       return "DW_AT_body_end";
     case DW_AT_GNU_vector:
       return "DW_AT_GNU_vector";
+    case DW_AT_regparm_location:
+      return "DW_AT_regparm_location";
 
     case DW_AT_VMS_rtnbeg_pd_address:
       return "DW_AT_VMS_rtnbeg_pd_address";
@@ -9746,14 +9752,7 @@
   int i;
 
   REAL_VALUE_FROM_CONST_DOUBLE (rv, rtl);
-  real_to_target (val, &rv, GET_MODE (rtl));
-
-  /* real_to_target puts 32-bit pieces in each long.  Pack them.  */
-  for (i = 0; i < GET_MODE_SIZE (GET_MODE (rtl)) / 4; i++)
-    {
-      insert_int (val[i], 4, array);
-      array += 4;
-    }
+  REAL_VALUE_TO_TARGET_SMAP_BCD (rv, array);
 }
 
 /* Attach a DW_AT_const_value attribute for a variable or a parameter which
@@ -9792,7 +9791,7 @@
 	    unsigned char *array = ggc_alloc (length);
 
 	    insert_float (rtl, array);
-	    add_AT_vec (die, DW_AT_const_value, length / 4, 4, array);
+	    add_AT_vec (die, DW_AT_const_value, 1, length, array); /* (TIGCC 20050403) */
 	  }
 	else
 	  {
@@ -11338,6 +11337,10 @@
    DW_TAG_unspecified_parameters DIE) to represent the types of the formal
    parameters as specified in some function type specification (except for
    those which appear as part of a function *definition*).  */
+/* (TIGCC 20050409) We also want to generate DW_AT_regparm_location
+   information for register parameters so GDB can call the function
+   correctly. We don't use DW_AT_location in order not to conflict with
+   the location list support. */
 
 static void
 gen_formal_types_die (tree function_or_method_type, dw_die_ref context_die)
@@ -11346,15 +11349,21 @@
   tree formal_type = NULL;
   tree first_parm_type;
   tree arg;
+  tree function_or_method_decl = NULL_TREE;
+  CUMULATIVE_ARGS cum;
 
   if (TREE_CODE (function_or_method_type) == FUNCTION_DECL)
     {
+      function_or_method_decl = function_or_method_type;
       arg = DECL_ARGUMENTS (function_or_method_type);
       function_or_method_type = TREE_TYPE (function_or_method_type);
     }
   else
     arg = NULL_TREE;
 
+  if (function_or_method_decl)
+    INIT_CUMULATIVE_ARGS (cum, function_or_method_type, NULL, function_or_method_decl, 0);
+
   first_parm_type = TYPE_ARG_TYPES (function_or_method_type);
 
   /* Make our first pass over the list of formal parameter types and output a
@@ -11374,6 +11383,17 @@
 	  || (arg && DECL_ARTIFICIAL (arg)))
 	add_AT_flag (parm_die, DW_AT_artificial, 1);
 
+      if (function_or_method_decl)
+        {
+          rtx argrtx = FUNCTION_ARG(cum, TYPE_MODE (formal_type), formal_type, 0);
+          if (argrtx && GET_CODE (argrtx) == REG && REGNO (argrtx) < FIRST_PSEUDO_REGISTER)
+            {
+              add_AT_location_description (parm_die, DW_AT_regparm_location, reg_loc_descriptor (argrtx));
+            }
+
+          FUNCTION_ARG_ADVANCE(cum, 0, 0, 0);
+        }
+
       link = TREE_CHAIN (link);
       if (arg)
 	arg = TREE_CHAIN (arg);
@@ -11477,6 +11497,10 @@
 
 /* Generate a DIE to represent a declared function (either file-scope or
    block-local).  */
+/* (TIGCC 20050409) We also want to generate DW_AT_regparm_location
+   information for register parameters so GDB can call the function
+   correctly. We don't use DW_AT_location in order not to conflict with
+   the location list support. */
 
 static void
 gen_subprogram_die (tree decl, dw_die_ref context_die)
@@ -11489,6 +11513,7 @@
   dw_die_ref old_die = lookup_decl_die (decl);
   int declaration = (current_function_decl != decl
 		     || class_or_namespace_scope_p (context_die));
+  CUMULATIVE_ARGS cum;
 
   /* It is possible to have both DECL_ABSTRACT and DECLARATION be true if we
      started to generate the abstract instance of an inline, decided to output
@@ -11739,6 +11764,8 @@
       tree arg_decls = DECL_ARGUMENTS (decl);
       tree parm;
 
+      INIT_CUMULATIVE_ARGS (cum, TREE_TYPE (decl), NULL, decl, 0);
+
       /* When generating DIEs, generate the unspecified_parameters DIE
 	 instead if we come across the arg "__builtin_va_alist" */
       for (parm = arg_decls; parm; parm = TREE_CHAIN (parm))
@@ -11749,7 +11776,16 @@
 			    "__builtin_va_alist"))
 	      gen_unspecified_parameters_die (parm, subr_die);
 	    else
-	      gen_decl_die (parm, subr_die);
+	      {
+	        dw_die_ref parm_die = gen_decl_die (parm, subr_die);
+	        rtx argrtx = FUNCTION_ARG(cum, TYPE_MODE (TREE_TYPE (parm)), TREE_TYPE (parm), 0);
+	        if (parm_die && argrtx && GET_CODE (argrtx) == REG && REGNO (argrtx) < FIRST_PSEUDO_REGISTER)
+	          {
+	            add_AT_location_description (parm_die, DW_AT_regparm_location, reg_loc_descriptor (argrtx));
+	          }
+	      }
+
+	    FUNCTION_ARG_ADVANCE(cum, 0, 0, 0);
 	  }
 
       /* Decide whether we need an unspecified_parameters DIE at the end.
@@ -12977,14 +13013,15 @@
 }
 
 /* Generate Dwarf debug information for a decl described by DECL.  */
+/* (TIGCC 20050409) Return the DIE for the parameter case. */
 
-static void
+static dw_die_ref
 gen_decl_die (tree decl, dw_die_ref context_die)
 {
   tree origin;
 
   if (DECL_P (decl) && DECL_IGNORED_P (decl))
-    return;
+    return NULL;
 
   switch (TREE_CODE (decl))
     {
@@ -13127,8 +13164,7 @@
 
     case PARM_DECL:
       gen_type_die (TREE_TYPE (decl), context_die);
-      gen_formal_parameter_die (decl, context_die);
-      break;
+      return gen_formal_parameter_die (decl, context_die);
 
     case NAMESPACE_DECL:
       gen_namespace_die (decl);
@@ -13139,6 +13175,8 @@
       gcc_assert ((int)TREE_CODE (decl) > NUM_TREE_CODES);
       break;
     }
+
+    return NULL;
 }
 
 /* Add Ada "use" clause information for SGI Workshop debugger.  */
@@ -13461,9 +13499,12 @@
      unused debug types, then we must emit .file here.  If we are eliminating
      unused debug types, then this will be done by the maybe_emit_file call in
      prune_unused_types_walk_attribs.  */
+  /* (TIGCC 20051220) Don't return the result of maybe_emit_file, it will cause
+                      maybe_emit_file to be called twice on the same fileno.
+                      -- Kevin Kofler */
 
   if (DWARF2_ASM_LINE_DEBUG_INFO && ! flag_eliminate_unused_debug_types)
-    return maybe_emit_file (i);
+    /*return*/ maybe_emit_file (i);
 
   return i;
 }
@@ -13586,7 +13627,10 @@
   if (debug_info_level >= DINFO_LEVEL_NORMAL
       && line != 0)
     {
-      current_function_section (current_function_decl);
+      /* (TIGCC 20050424) We also get called for top-level ASM with no
+                          current_function_decl, so don't crash in that case. */
+      if (current_function_decl)
+        current_function_section (current_function_decl);
 
       /* If requested, emit something human-readable.  */
       if (flag_debug_asm)
@@ -13606,10 +13650,10 @@
 	  line_info_table_in_use++;
 
 	  /* Indicate that multiple line number tables exist.  */
-	  if (DECL_SECTION_NAME (current_function_decl))
+	  if (current_function_decl && DECL_SECTION_NAME (current_function_decl))
 	    separate_line_info_table_in_use++;
 	}
-      else if (DECL_SECTION_NAME (current_function_decl))
+      else if (current_function_decl && DECL_SECTION_NAME (current_function_decl))
 	{
 	  dw_separate_line_info_ref line_info;
 	  targetm.asm_out.internal_label (asm_out_file, SEPARATE_LINE_CODE_LABEL,
diff -Naur gcc-4.1-20051216.orig/gcc/emit-rtl.c gcc-4.1-20051216-src/gcc/emit-rtl.c
--- gcc-4.1-20051216.orig/gcc/emit-rtl.c	2005-09-05 18:45:20.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/emit-rtl.c	2005-12-18 22:24:40.000000000 +0100
@@ -104,8 +104,10 @@
 REAL_VALUE_TYPE dconstm2;
 REAL_VALUE_TYPE dconsthalf;
 REAL_VALUE_TYPE dconstthird;
+#if 0
 REAL_VALUE_TYPE dconstpi;
 REAL_VALUE_TYPE dconste;
+#endif /* 0 */
 
 /* All references to the following fixed hard registers go through
    these unique rtl objects.  On machines where the frame-pointer and
@@ -240,8 +242,8 @@
     return (CONST_DOUBLE_LOW (a) == CONST_DOUBLE_LOW (b)
 	    && CONST_DOUBLE_HIGH (a) == CONST_DOUBLE_HIGH (b));
   else
-    return real_identical (CONST_DOUBLE_REAL_VALUE (a),
-			   CONST_DOUBLE_REAL_VALUE (b));
+    return REAL_VALUES_IDENTICAL (*CONST_DOUBLE_REAL_VALUE (a),
+			   *CONST_DOUBLE_REAL_VALUE (b));
 }
 
 /* Returns a hash code for X (which is a really a mem_attrs *).  */
@@ -1331,10 +1333,62 @@
       && (GET_MODE_SIZE (mode) < UNITS_PER_WORD))
     return 0;
 
-  /* If we want a word outside OP, return zero.  */
+  /* If we want a word outside OP, return zero, except for special BFmode cases.  */
   if (mode != BLKmode
       && (offset + 1) * UNITS_PER_WORD > GET_MODE_SIZE (mode))
+  {
+  if (mode == BFmode)
+  {
+   if (GET_CODE (op) == MEM)
+    {
+      rtx addr = plus_constant (XEXP (op, 0), offset * UNITS_PER_WORD);
+      rtx new;
+
+      if (validate_address)
+	{
+	  if (reload_completed)
+	    {
+	      if (! strict_memory_address_p (HImode, addr))
+		return 0;
+	    }
+	  else
+	    addr = memory_address (HImode, addr);
+	}
+
+      new = gen_rtx_MEM (HImode, addr);
+
+      MEM_COPY_ATTRIBUTES (new, op);
+      MEM_READONLY_P (new) = MEM_READONLY_P (op);
+
+      return new;
+    }
+  else if (REG_P (op))
+    {
+      if (REGNO (op) < FIRST_PSEUDO_REGISTER
+	  && REGNO (op) + offset >= FIRST_PSEUDO_REGISTER)
+	return 0;
+
+      if (REGNO (op) < FIRST_PSEUDO_REGISTER
+	  && (! HARD_REGNO_MODE_OK (REGNO (op), HImode)
+	      || ! HARD_REGNO_MODE_OK (REGNO (op) + offset, HImode)))
+	return 0;
+      else if (REGNO (op) >= FIRST_PSEUDO_REGISTER
+	       || (REG_FUNCTION_VALUE_P (op))
+	       || op == frame_pointer_rtx
+#if FRAME_POINTER_REGNUM != ARG_POINTER_REGNUM
+	       || op == arg_pointer_rtx
+#endif
+	       || op == stack_pointer_rtx)
+	return gen_rtx_SUBREG (HImode, op, offset);
+      else
+	return gen_rtx_REG (HImode, REGNO (op) + offset);
+    }
+  else if (GET_CODE (op) == SUBREG)
+    return gen_rtx_SUBREG (HImode, SUBREG_REG (op), offset + SUBREG_BYTE (op) / UNITS_PER_WORD);
+  }
+  else
     return const0_rtx;
+  }
 
   /* Form a new MEM at the requested address.  */
   if (MEM_P (op))
@@ -5307,17 +5361,17 @@
   REAL_VALUE_FROM_INT (dconstm1, -1, -1, double_mode);
   REAL_VALUE_FROM_INT (dconstm2, -2, -1, double_mode);
 
-  dconsthalf = dconst1;
-  SET_REAL_EXP (&dconsthalf, REAL_EXP (&dconsthalf) - 1);
-
+  real_arithmetic (&dconsthalf, RDIV_EXPR, &dconst1, &dconst2);
   real_arithmetic (&dconstthird, RDIV_EXPR, &dconst1, &dconst3);
 
+#if 0
   /* Initialize mathematical constants for constant folding builtins.
      These constants need to be given to at least 160 bits precision.  */
   real_from_string (&dconstpi,
     "3.1415926535897932384626433832795028841971693993751058209749445923078");
   real_from_string (&dconste,
     "2.7182818284590452353602874713526624977572470936999595749669676277241");
+#endif /* 0 */
 
   for (i = 0; i < (int) ARRAY_SIZE (const_tiny_rtx); i++)
     {
diff -Naur gcc-4.1-20051216.orig/gcc/explow.c gcc-4.1-20051216-src/gcc/explow.c
--- gcc-4.1-20051216.orig/gcc/explow.c	2005-08-02 22:39:24.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/explow.c	2005-12-18 22:24:40.000000000 +0100
@@ -569,6 +569,10 @@
 {
   rtx temp = gen_reg_rtx (mode);
 
+  if (GET_MODE (x) == BFmode && mode != BFmode)
+    convert_move (x, temp, 0);
+  else
+  {
   /* If not an operand, must be an address with PLUS and MULT so
      do the computation.  */
   if (! general_operand (x, VOIDmode))
@@ -577,6 +581,7 @@
   gcc_assert (GET_MODE (x) == mode || GET_MODE (x) == VOIDmode);
   if (x != temp)
     emit_move_insn (temp, x);
+  }
   return temp;
 }
 
diff -Naur gcc-4.1-20051216.orig/gcc/expr.c gcc-4.1-20051216-src/gcc/expr.c
--- gcc-4.1-20051216.orig/gcc/expr.c	2005-12-13 09:17:18.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/expr.c	2005-12-19 01:00:21.000000000 +0100
@@ -748,7 +748,7 @@
   if (GET_MODE (x) != VOIDmode)
     oldmode = GET_MODE (x);
 
-  if (mode == oldmode)
+  if (mode == oldmode || oldmode == BFmode)
     return x;
 
   /* There is one case that we must handle specially: If we are converting
@@ -1351,6 +1351,7 @@
   dst_tree = make_tree (ptr_type_node, dst_addr);
   src_tree = make_tree (ptr_type_node, src_addr);
 
+#if 0
   size_mode = TYPE_MODE (sizetype);
 
   size = convert_to_mode (size_mode, size, 1);
@@ -1360,8 +1361,8 @@
      memcpy in this context.  This could be a user call to memcpy and
      the user may wish to examine the return value from memcpy.  For
      targets where libcalls and normal calls have different conventions
-     for returning pointers, we could end up generating incorrect code.  */
-
+     for returning pointers, we could end up generating incorrect code.
+     (TIGCC 20050205) NO, the "incorrect" code is actually correct for us!  */
   size_tree = make_tree (sizetype, size);
 
   fn = emit_block_move_libcall_fn (true);
@@ -1376,6 +1377,14 @@
   CALL_EXPR_TAILCALL (call_expr) = tailcall;
 
   retval = expand_expr (call_expr, NULL_RTX, VOIDmode, 0);
+#endif /* 0 */
+
+  emit_library_call_value (memcpy_libfunc, retval, LCT_NORMAL,
+                           VOIDmode, 3, dst_addr, Pmode,
+                           src_addr, Pmode,
+                           convert_to_mode (TYPE_MODE (sizetype),
+                                            size, TYPE_UNSIGNED (sizetype)),
+                           TYPE_MODE (sizetype));
 
   return retval;
 }
@@ -2498,6 +2507,7 @@
 
   object = copy_to_mode_reg (Pmode, XEXP (object, 0));
 
+#if 0
   size_mode = TYPE_MODE (sizetype);
   size = convert_to_mode (size_mode, size, 1);
   size = copy_to_mode_reg (size_mode, size);
@@ -2506,7 +2516,8 @@
      memset in this context.  This could be a user call to memset and
      the user may wish to examine the return value from memset.  For
      targets where libcalls and normal calls have different conventions
-     for returning pointers, we could end up generating incorrect code.  */
+     for returning pointers, we could end up generating incorrect code.
+     (TIGCC 20050205) NO, the "incorrect" code is actually correct for us!  */
 
   object_tree = make_tree (ptr_type_node, object);
   size_tree = make_tree (sizetype, size);
@@ -2523,6 +2534,15 @@
   CALL_EXPR_TAILCALL (call_expr) = tailcall;
 
   retval = expand_expr (call_expr, NULL_RTX, VOIDmode, 0);
+#endif /* 0 */
+
+  /* Note: Our memset libcall expects a short integer zero even with -mlong.  */
+  emit_library_call_value (memset_libfunc, retval, LCT_NORMAL,
+                           VOIDmode, 3, object, Pmode,
+                           const0_rtx, TYPE_MODE (short_integer_type_node),
+                           convert_to_mode (TYPE_MODE (sizetype),
+                                            size, TYPE_UNSIGNED (sizetype)),
+                           TYPE_MODE (sizetype));
 
   return retval;
 }
@@ -2541,8 +2561,10 @@
       tree fn, args;
 
       fn = get_identifier ("memset");
+      /* TIGCC Patch: The memset libcall expects a short integer zero even with
+         -mlong.  */
       args = build_function_type_list (ptr_type_node, ptr_type_node,
-				       integer_type_node, sizetype,
+				       short_integer_type_node, sizetype,
 				       NULL_TREE);
 
       fn = build_decl (FUNCTION_DECL, fn, args);
@@ -2950,14 +2972,21 @@
   if (push_operand (x, mode))
     return emit_move_complex_push (mode, x, y);
 
+  /* For memory to memory moves, optimal behavior can be had with the
+     existing block move logic.  */
+  /* (TIGCC 20050323) ... and this is indeed the case for our target, despite
+     claims to the contrary in PR rtl-optimization/20306. -- Kevin Kofler  */
+  if (MEM_P (x) && MEM_P (y))
+    {
+      emit_block_move (x, y, GEN_INT (GET_MODE_SIZE (mode)),
+		       BLOCK_OP_NO_LIBCALL);
+      return get_last_insn ();
+    }
+
   /* See if we can coerce the target into moving both values at once.  */
 
-  /* Move floating point as parts.  */
-  if (GET_MODE_CLASS (mode) == MODE_COMPLEX_FLOAT
-      && mov_optab->handlers[GET_MODE_INNER (mode)].insn_code != CODE_FOR_nothing)
-    try_int = false;
   /* Not possible if the values are inherently not adjacent.  */
-  else if (GET_CODE (x) == CONCAT || GET_CODE (y) == CONCAT)
+  if (GET_CODE (x) == CONCAT || GET_CODE (y) == CONCAT)
     try_int = false;
   /* Is possible if both are registers (or subregs of registers).  */
   else if (register_operand (x, mode) && register_operand (y, mode))
@@ -2975,18 +3004,7 @@
 
   if (try_int)
     {
-      rtx ret;
-
-      /* For memory to memory moves, optimal behavior can be had with the
-	 existing block move logic.  */
-      if (MEM_P (x) && MEM_P (y))
-	{
-	  emit_block_move (x, y, GEN_INT (GET_MODE_SIZE (mode)),
-			   BLOCK_OP_NO_LIBCALL);
-	  return get_last_insn ();
-	}
-
-      ret = emit_move_via_integer (mode, x, y, true);
+      rtx ret = emit_move_via_integer (mode, x, y, true);
       if (ret)
 	return ret;
     }
@@ -3226,6 +3244,9 @@
   else
     oldcost = rtx_cost (force_const_mem (dstmode, y), SET);
 
+/* (TIGCC) We do not implement exact_real_truncate and there is no narrower
+           float mode anyway. -- Kevin Kofler */
+#if 0
   for (srcmode = GET_CLASS_NARROWEST_MODE (GET_MODE_CLASS (orig_srcmode));
        srcmode != orig_srcmode;
        srcmode = GET_MODE_WIDER_MODE (srcmode))
@@ -3275,6 +3296,7 @@
 
       return last_insn;
     }
+#endif /* 0 */
 
   return NULL_RTX;
 }
diff -Naur gcc-4.1-20051216.orig/gcc/final.c gcc-4.1-20051216-src/gcc/final.c
--- gcc-4.1-20051216.orig/gcc/final.c	2005-11-09 18:11:53.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/final.c	2005-12-18 22:24:40.000000000 +0100
@@ -3079,11 +3079,23 @@
 	    else if (letter == 'l')
 	      output_asm_label (operands[opnum]);
 	    else if (letter == 'a')
+	    {
 	      output_address (operands[opnum]);
+	      /* TIGCC Patch: This is a very bad try to implement addresses
+	         relative to a register.  See m68k.c
+	         (TIGCC 20040808) Added CONST here (and below) too. -- Kevin Kofler  */
+	      if (TARGET_REG_RELATIVE && (GET_CODE (operands[opnum]) == SYMBOL_REF || GET_CODE (operands[opnum]) == LABEL_REF || GET_CODE (operands[opnum]) == CODE_LABEL || GET_CODE (operands[opnum]) == CONST))
+		fprintf (asm_out_file, "-__relation(%%%s)", TARGET_RELATION_REG);
+	    }
 	    else if (letter == 'c')
 	      {
 		if (CONSTANT_ADDRESS_P (operands[opnum]))
+		{
 		  output_addr_const (asm_out_file, operands[opnum]);
+		  /* TIGCC Patch: See above  */
+		  if (TARGET_REG_RELATIVE && (GET_CODE (operands[opnum]) == SYMBOL_REF || GET_CODE (operands[opnum]) == LABEL_REF || GET_CODE (operands[opnum]) == CODE_LABEL || GET_CODE (operands[opnum]) == CONST))
+		    fprintf (asm_out_file, "-__relation(%%%s)", TARGET_RELATION_REG);
+		}
 		else
 		  output_operand (operands[opnum], 'c');
 	      }
@@ -3096,6 +3108,9 @@
 		  {
 		    putc ('-', asm_out_file);
 		    output_addr_const (asm_out_file, operands[opnum]);
+		    /* TIGCC Patch: See above */
+		    if (TARGET_REG_RELATIVE && (GET_CODE (operands[opnum]) == SYMBOL_REF || GET_CODE (operands[opnum]) == LABEL_REF || GET_CODE (operands[opnum]) == CODE_LABEL))
+		      fprintf (asm_out_file, "-__relation(%%%s)", TARGET_RELATION_REG);
 		  }
 	      }
 	    else
@@ -3607,6 +3622,8 @@
     }
   else
     {
+      gcc_unreachable ();
+#if 0
       REAL_VALUE_TYPE r;
       long l[2];
       REAL_VALUE_FROM_CONST_DOUBLE (r, value);
@@ -3635,6 +3652,7 @@
 
       *first = GEN_INT (l[0]);
       *second = GEN_INT (l[1]);
+#endif /* 0 */
     }
 }
 
diff -Naur gcc-4.1-20051216.orig/gcc/flags.h gcc-4.1-20051216-src/gcc/flags.h
--- gcc-4.1-20051216.orig/gcc/flags.h	2005-06-29 05:01:27.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/flags.h	2005-12-18 22:24:40.000000000 +0100
@@ -287,4 +287,10 @@
 #define HONOR_SIGN_DEPENDENT_ROUNDING(MODE) \
   (MODE_HAS_SIGN_DEPENDENT_ROUNDING (MODE) && flag_rounding_math)
 
+/* (TIGCC) Make compound literals (cast constructors) global for backwards compatibility.  */
+extern int flag_global_compound_literals;
+
+/* (TIGCC 20040727) When merging constants, also merge constant pools.  */
+extern int flag_merge_constant_pools;
+
 #endif /* ! GCC_FLAGS_H */
diff -Naur gcc-4.1-20051216.orig/gcc/fold-const.c gcc-4.1-20051216-src/gcc/fold-const.c
--- gcc-4.1-20051216.orig/gcc/fold-const.c	2005-11-26 00:12:32.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/fold-const.c	2005-12-19 03:00:36.000000000 +0100
@@ -1555,7 +1555,7 @@
       if ((flag_rounding_math
 	   || (REAL_MODE_FORMAT_COMPOSITE_P (mode)
 	       && !flag_unsafe_math_optimizations))
-	  && (inexact || !real_identical (&result, &value)))
+	  && (inexact || !REAL_VALUES_IDENTICAL (result, value)))
 	return NULL_TREE;
 
       t = build_real (type, result);
@@ -1778,6 +1778,7 @@
      FP-to-integer conversion is unspecified upon overflow.  */
 
   HOST_WIDE_INT high, low;
+#if 0
   REAL_VALUE_TYPE r;
   REAL_VALUE_TYPE x = TREE_REAL_CST (arg1);
 
@@ -1802,9 +1803,12 @@
     default:
       gcc_unreachable ();
     }
+#else
+  REAL_VALUE_TYPE r = TREE_REAL_CST (arg1);
+#endif /* 0 */
 
   /* If R is NaN, return zero and show we have an overflow.  */
-  if (REAL_VALUE_ISNAN (r))
+  if (REAL_VALUE_ISNANUINF (r))
     {
       overflow = 1;
       high = 0;
@@ -2113,7 +2117,7 @@
 /* When pedantic, return an expr equal to X but certainly not valid as a
    pedantic lvalue.  Otherwise, return X.  */
 
-static tree
+tree
 pedantic_non_lvalue (tree x)
 {
   if (pedantic_lvalues)
@@ -5711,6 +5715,10 @@
   if (!HONOR_SIGNED_ZEROS (TYPE_MODE (type)))
     return true;
 
+  /* (TIGCC 20050210) This is invalid independently of the rounding mode and the
+                      type of the zero for 3-sign-zeros. */
+  return false;
+
   /* Treat x + -0 as x - 0 and x - -0 as x + 0.  */
   if (TREE_CODE (addend) == REAL_CST
       && REAL_VALUE_MINUS_ZERO (TREE_REAL_CST (addend)))
@@ -5896,6 +5904,7 @@
 	}
       break;
 
+#if 0 /* (TIGCC 20050205) */
     case EQ_EXPR:
     case GE_EXPR:
       /* x == +Inf and x >= +Inf are always equal to x > DBL_MAX.  */
@@ -5924,6 +5933,7 @@
       temp = fold_build2 (neg ? LT_EXPR : GT_EXPR, type,
 			  arg0, build_real (TREE_TYPE (arg0), max));
       return fold_build1 (TRUTH_NOT_EXPR, type, temp);
+#endif /* 0 */
 
     default:
       break;
@@ -7839,8 +7849,11 @@
 	     when x is NaN, since x * 0 is also NaN.  Nor are they the
 	     same in modes with signed zeros, since multiplying a
 	     negative value by 0 gives -0, not +0.  */
+	  /* (TIGCC 20050210) We can do this for UNSIGNED_ZERO even when honoring
+	                      signed zeros. */
 	  if (!HONOR_NANS (TYPE_MODE (TREE_TYPE (arg0)))
-	      && !HONOR_SIGNED_ZEROS (TYPE_MODE (TREE_TYPE (arg0)))
+	      && (!HONOR_SIGNED_ZEROS (TYPE_MODE (TREE_TYPE (arg0)))
+	          || real_uzerop (arg1))
 	      && real_zerop (arg1))
 	    return omit_one_operand (type, arg1, arg0);
 	  /* In IEEE floating point, x*1 is not equivalent to x for snans.  */
@@ -9056,7 +9069,7 @@
 				  build_real (TREE_TYPE (arg1), dconst0));
 
 	    /* x != NaN is always true, other ops are always false.  */
-	    if (REAL_VALUE_ISNAN (cst)
+	    if (REAL_VALUE_ISNANUINF (cst)
 		&& ! HONOR_SNANS (TYPE_MODE (TREE_TYPE (arg1))))
 	      {
 		tem = (code == NE_EXPR) ? integer_one_node : integer_zero_node;
@@ -9829,7 +9842,7 @@
 
       /* If the first operand is NaN, the result is constant.  */
       if (TREE_CODE (arg0) == REAL_CST
-	  && REAL_VALUE_ISNAN (TREE_REAL_CST (arg0))
+	  && REAL_VALUE_ISNANUINF (TREE_REAL_CST (arg0))
 	  && (code != LTGT_EXPR || ! flag_trapping_math))
 	{
 	  t1 = (code == ORDERED_EXPR || code == LTGT_EXPR)
@@ -9840,7 +9853,7 @@
 
       /* If the second operand is NaN, the result is constant.  */
       if (TREE_CODE (arg1) == REAL_CST
-	  && REAL_VALUE_ISNAN (TREE_REAL_CST (arg1))
+	  && REAL_VALUE_ISNANUINF (TREE_REAL_CST (arg1))
 	  && (code != LTGT_EXPR || ! flag_trapping_math))
 	{
 	  t1 = (code == ORDERED_EXPR || code == LTGT_EXPR)
@@ -9878,12 +9891,12 @@
     case COMPOUND_EXPR:
       /* When pedantic, a compound expression can be neither an lvalue
 	 nor an integer constant expression.  */
-      if (TREE_SIDE_EFFECTS (arg0) || TREE_CONSTANT (arg1))
+      if (TREE_SIDE_EFFECTS (arg0) || pedantic)
 	return NULL_TREE;
       /* Don't let (0, 0) be null pointer constant.  */
-      tem = integer_zerop (arg1) ? build1 (NOP_EXPR, type, arg1)
-				 : fold_convert (type, arg1);
-      return pedantic_non_lvalue (tem);
+      if (integer_zerop (arg1))
+	return build1 (NOP_EXPR, type, arg1);
+      return convert (type, arg1);
 
     case COMPLEX_EXPR:
       if (wins)
@@ -10178,6 +10191,21 @@
     } /* switch (code) */
 }
 
+/* Return 1 if EXPR is the real constant UNSIGNED_ZERO.  */
+
+static int
+real_uzerop (tree expr)
+{
+  STRIP_NOPS (expr);
+
+  return ((TREE_CODE (expr) == REAL_CST
+	   && ! TREE_CONSTANT_OVERFLOW (expr)
+	   && REAL_VALUES_IDENTICAL (TREE_REAL_CST (expr), UNSIGNED_ZERO))
+	  || (TREE_CODE (expr) == COMPLEX_CST
+	      && real_uzerop (TREE_REALPART (expr))
+	      && real_uzerop (TREE_IMAGPART (expr))));
+}
+
 /* Perform constant folding and related simplification of EXPR.
    The related simplifications include x*1 => x, x*0 => 0, etc.,
    and application of the associative law.
@@ -11269,7 +11297,11 @@
       }
 
     case REAL_CST:
-      t = build_real (type, REAL_VALUE_NEGATE (TREE_REAL_CST (arg0)));
+	    {
+	      REAL_VALUE_TYPE x = TREE_REAL_CST (arg0);
+	      x = REAL_VALUE_NEGATE (x);
+	      t = build_real (type, x);
+	    }
       break;
 
     default:
@@ -11315,10 +11347,14 @@
       break;
 
     case REAL_CST:
-      if (REAL_VALUE_NEGATIVE (TREE_REAL_CST (arg0)))
-	t = build_real (type, REAL_VALUE_NEGATE (TREE_REAL_CST (arg0)));
-      else
-	t =  arg0;
+  	    {
+	      REAL_VALUE_TYPE x = TREE_REAL_CST (arg0);
+	      if (REAL_VALUE_NEGATIVE (x))
+		t = build_real (type,
+				REAL_VALUE_NEGATE (x));
+	      else
+		t =  arg0;
+	    }
       break;
 
     default:
@@ -11366,7 +11402,7 @@
       const REAL_VALUE_TYPE *c1 = TREE_REAL_CST_PTR (op1);
 
       /* Handle the cases where either operand is a NaN.  */
-      if (real_isnan (c0) || real_isnan (c1))
+      if (REAL_VALUE_ISNANUINF (*c0) || REAL_VALUE_ISNANUINF (*c1))
 	{
 	  switch (code)
 	    {
diff -Naur gcc-4.1-20051216.orig/gcc/function.c gcc-4.1-20051216-src/gcc/function.c
--- gcc-4.1-20051216.orig/gcc/function.c	2005-12-02 07:16:21.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/function.c	2005-12-18 22:24:47.000000000 +0100
@@ -5557,3 +5557,28 @@
 
 
 #include "gt-function.h"
+
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+/* Return 1 if an argument for the current function was passed in
+   register REGNO.  */
+
+int
+function_arg_regno_p (int regno)
+{
+  tree parm = DECL_ARGUMENTS (current_function_decl);
+  for (; parm; parm = TREE_CHAIN (parm))
+    {
+      rtx incoming = DECL_INCOMING_RTL (parm);
+      if (GET_CODE (incoming) == REG)
+	{
+	  int incoming_reg;
+	  incoming_reg = REGNO (incoming);
+	  if (regno >= incoming_reg &&
+	      regno < incoming_reg + HARD_REGNO_NREGS (incoming_reg,
+						       GET_MODE (incoming)))
+	    return 1;
+	}
+    }
+  return 0;
+}
+/* end-TIGCC-local (regparms) */
diff -Naur gcc-4.1-20051216.orig/gcc/function.h gcc-4.1-20051216-src/gcc/function.h
--- gcc-4.1-20051216.orig/gcc/function.h	2005-08-19 23:16:20.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/function.h	2005-12-18 22:24:47.000000000 +0100
@@ -574,4 +574,10 @@
 extern bool reference_callee_copied (CUMULATIVE_ARGS *, enum machine_mode,
 				     tree, bool);
 
+/* begin-TIGCC-local (regparms): explicit register specification for parameters */
+/* Return 1 if an argument for the current function was passed in
+   register REGNO.  */
+int function_arg_regno_p (int regno);
+/* end-TIGCC-local (regparms) */
+
 #endif  /* GCC_FUNCTION_H */
diff -Naur gcc-4.1-20051216.orig/gcc/gcc.c gcc-4.1-20051216-src/gcc/gcc.c
--- gcc-4.1-20051216.orig/gcc/gcc.c	2005-11-19 21:44:07.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/gcc.c	2005-12-19 01:04:29.000000000 +0100
@@ -1458,6 +1458,7 @@
 #define MD_STARTFILE_PREFIX_1 ""
 #endif
 
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
 static const char *const standard_exec_prefix = STANDARD_EXEC_PREFIX;
 static const char *const standard_exec_prefix_1 = "/usr/libexec/gcc/";
 static const char *const standard_exec_prefix_2 = "/usr/lib/gcc/";
@@ -1475,6 +1476,7 @@
 static const char *tooldir_prefix;
 
 static const char *const standard_bindir_prefix = STANDARD_BINDIR_PREFIX;
+#endif /* 0 */
 
 static const char *standard_libexec_prefix = STANDARD_LIBEXEC_PREFIX;
 
@@ -1546,6 +1548,7 @@
   INIT_STATIC_SPEC ("multilib_options",		&multilib_options),
   INIT_STATIC_SPEC ("linker",			&linker_name_spec),
   INIT_STATIC_SPEC ("link_libgcc",		&link_libgcc_spec),
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
   INIT_STATIC_SPEC ("md_exec_prefix",		&md_exec_prefix),
   INIT_STATIC_SPEC ("md_startfile_prefix",	&md_startfile_prefix),
   INIT_STATIC_SPEC ("md_startfile_prefix_1",	&md_startfile_prefix_1),
@@ -1553,6 +1556,7 @@
   INIT_STATIC_SPEC ("sysroot_spec",             &sysroot_spec),
   INIT_STATIC_SPEC ("sysroot_suffix_spec",	&sysroot_suffix_spec),
   INIT_STATIC_SPEC ("sysroot_hdrs_suffix_spec",	&sysroot_hdrs_suffix_spec),
+#endif /* 0 */
 };
 
 #ifdef EXTRA_SPECS		/* additional specs needed */
@@ -3149,7 +3153,9 @@
 process_command (int argc, const char **argv)
 {
   int i;
+#if 0 /* (TIGCC 20040104) Don't use environment variables. */
   const char *temp;
+#endif /* 0 */
   char *temp1;
   const char *spec_lang = 0;
   int last_language_n_infiles;
@@ -3159,7 +3165,9 @@
   int j;
 #endif
 
+#if 0 /* (TIGCC 20040104) Don't use environment variables. */
   GET_ENVIRONMENT (gcc_exec_prefix, "GCC_EXEC_PREFIX");
+#endif /* 0 */
 
   n_switches = 0;
   n_infiles = 0;
@@ -3241,7 +3249,7 @@
      see if we can create it from the pathname specified in argv[0].  */
 
   gcc_libexec_prefix = standard_libexec_prefix;
-#ifndef VMS
+#if 0
   /* FIXME: make_relative_prefix doesn't yet work for VMS.  */
   if (!gcc_exec_prefix)
     {
@@ -3260,6 +3268,7 @@
 #else
 #endif
 
+#if 0 /* (TIGCC 20040104) Don't use environment variables. */
   if (gcc_exec_prefix)
     {
       int len = strlen (gcc_exec_prefix);
@@ -3383,6 +3392,7 @@
 	    endp++;
 	}
     }
+#endif /* 0 */
 
   /* Convert new-style -- options to old-style.  */
   translate_options (&argc, (const char *const **) &argv);
@@ -3807,6 +3817,7 @@
 
   /* Set up the search paths before we go looking for config files.  */
 
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
   /* These come before the md prefixes so that we will find gcc's subcommands
      (such as cpp) rather than those of the host system.  */
   /* Use 2 as fourth arg meaning try just the machine as a suffix,
@@ -3868,6 +3879,7 @@
   add_prefix (&startfile_prefixes,
 	      concat (tooldir_prefix, "lib", dir_separator_str, NULL),
 	      "BINUTILS", PREFIX_PRIORITY_LAST, 0, 1);
+#endif /* 0 */
 
 #if defined(TARGET_SYSTEM_ROOT_RELOCATABLE) && !defined(VMS)
   /* If the normal TARGET_SYSTEM_ROOT is inside of $exec_prefix,
@@ -6146,6 +6158,7 @@
   else
     init_spec ();
 
+#if 0
   /* We need to check standard_exec_prefix/just_machine_suffix/specs
      for any override of as, ld and libraries.  */
   specs_file = alloca (strlen (standard_exec_prefix)
@@ -6179,7 +6192,9 @@
 		      PREFIX_PRIORITY_LAST, 0, 0);
 	}
     }
+#endif /* 0 */
 
+#if 0 /* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
   /* Process sysroot_suffix_spec.  */
   if (*sysroot_suffix_spec != 0
       && do_spec_2 (sysroot_suffix_spec) == 0)
@@ -6269,6 +6284,7 @@
 			      standard_startfile_prefix_2, "BINUTILS",
 			      PREFIX_PRIORITY_LAST, 0, 1);
     }
+#endif /* 0 */
 
   /* Process any user specified specs in the order given on the command
      line.  */
@@ -6279,10 +6295,12 @@
       read_specs (filename ? filename : uptr->filename, FALSE);
     }
 
+#if 0 /* (TIGCC 20040104) Don't use environment variables. */
   /* If we have a GCC_EXEC_PREFIX envvar, modify it for cpp's sake.  */
   if (gcc_exec_prefix)
     gcc_exec_prefix = concat (gcc_exec_prefix, spec_machine, dir_separator_str,
 			      spec_version, dir_separator_str, NULL);
+#endif /* 0 */
 
   /* Now we have the specs.
      Set the `valid' bits for switches that match anything in any spec.  */
@@ -6303,7 +6321,8 @@
 
   if (print_search_dirs)
     {
-      printf (_("install: %s%s\n"), standard_exec_prefix, machine_suffix);
+/* (TIGCC 20040104) Don't hardcode any prefix at compile time. */
+      printf (_("install: relocatable TIGCC installation\n"));
       printf (_("programs: %s\n"), build_search_list (&exec_prefixes, "", 0));
       printf (_("libraries: %s\n"), build_search_list (&startfile_prefixes, "", 0));
       return (0);
diff -Naur gcc-4.1-20051216.orig/gcc/gcse.c gcc-4.1-20051216-src/gcc/gcse.c
--- gcc-4.1-20051216.orig/gcc/gcse.c	2005-11-12 20:29:30.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/gcse.c	2005-12-18 22:24:47.000000000 +0100
@@ -3053,11 +3053,14 @@
   rtx newreg = NULL, newcnst = NULL;
 
   /* Rule out USE instructions and ASM statements as we don't want to
-     change the hard registers mentioned.  */
+     change the hard registers mentioned.
+     (TIGCC) The same thing goes for global register variables. CalcRogue gets
+             miscompiled without this patch.  */
   if (REG_P (x)
       && (REGNO (x) >= FIRST_PSEUDO_REGISTER
           || (GET_CODE (PATTERN (insn)) != USE
-	      && asm_noperands (PATTERN (insn)) < 0)))
+	      && asm_noperands (PATTERN (insn)) < 0
+	      && ! global_regs[REGNO (x)])))
     {
       cselib_val *val = cselib_lookup (x, GET_MODE (x), 0);
       struct elt_loc_list *l;
diff -Naur gcc-4.1-20051216.orig/gcc/genmodes.c gcc-4.1-20051216-src/gcc/genmodes.c
--- gcc-4.1-20051216.orig/gcc/genmodes.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/genmodes.c	2005-12-18 22:24:47.000000000 +0100
@@ -1068,6 +1068,7 @@
 static void
 emit_real_format_for_mode (void)
 {
+#if 0
   struct mode_data *m;
 
   /* The entities pointed to by this table are constant, whether
@@ -1093,6 +1094,7 @@
       tagged_printf ("&%s", m->format, m->name);
 
   print_closer ();
+#endif /* 0 */
 }
 
 static void
@@ -1177,10 +1179,12 @@
 	}
     }
       
+#if 0
   /* Real mode formats don't have to propagate anywhere.  */
   for (a = adj_format; a; a = a->next)
     printf ("\n  /* %s:%d */\n  REAL_MODE_FORMAT (%smode) = %s;\n",
 	    a->file, a->line, a->mode->name, a->adjustment);
+#endif /* 0 */
 
   puts ("}");
 }
diff -Naur gcc-4.1-20051216.orig/gcc/gimplify.c gcc-4.1-20051216-src/gcc/gimplify.c
--- gcc-4.1-20051216.orig/gcc/gimplify.c	2005-11-11 18:14:49.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/gimplify.c	2005-12-18 22:24:47.000000000 +0100
@@ -1899,6 +1899,7 @@
   /* There is a sequence point before the call, so any side effects in
      the calling expression must occur before the actual call.  Force
      gimplify_expr to use an internal post queue.  */
+  if (!flag_no_function_cse)
   ret = gimplify_expr (&TREE_OPERAND (*expr_p, 0), pre_p, NULL,
 		       is_gimple_call_addr, fb_rvalue);
 
@@ -1917,6 +1918,12 @@
   if (PUSH_ARGS_REVERSED)
     TREE_OPERAND (*expr_p, 1) = nreverse (TREE_OPERAND (*expr_p, 1));
 
+  /* (TIGCC 20050206) Gimplify the function expression only after the arguments
+                      if -fno-function-cse. */
+  if (flag_no_function_cse)
+  ret = gimplify_expr (&TREE_OPERAND (*expr_p, 0), pre_p, NULL,
+		       is_gimple_call_addr, fb_rvalue);
+
   /* Try this again in case gimplification exposed something.  */
   if (ret != GS_ERROR && decl && DECL_BUILT_IN (decl))
     {
diff -Naur gcc-4.1-20051216.orig/gcc/ifcvt.c gcc-4.1-20051216-src/gcc/ifcvt.c
--- gcc-4.1-20051216.orig/gcc/ifcvt.c	2005-11-09 22:34:31.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/ifcvt.c	2005-12-18 22:24:47.000000000 +0100
@@ -2026,6 +2026,16 @@
   if (MEM_P (op))
     return ! side_effects_p (XEXP (op, 0));
 
+  /* (TIGCC 20040925) Can't if-convert global register variables.
+                      -- Kevin Kofler */
+  if (GET_CODE (op) == REG)
+    {
+      int regno;
+      regno = REGNO (op);
+      if (regno < FIRST_PSEUDO_REGISTER && global_regs[regno])
+        return FALSE;
+    }
+
   if (side_effects_p (op))
     return FALSE;
 
@@ -3359,6 +3369,21 @@
 		 TEST range.  */
 	      if (for_each_rtx (&PATTERN (insn), find_memory, NULL))
 		return FALSE;
+
+	      /* (TIGCC 20040925) Can't if-convert global register variables.
+	                          -- Kevin Kofler */
+	      if (GET_CODE (PATTERN (insn)) == SET)
+            {
+              rtx dest;
+              dest = SET_DEST (PATTERN (insn));
+              if (GET_CODE (dest) == REG)
+                {
+                  int regno;
+                  regno = REGNO (dest);
+                  if (regno < FIRST_PSEUDO_REGISTER && global_regs[regno])
+                    return FALSE;
+                }
+            }
 	    }
 	  if (insn == end)
 	    break;
diff -Naur gcc-4.1-20051216.orig/gcc/langhooks-def.h gcc-4.1-20051216-src/gcc/langhooks-def.h
--- gcc-4.1-20051216.orig/gcc/langhooks-def.h	2005-11-19 00:40:29.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/langhooks-def.h	2005-12-19 01:07:11.000000000 +0100
@@ -107,6 +107,7 @@
 #define LANG_HOOKS_SAFE_FROM_P		lhd_safe_from_p
 #define LANG_HOOKS_FINISH_INCOMPLETE_DECL lhd_do_nothing_t
 #define LANG_HOOKS_STATICP		lhd_staticp
+#define LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES lhd_do_nothing_t
 #define LANG_HOOKS_DUP_LANG_SPECIFIC_DECL lhd_do_nothing_t
 #define LANG_HOOKS_SET_DECL_ASSEMBLER_NAME lhd_set_decl_assembler_name
 #define LANG_HOOKS_CAN_USE_BIT_FIELDS_P lhd_can_use_bit_fields_p
@@ -272,6 +273,7 @@
   LANG_HOOKS_EXPAND_CONSTANT, \
   LANG_HOOKS_EXPAND_EXPR, \
   LANG_HOOKS_EXPAND_DECL, \
+  LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES, \
   LANG_HOOKS_SAFE_FROM_P, \
   LANG_HOOKS_FINISH_INCOMPLETE_DECL, \
   LANG_HOOKS_MARK_ADDRESSABLE, \
diff -Naur gcc-4.1-20051216.orig/gcc/langhooks.h gcc-4.1-20051216-src/gcc/langhooks.h
--- gcc-4.1-20051216.orig/gcc/langhooks.h	2005-11-19 00:40:29.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/langhooks.h	2005-12-18 22:24:47.000000000 +0100
@@ -283,6 +283,10 @@
      1 if handled, 0 otherwise.  */
   int (*expand_decl) (tree);
 
+  /* Possibly apply default attributes to a function (represented by
+     a FUNCTION_DECL).  */
+  void (*insert_default_attributes) PARAMS ((tree));
+
   /* Hook called by safe_from_p for language-specific tree codes.  It is
      up to the language front-end to install a hook if it has any such
      codes that safe_from_p needs to know about.  Since same_from_p will
diff -Naur gcc-4.1-20051216.orig/gcc/loop.c gcc-4.1-20051216-src/gcc/loop.c
--- gcc-4.1-20051216.orig/gcc/loop.c	2005-12-16 13:14:15.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/loop.c	2005-12-18 22:24:47.000000000 +0100
@@ -1296,6 +1296,13 @@
 		      && REGNO_LAST_UID (regno) == INSN_UID (user)
 		      && regs->array[regno].set_in_loop == 1
 		      && GET_CODE (SET_SRC (set)) != ASM_OPERANDS
+		      /* (TIGCC 20050206) Patch by Ian Lance Taylor regarding using hard
+		                          register variables as an asm input
+		         See http://gcc.gnu.org/ml/gcc/2004-05/msg00678.html */
+		      && (regno >= FIRST_PSEUDO_REGISTER
+			  || asm_noperands (PATTERN (regs->array[regno]
+						     .single_usage))
+			  < 0)
 		      && ! side_effects_p (SET_SRC (set))
 		      && ! find_reg_note (p, REG_RETVAL, NULL_RTX)
 		      && (!SMALL_REGISTER_CLASSES
diff -Naur gcc-4.1-20051216.orig/gcc/machmode.def gcc-4.1-20051216-src/gcc/machmode.def
--- gcc-4.1-20051216.orig/gcc/machmode.def	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/machmode.def	2005-12-18 22:24:47.000000000 +0100
@@ -170,8 +170,8 @@
    These are the IEEE mappings.  They can be overridden with
    RESET_FLOAT_FORMAT or at runtime (in OVERRIDE_OPTIONS).  */
 
-FLOAT_MODE (SF, 4, ieee_single_format);
-FLOAT_MODE (DF, 8, ieee_double_format);
+FLOAT_MODE (SF, 4, 0);
+FLOAT_MODE (DF, 8, 0);
 
 /* Basic CC modes.
    FIXME define this only for targets that need it.  */
diff -Naur gcc-4.1-20051216.orig/gcc/optabs.c gcc-4.1-20051216-src/gcc/optabs.c
--- gcc-4.1-20051216.orig/gcc/optabs.c	2005-12-01 23:50:31.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/optabs.c	2005-12-18 22:24:47.000000000 +0100
@@ -1747,7 +1747,7 @@
   /* Look for a wider mode of the same class for which it appears we can do
      the operation.  */
 
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+  if (class == MODE_INT)
     {
       for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
 	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
@@ -2043,7 +2043,7 @@
 
   /* It can't be done in this mode.  Can we do it in a wider mode?  */
 
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+  if (class == MODE_INT)
     {
       for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
 	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
@@ -2231,6 +2231,7 @@
   return ret;
 }
 
+#if 0 /* (TIGCC 20050216) */
 /* Expand a floating point absolute value or negation operation via a
    logical operation on the sign bit.  */
 
@@ -2335,6 +2336,7 @@
 
   return target;
 }
+#endif /* 0 */
 
 /* Generate code to perform an operation specified by UNOPTAB
    on operand OP0, with result having machine-mode MODE.
@@ -2412,7 +2414,7 @@
 	goto try_libcall;
     }
 
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+  if (class == MODE_INT)
     for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
 	 wider_mode = GET_MODE_WIDER_MODE (wider_mode))
       {
@@ -2488,13 +2490,16 @@
 
   if (unoptab->code == NEG)
     {
+#if 0
       /* Try negating floating point values by flipping the sign bit.  */
+      /* (TIGCC 20050205) Don't. We have unsigned zero and infinity.  */
       if (class == MODE_FLOAT)
 	{
 	  temp = expand_absneg_bit (NEG, mode, op0, target);
 	  if (temp)
 	    return temp;
 	}
+#endif /* 0 */
 
       /* If there is no negation pattern, and we have no negative zero,
 	 try subtracting from zero.  */
@@ -2551,7 +2556,7 @@
 
   /* It can't be done in this mode.  Can we do it in a wider mode?  */
 
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+  if (class == MODE_INT)
     {
       for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
 	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
@@ -2640,13 +2645,16 @@
   if (temp != 0)
     return temp;
 
+#if 0
   /* For floating point modes, try clearing the sign bit.  */
+  /* (TIGCC 20050205) Don't. We have unsigned zero and infinity.  */
   if (GET_MODE_CLASS (mode) == MODE_FLOAT)
     {
       temp = expand_absneg_bit (ABS, mode, op0, target);
       if (temp)
 	return temp;
     }
+#endif /* 0 */
 
   /* If we have a MAX insn, we can do this as MAX (x, -x).  */
   if (smax_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing
@@ -2820,6 +2828,7 @@
 }
 
 
+#if 0
 /* A subroutine of expand_copysign, perform the entire copysign operation
    with integer bitmasks.  BITPOS is the position of the sign bit; OP0_IS_ABS
    is true if op0 is known to have its sign bit clear.  */
@@ -2971,6 +2980,7 @@
   return expand_copysign_bit (mode, op0, op1, target,
 			      fmt->signbit_rw, op0_is_abs);
 }
+#endif /* 0 */
 
 /* Generate an instruction whose insn-code is INSN_CODE,
    with two operands: an output TARGET and an input OP0.
@@ -4351,6 +4361,7 @@
 	  }
       }
 
+#if 0
   /* Unsigned integer, and no way to convert directly.
      Convert as signed, then conditionally adjust the result.  */
   if (unsignedp)
@@ -4455,6 +4466,7 @@
       emit_label (label);
       goto done;
     }
+#endif /* 0 */
 
   /* No hardware instruction available; call a library routine.  */
     {
@@ -4545,6 +4557,7 @@
 	  }
       }
 
+#if 0
   /* For an unsigned conversion, there is one more way to do it.
      If we have a signed conversion, we generate code that compares
      the real value to the largest representable positive number.  If if
@@ -4628,6 +4641,7 @@
 
 	  return;
 	}
+#endif /* 0 */
 
   /* We can't do it with an insn, so use a library call.  But first ensure
      that the mode of TO is at least as wide as SImode, since those are the
@@ -5231,6 +5245,9 @@
   /* Conversions.  */
   init_interclass_conv_libfuncs (sfloat_optab, "float",
 				 MODE_INT, MODE_FLOAT);
+  /* (TIGCC 20050208) Someone forgot this one... */
+  init_interclass_conv_libfuncs (ufloat_optab, "floatuns",
+				 MODE_INT, MODE_FLOAT);
   init_interclass_conv_libfuncs (sfix_optab, "fix",
 				 MODE_FLOAT, MODE_INT);
   init_interclass_conv_libfuncs (ufix_optab, "fixuns",
diff -Naur gcc-4.1-20051216.orig/gcc/opts.c gcc-4.1-20051216-src/gcc/opts.c
--- gcc-4.1-20051216.orig/gcc/opts.c	2005-12-06 12:28:18.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/opts.c	2005-12-18 22:24:47.000000000 +0100
@@ -570,7 +570,12 @@
 #endif
       flag_regmove = 1;
       flag_strict_aliasing = 1;
+#if 0 /* (TIGCC 20050213) Null pointer dereferences won't necessarily trigger
+         a trap. When reading, they definitely won't. When writing, they will
+         only when the variable being dereferenced is a scalar or a small
+         enough structure. */
       flag_delete_null_pointer_checks = 1;
+#endif
       flag_reorder_blocks = 1;
       flag_reorder_functions = 1;
       flag_tree_store_ccp = 1;
@@ -589,6 +594,10 @@
       flag_inline_functions = 1;
       flag_unswitch_loops = 1;
       flag_gcse_after_reload = 1;
+      /* (TIGCC 20050217) Halve maximum inline insns under -O3. Use -O4 to
+                          override this. */
+      if (optimize == 3)
+        set_param_value ("max-inline-insns-auto", 60);
     }
 
   if (optimize < 2 || optimize_size)
@@ -609,12 +618,17 @@
       flag_reorder_blocks_and_partition = 0;
     }
 
-  if (optimize_size)
+  /* (TIGCC 20050217) Do this at -O2 as well, as it improves both size and speed. */
+  if (optimize == 2 || optimize_size)
     {
       /* Inlining of very small functions usually reduces total size.  */
-      set_param_value ("max-inline-insns-single", 5);
       set_param_value ("max-inline-insns-auto", 5);
       flag_inline_functions = 1;
+    }
+  if (optimize_size)
+    {
+      /* Inlining of very small functions usually reduces total size.  */
+      set_param_value ("max-inline-insns-single", 5);
 
       /* We want to crossjump as much as possible.  */
       set_param_value ("min-crossjump-insns", 1);
@@ -645,6 +659,11 @@
   if (flag_pic && !flag_pie)
     flag_shlib = 1;
 
+  /* TIGCC Patch: Register d2 is used by the TIOS calling convention.
+     See "call-used-" further down in this file. */
+  if (TARGET_TIOS)
+    fix_register ("d2", 0, 1);
+
   if (flag_no_inline == 2)
     flag_no_inline = 0;
   else
@@ -922,6 +941,12 @@
       flag_profile_values_set = true;
       break;
 
+    case OPT_freg_relative_:
+      fix_register (arg, 1, 1);
+      target_flags |= MASK_REG_RELATIVE;
+      strcpy (TARGET_RELATION_REG, arg);
+      break;
+
     case OPT_fvisibility_:
       {
         if (!strcmp(arg, "default"))
diff -Naur gcc-4.1-20051216.orig/gcc/output.h gcc-4.1-20051216-src/gcc/output.h
--- gcc-4.1-20051216.orig/gcc/output.h	2005-10-26 09:03:30.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/output.h	2005-12-18 22:24:47.000000000 +0100
@@ -334,7 +334,7 @@
 #define assemble_aligned_integer(SIZE, VALUE) \
   assemble_integer (VALUE, SIZE, (SIZE) * BITS_PER_UNIT, 1)
 
-#ifdef REAL_VALUE_TYPE_SIZE
+#ifdef REAL_WIDTH /* (TIGCC 20050205) */
 /* Assemble the floating-point constant D into an object of size MODE.  */
 extern void assemble_real (REAL_VALUE_TYPE, enum machine_mode, unsigned);
 #endif
diff -Naur gcc-4.1-20051216.orig/gcc/postreload.c gcc-4.1-20051216-src/gcc/postreload.c
--- gcc-4.1-20051216.orig/gcc/postreload.c	2005-11-18 14:14:39.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/postreload.c	2005-12-18 22:24:50.000000000 +0100
@@ -1189,6 +1189,9 @@
        && TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (OUTMODE), \
 				 GET_MODE_BITSIZE (INMODE))))
 
+/* (TIGCC 20050213) Declare this target-dependent function. */
+int const_method (rtx);
+
 static void
 reload_cse_move2add (rtx first)
 {
@@ -1276,11 +1279,17 @@
 			   && narrow_mode != GET_MODE (reg);
 			   narrow_mode = GET_MODE_WIDER_MODE (narrow_mode))
 			{
-			  if (have_insn_for (STRICT_LOW_PART, narrow_mode)
+			  /* (TIGCC 20050213) Don't do this for QImode. Byte moves aren't
+			      any cheaper than word moves, they just kill chances to use a
+			      moveq. Also don't turn long moves which can be done using
+			      moveq into word moves. */
+			  if (narrow_mode != QImode
+			      && have_insn_for (STRICT_LOW_PART, narrow_mode)
 			      && ((reg_offset[regno]
 				   & ~GET_MODE_MASK (narrow_mode))
 				  == (INTVAL (src)
-				      & ~GET_MODE_MASK (narrow_mode))))
+				      & ~GET_MODE_MASK (narrow_mode)))
+			      && (GET_MODE (reg) != SImode || const_method (src)))
 			    {
 			      rtx narrow_reg = gen_rtx_REG (narrow_mode,
 							    REGNO (reg));
diff -Naur gcc-4.1-20051216.orig/gcc/print-rtl.c gcc-4.1-20051216-src/gcc/print-rtl.c
--- gcc-4.1-20051216.orig/gcc/print-rtl.c	2005-08-16 02:13:53.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/print-rtl.c	2005-12-18 22:24:50.000000000 +0100
@@ -586,6 +586,9 @@
 	{
 	  char s[60];
 
+	  REAL_VALUE_TO_STRING (*CONST_DOUBLE_REAL_VALUE (in_rtx), s);
+	  fprintf (outfile, " %s", s);
+#if 0
 	  real_to_decimal (s, CONST_DOUBLE_REAL_VALUE (in_rtx),
 			   sizeof (s), 0, 1);
 	  fprintf (outfile, " %s", s);
@@ -593,6 +596,7 @@
 	  real_to_hexadecimal (s, CONST_DOUBLE_REAL_VALUE (in_rtx),
 			       sizeof (s), 0, 1);
 	  fprintf (outfile, " [%s]", s);
+#endif /* 0 */
 	}
       break;
 #endif
diff -Naur gcc-4.1-20051216.orig/gcc/print-tree.c gcc-4.1-20051216-src/gcc/print-tree.c
--- gcc-4.1-20051216.orig/gcc/print-tree.c	2005-10-13 01:34:09.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/print-tree.c	2005-12-18 22:24:50.000000000 +0100
@@ -134,7 +134,7 @@
       else
 	{
 	  char string[60];
-	  real_to_decimal (string, &d, sizeof (string), 0, 1);
+	  REAL_VALUE_TO_STRING (d, string);
 	  fprintf (file, " %s", string);
 	}
     }
@@ -680,7 +680,7 @@
 	    else
 	      {
 		char string[64];
-		real_to_decimal (string, &d, sizeof (string), 0, 1);
+		REAL_VALUE_TO_STRING (d, string);
 		fprintf (file, " %s", string);
 	      }
 	  }
diff -Naur gcc-4.1-20051216.orig/gcc/real.c gcc-4.1-20051216-src/gcc/real.c
--- gcc-4.1-20051216.orig/gcc/real.c	2005-09-19 19:01:40.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/real.c	2005-12-18 22:24:50.000000000 +0100
@@ -72,6 +72,7 @@
    adjust the significand to match.  */
 
 
+#if 0
 /* Used to classify two numbers simultaneously.  */
 #define CLASS2(A, B)  ((A) << 2 | (B))
 
@@ -122,7 +123,9 @@
 static void times_pten (REAL_VALUE_TYPE *, int);
 
 static void round_for_format (const struct real_format *, REAL_VALUE_TYPE *);
+#endif /* 0 */
 
+#if 0
 /* Initialize R with a positive zero.  */
 
 static inline void
@@ -973,6 +976,614 @@
       gcc_unreachable ();
     }
 }
+#endif /* 0 */
+
+/* Add 1 unit in the last place to a positive SMAP II BCD float. */
+static void bcdpadd1ulp(smap_bcd_float *op)
+{
+  int i;
+  op->mantissa++; /* This will give a digit of 10 in some cases. */
+  for (i=0;i<60;i+=4) { /* for each digit except the first one */
+    int d=(op->mantissa>>i)&15;
+    if (d<10) /* if the digit is <10, we're done */
+      break;
+    op->mantissa += 6ull<<i; /* subtract 10 from the digit, add 1 to the next digit */
+  }
+  /* Now, we should have a carry only in one case: the mantissa was
+     9999999999999999. So now, we have A000000000000000, where A is 10 in a
+     single digit. We can safely truncate the last digit because it is 0 (so
+     there is no risk of double-rounding here). */
+  if (op->mantissa >= 0xA000000000000000ull) { /* if we have a carry */
+    gcc_assert (op->mantissa == 0xA000000000000000ull); /* sanity check */
+    op->mantissa = 0x1000000000000000ull; /* A -> 10, drop the last digit */
+    op->exponent++; /* adjust the exponent */
+    if (op->exponent > 0x4000+16383) /* exponent too large, overflow to +infinity */
+      *op = POSITIVE_INF;
+  }
+}
+
+/* Add 2 positive SMAP II BCD floats. */
+static smap_bcd_float bcdppadd(smap_bcd_float op0, smap_bcd_float op1)
+{
+  int lastdigit=0;
+
+  if (op0.exponent < op1.exponent) {
+    /* If op0 does not contribute to the result, avoid shift count overflow by
+       returning op1 immediately. */
+    if (op1.exponent-op0.exponent>16) return op1;
+    /* Adjust op0 exponent to fit op1. */
+    op0.mantissa >>= ((op1.exponent-op0.exponent-1)<<2);
+    lastdigit = (op0.mantissa&15); /* save the last digit of op0 */
+    op0.mantissa >>= 4; /* drop the last digit of op0 */
+    op0.exponent = op1.exponent; /* adjust the exponent of op0 */
+  } else if (op1.exponent < op0.exponent) {
+    /* If op1 does not contribute to the result, avoid shift count overflow by
+       returning op0 immediately. */
+    if (op0.exponent-op1.exponent>16) return op0;
+    /* Adjust op1 exponent to fit op0. */
+    op1.mantissa >>= ((op0.exponent-op1.exponent-1)<<2);
+    lastdigit = (op1.mantissa&15); /* save the last digit of op1 */
+    op1.mantissa >>= 4; /* drop the last digit of op1 */
+    op1.exponent = op0.exponent; /* adjust the exponent of op1 */
+  }
+
+  /* Now do the addition in the BCD-coded mantissa. */
+  {
+    int i,d,carry=0;
+    smap_bcd_float result={0,0};result.exponent=op0.exponent;
+    for (i=0;i<64;i+=4) { /* for each digit */
+      d = (op0.mantissa&15)+(op1.mantissa&15)+carry;
+      carry = (d>=10); /* handle carry */
+      if (carry) d -= 10;
+      /* We are done with this digit of the mantissa. */
+      op0.mantissa >>= 4;
+      op1.mantissa >>= 4;
+      /* Store it into the resulting mantissa. */
+      result.mantissa += ((unsigned long long)d)<<i;
+    }
+    if (carry) { /* The mantissa overflowed, so we need to adjust the exponent. */
+      lastdigit = (result.mantissa&15); /* save the last digit of result,
+                                           dropping the previously saved last
+                                           digit */
+      result.mantissa >>= 4; /* drop the last digit of result */
+      result.exponent++; /* adjust the exponent of result */
+      if (result.exponent > 0x4000+16383) /* exponent too large, overflow to */
+        return POSITIVE_INF;              /* +infinity */
+      /* prepend the first digit */
+      result.mantissa += ((unsigned long long)carry)<<60;
+    }
+    if (lastdigit>=5) /* now do the correct rounding */
+      bcdpadd1ulp(&result);
+    return result;
+  }
+}
+
+/* Subtract 2 positive SMAP II BCD floats. */
+static smap_bcd_float bcdppsub(smap_bcd_float op0, smap_bcd_float op1)
+{
+  unsigned long long lastdigits=0;
+
+  if (REAL_VALUES_LESS(op0,op1)) /* if op0<op1, subtract the other way round */
+    return REAL_VALUE_NEGATE(bcdppsub(op1,op0));
+  else if (REAL_VALUES_IDENTICAL(op0,op1)) /* if op0=op1, return unsigned 0 */
+    return UNSIGNED_ZERO;
+
+  /* Now, we can assume op0>op1. */
+  if (op1.exponent < op0.exponent) {
+    /* If op1 does not contribute to the result, avoid shift count overflow by
+       returning op0 immediately. */
+    if (op0.exponent-op1.exponent>16) return op0;
+    /* Adjust op1 exponent to fit op0.
+       Save all dropped digits, so we can round correctly. */
+    lastdigits = op1.mantissa << (64-((op0.exponent-op1.exponent)<<2));
+    if (op0.exponent-op1.exponent==16)
+      op1.mantissa = 0; /* special-cased because shifts by 64 aren't allowed */
+    else
+      op1.mantissa >>= ((op0.exponent-op1.exponent)<<2);
+    op1.exponent = op0.exponent; /* adjust the exponent of op1 */
+  }
+
+  /* Now do the subtraction in the BCD-coded mantissa. */
+  {
+    int i,d,carry=0;
+    smap_bcd_float result={0,0};result.exponent=op0.exponent;
+    for (i=0;i<64;i+=4) { /* for each digit */
+      d = (op0.mantissa&15)-((op1.mantissa&15)+carry);
+      carry = (d<0); /* handle carry */
+      if (carry) d += 10;
+      /* We are done with this digit of the mantissa. */
+      op0.mantissa >>= 4;
+      op1.mantissa >>= 4;
+      /* Store it into the resulting mantissa. */
+      result.mantissa += ((unsigned long long)d)<<i;
+    }
+    gcc_assert (!carry); /* Carry should be 0 here! */
+    /* Normalize and return the result (which is always positive here, since we
+       assumed op1>op0). Handle rounding and extra digits during normalization.
+       */
+    while ((result.mantissa<0x1000000000000000ull)
+           || ((result.mantissa==0x1000000000000000ull)
+              && ((lastdigits>0x5000000000000000ull)
+                 || ((lastdigits>0x500000000000000ull)
+                     && (result.exponent>0x4000-16383))))) {
+    /* while mantissa<1 */
+      int c = (result.mantissa==0x1000000000000000ull); /* used by the sanity
+                                                           check below */
+      result.exponent--; /* decrease exponent by 1 */
+      if (result.exponent<0x4000-16383) /* exponent too small, underflow to +0 */
+        return POSITIVE_ZERO;
+      result.mantissa <<= 4; /* left-shift mantissa */
+      carry = !!(lastdigits>>60);
+      result.mantissa -= (lastdigits>>60)+(carry*6); /* Subtract extra digit. If
+        there is a carry, add 10 to the digit, subtract 1 from the next digit.
+        This can give digits of 15 in some cases. */
+      for (i=4;i<64;i+=4) { /* for each digit except the last one */
+        int d=(result.mantissa>>i)&15;
+        if (d<10) /* if the digit is <10, we're done */
+          break;
+        result.mantissa -= 6ull<<i; /* add 10 to the digit, subtract 1 from the
+                                       next digit */
+        /* There should be no carry in the first digit except if the mantissa
+           was exactly 1. */
+        gcc_assert (c || result.mantissa<0xA000000000000000ull);
+      }
+      lastdigits <<= 4; /* We handled an extra digit. */
+    }
+    /* Now do the rounding. */
+    if (lastdigits>0x5000000000000000ull) {
+      int c = !result.mantissa; /* used by the sanity check below */
+      /* This corner case should have been handled above. */
+      gcc_assert (result.mantissa!=0x1000000000000000ull);
+      result.mantissa--; /* Subtract 1. This can give digits of 15 in some cases. */
+      for (i=0;i<64;i+=4) { /* for each digit */
+        int d=(result.mantissa>>i)&15;
+        if (d<10) /* if the digit is <10, we're done */
+          break;
+        result.mantissa -= 6ull<<i; /* add 10 to the digit, subtract 1 from the
+                                       next digit */
+        /* There should be no carry in the first digit except if the mantissa was
+           0 (which actually means 10^16 here). */
+        gcc_assert (c || result.mantissa<0xA000000000000000ull);
+      }
+    }
+    return result;
+  }
+}
+
+/* Add 2 SMAP II BCD floats. */
+static smap_bcd_float bcdadd(smap_bcd_float op0, smap_bcd_float op1)
+{
+  if (REAL_VALUE_ISNAN(op0) || REAL_VALUE_ISNAN(op1)) /* keep NAN */
+    return NAN;
+  else if (REAL_VALUE_ISINF(op0) && REAL_VALUE_ISINF(op1)) { /* both operands
+                                                                are infinity */
+    if (!REAL_VALUES_IDENTICAL(op0,op1)
+        || REAL_VALUES_IDENTICAL(op0,UNSIGNED_INF)) /* differing signs or both
+                                                       unsigned yield NAN */
+      return NAN;
+    else /* both positive or both negative */
+      return op0;
+  } else if (REAL_VALUE_ISINF(op0)) /* op0=inf, so op0+op1=inf+op1=inf=op0 */
+    return op0;
+  else if (REAL_VALUE_ISINF(op1)) /* op1=inf, so op0+op1=op0+inf=inf=op1 */
+    return op1;
+  else if (REAL_VALUE_ISZERO(op0) && REAL_VALUE_ISZERO(op1)) { /* both operands
+                                                                  are 0 */
+    if (REAL_VALUES_IDENTICAL(op0,op1)) /* both positive, both negative or both
+                                           unsigned */
+      return op0;
+    else /* differing signs yield unsigned zero */
+      return UNSIGNED_ZERO;
+  } else if (REAL_VALUE_ISZERO(op0)) /* op0=0, so op0+op1=0+op1=op1 */
+    return op1;
+  else if (REAL_VALUE_ISZERO(op1)) /* op1=0, so op0+op1=op0+0=op0 */
+    return op0;
+  else if (REAL_VALUE_ISPOSITIVE(op0) && REAL_VALUE_ISPOSITIVE(op1))
+    return bcdppadd(op0,op1);
+  else if (REAL_VALUE_ISPOSITIVE(op0)) /* and op1 negative */
+    return bcdppsub(op0,REAL_VALUE_NEGATE(op1));
+  else if (REAL_VALUE_ISPOSITIVE(op1)) /* and op0 negative */
+    return bcdppsub(op1,REAL_VALUE_NEGATE(op0));
+  else /* both negative */
+    return REAL_VALUE_NEGATE(bcdppadd(REAL_VALUE_NEGATE(op0),
+                                      REAL_VALUE_NEGATE(op1)));
+}
+
+/* Subtract 2 SMAP II BCD floats. */
+static smap_bcd_float bcdsub(smap_bcd_float op0, smap_bcd_float op1)
+{
+  return bcdadd(op0,REAL_VALUE_NEGATE(op1));
+}
+
+/* Multiply 2 positive SMAP II BCD floats. */
+static smap_bcd_float bcdppmul(smap_bcd_float op0, smap_bcd_float op1)
+{
+  /* Compute the result in 2 binary parts. The upper 16 decimal digits and the
+     lower ones. */
+  unsigned long long resulth=0, resultl=0;
+  int i,j,k,d0,d1,d32,exponent;
+  unsigned long long factor=1ull;
+  for (i=0;i<64;i+=4,factor*=10ull) { /* for each result digit <16 */
+    for (j=0;j<64;j+=4) { /* for each digit of op0 */
+      k = i-j; /* corresponding op1 digit */
+      if (k<0 || k>=64) continue; /* digit out of range */
+      d0 = (op0.mantissa>>j)&15; /* jth digit of op0 */
+      d1 = (op1.mantissa>>k)&15; /* kth digit of op0 */
+      resultl += (unsigned long long)(d0*d1)*factor;
+      while (resultl>=10000000000000000ull/*10^16*/) { /* carry into resulth */
+        resultl -= 10000000000000000ull/*10^16*/;
+        resulth++;
+      }
+    }
+  }
+  for (factor=1ull;i<128;i+=4,factor*=10ull) { /* for each result digit >=16 */
+    for (j=0;j<64;j+=4) { /* for each digit of op0 */
+      k = i-j; /* corresponding op1 digit */
+      if (k<0 || k>=64) continue; /* digit out of range */
+      d0 = (op0.mantissa>>j)&15; /* jth digit of op0 */
+      d1 = (op1.mantissa>>k)&15; /* kth digit of op0 */
+      resulth += (unsigned long long)(d0*d1)*factor;
+    }
+  }
+
+  /* resultl should always be <10^16 */
+  gcc_assert (resultl<10000000000000000ull);
+
+  /* Because of normalization, the result has either 31 or 32 digits. */
+  d32 = (resulth>=1000000000000000ull/*10^15*/
+         || (resulth==999999999999999ull/*10^15-1*/
+             && resultl>=9500000000000000ull/*9.5*10^15*/));
+  if (!d32) { /* if we have only 15 digits in resulth, take one from resultl */
+    resulth = resulth*10ull+resultl/1000000000000000ull/*10^15*/;
+    resultl = (resultl%1000000000000000ull/*10^15*/)*10ull;
+  }
+  if (resultl>=5000000000000000ull/*5*10^15*/) /* round resultl into resulth */
+    resulth++;
+
+  /* Now compute the exponent. */
+  exponent=op0.exponent+op1.exponent-0x4000+d32;
+  if (exponent>0x4000+16383) /* exponent too large, overflow to +infinity */
+    return POSITIVE_INF;
+  if (exponent<0x4000-16383) /* exponent too small, underflow to +0 */
+    return POSITIVE_ZERO;
+
+  /* Now convert resulth into a BCD mantissa. */
+  {
+    unsigned long long d;
+    smap_bcd_float result={0,0};result.exponent=exponent;
+    for (i=0;i<64;i+=4) { /* for each digit */
+      d = resulth%10ull; /* Extract the digit. */
+      resulth /= 10ull; /* We are done with this digit of the mantissa. */
+      result.mantissa += d<<i; /* Store it into the resulting mantissa. */
+    }
+    return result;
+  }
+}
+
+/* Multiply 2 SMAP II BCD floats. */
+static smap_bcd_float bcdmul(smap_bcd_float op0, smap_bcd_float op1)
+{
+  if (REAL_VALUE_ISNAN(op0) || REAL_VALUE_ISNAN(op1)
+      || (REAL_VALUE_ISINF(op0) && REAL_VALUE_ISZERO(op1))
+      || (REAL_VALUE_ISZERO(op0) && REAL_VALUE_ISINF(op1))) /* keep NAN,
+                                                               0*inf=NAN */
+    return NAN;
+  else if (REAL_VALUES_IDENTICAL(op0,UNSIGNED_INF)
+           || REAL_VALUES_IDENTICAL(op1,UNSIGNED_INF)) /* unsigned inf * non-0 =
+                                                          unsigned inf */
+    return UNSIGNED_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* +inf * +inf = +inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF))) /* -inf * -inf = +inf */
+    return POSITIVE_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* +inf * -inf = -inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF))) /* -inf * +inf = -inf */
+    return NEGATIVE_INF;
+  /* Now we can assume that at least 1 value is finite, and that we don't have
+     an unsigned infinity, a NAN or an inf*0 indeterminate form. */
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUE_ISPOSITIVE(op1)) /* +inf * +finite = +inf */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* +finite * +inf = +inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUE_ISNEGATIVE(op1)) /* -inf * -finite = +inf */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF))) /* -finite * -inf = +inf */
+    return POSITIVE_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUE_ISNEGATIVE(op1)) /* +inf * -finite = -inf */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* +finite * -inf = -inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUE_ISPOSITIVE(op1)) /* -inf * +finite = -inf */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF))) /* -finite * +inf = -inf */
+    return NEGATIVE_INF;
+  /* Now we can assume that both values are finite. */
+  else if (REAL_VALUES_IDENTICAL(op0,UNSIGNED_ZERO)
+           || REAL_VALUES_IDENTICAL(op1,UNSIGNED_ZERO)) /* unsigned 0 * finite =
+                                                           unsigned 0 */
+    return UNSIGNED_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO)) /* +0 * +0 = +0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO))) /* -0 * -0 = +0 */
+    return POSITIVE_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO)) /* +0 * -0 = -0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO))) /* -0 * +0 = -0 */
+    return NEGATIVE_ZERO;
+  /* Now we can assume that both values are finite, at least 1 value is non-0,
+     and that we don't have an unsigned 0. */
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUE_ISPOSITIVE(op1)) /* +0 * +finite = +0 */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO)) /* +finite * +0 = +0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUE_ISNEGATIVE(op1)) /* -0 * -finite = +0 */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO))) /* -finite * -0 = +0 */
+    return POSITIVE_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUE_ISNEGATIVE(op1)) /* +0 * -finite = -0 */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO)) /* +finite * -0 = -0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUE_ISPOSITIVE(op1)) /* -0 * +finite = -0 */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO))) /* -finite * +0 = -0 */
+    return NEGATIVE_ZERO;
+  /* Now we can assume that both values are finite and non-0. */
+  else if (REAL_VALUE_ISPOSITIVE(op0) && REAL_VALUE_ISPOSITIVE(op1))
+    return bcdppmul(op0,op1);
+  else if (REAL_VALUE_ISPOSITIVE(op0)) /* and op1 negative */
+    return REAL_VALUE_NEGATE(bcdppmul(op0,REAL_VALUE_NEGATE(op1)));
+  else if (REAL_VALUE_ISPOSITIVE(op1)) /* and op0 negative */
+    return REAL_VALUE_NEGATE(bcdppmul(REAL_VALUE_NEGATE(op0),op1));
+  else /* both negative */
+    return bcdppmul(REAL_VALUE_NEGATE(op0),REAL_VALUE_NEGATE(op1));
+}
+
+/* Divide 2 positive SMAP II BCD floats. Indicate if the computed result was exact. */
+static smap_bcd_float bcdppdiv(smap_bcd_float op0, smap_bcd_float op1, int *exactresult)
+{
+  /* The dividend is represented multiplied by 10^16, and in 2 binary parts. The
+     upper 64 bits and the lower ones. The divisor is represented in binary, in
+     2 parts to allow shifting. Compute the result mantissa in binary. */
+  unsigned long long dividendh, dividendl=0, divisorh, divisorl=0, resultm=0;
+  int i,d17,exponent;
+  unsigned long long factor=1ull;
+  /* Convert the mantissa of op0 to binary. */
+  for (i=0;i<64;i+=4,factor*=10ull) /* for each digit of op0 */
+    dividendl += (unsigned long long)((op0.mantissa>>i)&15)*factor;
+  /* Multiply the dividend with 10^16. */
+  dividendh = dividendl>>48; /* multiply first 16 bits with 2^16 */
+  dividendh *= 152587890625ull; /* and with 5^16 */
+  dividendl &= 0xFFFFFFFFFFFFull; /* remove them from dividendl */
+  dividendl *= 15625ull; /* multiply the remaining 48 bits with 5^6
+                            we still have to multiply them by 2^16*5^10 */
+  dividendh += (dividendl>>48)*9765625ull; /* multiply first 16 bits with 2^16*5^10 */
+  dividendl &= 0xFFFFFFFFFFFFull; /* remove them from dividendl */
+  dividendl *= 15625ull; /* multiply the remaining 48 bits with 5^6
+                            we still have to multiply them by 2^16*5^4 */
+  dividendh += (dividendl>>48)*625ull; /* multiply first 16 bits with 2^16*5^4 */
+  dividendl &= 0xFFFFFFFFFFFFull; /* remove them from dividendl */
+  dividendl *= 625ull; /* multiply the remaining 48 bits with 5^4
+                          we still have to multiply them by 2^16 */
+  dividendh += dividendl>>48; /* multiply first 16 bits with 2^16 */
+  dividendl <<= 16; /* multiply the remaining 48 bits with 2^16 */
+  /* Convert the mantissa of op1 to binary. */
+  for (i=0,factor=1ull;i<64;i+=4,factor*=10ull) /* for each digit of op1 */
+    divisorl += (unsigned long long)((op1.mantissa>>i)&15)*factor;
+  /* Multiply the divisor with 2^56. We know that, due to normalization, the
+     result is always <10^17, which is smaller than 2^57, so we don't have to go
+     through the full 128-bit division. */
+  divisorh = divisorl>>(64-56);
+  divisorl <<= 56;
+  /* Now do the 128-bit division. */
+  for (i=56;i>=0;i--) {
+    /* Shift the result to the left. */
+    resultm <<= 1;
+    /* Check if the divisor fits into the dividend. */
+    if (divisorh<dividendh || (divisorh==dividendh && divisorl<=dividendl)) {
+      /* Add 1 to the result. */
+      resultm++;
+      /* Subtract the divisor from the dividend. */
+      if (dividendl<divisorl) /* handle carry, use unsigned wraparound overflow */
+        dividendh--;
+      dividendl -= divisorl; /* now do the subtraction */
+      dividendh -= divisorh;
+    }
+    if (i) {
+      /* Shift the divisor to the right. */
+      divisorl = ((divisorh&1)<<63)+(divisorl>>1);
+      divisorh >>= 1;
+    }
+  }
+  /* dividendl now contains the remainder. It is always smaller than the
+     divisor, so it always fits into 64 bits. divisorl now contains the original
+     divisor. */
+
+  if (exactresult)
+    *exactresult = !dividendl; /* if there is a remainder, the result sure is
+                                  not exact, otherwise, let's assume it is for
+                                  a moment */
+
+  /* Because of normalization, the result has either 16 or 17 digits. */
+  d17 = (resultm>=10000000000000000ull/*10^16*/
+         || (resultm==9999999999999999ull/*10^16-1*/
+             && (dividendl<<1)>=divisorl) /* 2r>=d <=> r>=d/2 */);
+  if (d17) { /* if we have 17 digits in the result, drop one */
+    if (exactresult && (resultm%10ull)) /* if we are about to drop a non-0
+                                           digit, the result is not exact
+                                           anymore */
+      *exactresult = 0;
+    resultm = (resultm+5ull)/10ull; /* add 5 for correct rounding */
+  } else {
+    if ((dividendl<<1)>=divisorl /* r>=d/2 */) /* round remainder into result */
+      resultm++;
+  }
+
+  /* Now compute the exponent. */
+  exponent=op0.exponent-op1.exponent+0x4000-(!d17);
+  if (exactresult && (exponent>0x4000+16383 || exponent<0x4000-16383))
+    /* if we overflowed, the result is not exact anymore */
+    *exactresult = 0;
+  if (exponent>0x4000+16383) /* exponent too large, overflow to +infinity */
+    return POSITIVE_INF;
+  if (exponent<0x4000-16383) /* exponent too small, underflow to +0 */
+    return POSITIVE_ZERO;
+
+  /* Now convert resulth into a BCD mantissa. */
+  {
+    unsigned long long d;
+    smap_bcd_float result={0,0};result.exponent=exponent;
+    for (i=0;i<64;i+=4) { /* for each digit */
+      d = resultm%10ull; /* Extract the digit. */
+      resultm /= 10ull; /* We are done with this digit of the mantissa. */
+      result.mantissa += d<<i; /* Store it into the resulting mantissa. */
+    }
+    return result;
+  }
+}
+
+/* Divide 2 SMAP II BCD floats. Indicate if the computed result was exact. */
+static smap_bcd_float bcddiv(smap_bcd_float op0, smap_bcd_float op1, int *exactresult)
+{
+  if (exactresult) *exactresult=1; /* special cases are all exact */
+  if (REAL_VALUE_ISNAN(op0) || REAL_VALUE_ISNAN(op1)
+      || (REAL_VALUE_ISINF(op0) && REAL_VALUE_ISINF(op1))
+      || (REAL_VALUE_ISZERO(op0) && REAL_VALUE_ISZERO(op1))) /* keep NAN,
+                                                                0/0=inf/inf=NAN */
+    return NAN;
+  else if (REAL_VALUES_IDENTICAL(op0,UNSIGNED_INF)
+           || REAL_VALUES_IDENTICAL(op1,UNSIGNED_ZERO)) /* unsigned inf / finite
+                                          = non-0 / unsigned 0 = unsigned inf */
+    return UNSIGNED_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO)) /* +inf / +0 = +inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO))) /* -inf / -0 = +inf */
+    return POSITIVE_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO)) /* +inf / -0 = -inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO))) /* -inf / +0 = -inf */
+    return NEGATIVE_INF;
+  /* Now we can assume that at least 1 of op0 and 1/op1 is finite, and that we
+     don't have op0 = unsigned inf, op1 = unsigned 0, a NAN or an inf/inf or 0/0
+     indeterminate form. */
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUE_ISPOSITIVE(op1)) /* +inf / +non-0 = +inf */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO)) /* +finite / +0 = +inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUE_ISNEGATIVE(op1)) /* -inf / -non-0 = +inf */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO))) /* -finite / -0 = +inf */
+    return POSITIVE_INF;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+            && REAL_VALUE_ISNEGATIVE(op1)) /* +inf / -non-0 = -inf */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_ZERO)) /* +finite / -0 = -inf */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+               && REAL_VALUE_ISPOSITIVE(op1)) /* -inf / +non-0 = -inf */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_ZERO))) /* -finite / +0 = -inf */
+    return NEGATIVE_INF;
+  /* Now we can assume that both of op0 and 1/op1 are finite. */
+  else if (REAL_VALUES_IDENTICAL(op0,UNSIGNED_ZERO)
+           || REAL_VALUES_IDENTICAL(op1,UNSIGNED_INF)) /* unsigned 0 / non-0 =
+                                           finite / unsigned inf = unsigned 0 */
+    return UNSIGNED_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* +0 / +inf = +0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF))) /* -0 / -inf = +0 */
+    return POSITIVE_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* +0 / -inf = -0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF))) /* -0 / +inf = -0 */
+    return NEGATIVE_ZERO;
+  /* Now we can assume that both of op0 and 1/op1 are finite, at least 1 of them
+     is non-0, and that neither of them is an unsigned 0. */
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUE_ISPOSITIVE(op1)) /* +0 / +non-0 = +0 */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* +finite / +inf = +0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUE_ISNEGATIVE(op1)) /* -0 / -non-0 = +0 */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF))) /* -finite / -inf = +0 */
+    return POSITIVE_ZERO;
+  else if ((REAL_VALUES_IDENTICAL(op0,POSITIVE_ZERO)
+            && REAL_VALUE_ISNEGATIVE(op1)) /* +0 / -non-0 = -0 */
+           || (REAL_VALUE_ISPOSITIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* +finite / -inf = -0 */
+           || (REAL_VALUES_IDENTICAL(op0,NEGATIVE_ZERO)
+               && REAL_VALUE_ISPOSITIVE(op1)) /* -0 / +non-0 = -0 */
+           || (REAL_VALUE_ISNEGATIVE(op0)
+               && REAL_VALUES_IDENTICAL(op1,POSITIVE_INF))) /* -finite / +inf = -0 */
+    return NEGATIVE_ZERO;
+  /* Now we can assume that both values are finite and non-0. */
+  else if (REAL_VALUE_ISPOSITIVE(op0) && REAL_VALUE_ISPOSITIVE(op1))
+    return bcdppdiv(op0,op1,exactresult);
+  else if (REAL_VALUE_ISPOSITIVE(op0)) /* and op1 negative */
+    return REAL_VALUE_NEGATE(bcdppdiv(op0,REAL_VALUE_NEGATE(op1),exactresult));
+  else if (REAL_VALUE_ISPOSITIVE(op1)) /* and op0 negative */
+    return REAL_VALUE_NEGATE(bcdppdiv(REAL_VALUE_NEGATE(op0),op1,exactresult));
+  else /* both negative */
+    return bcdppdiv(REAL_VALUE_NEGATE(op0),REAL_VALUE_NEGATE(op1),exactresult);
+}
+
+/* Compute min of 2 SMAP II BCD floats. */
+static smap_bcd_float bcdmin(smap_bcd_float op0, smap_bcd_float op1)
+{
+  if (REAL_VALUE_ISNANUINF(op0) || REAL_VALUE_ISNANUINF(op1)) /* keep NAN,
+                    UNSIGNED_INF is neither smaller nor larger than the other */
+    return NAN;
+  else if (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)
+           || REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* keep -infinity */
+    return NEGATIVE_INF;
+  else if (REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)) /* all numbers are smaller
+                                                       than +infinity */
+    return op1;
+  else if (REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* all numbers are smaller
+                                                       than +infinity */
+    return op0;
+  /* Now, we can assume that all values are finite. */
+  else if (REAL_VALUES_LESS(op0,op1)) /* if op0<op1, return op0 */
+    return op0;
+  else /* if op0>=op1, return op1 */
+    return op1;
+}
+
+/* Compute max of 2 SMAP II BCD floats. */
+static smap_bcd_float bcdmax(smap_bcd_float op0, smap_bcd_float op1)
+{
+  if (REAL_VALUE_ISNANUINF(op0) || REAL_VALUE_ISNANUINF(op1)) /* keep NAN,
+                    UNSIGNED_INF is neither smaller nor larger than the other */
+    return NAN;
+  else if (REAL_VALUES_IDENTICAL(op0,POSITIVE_INF)
+           || REAL_VALUES_IDENTICAL(op1,POSITIVE_INF)) /* keep +infinity */
+    return POSITIVE_INF;
+  else if (REAL_VALUES_IDENTICAL(op0,NEGATIVE_INF)) /* all numbers are smaller
+                                                       than -infinity */
+    return op1;
+  else if (REAL_VALUES_IDENTICAL(op1,NEGATIVE_INF)) /* all numbers are smaller
+                                                       than -infinity */
+    return op0;
+  /* Now, we can assume that all values are finite. */
+  else if (REAL_VALUES_LESS(op0,op1)) /* if op0<op1, return op1 */
+    return op1;
+  else /* if op0>=op1, return op0 */
+    return op0;
+}
 
 /* Perform the binary or unary operation described by CODE.
    For a unary operation, leave OP1 NULL.  This function returns
@@ -982,6 +1593,37 @@
 real_arithmetic (REAL_VALUE_TYPE *r, int icode, const REAL_VALUE_TYPE *op0,
 		 const REAL_VALUE_TYPE *op1)
 {
+  switch (icode)
+    {
+    case PLUS_EXPR:
+      *r = bcdadd (*op0, *op1);
+      return true;
+
+    case MINUS_EXPR:
+      *r = bcdsub (*op0, *op1);
+      return true;
+
+    case MULT_EXPR:
+      *r = bcdmul (*op0, *op1);
+      return true;
+
+    case RDIV_EXPR:
+      *r = bcddiv (*op0, *op1, NULL);
+      return true;
+
+    case MIN_EXPR:
+      *r = bcdmin (*op0, *op1);
+      return false;
+
+    case MAX_EXPR:
+      *r = bcdmax (*op0, *op1);
+      return false;
+
+    default:
+      gcc_unreachable ();
+    }
+
+#if 0
   enum tree_code code = icode;
 
   switch (code)
@@ -1033,9 +1675,11 @@
     default:
       gcc_unreachable ();
     }
+#endif /* 0 */
   return false;
 }
 
+#if 0
 /* Legacy.  Similar, but return the result directly.  */
 
 REAL_VALUE_TYPE
@@ -1046,6 +1690,7 @@
   real_arithmetic (&r, icode, op0, op1);
   return r;
 }
+#endif /* 0 */
 
 bool
 real_compare (int icode, const REAL_VALUE_TYPE *op0,
@@ -1056,39 +1701,40 @@
   switch (code)
     {
     case LT_EXPR:
-      return do_compare (op0, op1, 1) < 0;
+      return REAL_VALUES_LESS (*op0, *op1);
     case LE_EXPR:
-      return do_compare (op0, op1, 1) <= 0;
+      return !real_compare (UNGT_EXPR, op0, op1);
     case GT_EXPR:
-      return do_compare (op0, op1, -1) > 0;
+      return real_compare (LT_EXPR, op1, op0);
     case GE_EXPR:
-      return do_compare (op0, op1, -1) >= 0;
+      return !real_compare (UNLT_EXPR, op0, op1);
     case EQ_EXPR:
-      return do_compare (op0, op1, -1) == 0;
+      return REAL_VALUES_EQUAL (*op0, *op1);
     case NE_EXPR:
-      return do_compare (op0, op1, -1) != 0;
+      return !real_compare (EQ_EXPR, op0, op1);
     case UNORDERED_EXPR:
-      return op0->cl == rvc_nan || op1->cl == rvc_nan;
+      return REAL_VALUE_ISNANUINF (*op0) || REAL_VALUE_ISNANUINF (*op1);
     case ORDERED_EXPR:
-      return op0->cl != rvc_nan && op1->cl != rvc_nan;
+      return !real_compare (UNORDERED_EXPR, op0, op1);
     case UNLT_EXPR:
-      return do_compare (op0, op1, -1) < 0;
+      return real_compare (UNORDERED_EXPR, op0, op1) || real_compare (LT_EXPR, op0, op1);
     case UNLE_EXPR:
-      return do_compare (op0, op1, -1) <= 0;
+      return !real_compare (GT_EXPR, op0, op1);
     case UNGT_EXPR:
-      return do_compare (op0, op1, 1) > 0;
+      return real_compare (UNORDERED_EXPR, op0, op1) || real_compare (GT_EXPR, op0, op1);
     case UNGE_EXPR:
-      return do_compare (op0, op1, 1) >= 0;
+      return !real_compare (LT_EXPR, op0, op1);
     case UNEQ_EXPR:
-      return do_compare (op0, op1, 0) == 0;
+      return real_compare (UNORDERED_EXPR, op0, op1) || real_compare (EQ_EXPR, op0, op1);
     case LTGT_EXPR:
-      return do_compare (op0, op1, 0) != 0;
+      return !real_compare (UNEQ_EXPR, op0, op1);
 
     default:
       gcc_unreachable ();
     }
 }
 
+#if 0
 /* Return floor log2(R).  */
 
 int
@@ -1209,6 +1855,7 @@
 
   return true;
 }
+#endif /* 0 */
 
 /* Try to change R into its exact multiplicative inverse in machine
    mode MODE.  Return true if successful.  */
@@ -1216,6 +1863,13 @@
 bool
 exact_real_inverse (enum machine_mode mode, REAL_VALUE_TYPE *r)
 {
+  int exactresult=0;
+  smap_bcd_float one={0x4000,0x1000000000000000ull}, invr;
+
+  invr = bcddiv(one,*r,&exactresult);
+  if (exactresult) *r=invr;
+  return exactresult;
+#if 0
   const REAL_VALUE_TYPE *one = real_digit (1);
   REAL_VALUE_TYPE u;
   int i;
@@ -1245,8 +1899,10 @@
 
   *r = u;
   return true;
+#endif /* 0 */
 }
 
+#if 0
 /* Render R as an integer.  */
 
 HOST_WIDE_INT
@@ -1298,6 +1954,7 @@
       gcc_unreachable ();
     }
 }
+#endif /* 0 */
 
 /* Likewise, but to an integer pair, HI+LOW.  */
 
@@ -1305,6 +1962,59 @@
 real_to_integer2 (HOST_WIDE_INT *plow, HOST_WIDE_INT *phigh,
 		  const REAL_VALUE_TYPE *r)
 {
+  unsigned short exponent = (r->exponent & 0x7fff);
+  unsigned HOST_WIDE_INT low = 0, high = 0;
+  int e, i;
+  unsigned long long mantissa = r->mantissa;
+
+  /* Return 0 for transfinite, zero or |*r|<1 */
+  if (!REAL_VALUE_ISFINITE(*r) || REAL_VALUE_ISZERO(*r) || exponent < 0x4000) {
+    *plow = *phigh = 0;
+    return;
+  }
+
+  /* Compute the effective exponent */
+  e = (int)exponent - (0x4000+15);
+
+  /* Delete any digits following the decimal point right now */
+  if (e < 0) {
+    mantissa >>= ((-e)<<2);
+    e = 0;
+  } else if (e > 2*HOST_BITS_PER_WIDE_INT) {
+    /* We'll multiply by 10^(2*HBPWI)=5^(2*HBPWI)*2^(2*HBPWI). This will zero
+       out all digits. So avoid the long loop and return 0 right now. */
+    *plow = *phigh = 0;
+    return;
+  }
+
+  /* Convert the mantissa from BCD to binary */
+  for (i=60;i>=0;i-=4) {
+    /* Multiply by 10 using x*10=(x<<3)+(x<<1) */
+    high = (high<<3) + (low>>(HOST_BITS_PER_WIDE_INT-3)) /* (x<<3) */
+           + (high<<1) + (low>>(HOST_BITS_PER_WIDE_INT-1)) /* (x<<1) */
+           + ((low<<3) + (low<<1) < (low<<1)); /* (carry) */
+    low = (low<<3) + (low<<1);
+    low += (mantissa>>i)&15;
+  }
+
+  /* Multiply by 10^e */
+  for (i=0;i<e;i++) {
+    /* Multiply by 10 using x*10=(x<<3)+(x<<1) */
+    high = (high<<3) + (low>>(HOST_BITS_PER_WIDE_INT-3)) /* (x<<3) */
+           + (high<<1) + (low>>(HOST_BITS_PER_WIDE_INT-1)) /* (x<<1) */
+           + ((low<<3) + (low<<1) < (low<<1)); /* (carry) */
+    low = (low<<3) + (low<<1);
+  }
+
+  /* Negate the result if *r was negative */
+  if (r->exponent >= 0x8000) {
+	if (low == 0)
+	  high = -high;
+	else
+	  low = -low, high = ~high;
+  }
+
+#if 0
   REAL_VALUE_TYPE t;
   HOST_WIDE_INT low, high;
   int exp;
@@ -1370,11 +2080,13 @@
     default:
       gcc_unreachable ();
     }
+#endif /* 0 */
 
   *plow = low;
   *phigh = high;
 }
 
+#if 0
 /* A subroutine of real_to_decimal.  Compute the quotient and remainder
    of NUM / DEN.  Return the quotient and place the remainder in NUM.
    It is expected that NUM / DEN are close enough that the quotient is
@@ -1749,6 +2461,327 @@
 
   sprintf (p, "p%+d", exp);
 }
+#endif /* 0 */
+
+static void real_value_dtof (REAL_VALUE_TYPE *r, const char *string)
+{
+	const char *strpart = string;
+	unsigned char state = 0;
+	unsigned long long mpmul = 0x1000000000000000;
+	signed short expshift = -1;
+	unsigned short exp = 0;
+	unsigned short expmul = 1;
+	unsigned short expadd = 0;
+	int endrounding = -1;
+	r->mantissa = 0;
+	while (strpart && *strpart)
+	{
+		switch (state)
+		{
+			case 0:
+				if (*strpart == '.')
+				{
+					state = 1;
+					break;
+				}
+				else if (*strpart == '+')
+					expadd = 0;
+				else if (*strpart == '-')
+					expadd = 0x8000;
+				else if (((*strpart) >= '0' && (*strpart) <= '9') && ((r->mantissa) || (*strpart != '0')))
+					expshift++;
+				else if ((*strpart == 'i') || (*strpart == 'I'))
+				{
+					if (expadd == 0x8000)
+						*r = NEGATIVE_INF;
+					else
+						*r = POSITIVE_INF;
+					expadd = 0x3FFF;
+					strpart = 0;
+				}
+				else if ((*strpart == 'n') || (*strpart == 'N'))
+				{
+					*r = NAN;
+					expadd = 0x3FFF;
+					strpart = 0;
+				}
+			case 1:
+				if ((*strpart == 'e') || (*strpart == 'E'))
+					state = 2;
+				else if ((*strpart) >= '0' && (*strpart) <= '9')
+				{
+					if (mpmul)
+						r->mantissa |= (*strpart - '0') * mpmul;
+					else if (endrounding < 0)
+						endrounding = (*strpart >= '5');
+					if (r->mantissa)
+						mpmul /= 0x10;
+					else if (state)
+						expshift--;
+				}
+				break;
+			case 2:
+				if (*strpart == '+')
+					expmul = 1;
+				else if (*strpart == '-')
+					expmul = -1;
+				if ((*strpart) >= '0' && (*strpart) <= '9')
+				{
+					exp *= 10;
+					exp += (*strpart - '0');
+				}
+				break;
+		}
+		if (strpart)
+			strpart++;
+		else
+			break;
+	}
+	if (!(r->mantissa))
+		*r = ZERO;
+	else if (expadd != 0x3FFF)
+	{
+		r->exponent = exp * expmul + 0x4000 + expshift;
+		if (r->exponent>0x4000+16383) /* exponent too large, overflow to +infinity */
+			*r = POSITIVE_INF;
+		else if (r->exponent<0x4000-16383) /* exponent too small, underflow to +0 */
+			*r = POSITIVE_ZERO;
+		else if (endrounding > 0)
+			bcdpadd1ulp (r);
+		r->exponent += expadd;
+	}
+}
+
+typedef struct {
+  int ndigits;
+  unsigned char *digits;
+  long effexp;
+} arbprec_decimal;
+
+static void arbprec_pack (arbprec_decimal *r)
+{
+  unsigned char *p = r->digits;
+  if (r->ndigits) {
+    while (p < r->digits + r->ndigits && !*p) p++;
+    r->ndigits -= p - r->digits;
+    memmove (r->digits, p, r->ndigits);
+    if (r->ndigits) {
+      p = r->digits + r->ndigits - 1;
+      while (p > r->digits && !*p) {
+        p--;
+        r->effexp++;
+      }
+      r->ndigits = (p + 1) - r->digits;
+    }
+    r->digits = xrealloc (r->digits, r->ndigits);
+  }
+}
+
+static void arbprec_mul2 (arbprec_decimal *r)
+{
+  unsigned char *p;
+  unsigned char carry = 0;
+  r->ndigits++;
+  r->digits = xrealloc (r->digits, r->ndigits);
+  for (p = r->digits + r->ndigits - 1; p > r->digits; p--) {
+    unsigned char digit = (p[-1]<<1) + carry;
+    *p = digit % 10;
+    carry = digit / 10;
+  }
+  *p = carry;
+  arbprec_pack (r);
+}
+
+static void arbprec_div2 (arbprec_decimal *r)
+{
+  unsigned char *p;
+  unsigned char carry = 0;
+  r->ndigits++;
+  r->digits = xrealloc (r->digits, r->ndigits);
+  for (p = r->digits; p < r->digits + r->ndigits - 1; p++) {
+    unsigned char digit = (*p>>1) + carry;
+    carry = (*p&1)*5;
+    *p = digit;
+  }
+  *p = carry;
+  r->effexp--;
+  arbprec_pack (r);
+}
+
+static void arbprec_mul16 (arbprec_decimal *r)
+{
+  arbprec_mul2 (r);
+  arbprec_mul2 (r);
+  arbprec_mul2 (r);
+  arbprec_mul2 (r);
+}
+
+static void arbprec_div16 (arbprec_decimal *r)
+{
+  arbprec_div2 (r);
+  arbprec_div2 (r);
+  arbprec_div2 (r);
+  arbprec_div2 (r);
+}
+
+static void arbprec_add (arbprec_decimal *r1, arbprec_decimal *r2)
+{
+  if (!r2->ndigits)
+    return;
+  else if (!r1->ndigits) {
+    r1->digits = xrealloc (r1->digits, r2->ndigits);
+    memcpy (r1->digits, r2->digits, r2->ndigits);
+    r1->ndigits = r2->ndigits;
+    r1->effexp = r2->effexp;
+  } else {
+    if (r1->effexp > r2->effexp) {
+      long effexpdiff = r1->effexp - r2->effexp;
+      r1->digits = xrealloc (r1->digits, r1->ndigits + effexpdiff);
+      memset (r1->digits + r1->ndigits, 0, effexpdiff);
+      r1->ndigits += effexpdiff;
+      r1->effexp = r2->effexp;
+    } else if (r2->effexp > r1->effexp) {
+      long effexpdiff = r2->effexp - r1->effexp;
+      r2->digits = xrealloc (r2->digits, r2->ndigits + effexpdiff);
+      memset (r2->digits + r2->ndigits, 0, effexpdiff);
+      r2->ndigits += effexpdiff;
+      r2->effexp = r1->effexp;
+    }
+
+    {
+      int ndigits = MAX (r1->ndigits, r2->ndigits) + 1;
+      unsigned char *digits = xmalloc (ndigits);
+      unsigned char *p, *q1, *q2;
+      unsigned char carry = 0;
+      for (p = digits + ndigits - 1, q1 = r1->digits + r1->ndigits - 1,
+           q2 = r2->digits + r2->ndigits - 1; p > digits; p--, q1--, q2--) {
+        unsigned char digit = (q1>=r1->digits?*q1:0) + (q2>=r2->digits?*q2:0)
+                              + carry;
+        *p = digit % 10;
+        carry = digit / 10;
+      }
+      *p = carry;
+      free (r1->digits);
+      r1->digits = digits;
+      r1->ndigits = ndigits;
+      arbprec_pack (r1);
+      arbprec_pack (r2);
+    }
+  }
+}
+
+static void arbprec_add_n_times (arbprec_decimal *r1, arbprec_decimal *r2, int n)
+{
+  int i;
+  for (i = 0; i < n; i++) arbprec_add (r1, r2);
+}
+
+static void arbprec_to_bcd (arbprec_decimal *a, smap_bcd_float *r)
+{
+  if (a->ndigits) {
+    long exponent = a->effexp + a->ndigits - 1;
+    if (exponent>16383) /* exponent too large, overflow to +infinity */
+      *r = POSITIVE_INF;
+    else if (exponent<-16383) /* exponent too small, underflow to +0 */
+      *r = POSITIVE_ZERO;
+    else {
+      int i;
+      r->exponent = 0x4000 + exponent;
+      r->mantissa = 0;
+      for (i = 0; i < a->ndigits && i < 16; i++) {
+        r->mantissa = (r->mantissa << 4) + a->digits[i];
+      }
+      for (; i < 16; i++) {
+        r->mantissa <<= 4;
+      }
+      if (a->ndigits > 16 && a->digits[16] >= 5)
+        bcdpadd1ulp (r);
+    }
+  } else {
+    *r = UNSIGNED_ZERO;
+  }
+}
+
+static void real_value_htof (REAL_VALUE_TYPE *res, const char *string)
+{
+	arbprec_decimal r = {0, NULL, 0};
+	const char *strpart = string;
+	signed char state = -1;
+	arbprec_decimal rdiv = {1, NULL, 0};
+	unsigned int negative = 0;
+	unsigned short exp = 0;
+	unsigned short expsign = 1;
+	unsigned long exp2 = 1;
+	rdiv.digits = xmalloc (1);
+	*(rdiv.digits) = 1;
+	while (strpart && *strpart)
+	{
+		switch (state)
+		{
+			case -1:
+				if (*strpart == 'x' || *strpart == 'X')
+					state = 0;
+				else if (*strpart == '+')
+					negative = 0;
+				else if (*strpart == '-')
+					negative = 1;
+				break;
+			case 0:
+				if (*strpart == '.')
+				{
+					state = 1;
+					break;
+				}
+				else if ((*strpart >= '0' && *strpart <= '9') || (*strpart >= 'a' && *strpart <= 'f') || (*strpart >= 'A' && *strpart <= 'F'))
+					arbprec_mul16 (&r);
+			case 1:
+				if (state == 1)
+					arbprec_div16 (&rdiv);
+				if ((*strpart == 'p') || (*strpart == 'P'))
+					state = 2;
+				else if (*strpart >= '0' && *strpart <= '9')
+					arbprec_add_n_times (&r, &rdiv, (*strpart - '0'));
+				else if (*strpart >= 'a' && *strpart <= 'f')
+					arbprec_add_n_times (&r, &rdiv, (*strpart - 'a' + 0xA));
+				else if (*strpart >= 'A' && *strpart <= 'F')
+					arbprec_add_n_times (&r, &rdiv, (*strpart - 'A' + 0xA));
+				break;
+			case 2:
+				if (*strpart == '+')
+					expsign = 1;
+				else if (*strpart == '-')
+					expsign = -1;
+				if ((*strpart) >= '0' && (*strpart) <= '9')
+				{
+					exp *= 10;
+					exp += (*strpart - '0');
+				}
+				break;
+		}
+		strpart++;
+	}
+	free (rdiv.digits);
+	if (expsign == 1)
+	{
+		while (exp)
+		{
+			arbprec_mul2 (&r);
+			exp--;
+		}
+	}
+	else
+	{
+		while (exp)
+		{
+			arbprec_div2 (&r);
+			exp--;
+		}
+	}
+	arbprec_to_bcd (&r, res);
+	free (r.digits);
+	if (negative)
+		*res = REAL_VALUE_NEGATE (*res);
+}
 
 /* Initialize R from a decimal or hexadecimal string.  The string is
    assumed to have been syntax checked already.  */
@@ -1756,6 +2789,17 @@
 void
 real_from_string (REAL_VALUE_TYPE *r, const char *str)
 {
+  const char *p = str;
+
+  if (*p == '-' || *p == '+')
+    p++;
+
+  if (p[0] == '0' && (p[1] == 'x' || p[1] == 'X'))
+    real_value_htof (r, str);
+  else
+    real_value_dtof (r, str);
+
+#if 0
   int exp = 0;
   bool sign = false;
 
@@ -1941,6 +2985,7 @@
  overflow:
   get_inf (r, sign);
   return;
+#endif /* 0 */
 }
 
 /* Legacy.  Similar, but return the result directly.  */
@@ -1964,6 +3009,67 @@
 		   unsigned HOST_WIDE_INT low, HOST_WIDE_INT high,
 		   int unsigned_p)
 {
+  int i, j, e = -1, lastdigit = 0;
+  bool negative = high < 0 && !unsigned_p;
+  unsigned HOST_WIDE_INT uhigh = (unsigned HOST_WIDE_INT)high;
+  unsigned HOST_WIDE_INT ulow = low;
+  unsigned HOST_WIDE_INT remainderh, remainderl, divisorh, divisorl;
+  unsigned long long mantissa = 0;
+
+  if (negative) {
+    uhigh = ~uhigh;
+    if (!ulow) uhigh++; else ulow = -ulow;
+  }
+
+  /* Convert the integer to BCD */
+  while (uhigh || ulow) {
+    remainderh = uhigh; remainderl = ulow;
+    divisorl = uhigh = ulow = 0;
+    divisorh = (HOST_WIDE_INT)10<<(HOST_BITS_PER_WIDE_INT-4);
+    /* Divide the pair of HOST_WIDE_INTs by 10 */
+    for (j=2*HOST_BITS_PER_WIDE_INT-4;j>=0;j--) {
+      /* Shift the result to the left. */
+      uhigh = (uhigh<<1) + (ulow>>(HOST_BITS_PER_WIDE_INT-1));
+      ulow <<= 1;
+      /* Check if the divisor 10 fits into the dividend. */
+      if (divisorh<remainderh || (divisorh==remainderh && divisorl<=remainderl)) {
+        /* Add 1 to the result. */
+        ulow++;
+        if (!ulow) uhigh++; /* handle carry */
+        /* Subtract the divisor from the dividend. */
+        if (remainderl<divisorl) /* handle carry, use unsigned wraparound overflow */
+          remainderh--;
+        remainderl -= divisorl; /* now do the subtraction */
+        remainderh -= divisorh;
+      }
+      if (j) {
+        /* Shift the divisor to the right. */
+        divisorl = ((divisorh&1)<<(HOST_BITS_PER_WIDE_INT-1))+(divisorl>>1);
+        divisorh >>= 1;
+      }
+    }
+    e++;
+    lastdigit = (mantissa&15);
+    mantissa = (mantissa>>4) + ((unsigned long long)remainderl<<60);
+  }
+
+  if (e >= 0) {
+    /* We have a nonnegative exponent. Do the correct rounding for the last
+       digit. */
+
+    r->exponent = e+0x4000;
+    r->mantissa = mantissa;
+
+    if (lastdigit >= 5) bcdpadd1ulp(r);
+  } else {
+    /* We don't have any digit, so our number is actually zero. */
+    *r = UNSIGNED_ZERO;
+  }
+
+  /* Negate *r if the integer was negative */
+  if (negative) *r = REAL_VALUE_NEGATE (*r);
+
+#if 0
   if (low == 0 && high == 0)
     get_zero (r, 0);
   else
@@ -2001,8 +3107,10 @@
 
   if (mode != VOIDmode)
     real_convert (r, mode, r);
+#endif /* 0 */
 }
 
+#if 0
 /* Returns 10**2**N.  */
 
 static const REAL_VALUE_TYPE *
@@ -2490,6 +3598,7 @@
 
   return fmt->p * fmt->log2_b;
 }
+#endif /* 0 */
 
 /* Return a hash value for the given real value.  */
 /* ??? The "unsigned int" return value is intended to be hashval_t,
@@ -2498,6 +3607,12 @@
 unsigned int
 real_hash (const REAL_VALUE_TYPE *r)
 {
+  /* (TIGCC) Very naive hash for lack of something better. -- Kevin Kofler */
+  unsigned int h=r->exponent;
+  return h+(unsigned int)(r->mantissa >>
+                          ((sizeof(unsigned long long)-sizeof(unsigned int))*8));
+
+#if 0
   unsigned int h;
   size_t i;
 
@@ -2534,8 +3649,10 @@
       h ^= r->sig[i];
 
   return h;
+#endif /* 0 */
 }
 
+#if 0
 /* IEEE single-precision format.  */
 
 static void encode_ieee_single (const struct real_format *fmt,
@@ -4705,4 +5822,5 @@
 {
   r->sign = x->sign;
 }
+#endif /* 0 */
 
diff -Naur gcc-4.1-20051216.orig/gcc/real.h gcc-4.1-20051216-src/gcc/real.h
--- gcc-4.1-20051216.orig/gcc/real.h	2005-08-01 23:16:31.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/real.h	2005-12-18 22:24:50.000000000 +0100
@@ -22,6 +22,22 @@
 #ifndef GCC_REAL_H
 #define GCC_REAL_H
 
+/* (TIGCC) smapbcd.h need this, but gengtype needs it to be in this file. */
+/* (TIGCC) Hack to make gengtype shut up while still packing the structure. */
+#define exponent exponent __attribute__((packed))
+#define mantissa mantissa __attribute__((packed))
+__attribute__ ((packed))
+struct real_value GTY(())
+{
+	unsigned short exponent;
+	unsigned long long mantissa;
+};
+#undef exponent
+#undef mantissa
+
+#include <config/smapbcd.h>
+#define SMAP_BCD_FLOAT_FORMAT 5
+
 #include "machmode.h"
 
 /* An expanded form of the represented number.  */
@@ -40,19 +56,22 @@
 #define SIGSZ			(SIGNIFICAND_BITS / HOST_BITS_PER_LONG)
 #define SIG_MSB			((unsigned long)1 << (HOST_BITS_PER_LONG - 1))
 
+/*
 struct real_value GTY(())
 {
-  /* Use the same underlying type for all bit-fields, so as to make
+  ** Use the same underlying type for all bit-fields, so as to make
      sure they're packed together, otherwise REAL_VALUE_TYPE_SIZE will
-     be miscomputed.  */
-  unsigned int /* ENUM_BITFIELD (real_value_class) */ cl : 2;
+     be miscomputed.  **
+  unsigned int ** ENUM_BITFIELD (real_value_class) ** cl : 2;
   unsigned int sign : 1;
   unsigned int signalling : 1;
   unsigned int canonical : 1;
   unsigned int uexp : EXP_BITS;
   unsigned long sig[SIGSZ];
 };
-
+*/
+  
+#if 0
 #define REAL_EXP(REAL) \
   ((int)((REAL)->uexp ^ (unsigned int)(1 << (EXP_BITS - 1))) \
    - (1 << (EXP_BITS - 1)))
@@ -76,6 +95,9 @@
 /* Verify the guess.  */
 extern char test_real_width
   [sizeof(REAL_VALUE_TYPE) <= REAL_WIDTH*sizeof(HOST_WIDE_INT) ? 1 : -1];
+#endif /* 0 */
+
+#define REAL_WIDTH (11*8 + HOST_BITS_PER_WIDE_INT)/HOST_BITS_PER_WIDE_INT
 
 /* Calculate the format for CONST_DOUBLE.  We need as many slots as
    are necessary to overlay a REAL_VALUE_TYPE on them.  This could be
@@ -111,6 +133,7 @@
 #endif
 
 
+#if 0
 /* Describes the properties of the specific target format in use.  */
 struct real_format
 {
@@ -167,6 +190,7 @@
    case compile-time FP overflow may not model run-time overflow.  */
 #define REAL_MODE_FORMAT_COMPOSITE_P(MODE) \
 	((REAL_MODE_FORMAT(MODE))->pnan < (REAL_MODE_FORMAT (MODE))->p)
+#endif /* 0 */
 
 /* Declare functions in real.c.  */
 
@@ -177,6 +201,7 @@
 /* Compare reals by tree_code.  */
 extern bool real_compare (int, const REAL_VALUE_TYPE *, const REAL_VALUE_TYPE *);
 
+#if 0
 /* Determine whether a floating-point value X is infinite.  */
 extern bool real_isinf (const REAL_VALUE_TYPE *);
 
@@ -209,6 +234,7 @@
 
 /* Render R as an integer.  */
 extern HOST_WIDE_INT real_to_integer (const REAL_VALUE_TYPE *);
+#endif /* 0 */
 extern void real_to_integer2 (HOST_WIDE_INT *, HOST_WIDE_INT *,
 			      const REAL_VALUE_TYPE *);
 
@@ -219,6 +245,7 @@
 extern void real_from_integer (REAL_VALUE_TYPE *, enum machine_mode,
 			       unsigned HOST_WIDE_INT, HOST_WIDE_INT, int);
 
+#if 0
 extern long real_to_target_fmt (long *, const REAL_VALUE_TYPE *,
 				const struct real_format *);
 extern long real_to_target (long *, const REAL_VALUE_TYPE *, enum machine_mode);
@@ -235,10 +262,12 @@
 extern void real_maxval (REAL_VALUE_TYPE *, int, enum machine_mode);
 
 extern void real_2expN (REAL_VALUE_TYPE *, int);
+#endif /* 0 */
 
 extern unsigned int real_hash (const REAL_VALUE_TYPE *);
 
 
+#if 0
 /* Target formats defined in real.c.  */
 extern const struct real_format ieee_single_format;
 extern const struct real_format mips_single_format;
@@ -318,9 +347,11 @@
   real_arithmetic2 (ABS_EXPR, &(X), NULL)
 
 extern int significand_size (enum machine_mode);
+#endif /* 0 */
 
 extern REAL_VALUE_TYPE real_from_string2 (const char *, enum machine_mode);
 
+#if 0
 #define REAL_VALUE_ATOF(s, m) \
   real_from_string2 (s, m)
 
@@ -343,6 +374,7 @@
 extern void real_ldexp (REAL_VALUE_TYPE *, const REAL_VALUE_TYPE *, int);
 
 /* **** End of software floating point emulator interface macros **** */
+#endif /* 0 */
 
 /* Constant real values 0, 1, 2, 3, 10, -1, -2, 0.5 and 1/3.  */
 
@@ -355,8 +387,10 @@
 extern REAL_VALUE_TYPE dconstm2;
 extern REAL_VALUE_TYPE dconsthalf;
 extern REAL_VALUE_TYPE dconstthird;
+#if 0
 extern REAL_VALUE_TYPE dconstpi;
 extern REAL_VALUE_TYPE dconste;
+#endif /* 0 */
 
 /* Function to return a real value (not a tree node)
    from a given integer constant.  */
@@ -377,6 +411,7 @@
 /* In tree.c: wrap up a REAL_VALUE_TYPE in a tree node.  */
 extern tree build_real (tree, REAL_VALUE_TYPE);
 
+#if 0
 /* Calculate R as the square root of X in the given machine mode.  */
 extern bool real_sqrt (REAL_VALUE_TYPE *, enum machine_mode,
 		       const REAL_VALUE_TYPE *);
@@ -397,5 +432,6 @@
 
 /* Set the sign of R to the sign of X.  */
 extern void real_copysign (REAL_VALUE_TYPE *, const REAL_VALUE_TYPE *);
+#endif /* 0 */
 
 #endif /* ! GCC_REAL_H */
diff -Naur gcc-4.1-20051216.orig/gcc/rtlanal.c gcc-4.1-20051216-src/gcc/rtlanal.c
--- gcc-4.1-20051216.orig/gcc/rtlanal.c	2005-11-03 12:31:46.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/rtlanal.c	2005-12-19 01:11:06.000000000 +0100
@@ -3183,6 +3183,19 @@
   if (offset == 0 || nregs_xmode == nregs_ymode)
     return 0;
 
+  /* (TIGCC 20050324) Subregs of a 10-byte mode are special, hardcode them. */
+  if (GET_MODE_SIZE (xmode) == 10)
+  {
+     gcc_assert (nregs_xmode == 3);
+
+     if (offset < 4)
+       return 0;
+     else if (offset < 8)
+       return 1;
+     else
+       return 2;
+  }
+
   /* Size of ymode must not be greater than the size of xmode.  */
   mode_multiple = GET_MODE_SIZE (xmode) / GET_MODE_SIZE (ymode);
   gcc_assert (mode_multiple != 0);
@@ -3266,6 +3279,28 @@
 	  ? WORDS_BIG_ENDIAN : BYTES_BIG_ENDIAN))
     return true;
 
+  /* (TIGCC 20050324) Subregs of a 10-byte mode are special, hardcode them. */
+  if (GET_MODE_SIZE (xmode) == 10)
+  {
+     switch (GET_MODE_SIZE (ymode))
+     {
+       case 1:
+         return (offset == 3 || offset == 7 || offset == 9);
+
+       case 2:
+         return (offset == 2 || offset == 6 || offset == 8);
+
+       case 4:
+         return (offset == 0 || offset == 4);
+
+       case 8:
+         return !offset;
+
+       default:
+         return false;
+     }
+  }
+
   /* Lowpart subregs are otherwise valid.  */
   if (offset == subreg_lowpart_offset (ymode, xmode))
     return true;
diff -Naur gcc-4.1-20051216.orig/gcc/sdbout.c gcc-4.1-20051216-src/gcc/sdbout.c
--- gcc-4.1-20051216.orig/gcc/sdbout.c	2005-06-25 04:02:01.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/sdbout.c	2005-12-18 22:24:50.000000000 +0100
@@ -1541,9 +1541,7 @@
 #ifdef SDB_OUTPUT_SOURCE_LINE
       SDB_OUTPUT_SOURCE_LINE (asm_out_file, line);
 #else
-      fprintf (asm_out_file, "\t.ln\t%d\n",
-	       ((sdb_begin_function_line > -1)
-		? line - sdb_begin_function_line : 1));
+      fprintf (asm_out_file, "\t.ln\t%d\n", line);
 #endif
     }
 }
diff -Naur gcc-4.1-20051216.orig/gcc/simplify-rtx.c gcc-4.1-20051216-src/gcc/simplify-rtx.c
--- gcc-4.1-20051216.orig/gcc/simplify-rtx.c	2005-11-16 18:15:23.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/simplify-rtx.c	2005-12-19 03:19:57.000000000 +0100
@@ -494,13 +494,14 @@
 	 both +0, (minus Y X) is the same as (minus X Y).  If the
 	 rounding mode is towards +infinity (or -infinity) then the two
 	 expressions will be rounded differently.  */
+      /* (TIGCC 20050210) This identity is valid for us thanks to unsigned 0. */
       if (GET_CODE (op) == MINUS
-	  && !HONOR_SIGNED_ZEROS (mode)
+	  /*&& !HONOR_SIGNED_ZEROS (mode)*/
 	  && !HONOR_SIGN_DEPENDENT_ROUNDING (mode))
 	return simplify_gen_binary (MINUS, mode, XEXP (op, 1), XEXP (op, 0));
       
       if (GET_CODE (op) == PLUS
-	  && !HONOR_SIGNED_ZEROS (mode)
+	  /*&& !HONOR_SIGNED_ZEROS (mode)*/
 	  && !HONOR_SIGN_DEPENDENT_ROUNDING (mode))
 	{
 	  /* (neg (plus A C)) is simplified to (minus -C A).  */
@@ -701,7 +702,7 @@
 	lv = CONST_DOUBLE_LOW (op),  hv = CONST_DOUBLE_HIGH (op);
 
       REAL_VALUE_FROM_INT (d, lv, hv, mode);
-      d = real_value_truncate (mode, d);
+      d = REAL_VALUE_TRUNCATE (mode, d);
       return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);
     }
   else if (code == UNSIGNED_FLOAT && GET_MODE (op) == VOIDmode
@@ -729,7 +730,7 @@
 	hv = 0, lv &= GET_MODE_MASK (op_mode);
 
       REAL_VALUE_FROM_UNSIGNED_INT (d, lv, hv, mode);
-      d = real_value_truncate (mode, d);
+      d = REAL_VALUE_TRUNCATE (mode, d);
       return CONST_DOUBLE_FROM_REAL_VALUE (d, mode);
     }
 
@@ -991,11 +992,7 @@
       switch (code)
 	{
 	case SQRT:
-	  if (HONOR_SNANS (mode) && real_isnan (&d))
-	    return 0;
-	  real_sqrt (&t, mode, &d);
-	  d = t;
-	  break;
+	  return 0;
 	case ABS:
 	  d = REAL_VALUE_ABS (d);
 	  break;
@@ -1003,7 +1000,7 @@
 	  d = REAL_VALUE_NEGATE (d);
 	  break;
 	case FLOAT_TRUNCATE:
-	  d = real_value_truncate (mode, d);
+	  d = REAL_VALUE_TRUNCATE (mode, d);
 	  break;
 	case FLOAT_EXTEND:
 	  /* All this does is change the mode.  */
@@ -1013,6 +1010,7 @@
 	  break;
 	case NOT:
 	  {
+#if 0
 	    long tmp[4];
 	    int i;
 
@@ -1020,6 +1018,11 @@
 	    for (i = 0; i < 4; i++)
 	      tmp[i] = ~tmp[i];
 	    real_from_target (&d, tmp, mode);
+#else
+	    /* (TIGCC 20050205) Use SMAP BCD representation directly. */
+	    d.exponent = ~d.exponent;
+	    d.mantissa = ~d.mantissa;
+#endif /* 0 */
 	    break;
 	  }
 	default:
@@ -1046,7 +1049,7 @@
       switch (code)
 	{
 	case FIX:
-	  if (REAL_VALUE_ISNAN (x))
+	  if (REAL_VALUE_ISNANUINF (x))
 	    return const0_rtx;
 
 	  /* Test against the signed upper bound.  */
@@ -1091,7 +1094,7 @@
 	  break;
 
 	case UNSIGNED_FIX:
-	  if (REAL_VALUE_ISNAN (x) || REAL_VALUE_NEGATIVE (x))
+	  if (REAL_VALUE_ISNANUINF (x) || REAL_VALUE_NEGATIVE (x))
 	    return const0_rtx;
 
 	  /* Test against the unsigned upper bound.  */
@@ -1438,8 +1441,10 @@
       /* Subtracting 0 has no effect unless the mode has signed zeros
 	 and supports rounding towards -infinity.  In such a case,
 	 0 - 0 is -0.  */
+      /* (TIGCC 20050210) This is invalid independently of the rounding mode
+                          for 3-sign-zeros. */
       if (!(HONOR_SIGNED_ZEROS (mode)
-	    && HONOR_SIGN_DEPENDENT_ROUNDING (mode))
+	    /*&& HONOR_SIGN_DEPENDENT_ROUNDING (mode))*/
 	  && trueop1 == CONST0_RTX (mode))
 	return op0;
 
@@ -1575,8 +1580,11 @@
 	 x is NaN, since x * 0 is then also NaN.  Nor is it valid
 	 when the mode has signed zeros, since multiplying a negative
 	 number by 0 will give -0, not 0.  */
+      /* (TIGCC 20050210) We can do this for UNSIGNED_ZERO even when honoring
+                          signed zeros.
+         Note: CONST0_RTX (BFmode) is UNSIGNED_ZERO.  */
       if (!HONOR_NANS (mode)
-	  && !HONOR_SIGNED_ZEROS (mode)
+	  /*&& !HONOR_SIGNED_ZEROS (mode)*/
 	  && trueop1 == CONST0_RTX (mode)
 	  && ! side_effects_p (op0))
 	return op1;
@@ -2155,6 +2163,7 @@
 	  || code == IOR
 	  || code == XOR)
 	{
+#if 0
 	  long tmp0[4];
 	  long tmp1[4];
 	  REAL_VALUE_TYPE r;
@@ -2182,6 +2191,30 @@
 	      }
 	    }
 	   real_from_target (&r, tmp0, mode);
+#else
+	  /* (TIGCC 20050205) Use SMAP BCD representation directly. */
+	  REAL_VALUE_TYPE *tmp1, r;
+
+	  r = *CONST_DOUBLE_REAL_VALUE (op0);
+	  tmp1 = CONST_DOUBLE_REAL_VALUE (op1);
+	  switch (code)
+	    {
+	      case AND:
+	        r.exponent &= tmp1->exponent;
+	        r.mantissa &= tmp1->mantissa;
+	        break;
+	      case IOR:
+	        r.exponent |= tmp1->exponent;
+	        r.mantissa |= tmp1->mantissa;
+	        break;
+	      case XOR:
+	        r.exponent ^= tmp1->exponent;
+	        r.mantissa ^= tmp1->mantissa;
+	        break;
+	      default:
+	        gcc_unreachable ();
+	    }
+#endif /* 0 */
 	   return CONST_DOUBLE_FROM_REAL_VALUE (r, mode);
 	}
       else
@@ -2261,7 +2294,7 @@
 	  if ((flag_rounding_math
 	       || (REAL_MODE_FORMAT_COMPOSITE_P (mode)
 		   && !flag_unsafe_math_optimizations))
-	      && (inexact || !real_identical (&result, &value)))
+	      && (inexact || !REAL_VALUES_IDENTICAL (result, value)))
 	    return NULL_RTX;
 
 	  return CONST_DOUBLE_FROM_REAL_VALUE (result, mode);
@@ -3116,7 +3149,7 @@
       REAL_VALUE_FROM_CONST_DOUBLE (d1, trueop1);
 
       /* Comparisons are unordered iff at least one of the values is NaN.  */
-      if (REAL_VALUE_ISNAN (d0) || REAL_VALUE_ISNAN (d1))
+      if (REAL_VALUE_ISNANUINF (d0) || REAL_VALUE_ISNANUINF (d1))
 	switch (code)
 	  {
 	  case UNEQ:
@@ -3639,13 +3672,14 @@
 	    }
 	  else
 	    {
-	      long tmp[max_bitsize / 32];
+	      REAL_VALUE_TYPE *tmp;
 	      int bitsize = GET_MODE_BITSIZE (GET_MODE (el));
 
 	      gcc_assert (GET_MODE_CLASS (GET_MODE (el)) == MODE_FLOAT);
 	      gcc_assert (bitsize <= elem_bitsize);
 	      gcc_assert (bitsize % value_bit == 0);
 
+#if 0
 	      real_to_target (tmp, CONST_DOUBLE_REAL_VALUE (el),
 			      GET_MODE (el));
 
@@ -3667,6 +3701,14 @@
 		 zero.  */
 	      for (; i < elem_bitsize; i += value_bit)
 		*vp++ = 0;
+#else
+	      /* (TIGCC 20050205) Use SMAP BCD representation directly. */
+	      tmp = CONST_DOUBLE_REAL_VALUE (el);
+	      *vp++ = tmp->exponent >> 8;
+	      *vp++ = tmp->exponent;
+	      for (i = 56; i >= 0; i -= 8)
+	        *vp++ = tmp->mantissa >> i;
+#endif /* 0 */
 	    }
 	  break;
 	  
@@ -3764,6 +3806,7 @@
 	case MODE_FLOAT:
 	  {
 	    REAL_VALUE_TYPE r;
+#if 0
 	    long tmp[max_bitsize / 32];
 	    
 	    /* real_from_target wants its input in words affected by
@@ -3783,6 +3826,14 @@
 	      }
 
 	    real_from_target (&r, tmp, outer_submode);
+#else
+	    /* (TIGCC 20050205) Use SMAP BCD representation directly. */
+	    r.exponent = (*vp++ << 8);
+	    r.exponent += *vp++;
+	    r.mantissa = *vp++;
+	    for (i = 0; i < 7; i++)
+	      r.mantissa = (r.mantissa << 8) + *vp++;
+#endif /* 0 */
 	    elems[elem] = CONST_DOUBLE_FROM_REAL_VALUE (r, outer_submode);
 	  }
 	  break;
diff -Naur gcc-4.1-20051216.orig/gcc/stmt.c gcc-4.1-20051216-src/gcc/stmt.c
--- gcc-4.1-20051216.orig/gcc/stmt.c	2005-08-06 13:31:49.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/stmt.c	2005-12-18 22:24:50.000000000 +0100
@@ -2484,6 +2484,9 @@
 	  use_cost_table
 	    = (TREE_CODE (orig_type) != ENUMERAL_TYPE
 	       && estimate_case_costs (case_list));
+/* (TIGCC 20030907) Don't balance the tree when optimizing for size. A linear
+                    decision tree gives far smaller code. -- Kevin Kofler  */
+	  if (!optimize_size)
 	  balance_case_nodes (&case_list, NULL);
 	  emit_case_nodes (index, case_list, default_label, index_type);
 	  emit_jump (default_label);
@@ -3048,10 +3051,17 @@
 	     does not have any children and is single valued; it would
 	     cost too much space to save so little time.  */
 
+	  /* (TIGCC 20030907) Also omit the conditional branch to default if we are
+	                      optimizing for size. -- Kevin Kofler
+         (TIGCC 20040719) But don't omit branches which are needed for
+                          correctness in case ranges. -- Kevin Kofler  */
+
 	  if (node->right->right || node->right->left
 	      || !tree_int_cst_equal (node->right->low, node->right->high))
 	    {
-	      if (!node_has_low_bound (node, index_type))
+	      if (!node_has_low_bound (node, index_type)
+	          && (!optimize_size
+	              || !tree_int_cst_equal (node->right->low, node->right->high)))
 		{
 		  emit_cmp_and_jump_insns (index,
 					   convert_modes
diff -Naur gcc-4.1-20051216.orig/gcc/system.h gcc-4.1-20051216-src/gcc/system.h
--- gcc-4.1-20051216.orig/gcc/system.h	2005-08-16 02:13:53.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/system.h	2005-12-18 22:24:50.000000000 +0100
@@ -732,7 +732,7 @@
 
 /* Hooks that are no longer used.  */
  #pragma GCC poison LANG_HOOKS_FUNCTION_MARK LANG_HOOKS_FUNCTION_FREE	\
-	LANG_HOOKS_MARK_TREE LANG_HOOKS_INSERT_DEFAULT_ATTRIBUTES \
+	LANG_HOOKS_MARK_TREE \
 	LANG_HOOKS_TREE_INLINING_ESTIMATE_NUM_INSNS \
 	LANG_HOOKS_PUSHLEVEL LANG_HOOKS_SET_BLOCK \
 	LANG_HOOKS_MAYBE_BUILD_CLEANUP LANG_HOOKS_UPDATE_DECL_AFTER_SAVING \
diff -Naur gcc-4.1-20051216.orig/gcc/toplev.c gcc-4.1-20051216-src/gcc/toplev.c
--- gcc-4.1-20051216.orig/gcc/toplev.c	2005-11-09 07:30:03.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/toplev.c	2005-12-18 22:24:50.000000000 +0100
@@ -414,6 +414,15 @@
     }
 
   src_pwd = xstrdup (pwd);
+/* (TIGCC 20050420) Eliminate duplicate backslashes. */
+#ifdef __WIN32__
+  if (strstr (src_pwd, "\\\\"))
+    {
+      char *p = (char *)src_pwd;
+      while ((p = strstr (p, "\\\\")))
+        memmove (p, p + 1, strlen (p));
+    }
+#endif
   return true;
 }
 
@@ -1759,7 +1768,7 @@
       flag_prefetch_loop_arrays = 0;
     }
 
-#ifndef OBJECT_FORMAT_ELF
+#if 0 /*ndef OBJECT_FORMAT_ELF*/ /* (TIGCC 20040619) Remove pointless warning. */
   if (flag_function_sections && write_symbols != NO_DEBUG)
     warning (0, "-ffunction-sections may affect debugging on some targets");
 #endif
diff -Naur gcc-4.1-20051216.orig/gcc/tree.c gcc-4.1-20051216-src/gcc/tree.c
--- gcc-4.1-20051216.orig/gcc/tree.c	2005-12-07 12:37:53.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree.c	2005-12-18 22:24:53.000000000 +0100
@@ -1374,7 +1374,7 @@
 
   return ((TREE_CODE (expr) == REAL_CST
 	   && ! TREE_CONSTANT_OVERFLOW (expr)
-	   && REAL_VALUES_EQUAL (TREE_REAL_CST (expr), dconst0))
+	   && REAL_VALUE_ISZERO (TREE_REAL_CST (expr)))
 	  || (TREE_CODE (expr) == COMPLEX_CST
 	      && real_zerop (TREE_REALPART (expr))
 	      && real_zerop (TREE_IMAGPART (expr))));
@@ -6604,17 +6604,14 @@
       return integer_zerop (init);
 
     case REAL_CST:
-      /* ??? Note that this is not correct for C4X float formats.  There,
-	 a bit pattern of all zeros is 1.0; 0.0 is encoded with the most
-	 negative exponent.  */
-      return real_zerop (init)
-	&& ! REAL_VALUE_MINUS_ZERO (TREE_REAL_CST (init));
+      /* (TIGCC 20050210) For AMS, all zeros is POSITIVE_ZERO. This code tried
+         to use it for both POSITIVE_ZERO and UNSIGNED_ZERO. I fixed that. */
+      return REAL_VALUES_IDENTICAL (TREE_REAL_CST (init), POSITIVE_ZERO);
 
     case COMPLEX_CST:
       return integer_zerop (init)
-	|| (real_zerop (init)
-	    && ! REAL_VALUE_MINUS_ZERO (TREE_REAL_CST (TREE_REALPART (init)))
-	    && ! REAL_VALUE_MINUS_ZERO (TREE_REAL_CST (TREE_IMAGPART (init))));
+	|| (REAL_VALUES_IDENTICAL (TREE_REAL_CST (TREE_REALPART (init)), POSITIVE_ZERO)
+	    && REAL_VALUES_IDENTICAL (TREE_REAL_CST (TREE_IMAGPART (init)), POSITIVE_ZERO));
 
     case VECTOR_CST:
       for (elt = TREE_VECTOR_CST_ELTS (init); elt; elt = TREE_CHAIN (elt))
diff -Naur gcc-4.1-20051216.orig/gcc/tree.h gcc-4.1-20051216-src/gcc/tree.h
--- gcc-4.1-20051216.orig/gcc/tree.h	2005-11-09 21:13:41.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree.h	2005-12-19 00:22:07.000000000 +0100
@@ -3477,6 +3477,7 @@
 /* Return an expr equal to X but certainly not valid as an lvalue.  */
 
 extern tree non_lvalue (tree);
+extern tree pedantic_non_lvalue (tree);
 
 extern tree convert (tree, tree);
 extern unsigned int expr_align (tree);
diff -Naur gcc-4.1-20051216.orig/gcc/tree-inline.c gcc-4.1-20051216-src/gcc/tree-inline.c
--- gcc-4.1-20051216.orig/gcc/tree-inline.c	2005-10-31 15:05:12.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree-inline.c	2005-12-19 01:15:28.000000000 +0100
@@ -2044,6 +2044,48 @@
     verify_cgraph_node (cg_edge->callee);
 #endif
 
+  /* (TIGCC 20040926) The following code by Eric Botcazou fixes an ICE when
+     inlining tries to change the mode of parameters or the return value. Eric
+     Botcazou's comments explain the details.  -- Kevin Kofler  */
+  /* We can't inline functions at a calling point where they are viewed
+     with too different a prototype than the actual one, because the
+     calling convention may not be the same on both sides.  */
+  if (TREE_CODE (TREE_OPERAND (t, 0)) == NOP_EXPR)
+    {
+      tree from_ftype = TREE_TYPE (TREE_TYPE (TREE_OPERAND (t, 0)));
+      tree to_ftype = TREE_TYPE (fn);
+
+      if (from_ftype != to_ftype)
+	{
+	  tree from_arg, to_arg;
+
+	  /* If the calling point expects a return value and it is too
+	     different from the one actually returned, don't inline.  */
+	  if (! VOID_TYPE_P (TREE_TYPE (from_ftype))
+	      && TYPE_MODE (TREE_TYPE (from_ftype))
+		 != TYPE_MODE (TREE_TYPE (to_ftype)))
+	    goto egress;
+
+	  /* If the calling point doesn't pass at least the correct
+	     number of arguments with the correct modes, don't inline.
+	     Objective-C appears to add a trailing void parameter at
+	     the calling point under certain circumstances.  */
+	  from_arg = TYPE_ARG_TYPES (from_ftype);
+	  to_arg = TYPE_ARG_TYPES (to_ftype);
+
+	  while (to_arg)
+	    {
+	      if (! from_arg
+		  || TYPE_MODE (TREE_VALUE (from_arg))
+		     != TYPE_MODE (TREE_VALUE (to_arg)))
+		goto egress;
+
+	      from_arg = TREE_CHAIN (from_arg);
+	      to_arg = TREE_CHAIN (to_arg);
+	    }
+	}
+    }
+
   /* We will be inlining this callee.  */
 
   id->eh_region = lookup_stmt_eh_region (stmt);
diff -Naur gcc-4.1-20051216.orig/gcc/tree-pretty-print.c gcc-4.1-20051216-src/gcc/tree-pretty-print.c
--- gcc-4.1-20051216.orig/gcc/tree-pretty-print.c	2005-07-31 22:55:41.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/tree-pretty-print.c	2005-12-18 22:24:53.000000000 +0100
@@ -608,7 +608,7 @@
 	else
 	  {
 	    char string[100];
-	    real_to_decimal (string, &d, sizeof (string), 0, 1);
+	    REAL_VALUE_TO_STRING (d, string);
 	    pp_string (buffer, string);
 	  }
 #else
diff -Naur gcc-4.1-20051216.orig/gcc/tree-ssa-ccp.c gcc-4.1-20051216-src/gcc/tree-ssa-ccp.c
--- gcc-4.1-20051216.orig/gcc/tree-ssa-ccp.c	2005-11-22 17:56:48.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree-ssa-ccp.c	2005-12-19 01:18:23.000000000 +0100
@@ -2123,6 +2123,7 @@
 static tree
 ccp_fold_builtin (tree stmt, tree fn)
 {
+#if 0 /* (TIGCC 20050205) */
   tree result, val[3];
   tree callee, arglist, a;
   int arg_mask, i, type;
@@ -2278,6 +2279,9 @@
   if (result && ignore)
     result = fold_ignored_result (result);
   return result;
+#else
+  return NULL_TREE;
+#endif /* 0 */
 }
 
 
diff -Naur gcc-4.1-20051216.orig/gcc/tree-ssa-dom.c gcc-4.1-20051216-src/gcc/tree-ssa-dom.c
--- gcc-4.1-20051216.orig/gcc/tree-ssa-dom.c	2005-11-18 14:32:05.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/tree-ssa-dom.c	2005-12-18 22:24:53.000000000 +0100
@@ -2978,6 +2978,19 @@
 			|| TREE_CODE (stmt) == COND_EXPR
 			|| TREE_CODE (stmt) == SWITCH_EXPR));
 
+  /* (TIGCC 20050206) If -fno-function-cse, keep function call sequences in
+                      their expected form. */
+  if (flag_no_function_cse && may_optimize_p && TREE_CODE (stmt) == MODIFY_EXPR)
+    {
+      block_stmt_iterator bsi2 = si;
+      bsi_next (&bsi2);
+      if (!bsi_end_p (bsi2))
+        {
+          tree call = get_call_expr_in (bsi_stmt (bsi2));
+          if (call && TREE_OPERAND (stmt, 0) == TREE_OPERAND (call, 0)) may_optimize_p = false;
+        }
+    }
+
   if (may_optimize_p)
     may_have_exposed_new_symbols
       |= eliminate_redundant_computations (stmt, ann);
diff -Naur gcc-4.1-20051216.orig/gcc/tree-ssa-pre.c gcc-4.1-20051216-src/gcc/tree-ssa-pre.c
--- gcc-4.1-20051216.orig/gcc/tree-ssa-pre.c	2005-10-19 05:34:50.000000000 +0200
+++ gcc-4.1-20051216-src/gcc/tree-ssa-pre.c	2005-12-18 22:24:53.000000000 +0100
@@ -2394,6 +2394,19 @@
 	      tree *rhs_p = &TREE_OPERAND (stmt, 1);
 	      tree sprime;
 
+	      /* (TIGCC 20050216) If -fno-function-cse, keep function call sequences in
+	                          their expected form. */
+	      if (flag_no_function_cse)
+	        {
+	          block_stmt_iterator bsi2 = i;
+	          bsi_next (&bsi2);
+	          if (!bsi_end_p (bsi2))
+	            {
+	              tree call = get_call_expr_in (bsi_stmt (bsi2));
+	              if (call && TREE_OPERAND (stmt, 0) == TREE_OPERAND (call, 0)) continue;
+	            }
+	        }
+
 	      sprime = bitmap_find_leader (AVAIL_OUT (b),
 					   vn_lookup (lhs, NULL));
 	      if (sprime 
diff -Naur gcc-4.1-20051216.orig/gcc/varasm.c gcc-4.1-20051216-src/gcc/varasm.c
--- gcc-4.1-20051216.orig/gcc/varasm.c	2005-12-15 23:33:44.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/varasm.c	2005-12-19 01:24:34.000000000 +0100
@@ -681,6 +681,26 @@
 			  unsigned HOST_WIDE_INT align ATTRIBUTE_UNUSED,
 			  unsigned int flags ATTRIBUTE_UNUSED)
 {
+/* (TIGCC 20040725) Implement string merging for TIGCC-extended COFF.
+                    We only handle 2 cases: aligned or unaligned.
+                    SECTION_STRINGS is abused for the unaligned flag. */
+  if (flag_merge_constants
+      && TREE_CODE (decl) == STRING_CST
+      && TREE_CODE (TREE_TYPE (decl)) == ARRAY_TYPE)
+    {
+      if (align == 8)
+        {
+          named_section_flags (".rodata.__unalignedstr", flags | SECTION_MERGE | SECTION_STRINGS);
+          return;
+        }
+      else if (align == 16)
+        {
+          named_section_flags (".rodata.__alignedstr", flags | SECTION_MERGE);
+          return;
+        }
+    }
+
+#if 0
   if (HAVE_GAS_SHF_MERGE && flag_merge_constants
       && TREE_CODE (decl) == STRING_CST
       && TREE_CODE (TREE_TYPE (decl)) == ARRAY_TYPE
@@ -743,6 +763,7 @@
 	    }
 	}
     }
+#endif
 
   readonly_data_section ();
 }
@@ -754,6 +775,25 @@
 			    unsigned HOST_WIDE_INT align ATTRIBUTE_UNUSED,
 			    unsigned int flags ATTRIBUTE_UNUSED)
 {
+/* (TIGCC 20040725) Implement constant merging for TIGCC-extended COFF.
+                    We only handle 2 cases: aligned or unaligned.
+                    SECTION_STRINGS is abused for the unaligned flag. */
+  if (flag_merge_constants
+      && mode != VOIDmode)
+    {
+      if (align == 8)
+        {
+          named_section_flags (".rodata.__unalignedcst", flags | SECTION_MERGE | SECTION_STRINGS);
+          return;
+        }
+      else if (align == 16)
+        {
+          named_section_flags (".rodata.__alignedcst", flags | SECTION_MERGE);
+          return;
+        }
+    }
+
+#if 0
   unsigned int modesize = GET_MODE_BITSIZE (mode);
 
   if (HAVE_GAS_SHF_MERGE && flag_merge_constants
@@ -771,6 +811,7 @@
       named_section_flags (name, flags);
       return;
     }
+#endif
 
   readonly_data_section ();
 }
@@ -1048,12 +1089,25 @@
 void
 assemble_asm (tree string)
 {
+  /* (TIGCC 20050424) Emit proper .loc directives for top-level asm statements,
+     so GNU as won't try to make up its own and cause conflicts. */
+  if (debug_hooks == &dwarf2_debug_hooks)
+    (*debug_hooks->source_line) (input_location.line, input_location.file);
+
+  /* (TIGCC 20050424) Now switch to the text section, so the asm won't end up in
+                      some unknown section. */
+  text_section ();
+
   app_enable ();
 
   if (TREE_CODE (string) == ADDR_EXPR)
     string = TREE_OPERAND (string, 0);
 
   fprintf (asm_out_file, "\t%s\n", TREE_STRING_POINTER (string));
+
+  /* (TIGCC 20050424) And now forget the section we've set. There's no telling
+                      what section the asm switched to. */
+  in_section = no_section;
 }
 
 /* Record an element in the table of global destructors.  SYMBOL is
@@ -1533,9 +1587,18 @@
 	destination = asm_dest_common;
     }
 
-  if (destination != asm_dest_common)
+  /* (TIGCC 20050517) See below for why the TARGET_NO_BSS is necessary here. */
+  if (destination != asm_dest_common || (flag_data_sections && TARGET_NO_BSS))
     {
-      resolve_unique_section (decl, 0, flag_data_sections);
+      /* (TIGCC 20040620) Common symbols are handled by our linker as separate
+         sections, so there is no point in manually creating separate BSS sections
+         under -fdata-sections. The TARGET_NO_BSS check here is a hack (it should
+         not be in supposedly target-independent code), but it is necessary because
+         -mno-bss would otherwise compact everything into a single huge section.
+                                                              -- Kevin Kofler */
+      resolve_unique_section (decl, 0, flag_data_sections
+                                       && ((destination == asm_dest_bss)
+                                           || TARGET_NO_BSS));
       /* Custom sections don't belong here.  */
       if (DECL_SECTION_NAME (decl))
         return false;
@@ -1786,7 +1849,24 @@
     }
 
   /* Switch to the appropriate section.  */
-  resolve_unique_section (decl, reloc, flag_data_sections);
+  /* (TIGCC 20040620) See the note about common symbols above. -- Kevin Kofler */
+  /* (TIGCC 20050206) And always emit mergeable constructors into their own
+                      sections so the linker can merge them, as GCC fails to do
+                      it on its own. */
+  resolve_unique_section (decl, reloc, (flag_data_sections
+                                        && (!((!TREE_PUBLIC(decl) || DECL_COMMON(decl))
+                                              && (DECL_INITIAL (decl) == 0
+                                                  || DECL_INITIAL (decl) == error_mark_node
+                                                  || (flag_zero_initialized_in_bss
+                                                      && !TREE_READONLY (decl)
+                                                      && initializer_zerop (DECL_INITIAL (decl)))))
+                                            || TARGET_NO_BSS))
+                                       || (DECL_INITIAL (decl)
+                                           && TREE_CODE (DECL_INITIAL (decl)) == CONSTRUCTOR
+                                           && (! (reloc
+                                                  || (!TREE_READONLY (decl))
+                                                  || TREE_SIDE_EFFECTS (decl)
+                                                  || !TREE_CONSTANT (DECL_INITIAL (decl))))));
   variable_section (decl, reloc);
 
   /* dbxout.c needs to know this.  */
@@ -2277,7 +2357,16 @@
 void
 assemble_real (REAL_VALUE_TYPE d, enum machine_mode mode, unsigned int align)
 {
-  long data[4];
+  long data[3];
+  unsigned int nalign = min_align (align, 16);
+
+  /* This is how to output a SMAP BCD real constant. */
+  REAL_VALUE_TO_TARGET_SMAP_BCD (d, data);
+  assemble_integer (GEN_INT (data[0]), 2, align, 1);
+  assemble_integer (GEN_INT (data[1]), 4, nalign, 1);
+  assemble_integer (GEN_INT (data[2]), 4, nalign, 1);
+
+#if 0
   int i;
   int bitsize, nelts, nunits, units_per;
 
@@ -2312,6 +2401,7 @@
       assemble_integer (GEN_INT (data[i]), MIN (nunits, units_per), align, 1);
       nunits -= units_per;
     }
+#endif /* 0 */
 }
 
 /* Given an expression EXP with a constant value,
@@ -3307,7 +3397,7 @@
 /* Worker function for output_constant_pool.  Emit POOL.  */
 
 static void
-output_constant_pool_1 (struct constant_descriptor_rtx *desc)
+output_constant_pool_1 (const char *fnname, struct constant_descriptor_rtx *desc)
 {
   rtx x, tmp;
 
@@ -3346,8 +3436,19 @@
     }
 
   /* First switch to correct section.  */
-  targetm.asm_out.select_rtx_section (desc->mode, x, desc->align);
+  if (flag_merge_constants && flag_merge_constant_pools)
+    {
+      /* (TIGCC 20040727) If we want to merge constant pools, we need to
+                          create a separate section for each constant pool.
+                          -- Kevin Kofler  */
+      char name[strlen(fnname)+15];
 
+      sprintf (name, ".rodata.%s.cpool", fnname);
+      named_section_flags (name, SECTION_MERGE);
+    }
+  else
+     targetm.asm_out.select_rtx_section (desc->mode, x, desc->align);
+ 
 #ifdef ASM_OUTPUT_SPECIAL_POOL_ENTRY
   ASM_OUTPUT_SPECIAL_POOL_ENTRY (asm_out_file, x, desc->mode,
 				 desc->align, desc->labelno, done);
@@ -3462,7 +3563,7 @@
 /* Write all the constants in the constant pool.  */
 
 void
-output_constant_pool (const char *fnname ATTRIBUTE_UNUSED,
+output_constant_pool (const char *fnname,
 		      tree fndecl ATTRIBUTE_UNUSED)
 {
   struct rtx_constant_pool *pool = cfun->varasm->pool;
@@ -3478,7 +3579,7 @@
 #endif
 
   for (desc = pool->first; desc ; desc = desc->next)
-    output_constant_pool_1 (desc);
+    output_constant_pool_1 (fnname, desc);
 
 #ifdef ASM_OUTPUT_POOL_EPILOGUE
   ASM_OUTPUT_POOL_EPILOGUE (asm_out_file, fnname, fndecl, pool->offset);
@@ -3522,10 +3623,18 @@
     case MINUS_EXPR:
       reloc = compute_reloc_for_constant (TREE_OPERAND (exp, 0));
       reloc2 = compute_reloc_for_constant (TREE_OPERAND (exp, 1));
+#if 0
       /* The difference of two local labels is computable at link time.  */
+      /* (TIGCC 20040808) That's true, but it is still not valid in a mergeable
+         section. GCC doesn't seem to accept that as a constant anyway (at least
+         in C), but it is never a good idea to let a latent problem just lie
+         around. And besides, this code is unsafe, consider (addr1+addr2)-addr3.
+         Still a potentially valid expression for the assembler and linker, but
+         mishandled awfully by this code. -- Kevin Kofler  */
       if (reloc == 1 && reloc2 == 1)
 	reloc = 0;
       else
+#endif /* 0 */
 	reloc |= reloc2;
       break;
 
@@ -5110,6 +5219,31 @@
 	  || strcmp (name, ".preinit_array") == 0))
     flags |= SECTION_NOTYPE;
 
+/* (TIGCC 20040725) This was mostly copied out of the ELF section selector. It
+                    handles mergeable sections. -- Kevin Kofler */
+  switch (categorize_decl_for_section (decl, reloc, shlib))
+    {
+    case SECCAT_RODATA_MERGE_STR:
+    case SECCAT_RODATA_MERGE_STR_INIT:
+    case SECCAT_RODATA_MERGE_CONST:
+      flags |= SECTION_MERGE;
+      break;
+    default:
+      break;
+    }
+
+  if (DECL_INITIAL (decl) && TREE_CODE (DECL_INITIAL (decl)) == CONSTRUCTOR)
+    {
+      /* (TIGCC 20040727) Put compound literals in mergeable sections in global
+                          compound literal mode. -- Kevin Kofler
+         (TIGCC 20040808) But not if they contain relocations. -- Kevin Kofler */
+      if (! (reloc
+             || (!TREE_READONLY (decl))
+             || TREE_SIDE_EFFECTS (decl)
+             || !TREE_CONSTANT (DECL_INITIAL (decl))))
+          flags |= SECTION_MERGE;
+    }
+
   return flags;
 }
 
@@ -5231,18 +5365,51 @@
 {
   bool readonly = false;
 
+/* (TIGCC 20040725) This was copied out of the ELF section selector. It handles
+                    mergeable sections. -- Kevin Kofler */
+  switch (categorize_decl_for_section (decl, reloc, flag_pic))
+    {
+    case SECCAT_RODATA_MERGE_STR:
+      mergeable_string_section (decl, align, 0);
+      break;
+    case SECCAT_RODATA_MERGE_STR_INIT:
+      mergeable_string_section (DECL_INITIAL (decl), align, 0);
+      break;
+    case SECCAT_RODATA_MERGE_CONST:
+      mergeable_constant_section (DECL_MODE (decl), align, 0);
+      break;
+    default:
+
   if (DECL_P (decl))
     {
+#if 0
+/* (TIGCC 20050206) This doesn't work very well because GCC doesn't merge
+                    the compound literals properly. So I emit them into
+                    individual mergeable sections instead. */
+      if (TREE_CODE (DECL_INITIAL (decl)) == CONSTRUCTOR)
+        {
+          /* (TIGCC 20040727) Put compound literals in mergeable sections in global
+                              compound literal mode. -- Kevin Kofler
+             (TIGCC 20040808) But not if they contain relocations. -- Kevin Kofler */
+          if (! (reloc
+                 || (!TREE_READONLY (decl))
+                 || TREE_SIDE_EFFECTS (decl)
+                 || !TREE_CONSTANT (DECL_INITIAL (decl))))
+            {
+              mergeable_constant_section (DECL_MODE (decl), align, 0);
+              break;
+            }
+        }
+#endif /* 0 */
       if (decl_readonly_section (decl, reloc))
 	readonly = true;
     }
-  else if (TREE_CODE (decl) == CONSTRUCTOR)
+  /* (TIGCC 20040727) Put complex literals in mergeable sections.
+                      -- Kevin Kofler */
+  else if (TREE_CODE (decl) == COMPLEX_CST)
     {
-      if (! ((flag_pic && reloc)
-	     || !TREE_READONLY (decl)
-	     || TREE_SIDE_EFFECTS (decl)
-	     || !TREE_CONSTANT (decl)))
-	readonly = true;
+      mergeable_constant_section (DECL_MODE (decl), align, 0);
+      break;
     }
   else if (TREE_CODE (decl) == STRING_CST)
     readonly = true;
@@ -5253,6 +5420,7 @@
     readonly_data_section ();
   else
     data_section ();
+  } /* end of switch-case */
 }
 
 enum section_category
diff -Naur gcc-4.1-20051216.orig/gcc/version.c gcc-4.1-20051216-src/gcc/version.c
--- gcc-4.1-20051216.orig/gcc/version.c	2005-03-16 07:04:10.000000000 +0100
+++ gcc-4.1-20051216-src/gcc/version.c	2005-12-19 01:29:14.000000000 +0100
@@ -8,7 +8,7 @@
    in parentheses.  You may also wish to include a number indicating
    the revision of your modified compiler.  */
 
-#define VERSUFFIX ""
+#define VERSUFFIX "(TIGCC)"
 
 /* This is the location of the online document giving instructions for
    reporting bugs.  If you distribute a modified version of GCC,
@@ -17,7 +17,7 @@
    forward us bugs reported to you, if you determine that they are
    not bugs in your modifications.)  */
 
-const char bug_report_url[] = "<URL:http://gcc.gnu.org/bugs.html>";
+const char bug_report_url[] = "http://tigcc.ticalc.org/";
 
 /* The complete version string, assembled from several pieces.
    BASEVER, DATESTAMP, and DEVPHASE are defined by the Makefile.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/directives.c gcc-4.1-20051216-src/libcpp/directives.c
--- gcc-4.1-20051216.orig/libcpp/directives.c	2005-10-04 20:06:19.000000000 +0200
+++ gcc-4.1-20051216-src/libcpp/directives.c	2005-12-18 22:24:57.000000000 +0100
@@ -1138,6 +1138,7 @@
 _cpp_init_internal_pragmas (cpp_reader *pfile)
 {
   /* Pragmas in the global namespace.  */
+  register_pragma (pfile, 0, "poison", do_pragma_poison, false, true); /* (TIGCC) */
   register_pragma (pfile, 0, "once", do_pragma_once, false, true);
 
   /* New GCC-specific pragmas should be put in the GCC namespace.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/expr.c gcc-4.1-20051216-src/libcpp/expr.c
--- gcc-4.1-20051216.orig/libcpp/expr.c	2005-06-29 04:34:39.000000000 +0200
+++ gcc-4.1-20051216-src/libcpp/expr.c	2005-12-18 22:24:57.000000000 +0100
@@ -171,6 +171,13 @@
 	  radix = 16;
 	  str++;
 	}
+      /* Require at least one binary digit to classify it as binary.  */
+      else if ((*str == 'b' || *str == 'B') && (str[1]=='0' || str[1]=='1'))
+	{
+	  radix = 2;
+	  str++;
+	}
+
     }
 
   /* Now scan for a well-formed integer or float.  */
@@ -205,11 +212,15 @@
 	}
     }
 
-  if (float_flag != NOT_FLOAT && radix == 8)
+  if ((float_flag != NOT_FLOAT || CPP_OPTION(pfile,no_auto_octals)) && radix == 8)
     radix = 10;
 
-  if (max_digit >= radix)
-    SYNTAX_ERROR2 ("invalid digit \"%c\" in octal constant", '0' + max_digit);
+  if (max_digit >= radix) {
+    if (radix == 2)
+      SYNTAX_ERROR2 ("invalid digit \"%c\" in binary constant", '0' + max_digit);
+    else
+      SYNTAX_ERROR2 ("invalid digit \"%c\" in octal constant", '0' + max_digit);
+  }
 
   if (float_flag != NOT_FLOAT)
     {
@@ -293,6 +304,12 @@
     result |= CPP_N_DECIMAL;
   else if (radix == 16)
     result |= CPP_N_HEX;
+  else if (radix == 2)
+    {
+      if (CPP_PEDANTIC (pfile))
+        cpp_error(pfile, CPP_DL_PEDWARN, "binary constants are a TIGCC extension");
+      result |= CPP_N_BINARY;
+    }
   else
     result |= CPP_N_OCTAL;
 
@@ -343,6 +360,11 @@
 	  base = 16;
 	  p += 2;
 	}
+      else if ((type & CPP_N_RADIX) == CPP_N_BINARY)
+	{
+	  base = 2;
+	  p += 2;
+	}
 
       /* We can add a digit to numbers strictly less than this without
 	 needing the precision and slowness of double integers.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/files.c gcc-4.1-20051216-src/libcpp/files.c
--- gcc-4.1-20051216.orig/libcpp/files.c	2005-11-04 03:10:19.000000000 +0100
+++ gcc-4.1-20051216-src/libcpp/files.c	2005-12-18 22:24:57.000000000 +0100
@@ -48,6 +48,11 @@
 #  define set_stdin_to_binary_mode() /* Nothing */
 #endif
 
+/* (TIGCC 20050205) FIXME: This should be handled by configure... */
+#ifdef _WIN32
+#define ssize_t int
+#endif
+
 /* This structure represents a file searched for by CPP, whether it
    exists or not.  An instance may be pointed to by more than one
    file_hash_entry; at present no reference count is kept.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/include/cpplib.h gcc-4.1-20051216-src/libcpp/include/cpplib.h
--- gcc-4.1-20051216.orig/libcpp/include/cpplib.h	2005-11-14 17:28:55.000000000 +0100
+++ gcc-4.1-20051216-src/libcpp/include/cpplib.h	2005-12-18 22:24:57.000000000 +0100
@@ -399,6 +399,9 @@
   /* True if dependencies should be restored from a precompiled header.  */
   bool restore_pch_deps;
 
+  /* (TIGCC) True if numbers starting with zero should NOT be octal. */
+  unsigned char no_auto_octals;
+
   /* Dependency generation.  */
   struct
   {
@@ -740,6 +743,7 @@
 #define CPP_N_DECIMAL	0x0100
 #define CPP_N_HEX	0x0200
 #define CPP_N_OCTAL	0x0400
+#define CPP_N_BINARY	0x0800
 
 #define CPP_N_UNSIGNED	0x1000	/* Properties.  */
 #define CPP_N_IMAGINARY	0x2000
@@ -803,6 +807,7 @@
    string literal.  Handles all relevant diagnostics.  */
 extern cppchar_t cpp_parse_escape (cpp_reader *, const unsigned char ** pstr,
 				   const unsigned char *limit, int wide);
+extern void cpp_unterminated (cpp_reader *, int);
 
 /* In cpphash.c */
 
diff -Naur gcc-4.1-20051216.orig/libcpp/init.c gcc-4.1-20051216-src/libcpp/init.c
--- gcc-4.1-20051216.orig/libcpp/init.c	2005-11-09 07:30:03.000000000 +0100
+++ gcc-4.1-20051216-src/libcpp/init.c	2005-12-19 00:14:12.000000000 +0100
@@ -160,6 +160,7 @@
   CPP_OPTION (pfile, warn_dollars) = 1;
   CPP_OPTION (pfile, warn_variadic_macros) = 1;
   CPP_OPTION (pfile, warn_normalize) = normalized_C;
+  CPP_OPTION (pfile, no_auto_octals) = 0; /* (TIGCC) */
 
   /* Default CPP arithmetic to something sensible for the host for the
      benefit of dumb users like fix-header.  */
diff -Naur gcc-4.1-20051216.orig/libcpp/internal.h gcc-4.1-20051216-src/libcpp/internal.h
--- gcc-4.1-20051216.orig/libcpp/internal.h	2005-10-21 19:54:20.000000000 +0200
+++ gcc-4.1-20051216-src/libcpp/internal.h	2005-12-18 22:24:57.000000000 +0100
@@ -372,6 +372,11 @@
   /* Error counter for exit code.  */
   unsigned int errors;
 
+  /* Line and column where a newline was first seen in a string
+     constant (multi-line strings).  */
+  source_location mls_line;
+  unsigned int mls_col;
+
   /* Buffer to hold macro definition string.  */
   unsigned char *macro_buffer;
   unsigned int macro_buffer_len;
diff -Naur gcc-4.1-20051216.orig/libcpp/lex.c gcc-4.1-20051216-src/libcpp/lex.c
--- gcc-4.1-20051216.orig/libcpp/lex.c	2005-09-20 22:31:37.000000000 +0200
+++ gcc-4.1-20051216-src/libcpp/lex.c	2005-12-18 22:24:57.000000000 +0100
@@ -212,7 +212,11 @@
     }
 
  done:
-  *d = '\n';
+  /* (TIGCC 20050212) Don't convert \r to \n, switch them instead. */
+  if (*d=='\r' && d[1]=='\n')
+    {*d='\n'; d[1]='\r';}
+  else
+    *d = '\n';
   /* A sentinel note that should never be processed.  */
   add_line_note (buffer, d + 1, '\n');
   buffer->next_line = s + 1;
@@ -588,10 +592,19 @@
 create_literal (cpp_reader *pfile, cpp_token *token, const uchar *base,
 		unsigned int len, enum cpp_ttype type)
 {
+  char *p;
   uchar *dest = _cpp_unaligned_alloc (pfile, len + 1);
 
   memcpy (dest, base, len);
   dest[len] = '\0';
+  /* (TIGCC 20050206) Delete \r characters in multi-line strings. */
+  p = (char *)dest;
+  while (p < (char *)dest + len) {
+    if (*p == '\r') {
+      memmove (p, p + 1, (char *)dest + len - p);
+      len--;
+    } else p++;
+  }
   token->type = type;
   token->val.str.len = len;
   token->val.str.text = dest;
@@ -603,7 +616,10 @@
    literal, or CPP_OTHER if it was not properly terminated.
 
    The spelling is NUL-terminated, but it is not guaranteed that this
-   is the first NUL since embedded NULs are preserved.  */
+   is the first NUL since embedded NULs are preserved.
+
+   Multi-line strings are allowed as a TIGCC extension (removed in the FSF GCC
+   since version 3.3).  */
 static void
 lex_string (cpp_reader *pfile, cpp_token *token, const uchar *base)
 {
@@ -611,7 +627,11 @@
   const uchar *cur;
   cppchar_t terminator;
   enum cpp_ttype type;
+  cpp_buffer *buffer;
+  unsigned int startcol;
 
+  buffer = pfile->buffer;
+  startcol = CPP_BUF_COL (buffer);
   cur = base;
   terminator = *cur++;
   if (terminator == 'L')
@@ -634,9 +654,50 @@
 	break;
       else if (c == '\n')
 	{
-	  cur--;
-	  type = CPP_OTHER;
-	  break;
+	  unsigned int cols;
+
+	  /* In assembly language, silently terminate string and
+	     character literals at end of line.  This is a kludge
+	     around not knowing where comments are.  */
+	  if (CPP_OPTION (pfile, lang) == CLK_ASM && terminator != '>')
+	    {
+	      cur--;
+	      break;
+	    }
+
+	  /* Character constants and header names may not extend over
+	     multiple lines.  In Standard C, neither may strings.
+	     In TIGCC, we accept multiline strings as an
+	     extension, except in #include family directives.  */
+	  if (terminator != '"' || pfile->state.angled_headers)
+	    {
+	      cur--;
+	      type = CPP_OTHER;
+	      break;
+	    }
+
+	  if (CPP_PEDANTIC (pfile))
+	    cpp_error(pfile, CPP_DL_PEDWARN, "ISO C forbids newline in string literal");
+	  buffer->cur = cur - 1;
+	  _cpp_process_line_notes (pfile, true);
+	  if (buffer->next_line >= buffer->rlimit)
+	    {
+	      cur--;
+	      type = CPP_OTHER;
+	      break;
+	    }
+	  _cpp_clean_line (pfile);
+
+	  cols = buffer->next_line - buffer->line_base;
+	  CPP_INCREMENT_LINE (pfile, cols);
+
+	  cur = buffer->cur;
+
+	  if (pfile->mls_line == 0)
+	    {
+	      pfile->mls_line = token->src_loc;
+	      pfile->mls_col = startcol;
+	    }
 	}
       else if (c == '\0')
 	saw_NUL = true;
@@ -1703,3 +1764,18 @@
       return CPP_TOKEN_FLD_NONE;
     }
 }
+
+/* Emits error for unterminated strings.  */
+void
+cpp_unterminated (cpp_reader *pfile, int term)
+{
+  cpp_error (pfile, CPP_DL_ERROR, "missing terminating %c character", term);
+
+  if (term == '\"' && pfile->mls_line && pfile->mls_line != pfile->line_table->highest_line)
+    {
+      cpp_error_with_line (pfile, CPP_DL_ERROR, pfile->mls_line, pfile->mls_col,
+			   "possible start of unterminated string literal");
+      pfile->mls_line = 0;
+    }
+}
+
diff -Naur gcc-4.1-20051216.orig/libcpp/macro.c gcc-4.1-20051216-src/libcpp/macro.c
--- gcc-4.1-20051216.orig/libcpp/macro.c	2005-11-04 01:23:01.000000000 +0100
+++ gcc-4.1-20051216-src/libcpp/macro.c	2005-12-18 22:24:57.000000000 +0100
@@ -772,6 +772,11 @@
   macro_arg *arg;
   _cpp_buff *buff;
 
+  /* (TIGCC) If 'SYMSTR' is used with a string literal, it should be
+             converted automatically to 'SYMSTR_CONST'.  */
+  cpp_hashnode *orig_node=node; /* save the original node in case we change it */
+  symstr_const: /* start again from here after changing SYMSTR to SYMSTR_CONST */
+
   /* First, fully macro-expand arguments, calculating the number of
      tokens in the final expansion as we go.  The ordering of the if
      statements below is subtle; we must handle stringification before
@@ -805,6 +810,33 @@
 	  }
       }
 
+  if (!ustrcmp (node->ident.str, U"SYMSTR"))
+  {
+    /* Accept one or more literal strings. If there are multiple ones, they
+       concatenate. Ignore any padding.
+       Refuse any other argument type. */
+    unsigned int i;
+    cpp_hashnode *newnode;
+
+    for (i=0;i<args->expanded_count;i++)
+    {
+      if ((args->expanded[i]->type != CPP_STRING)
+          && (args->expanded[i]->type != CPP_PADDING)) goto notconststring;
+    }
+
+    /* Change the macro to SYMSTR_CONST, if it is defined. */
+    newnode = cpp_lookup (pfile, U"SYMSTR_CONST",
+                          sizeof ("SYMSTR_CONST") - 1);
+    if (newnode->type == NT_MACRO) {
+      node = newnode;
+      macro = node->value.macro;
+      goto symstr_const; /* Start over from the beginning. */
+    }
+
+    notconststring:;
+  }
+  /* (END TIGCC) */
+
   /* Now allocate space for the expansion, copy the tokens and replace
      the arguments.  */
   buff = _cpp_get_buff (pfile, total * sizeof (cpp_token *));
@@ -891,7 +923,10 @@
     if (args[i].expanded)
       free (args[i].expanded);
 
-  push_ptoken_context (pfile, node, buff, first, dest - first);
+  push_ptoken_context (pfile, orig_node, buff, first, dest - first);
+  /* (TIGCC) Always use the ORIGINAL node here, not the modified one. Doing
+             otherwise would make subsequent expansions of SYMSTR fail after
+             the first conversion to SYMSTR_CONST. */
 }
 
 /* Return a special padding token, with padding inherited from SOURCE.  */
